{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 4\n",
    "\n",
    "weight = 1.03\n",
    "lr = 4e-3\n",
    "sub = 0.0005\n",
    "limit = 0.02\n",
    "\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 242, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\":256, \"out_channels\": 256, \"use_bn\":  True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers141\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\":  True, \"drop_rate\": 0.05}\n",
    "# h_hyper_prmts[\"convlayers142\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers143\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "\n",
    "\n",
    "\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":64, \"out_channels\":4, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12704, 242)"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/primary\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=242, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (9): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut():\n",
    "    hgnn_trainer.eval()\n",
    "    outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "    outs_straight = StraightThroughEstimator.apply(outs)\n",
    "    G_clone = G.clone()\n",
    "    edges, _  = G_clone.e\n",
    "    cut = 0\n",
    "    for vertices in edges:\n",
    "        if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "            cut += 1\n",
    "        else:\n",
    "            G_clone.remove_hyperedges(vertices)\n",
    "    assert cut == G_clone.num_e\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 10 epoch, average loss: -3732.409375\n",
      "                , loss1: -3727.80703125\n",
      "                , loss2: 94.10326538085937\n",
      "                , weight: 1.0250000000000006\n",
      "=================================\n",
      "in 20 epoch, average loss: -7852.52265625\n",
      "                , loss1: -7803.2453125\n",
      "                , loss2: 123.53260498046875\n",
      "                , weight: 1.0200000000000011\n",
      "=================================\n",
      "in 30 epoch, average loss: -8738.0234375\n",
      "                , loss1: -8724.16875\n",
      "                , loss2: 136.5334228515625\n",
      "                , weight: 1.0150000000000017\n",
      "=================================\n",
      "in 40 epoch, average loss: -8804.71328125\n",
      "                , loss1: -8836.86953125\n",
      "                , loss2: 140.38841552734374\n",
      "                , weight: 1.0100000000000022\n",
      "=================================\n",
      "in 50 epoch, average loss: -8784.24140625\n",
      "                , loss1: -8860.959375\n",
      "                , loss2: 140.95411376953126\n",
      "                , weight: 1.0050000000000028\n",
      "=================================\n",
      "in 60 epoch, average loss: -8746.99609375\n",
      "                , loss1: -8868.284375\n",
      "                , loss2: 141.24066162109375\n",
      "                , weight: 1.0000000000000033\n",
      "=================================\n",
      "in 70 epoch, average loss: -8706.0375\n",
      "                , loss1: -8871.76484375\n",
      "                , loss2: 141.3288818359375\n",
      "                , weight: 0.9950000000000039\n",
      "=================================\n",
      "in 80 epoch, average loss: -8662.9796875\n",
      "                , loss1: -8873.125\n",
      "                , loss2: 141.37762451171875\n",
      "                , weight: 0.9900000000000044\n",
      "=================================\n",
      "in 90 epoch, average loss: -8620.31953125\n",
      "                , loss1: -8874.89921875\n",
      "                , loss2: 141.42462158203125\n",
      "                , weight: 0.985000000000005\n",
      "=================================\n",
      "in 100 epoch, average loss: -8576.7609375\n",
      "                , loss1: -8875.7453125\n",
      "                , loss2: 141.43966064453124\n",
      "                , weight: 0.9800000000000055\n",
      "=================================\n",
      "in 110 epoch, average loss: -8533.2140625\n",
      "                , loss1: -8876.6046875\n",
      "                , loss2: 141.44656982421876\n",
      "                , weight: 0.9750000000000061\n",
      "=================================\n",
      "in 120 epoch, average loss: -8489.4328125\n",
      "                , loss1: -8877.234375\n",
      "                , loss2: 141.459375\n",
      "                , weight: 0.9700000000000066\n",
      "=================================\n",
      "in 130 epoch, average loss: -8445.78203125\n",
      "                , loss1: -8878.0\n",
      "                , loss2: 141.46239013671874\n",
      "                , weight: 0.9650000000000072\n",
      "=================================\n",
      "in 140 epoch, average loss: -8401.7578125\n",
      "                , loss1: -8878.41171875\n",
      "                , loss2: 141.4946044921875\n",
      "                , weight: 0.9600000000000077\n",
      "=================================\n",
      "in 150 epoch, average loss: -8358.034375\n",
      "                , loss1: -8879.1171875\n",
      "                , loss2: 141.50115966796875\n",
      "                , weight: 0.9550000000000083\n",
      "=================================\n",
      "in 160 epoch, average loss: -8313.94765625\n",
      "                , loss1: -8879.46015625\n",
      "                , loss2: 141.5172119140625\n",
      "                , weight: 0.9500000000000088\n",
      "=================================\n",
      "in 170 epoch, average loss: -8270.0984375\n",
      "                , loss1: -8880.03125\n",
      "                , loss2: 141.51138916015626\n",
      "                , weight: 0.9450000000000094\n",
      "=================================\n",
      "in 180 epoch, average loss: -8226.025\n",
      "                , loss1: -8880.39296875\n",
      "                , loss2: 141.52535400390624\n",
      "                , weight: 0.9400000000000099\n",
      "=================================\n",
      "in 190 epoch, average loss: -8181.946875\n",
      "                , loss1: -8880.7359375\n",
      "                , loss2: 141.52314453125\n",
      "                , weight: 0.9350000000000105\n",
      "=================================\n",
      "in 200 epoch, average loss: -8137.91171875\n",
      "                , loss1: -8881.15703125\n",
      "                , loss2: 141.54617919921876\n",
      "                , weight: 0.930000000000011\n",
      "=================================\n",
      "in 210 epoch, average loss: -8093.76796875\n",
      "                , loss1: -8881.4609375\n",
      "                , loss2: 141.5666748046875\n",
      "                , weight: 0.9250000000000116\n",
      "=================================\n",
      "in 220 epoch, average loss: -8049.69453125\n",
      "                , loss1: -8881.80390625\n",
      "                , loss2: 141.54879150390624\n",
      "                , weight: 0.9200000000000121\n",
      "=================================\n",
      "in 230 epoch, average loss: -8005.4578125\n",
      "                , loss1: -8882.01015625\n",
      "                , loss2: 141.565673828125\n",
      "                , weight: 0.9150000000000127\n",
      "=================================\n",
      "in 240 epoch, average loss: -7961.20390625\n",
      "                , loss1: -8882.178125\n",
      "                , loss2: 141.5635986328125\n",
      "                , weight: 0.9100000000000132\n",
      "=================================\n",
      "in 250 epoch, average loss: -7916.92265625\n",
      "                , loss1: -8882.3421875\n",
      "                , loss2: 141.5833984375\n",
      "                , weight: 0.9050000000000138\n",
      "=================================\n",
      "in 260 epoch, average loss: -7872.64453125\n",
      "                , loss1: -8882.4875\n",
      "                , loss2: 141.5793701171875\n",
      "                , weight: 0.9000000000000143\n",
      "=================================\n",
      "in 270 epoch, average loss: -7828.4078125\n",
      "                , loss1: -8882.6875\n",
      "                , loss2: 141.58387451171876\n",
      "                , weight: 0.8950000000000149\n",
      "=================================\n",
      "in 280 epoch, average loss: -7783.98046875\n",
      "                , loss1: -8882.675\n",
      "                , loss2: 141.58594970703126\n",
      "                , weight: 0.8900000000000154\n",
      "=================================\n",
      "in 290 epoch, average loss: -7739.853125\n",
      "                , loss1: -8883.0\n",
      "                , loss2: 141.58858642578124\n",
      "                , weight: 0.885000000000016\n",
      "=================================\n",
      "in 300 epoch, average loss: -7695.61015625\n",
      "                , loss1: -8883.19921875\n",
      "                , loss2: 141.59212646484374\n",
      "                , weight: 0.8800000000000165\n",
      "=================================\n",
      "in 310 epoch, average loss: -7651.328125\n",
      "                , loss1: -8883.3609375\n",
      "                , loss2: 141.60029296875\n",
      "                , weight: 0.8750000000000171\n",
      "=================================\n",
      "in 320 epoch, average loss: -7606.90546875\n",
      "                , loss1: -8883.34765625\n",
      "                , loss2: 141.59444580078124\n",
      "                , weight: 0.8700000000000176\n",
      "=================================\n",
      "in 330 epoch, average loss: -7562.64609375\n",
      "                , loss1: -8883.5328125\n",
      "                , loss2: 141.5988525390625\n",
      "                , weight: 0.8650000000000182\n",
      "=================================\n",
      "in 340 epoch, average loss: -7518.30625\n",
      "                , loss1: -8883.621875\n",
      "                , loss2: 141.59788818359374\n",
      "                , weight: 0.8600000000000187\n",
      "=================================\n",
      "in 350 epoch, average loss: -7474.01171875\n",
      "                , loss1: -8883.78125\n",
      "                , loss2: 141.60980224609375\n",
      "                , weight: 0.8550000000000193\n",
      "=================================\n",
      "in 360 epoch, average loss: -7429.59375\n",
      "                , loss1: -8883.78125\n",
      "                , loss2: 141.6091796875\n",
      "                , weight: 0.8500000000000199\n",
      "=================================\n",
      "in 370 epoch, average loss: -7385.2484375\n",
      "                , loss1: -8883.86171875\n",
      "                , loss2: 141.604150390625\n",
      "                , weight: 0.8450000000000204\n",
      "=================================\n",
      "in 380 epoch, average loss: -7340.8203125\n",
      "                , loss1: -8883.865625\n",
      "                , loss2: 141.6153564453125\n",
      "                , weight: 0.840000000000021\n",
      "=================================\n",
      "in 390 epoch, average loss: -7296.4546875\n",
      "                , loss1: -8883.9171875\n",
      "                , loss2: 141.60443115234375\n",
      "                , weight: 0.8350000000000215\n",
      "=================================\n",
      "in 400 epoch, average loss: -7252.2234375\n",
      "                , loss1: -8884.1515625\n",
      "                , loss2: 141.612255859375\n",
      "                , weight: 0.830000000000022\n",
      "=================================\n",
      "in 410 epoch, average loss: -7207.83203125\n",
      "                , loss1: -8884.19609375\n",
      "                , loss2: 141.61986083984374\n",
      "                , weight: 0.8250000000000226\n",
      "=================================\n",
      "in 420 epoch, average loss: -7163.50859375\n",
      "                , loss1: -8884.3078125\n",
      "                , loss2: 141.6142578125\n",
      "                , weight: 0.8200000000000232\n",
      "=================================\n",
      "in 430 epoch, average loss: -7119.15703125\n",
      "                , loss1: -8884.4046875\n",
      "                , loss2: 141.62203369140624\n",
      "                , weight: 0.8150000000000237\n",
      "=================================\n",
      "in 440 epoch, average loss: -7074.6640625\n",
      "                , loss1: -8884.31875\n",
      "                , loss2: 141.62435302734374\n",
      "                , weight: 0.8100000000000243\n",
      "=================================\n",
      "in 450 epoch, average loss: -7030.39765625\n",
      "                , loss1: -8884.50703125\n",
      "                , loss2: 141.6211181640625\n",
      "                , weight: 0.8050000000000248\n",
      "=================================\n",
      "in 460 epoch, average loss: -6985.94140625\n",
      "                , loss1: -8884.46328125\n",
      "                , loss2: 141.6194580078125\n",
      "                , weight: 0.8000000000000254\n",
      "=================================\n",
      "in 470 epoch, average loss: -6941.5765625\n",
      "                , loss1: -8884.54765625\n",
      "                , loss2: 141.6290771484375\n",
      "                , weight: 0.7950000000000259\n",
      "=================================\n",
      "in 480 epoch, average loss: -6897.159375\n",
      "                , loss1: -8884.54765625\n",
      "                , loss2: 141.6237060546875\n",
      "                , weight: 0.7900000000000265\n",
      "=================================\n",
      "in 490 epoch, average loss: -6852.8484375\n",
      "                , loss1: -8884.69453125\n",
      "                , loss2: 141.62718505859374\n",
      "                , weight: 0.785000000000027\n",
      "=================================\n",
      "in 500 epoch, average loss: -6808.38515625\n",
      "                , loss1: -8884.646875\n",
      "                , loss2: 141.6296630859375\n",
      "                , weight: 0.7800000000000276\n",
      "=================================\n",
      "in 510 epoch, average loss: -6764.04609375\n",
      "                , loss1: -8884.75546875\n",
      "                , loss2: 141.63011474609374\n",
      "                , weight: 0.7750000000000281\n",
      "=================================\n",
      "in 520 epoch, average loss: -6719.621875\n",
      "                , loss1: -8884.753125\n",
      "                , loss2: 141.6296875\n",
      "                , weight: 0.7700000000000287\n",
      "=================================\n",
      "in 530 epoch, average loss: -6675.24609375\n",
      "                , loss1: -8884.81875\n",
      "                , loss2: 141.631494140625\n",
      "                , weight: 0.7650000000000292\n",
      "=================================\n",
      "in 540 epoch, average loss: -6630.7859375\n",
      "                , loss1: -8884.76875\n",
      "                , loss2: 141.628564453125\n",
      "                , weight: 0.7600000000000298\n",
      "=================================\n",
      "in 550 epoch, average loss: -6586.43671875\n",
      "                , loss1: -8884.8734375\n",
      "                , loss2: 141.63392333984376\n",
      "                , weight: 0.7550000000000303\n",
      "=================================\n",
      "in 560 epoch, average loss: -6542.00546875\n",
      "                , loss1: -8884.8625\n",
      "                , loss2: 141.63194580078124\n",
      "                , weight: 0.7500000000000309\n",
      "=================================\n",
      "in 570 epoch, average loss: -6497.63125\n",
      "                , loss1: -8884.93125\n",
      "                , loss2: 141.63409423828125\n",
      "                , weight: 0.7450000000000314\n",
      "=================================\n",
      "in 580 epoch, average loss: -6453.26796875\n",
      "                , loss1: -8885.015625\n",
      "                , loss2: 141.6341552734375\n",
      "                , weight: 0.740000000000032\n",
      "=================================\n",
      "in 590 epoch, average loss: -6408.8546875\n",
      "                , loss1: -8885.03671875\n",
      "                , loss2: 141.6383056640625\n",
      "                , weight: 0.7350000000000325\n",
      "=================================\n",
      "in 600 epoch, average loss: -6364.419921875\n",
      "                , loss1: -8885.0125\n",
      "                , loss2: 141.63056640625\n",
      "                , weight: 0.7300000000000331\n",
      "=================================\n",
      "in 610 epoch, average loss: -6319.991796875\n",
      "                , loss1: -8885.02109375\n",
      "                , loss2: 141.639306640625\n",
      "                , weight: 0.7250000000000336\n",
      "=================================\n",
      "in 620 epoch, average loss: -6275.63125\n",
      "                , loss1: -8885.10625\n",
      "                , loss2: 141.6364990234375\n",
      "                , weight: 0.7200000000000342\n",
      "=================================\n",
      "in 630 epoch, average loss: -6231.210546875\n",
      "                , loss1: -8885.11015625\n",
      "                , loss2: 141.6351806640625\n",
      "                , weight: 0.7150000000000347\n",
      "=================================\n",
      "in 640 epoch, average loss: -6186.798828125\n",
      "                , loss1: -8885.1328125\n",
      "                , loss2: 141.6376220703125\n",
      "                , weight: 0.7100000000000353\n",
      "=================================\n",
      "in 650 epoch, average loss: -6142.351953125\n",
      "                , loss1: -8885.10703125\n",
      "                , loss2: 141.64022216796874\n",
      "                , weight: 0.7050000000000358\n",
      "=================================\n",
      "in 660 epoch, average loss: -6097.9609375\n",
      "                , loss1: -8885.1578125\n",
      "                , loss2: 141.6410400390625\n",
      "                , weight: 0.7000000000000364\n",
      "=================================\n",
      "in 670 epoch, average loss: -6053.5609375\n",
      "                , loss1: -8885.19609375\n",
      "                , loss2: 141.641650390625\n",
      "                , weight: 0.6950000000000369\n",
      "=================================\n",
      "in 680 epoch, average loss: -6009.17109375\n",
      "                , loss1: -8885.24453125\n",
      "                , loss2: 141.6390380859375\n",
      "                , weight: 0.6900000000000375\n",
      "=================================\n",
      "in 690 epoch, average loss: -5964.75390625\n",
      "                , loss1: -8885.26328125\n",
      "                , loss2: 141.64212646484376\n",
      "                , weight: 0.685000000000038\n",
      "=================================\n",
      "in 700 epoch, average loss: -5920.323046875\n",
      "                , loss1: -8885.25625\n",
      "                , loss2: 141.64278564453124\n",
      "                , weight: 0.6800000000000386\n",
      "=================================\n",
      "in 710 epoch, average loss: -5875.912109375\n",
      "                , loss1: -8885.275\n",
      "                , loss2: 141.6397216796875\n",
      "                , weight: 0.6750000000000391\n",
      "=================================\n",
      "in 720 epoch, average loss: -5831.4609375\n",
      "                , loss1: -8885.2390625\n",
      "                , loss2: 141.6406494140625\n",
      "                , weight: 0.6700000000000397\n",
      "=================================\n",
      "in 730 epoch, average loss: -5787.06796875\n",
      "                , loss1: -8885.29140625\n",
      "                , loss2: 141.64271240234376\n",
      "                , weight: 0.6650000000000402\n",
      "=================================\n",
      "in 740 epoch, average loss: -5742.632421875\n",
      "                , loss1: -8885.27890625\n",
      "                , loss2: 141.64393310546876\n",
      "                , weight: 0.6600000000000408\n",
      "=================================\n",
      "in 750 epoch, average loss: -5698.24453125\n",
      "                , loss1: -8885.33515625\n",
      "                , loss2: 141.6421875\n",
      "                , weight: 0.6550000000000413\n",
      "=================================\n",
      "in 760 epoch, average loss: -5653.81015625\n",
      "                , loss1: -8885.32734375\n",
      "                , loss2: 141.6443115234375\n",
      "                , weight: 0.6500000000000419\n",
      "=================================\n",
      "in 770 epoch, average loss: -5609.408984375\n",
      "                , loss1: -8885.365625\n",
      "                , loss2: 141.6439208984375\n",
      "                , weight: 0.6450000000000424\n",
      "=================================\n",
      "in 780 epoch, average loss: -5564.975390625\n",
      "                , loss1: -8885.36171875\n",
      "                , loss2: 141.6472900390625\n",
      "                , weight: 0.640000000000043\n",
      "=================================\n",
      "in 790 epoch, average loss: -5520.5765625\n",
      "                , loss1: -8885.4046875\n",
      "                , loss2: 141.64725341796876\n",
      "                , weight: 0.6350000000000435\n",
      "=================================\n",
      "in 800 epoch, average loss: -5476.17109375\n",
      "                , loss1: -8885.43359375\n",
      "                , loss2: 141.644287109375\n",
      "                , weight: 0.6300000000000441\n",
      "=================================\n",
      "in 810 epoch, average loss: -5431.705859375\n",
      "                , loss1: -8885.371875\n",
      "                , loss2: 141.64398193359375\n",
      "                , weight: 0.6250000000000446\n",
      "=================================\n",
      "in 820 epoch, average loss: -5387.334375\n",
      "                , loss1: -8885.46953125\n",
      "                , loss2: 141.6492431640625\n",
      "                , weight: 0.6200000000000452\n",
      "=================================\n",
      "in 830 epoch, average loss: -5342.915234375\n",
      "                , loss1: -8885.47265625\n",
      "                , loss2: 141.64261474609376\n",
      "                , weight: 0.6150000000000457\n",
      "=================================\n",
      "in 840 epoch, average loss: -5298.469140625\n",
      "                , loss1: -8885.44765625\n",
      "                , loss2: 141.6462890625\n",
      "                , weight: 0.6100000000000463\n",
      "=================================\n",
      "in 850 epoch, average loss: -5254.06015625\n",
      "                , loss1: -8885.47890625\n",
      "                , loss2: 141.64754638671874\n",
      "                , weight: 0.6050000000000468\n",
      "=================================\n",
      "in 860 epoch, average loss: -5209.63828125\n",
      "                , loss1: -8885.49140625\n",
      "                , loss2: 141.6490478515625\n",
      "                , weight: 0.6000000000000474\n",
      "=================================\n",
      "in 870 epoch, average loss: -5165.22265625\n",
      "                , loss1: -8885.503125\n",
      "                , loss2: 141.644482421875\n",
      "                , weight: 0.5950000000000479\n",
      "=================================\n",
      "in 880 epoch, average loss: -5120.800390625\n",
      "                , loss1: -8885.52265625\n",
      "                , loss2: 141.64981689453126\n",
      "                , weight: 0.5900000000000485\n",
      "=================================\n",
      "in 890 epoch, average loss: -5076.369921875\n",
      "                , loss1: -8885.5140625\n",
      "                , loss2: 141.6484130859375\n",
      "                , weight: 0.585000000000049\n",
      "=================================\n",
      "in 900 epoch, average loss: -5031.948046875\n",
      "                , loss1: -8885.52109375\n",
      "                , loss2: 141.64681396484374\n",
      "                , weight: 0.5800000000000496\n",
      "=================================\n",
      "in 910 epoch, average loss: -4987.53515625\n",
      "                , loss1: -8885.546875\n",
      "                , loss2: 141.6463134765625\n",
      "                , weight: 0.5750000000000501\n",
      "=================================\n",
      "in 920 epoch, average loss: -4943.1\n",
      "                , loss1: -8885.5328125\n",
      "                , loss2: 141.646142578125\n",
      "                , weight: 0.5700000000000507\n",
      "=================================\n",
      "in 930 epoch, average loss: -4898.695703125\n",
      "                , loss1: -8885.57734375\n",
      "                , loss2: 141.64849853515625\n",
      "                , weight: 0.5650000000000512\n",
      "=================================\n",
      "in 940 epoch, average loss: -4854.252734375\n",
      "                , loss1: -8885.54921875\n",
      "                , loss2: 141.6468994140625\n",
      "                , weight: 0.5600000000000518\n",
      "=================================\n",
      "in 950 epoch, average loss: -4809.853515625\n",
      "                , loss1: -8885.60078125\n",
      "                , loss2: 141.64708251953124\n",
      "                , weight: 0.5550000000000523\n",
      "=================================\n",
      "in 960 epoch, average loss: -4765.416015625\n",
      "                , loss1: -8885.584375\n",
      "                , loss2: 141.6489990234375\n",
      "                , weight: 0.5500000000000529\n",
      "=================================\n",
      "in 970 epoch, average loss: -4720.98671875\n",
      "                , loss1: -8885.5890625\n",
      "                , loss2: 141.6514892578125\n",
      "                , weight: 0.5450000000000534\n",
      "=================================\n",
      "in 980 epoch, average loss: -4676.583203125\n",
      "                , loss1: -8885.6265625\n",
      "                , loss2: 141.64775390625\n",
      "                , weight: 0.540000000000054\n",
      "=================================\n",
      "in 990 epoch, average loss: -4632.140625\n",
      "                , loss1: -8885.6015625\n",
      "                , loss2: 141.64859619140626\n",
      "                , weight: 0.5350000000000545\n",
      "=================================\n",
      "in 1000 epoch, average loss: -4587.709375\n",
      "                , loss1: -8885.596875\n",
      "                , loss2: 141.65013427734374\n",
      "                , weight: 0.5300000000000551\n",
      "=================================\n",
      "in 1010 epoch, average loss: -4543.290234375\n",
      "                , loss1: -8885.615625\n",
      "                , loss2: 141.650537109375\n",
      "                , weight: 0.5250000000000556\n",
      "=================================\n",
      "in 1020 epoch, average loss: -4498.88203125\n",
      "                , loss1: -8885.6546875\n",
      "                , loss2: 141.65072021484374\n",
      "                , weight: 0.5200000000000562\n",
      "=================================\n",
      "in 1030 epoch, average loss: -4454.451953125\n",
      "                , loss1: -8885.6484375\n",
      "                , loss2: 141.6494140625\n",
      "                , weight: 0.5150000000000567\n",
      "=================================\n",
      "in 1040 epoch, average loss: -4410.019921875\n",
      "                , loss1: -8885.63828125\n",
      "                , loss2: 141.6487060546875\n",
      "                , weight: 0.5100000000000573\n",
      "=================================\n",
      "in 1050 epoch, average loss: -4365.583984375\n",
      "                , loss1: -8885.62890625\n",
      "                , loss2: 141.651220703125\n",
      "                , weight: 0.5050000000000578\n",
      "=================================\n",
      "in 1060 epoch, average loss: -4321.16171875\n",
      "                , loss1: -8885.64140625\n",
      "                , loss2: 141.6522705078125\n",
      "                , weight: 0.5000000000000584\n",
      "=================================\n",
      "in 1070 epoch, average loss: -4276.74921875\n",
      "                , loss1: -8885.6671875\n",
      "                , loss2: 141.64937744140624\n",
      "                , weight: 0.4950000000000584\n",
      "=================================\n",
      "in 1080 epoch, average loss: -4232.33125\n",
      "                , loss1: -8885.6890625\n",
      "                , loss2: 141.6487060546875\n",
      "                , weight: 0.4900000000000584\n",
      "=================================\n",
      "in 1090 epoch, average loss: -4187.89140625\n",
      "                , loss1: -8885.66796875\n",
      "                , loss2: 141.65052490234376\n",
      "                , weight: 0.4850000000000584\n",
      "=================================\n",
      "in 1100 epoch, average loss: -4143.468359375\n",
      "                , loss1: -8885.68046875\n",
      "                , loss2: 141.6510009765625\n",
      "                , weight: 0.4800000000000584\n",
      "=================================\n",
      "in 1110 epoch, average loss: -4099.055078125\n",
      "                , loss1: -8885.7125\n",
      "                , loss2: 141.65155029296875\n",
      "                , weight: 0.4750000000000584\n",
      "=================================\n",
      "in 1120 epoch, average loss: -4054.626953125\n",
      "                , loss1: -8885.71015625\n",
      "                , loss2: 141.64952392578124\n",
      "                , weight: 0.47000000000005837\n",
      "=================================\n",
      "in 1130 epoch, average loss: -4010.180859375\n",
      "                , loss1: -8885.67421875\n",
      "                , loss2: 141.650732421875\n",
      "                , weight: 0.46500000000005837\n",
      "=================================\n",
      "in 1140 epoch, average loss: -3965.775390625\n",
      "                , loss1: -8885.728125\n",
      "                , loss2: 141.6524169921875\n",
      "                , weight: 0.46000000000005836\n",
      "=================================\n",
      "in 1150 epoch, average loss: -3921.346484375\n",
      "                , loss1: -8885.72421875\n",
      "                , loss2: 141.650830078125\n",
      "                , weight: 0.45500000000005836\n",
      "=================================\n",
      "in 1160 epoch, average loss: -3876.9265625\n",
      "                , loss1: -8885.74296875\n",
      "                , loss2: 141.65050048828124\n",
      "                , weight: 0.45000000000005835\n",
      "=================================\n",
      "in 1170 epoch, average loss: -3832.493359375\n",
      "                , loss1: -8885.734375\n",
      "                , loss2: 141.651416015625\n",
      "                , weight: 0.44500000000005835\n",
      "=================================\n",
      "in 1180 epoch, average loss: -3788.06796875\n",
      "                , loss1: -8885.7484375\n",
      "                , loss2: 141.65406494140626\n",
      "                , weight: 0.44000000000005834\n",
      "=================================\n",
      "in 1190 epoch, average loss: -3743.644140625\n",
      "                , loss1: -8885.75625\n",
      "                , loss2: 141.6526611328125\n",
      "                , weight: 0.43500000000005834\n",
      "=================================\n",
      "in 1200 epoch, average loss: -3699.213671875\n",
      "                , loss1: -8885.74609375\n",
      "                , loss2: 141.64996337890625\n",
      "                , weight: 0.43000000000005834\n",
      "=================================\n",
      "in 1210 epoch, average loss: -3654.7875\n",
      "                , loss1: -8885.76015625\n",
      "                , loss2: 141.653271484375\n",
      "                , weight: 0.42500000000005833\n",
      "=================================\n",
      "in 1220 epoch, average loss: -3610.3625\n",
      "                , loss1: -8885.76171875\n",
      "                , loss2: 141.6502685546875\n",
      "                , weight: 0.4200000000000583\n",
      "=================================\n",
      "in 1230 epoch, average loss: -3565.930078125\n",
      "                , loss1: -8885.7546875\n",
      "                , loss2: 141.6511474609375\n",
      "                , weight: 0.4150000000000583\n",
      "=================================\n",
      "in 1240 epoch, average loss: -3521.501953125\n",
      "                , loss1: -8885.76171875\n",
      "                , loss2: 141.653076171875\n",
      "                , weight: 0.4100000000000583\n",
      "=================================\n",
      "in 1250 epoch, average loss: -3477.078515625\n",
      "                , loss1: -8885.77265625\n",
      "                , loss2: 141.65189208984376\n",
      "                , weight: 0.4050000000000583\n",
      "=================================\n",
      "in 1260 epoch, average loss: -3432.645703125\n",
      "                , loss1: -8885.76171875\n",
      "                , loss2: 141.65233154296874\n",
      "                , weight: 0.4000000000000583\n",
      "=================================\n",
      "in 1270 epoch, average loss: -3388.2234375\n",
      "                , loss1: -8885.77578125\n",
      "                , loss2: 141.65091552734376\n",
      "                , weight: 0.3950000000000583\n",
      "=================================\n",
      "in 1280 epoch, average loss: -3343.803515625\n",
      "                , loss1: -8885.8046875\n",
      "                , loss2: 141.6533447265625\n",
      "                , weight: 0.3900000000000583\n",
      "=================================\n",
      "in 1290 epoch, average loss: -3299.37734375\n",
      "                , loss1: -8885.8140625\n",
      "                , loss2: 141.65396728515626\n",
      "                , weight: 0.3850000000000583\n",
      "=================================\n",
      "in 1300 epoch, average loss: -3254.9337890625\n",
      "                , loss1: -8885.77421875\n",
      "                , loss2: 141.65341796875\n",
      "                , weight: 0.3800000000000583\n",
      "=================================\n",
      "in 1310 epoch, average loss: -3210.511328125\n",
      "                , loss1: -8885.790625\n",
      "                , loss2: 141.65296630859376\n",
      "                , weight: 0.3750000000000583\n",
      "=================================\n",
      "in 1320 epoch, average loss: -3166.087109375\n",
      "                , loss1: -8885.80234375\n",
      "                , loss2: 141.65296630859376\n",
      "                , weight: 0.3700000000000583\n",
      "=================================\n",
      "in 1330 epoch, average loss: -3121.6529296875\n",
      "                , loss1: -8885.78671875\n",
      "                , loss2: 141.65247802734376\n",
      "                , weight: 0.3650000000000583\n",
      "=================================\n",
      "in 1340 epoch, average loss: -3077.2302734375\n",
      "                , loss1: -8885.8046875\n",
      "                , loss2: 141.65263671875\n",
      "                , weight: 0.3600000000000583\n",
      "=================================\n",
      "in 1350 epoch, average loss: -3032.8048828125\n",
      "                , loss1: -8885.81171875\n",
      "                , loss2: 141.65162353515626\n",
      "                , weight: 0.35500000000005827\n",
      "=================================\n",
      "in 1360 epoch, average loss: -2988.368359375\n",
      "                , loss1: -8885.79609375\n",
      "                , loss2: 141.6531494140625\n",
      "                , weight: 0.35000000000005826\n",
      "=================================\n",
      "in 1370 epoch, average loss: -2943.9400390625\n",
      "                , loss1: -8885.79609375\n",
      "                , loss2: 141.6528076171875\n",
      "                , weight: 0.34500000000005826\n",
      "=================================\n",
      "in 1380 epoch, average loss: -2899.516015625\n",
      "                , loss1: -8885.8078125\n",
      "                , loss2: 141.6514892578125\n",
      "                , weight: 0.34000000000005826\n",
      "=================================\n",
      "in 1390 epoch, average loss: -2855.0857421875\n",
      "                , loss1: -8885.80546875\n",
      "                , loss2: 141.65185546875\n",
      "                , weight: 0.33500000000005825\n",
      "=================================\n",
      "in 1400 epoch, average loss: -2810.66015625\n",
      "                , loss1: -8885.821875\n",
      "                , loss2: 141.654248046875\n",
      "                , weight: 0.33000000000005825\n",
      "=================================\n",
      "in 1410 epoch, average loss: -2766.2234375\n",
      "                , loss1: -8885.7875\n",
      "                , loss2: 141.65067138671876\n",
      "                , weight: 0.32500000000005824\n",
      "=================================\n",
      "in 1420 epoch, average loss: -2721.8060546875\n",
      "                , loss1: -8885.82578125\n",
      "                , loss2: 141.65128173828126\n",
      "                , weight: 0.32000000000005824\n",
      "=================================\n",
      "in 1430 epoch, average loss: -2677.3759765625\n",
      "                , loss1: -8885.82421875\n",
      "                , loss2: 141.6514892578125\n",
      "                , weight: 0.31500000000005823\n",
      "=================================\n",
      "in 1440 epoch, average loss: -2632.941015625\n",
      "                , loss1: -8885.81015625\n",
      "                , loss2: 141.65341796875\n",
      "                , weight: 0.31000000000005823\n",
      "=================================\n",
      "in 1450 epoch, average loss: -2588.5265625\n",
      "                , loss1: -8885.85546875\n",
      "                , loss2: 141.6526123046875\n",
      "                , weight: 0.3050000000000582\n",
      "=================================\n",
      "in 1460 epoch, average loss: -2544.0912109375\n",
      "                , loss1: -8885.83984375\n",
      "                , loss2: 141.65382080078126\n",
      "                , weight: 0.3000000000000582\n",
      "=================================\n",
      "in 1470 epoch, average loss: -2499.6611328125\n",
      "                , loss1: -8885.8328125\n",
      "                , loss2: 141.6528076171875\n",
      "                , weight: 0.2950000000000582\n",
      "=================================\n",
      "in 1480 epoch, average loss: -2455.2314453125\n",
      "                , loss1: -8885.82421875\n",
      "                , loss2: 141.65079345703126\n",
      "                , weight: 0.2900000000000582\n",
      "=================================\n",
      "in 1490 epoch, average loss: -2410.8017578125\n",
      "                , loss1: -8885.83125\n",
      "                , loss2: 141.65279541015624\n",
      "                , weight: 0.2850000000000582\n",
      "=================================\n",
      "in 1500 epoch, average loss: -2366.3783203125\n",
      "                , loss1: -8885.8453125\n",
      "                , loss2: 141.65142822265625\n",
      "                , weight: 0.2800000000000582\n",
      "=================================\n",
      "in 1510 epoch, average loss: -2321.94921875\n",
      "                , loss1: -8885.8484375\n",
      "                , loss2: 141.6525634765625\n",
      "                , weight: 0.2750000000000582\n",
      "=================================\n",
      "in 1520 epoch, average loss: -2277.516015625\n",
      "                , loss1: -8885.8390625\n",
      "                , loss2: 141.6532470703125\n",
      "                , weight: 0.2700000000000582\n",
      "=================================\n",
      "in 1530 epoch, average loss: -2233.087890625\n",
      "                , loss1: -8885.8359375\n",
      "                , loss2: 141.65169677734374\n",
      "                , weight: 0.2650000000000582\n",
      "=================================\n",
      "in 1540 epoch, average loss: -2188.6623046875\n",
      "                , loss1: -8885.85\n",
      "                , loss2: 141.651904296875\n",
      "                , weight: 0.2600000000000582\n",
      "=================================\n",
      "in 1550 epoch, average loss: -2144.2259765625\n",
      "                , loss1: -8885.8203125\n",
      "                , loss2: 141.65126953125\n",
      "                , weight: 0.2550000000000582\n",
      "=================================\n",
      "in 1560 epoch, average loss: -2099.809765625\n",
      "                , loss1: -8885.86171875\n",
      "                , loss2: 141.64884033203126\n",
      "                , weight: 0.2500000000000582\n",
      "=================================\n",
      "in 1570 epoch, average loss: -2055.3755859375\n",
      "                , loss1: -8885.840625\n",
      "                , loss2: 141.64876708984374\n",
      "                , weight: 0.24500000000005817\n",
      "=================================\n",
      "in 1580 epoch, average loss: -2010.9431640625\n",
      "                , loss1: -8885.840625\n",
      "                , loss2: 141.65174560546876\n",
      "                , weight: 0.24000000000005817\n",
      "=================================\n",
      "in 1590 epoch, average loss: -1966.5150390625\n",
      "                , loss1: -8885.83671875\n",
      "                , loss2: 141.64971923828125\n",
      "                , weight: 0.23500000000005816\n",
      "=================================\n",
      "in 1600 epoch, average loss: -1922.084375\n",
      "                , loss1: -8885.8359375\n",
      "                , loss2: 141.6508056640625\n",
      "                , weight: 0.23000000000005816\n",
      "=================================\n",
      "in 1610 epoch, average loss: -1877.658203125\n",
      "                , loss1: -8885.8265625\n",
      "                , loss2: 141.645947265625\n",
      "                , weight: 0.22500000000005815\n",
      "=================================\n",
      "in 1620 epoch, average loss: -1833.2310546875\n",
      "                , loss1: -8885.8375\n",
      "                , loss2: 141.64617919921875\n",
      "                , weight: 0.22000000000005815\n",
      "=================================\n",
      "in 1630 epoch, average loss: -1788.8033203125\n",
      "                , loss1: -8885.83828125\n",
      "                , loss2: 141.64495849609375\n",
      "                , weight: 0.21500000000005814\n",
      "=================================\n",
      "in 1640 epoch, average loss: -1744.3763671875\n",
      "                , loss1: -8885.8015625\n",
      "                , loss2: 141.63521728515624\n",
      "                , weight: 0.21000000000005814\n",
      "=================================\n",
      "in 1650 epoch, average loss: -1699.9501953125\n",
      "                , loss1: -8885.4875\n",
      "                , loss2: 141.5675048828125\n",
      "                , weight: 0.20500000000005814\n",
      "=================================\n",
      "in 1660 epoch, average loss: -1669.96875\n",
      "                , loss1: -8672.77109375\n",
      "                , loss2: 84.32423095703125\n",
      "                , weight: 0.20000000000005813\n",
      "=================================\n",
      "in 1670 epoch, average loss: -1676.0130859375\n",
      "                , loss1: -8753.6828125\n",
      "                , loss2: 50.491888427734374\n",
      "                , weight: 0.19500000000005813\n",
      "=================================\n",
      "in 1680 epoch, average loss: -1650.5919921875\n",
      "                , loss1: -8811.8265625\n",
      "                , loss2: 43.531915283203126\n",
      "                , weight: 0.19000000000005812\n",
      "=================================\n",
      "in 1690 epoch, average loss: -1619.58115234375\n",
      "                , loss1: -8715.2265625\n",
      "                , loss2: 12.303068542480469\n",
      "                , weight: 0.18500000000005812\n",
      "=================================\n",
      "in 1700 epoch, average loss: -1583.5029296875\n",
      "                , loss1: -8705.1359375\n",
      "                , loss2: 3.0222164154052735\n",
      "                , weight: 0.1800000000000581\n",
      "=================================\n",
      "in 1710 epoch, average loss: -1542.17314453125\n",
      "                , loss1: -8714.2484375\n",
      "                , loss2: 2.4077367782592773\n",
      "                , weight: 0.1750000000000581\n",
      "=================================\n",
      "in 1720 epoch, average loss: -1502.33232421875\n",
      "                , loss1: -8742.93671875\n",
      "                , loss2: 3.638555145263672\n",
      "                , weight: 0.1700000000000581\n",
      "=================================\n",
      "in 1730 epoch, average loss: -1458.64501953125\n",
      "                , loss1: -8743.37109375\n",
      "                , loss2: 3.6835113525390626\n",
      "                , weight: 0.1650000000000581\n",
      "=================================\n",
      "in 1740 epoch, average loss: -1414.9939453125\n",
      "                , loss1: -8743.2140625\n",
      "                , loss2: 3.59151611328125\n",
      "                , weight: 0.1600000000000581\n",
      "=================================\n",
      "in 1750 epoch, average loss: -1371.41416015625\n",
      "                , loss1: -8744.51953125\n",
      "                , loss2: 3.6614364624023437\n",
      "                , weight: 0.1550000000000581\n",
      "=================================\n",
      "in 1760 epoch, average loss: -1327.69697265625\n",
      "                , loss1: -8744.56875\n",
      "                , loss2: 3.6635669708251952\n",
      "                , weight: 0.1500000000000581\n",
      "=================================\n",
      "in 1770 epoch, average loss: -1283.94921875\n",
      "                , loss1: -8744.40546875\n",
      "                , loss2: 3.66434326171875\n",
      "                , weight: 0.14500000000005808\n",
      "=================================\n",
      "in 1780 epoch, average loss: -1240.267578125\n",
      "                , loss1: -8744.69609375\n",
      "                , loss2: 3.665322494506836\n",
      "                , weight: 0.14000000000005808\n",
      "=================================\n",
      "in 1790 epoch, average loss: -1196.56845703125\n",
      "                , loss1: -8744.8671875\n",
      "                , loss2: 3.664542007446289\n",
      "                , weight: 0.13500000000005807\n",
      "=================================\n",
      "in 1800 epoch, average loss: -1152.83271484375\n",
      "                , loss1: -8744.78359375\n",
      "                , loss2: 3.664904022216797\n",
      "                , weight: 0.13000000000005807\n",
      "=================================\n",
      "in 1810 epoch, average loss: -1109.10546875\n",
      "                , loss1: -8744.7359375\n",
      "                , loss2: 3.6619331359863283\n",
      "                , weight: 0.12500000000005806\n",
      "=================================\n",
      "in 1820 epoch, average loss: -1065.38515625\n",
      "                , loss1: -8744.7984375\n",
      "                , loss2: 3.6664806365966798\n",
      "                , weight: 0.12000000000005806\n",
      "=================================\n",
      "in 1830 epoch, average loss: -1021.66904296875\n",
      "                , loss1: -8744.84921875\n",
      "                , loss2: 3.6645275115966798\n",
      "                , weight: 0.11500000000005806\n",
      "=================================\n",
      "in 1840 epoch, average loss: -977.94921875\n",
      "                , loss1: -8744.8875\n",
      "                , loss2: 3.6644260406494142\n",
      "                , weight: 0.11000000000005805\n",
      "=================================\n",
      "in 1850 epoch, average loss: -934.2251953125\n",
      "                , loss1: -8744.89296875\n",
      "                , loss2: 3.6646175384521484\n",
      "                , weight: 0.10500000000005805\n",
      "=================================\n",
      "in 1860 epoch, average loss: -890.4908203125\n",
      "                , loss1: -8744.8234375\n",
      "                , loss2: 3.667177200317383\n",
      "                , weight: 0.10000000000005804\n",
      "=================================\n",
      "in 1870 epoch, average loss: -846.778515625\n",
      "                , loss1: -8744.91484375\n",
      "                , loss2: 3.664388656616211\n",
      "                , weight: 0.09500000000005804\n",
      "=================================\n",
      "in 1880 epoch, average loss: -803.054052734375\n",
      "                , loss1: -8744.9171875\n",
      "                , loss2: 3.6646049499511717\n",
      "                , weight: 0.09000000000005803\n",
      "=================================\n",
      "in 1890 epoch, average loss: -759.33115234375\n",
      "                , loss1: -8744.9390625\n",
      "                , loss2: 3.6647884368896486\n",
      "                , weight: 0.08500000000005803\n",
      "=================================\n",
      "in 1900 epoch, average loss: -715.605126953125\n",
      "                , loss1: -8744.92109375\n",
      "                , loss2: 3.664616012573242\n",
      "                , weight: 0.08000000000005802\n",
      "=================================\n",
      "in 1910 epoch, average loss: -671.88134765625\n",
      "                , loss1: -8744.92734375\n",
      "                , loss2: 3.6644607543945313\n",
      "                , weight: 0.07500000000005802\n",
      "=================================\n",
      "in 1920 epoch, average loss: -628.158837890625\n",
      "                , loss1: -8744.9640625\n",
      "                , loss2: 3.6647735595703126\n",
      "                , weight: 0.07000000000005802\n",
      "=================================\n",
      "in 1930 epoch, average loss: -584.434375\n",
      "                , loss1: -8744.9703125\n",
      "                , loss2: 3.6648250579833985\n",
      "                , weight: 0.06500000000005801\n",
      "=================================\n",
      "in 1940 epoch, average loss: -540.7107421875\n",
      "                , loss1: -8744.9796875\n",
      "                , loss2: 3.6641860961914063\n",
      "                , weight: 0.06000000000005801\n",
      "=================================\n",
      "in 1950 epoch, average loss: -496.984033203125\n",
      "                , loss1: -8744.95078125\n",
      "                , loss2: 3.6644359588623048\n",
      "                , weight: 0.055000000000058\n",
      "=================================\n",
      "in 1960 epoch, average loss: -453.26064453125\n",
      "                , loss1: -8744.978125\n",
      "                , loss2: 3.6644081115722655\n",
      "                , weight: 0.050000000000058\n",
      "=================================\n",
      "in 1970 epoch, average loss: -409.5345703125\n",
      "                , loss1: -8744.96015625\n",
      "                , loss2: 3.6647605895996094\n",
      "                , weight: 0.045000000000057994\n",
      "=================================\n",
      "in 1980 epoch, average loss: -365.812109375\n",
      "                , loss1: -8745.015625\n",
      "                , loss2: 3.6647876739501952\n",
      "                , weight: 0.04000000000005799\n",
      "=================================\n",
      "in 1990 epoch, average loss: -322.085205078125\n",
      "                , loss1: -8744.965625\n",
      "                , loss2: 3.664750671386719\n",
      "                , weight: 0.035000000000057985\n",
      "=================================\n",
      "in 2000 epoch, average loss: -278.361376953125\n",
      "                , loss1: -8744.98125\n",
      "                , loss2: 3.6642040252685546\n",
      "                , weight: 0.03000000000005798\n",
      "=================================\n",
      "in 2010 epoch, average loss: -234.6345703125\n",
      "                , loss1: -8744.9421875\n",
      "                , loss2: 3.6651439666748047\n",
      "                , weight: 0.025000000000057976\n",
      "=================================\n",
      "in 2020 epoch, average loss: -190.9115478515625\n",
      "                , loss1: -8745.0171875\n",
      "                , loss2: 3.665085220336914\n",
      "                , weight: 0.02000000000005797\n",
      "=================================\n",
      "in 2030 epoch, average loss: -166.8628662109375\n",
      "                , loss1: -8745.0234375\n",
      "                , loss2: 3.6650726318359377\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2040 epoch, average loss: -166.8625244140625\n",
      "                , loss1: -8744.96796875\n",
      "                , loss2: 3.6643497467041017\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2050 epoch, average loss: -166.86280517578126\n",
      "                , loss1: -8744.9921875\n",
      "                , loss2: 3.664529800415039\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2060 epoch, average loss: -166.857080078125\n",
      "                , loss1: -8744.8921875\n",
      "                , loss2: 3.668330764770508\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2070 epoch, average loss: -166.86248779296875\n",
      "                , loss1: -8744.93984375\n",
      "                , loss2: 3.66383056640625\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2080 epoch, average loss: -166.8626220703125\n",
      "                , loss1: -8744.9953125\n",
      "                , loss2: 3.664779281616211\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2090 epoch, average loss: -166.86268310546876\n",
      "                , loss1: -8745.015625\n",
      "                , loss2: 3.665121841430664\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2100 epoch, average loss: -166.8632080078125\n",
      "                , loss1: -8745.0125\n",
      "                , loss2: 3.664523696899414\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2110 epoch, average loss: -166.8634033203125\n",
      "                , loss1: -8744.9796875\n",
      "                , loss2: 3.6637107849121096\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2120 epoch, average loss: -166.8638916015625\n",
      "                , loss1: -8744.984375\n",
      "                , loss2: 3.6633392333984376\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2130 epoch, average loss: -166.86290283203124\n",
      "                , loss1: -8744.98984375\n",
      "                , loss2: 3.664413833618164\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2140 epoch, average loss: -166.8634033203125\n",
      "                , loss1: -8744.97734375\n",
      "                , loss2: 3.6636478424072267\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2150 epoch, average loss: -166.86236572265625\n",
      "                , loss1: -8744.96328125\n",
      "                , loss2: 3.6644168853759767\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2160 epoch, average loss: -166.86378173828126\n",
      "                , loss1: -8744.96328125\n",
      "                , loss2: 3.663015365600586\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2170 epoch, average loss: -166.86678466796874\n",
      "                , loss1: -8744.553125\n",
      "                , loss2: 3.652025604248047\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2180 epoch, average loss: -166.9591064453125\n",
      "                , loss1: -8741.128125\n",
      "                , loss2: 3.4928741455078125\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2190 epoch, average loss: -168.080615234375\n",
      "                , loss1: -8725.9984375\n",
      "                , loss2: 2.0763708114624024\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2200 epoch, average loss: -168.58837890625\n",
      "                , loss1: -8710.45078125\n",
      "                , loss2: 1.2654032707214355\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2210 epoch, average loss: -168.84169921875\n",
      "                , loss1: -8722.32265625\n",
      "                , loss2: 1.2436022758483887\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2220 epoch, average loss: -169.02796630859376\n",
      "                , loss1: -8721.36171875\n",
      "                , loss2: 1.0386001586914062\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2230 epoch, average loss: -169.13759765625\n",
      "                , loss1: -8725.371875\n",
      "                , loss2: 1.00715970993042\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2240 epoch, average loss: -169.11170654296876\n",
      "                , loss1: -8724.20859375\n",
      "                , loss2: 1.0103752136230468\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2250 epoch, average loss: -169.1619140625\n",
      "                , loss1: -8726.259375\n",
      "                , loss2: 1.0001491546630858\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2260 epoch, average loss: -169.157958984375\n",
      "                , loss1: -8726.06953125\n",
      "                , loss2: 1.0004013061523438\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2270 epoch, average loss: -169.1625244140625\n",
      "                , loss1: -8726.290625\n",
      "                , loss2: 1.0001182556152344\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2280 epoch, average loss: -169.102587890625\n",
      "                , loss1: -8724.734375\n",
      "                , loss2: 1.0297346115112305\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2290 epoch, average loss: -169.16314697265625\n",
      "                , loss1: -8726.321875\n",
      "                , loss2: 1.0001431465148927\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2300 epoch, average loss: -169.1633056640625\n",
      "                , loss1: -8726.3421875\n",
      "                , loss2: 1.0003494262695312\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2310 epoch, average loss: -169.1610107421875\n",
      "                , loss1: -8726.20234375\n",
      "                , loss2: 0.9999382019042968\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2320 epoch, average loss: -169.161376953125\n",
      "                , loss1: -8726.23046875\n",
      "                , loss2: 1.0001337051391601\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2330 epoch, average loss: -169.1627685546875\n",
      "                , loss1: -8726.29765625\n",
      "                , loss2: 1.0000411987304687\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2340 epoch, average loss: -169.16275634765626\n",
      "                , loss1: -8726.30390625\n",
      "                , loss2: 1.0001882553100585\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2350 epoch, average loss: -169.16318359375\n",
      "                , loss1: -8726.32109375\n",
      "                , loss2: 1.0000595092773437\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2360 epoch, average loss: -169.14403076171874\n",
      "                , loss1: -8725.40234375\n",
      "                , loss2: 1.0013225555419922\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2370 epoch, average loss: -169.15845947265626\n",
      "                , loss1: -8726.07734375\n",
      "                , loss2: 1.0000492095947267\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2380 epoch, average loss: -169.12337646484374\n",
      "                , loss1: -8724.378125\n",
      "                , loss2: 1.0020222663879395\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2390 epoch, average loss: -169.1637451171875\n",
      "                , loss1: -8726.359375\n",
      "                , loss2: 1.0002810478210449\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2400 epoch, average loss: -169.163427734375\n",
      "                , loss1: -8726.33671875\n",
      "                , loss2: 1.0001174926757812\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2410 epoch, average loss: -169.16337890625\n",
      "                , loss1: -8726.32421875\n",
      "                , loss2: 0.9999371528625488\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2420 epoch, average loss: -169.16376953125\n",
      "                , loss1: -8726.35859375\n",
      "                , loss2: 1.0002324104309082\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2430 epoch, average loss: -169.16251220703126\n",
      "                , loss1: -8726.2828125\n",
      "                , loss2: 1.0000057220458984\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2440 epoch, average loss: -169.1638916015625\n",
      "                , loss1: -8726.3609375\n",
      "                , loss2: 1.0001502990722657\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2450 epoch, average loss: -169.16396484375\n",
      "                , loss1: -8726.36796875\n",
      "                , loss2: 1.0001896858215331\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2460 epoch, average loss: -169.13670654296874\n",
      "                , loss1: -8725.11953125\n",
      "                , loss2: 1.0031200408935548\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2470 epoch, average loss: -169.16263427734376\n",
      "                , loss1: -8726.29453125\n",
      "                , loss2: 1.0000997543334962\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2480 epoch, average loss: -169.10194091796876\n",
      "                , loss1: -8723.47265625\n",
      "                , loss2: 1.005782699584961\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2490 epoch, average loss: -169.16470947265626\n",
      "                , loss1: -8726.396875\n",
      "                , loss2: 1.0000353813171388\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2500 epoch, average loss: -169.16234130859374\n",
      "                , loss1: -8726.290625\n",
      "                , loss2: 1.0003109931945802\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2510 epoch, average loss: -169.1405517578125\n",
      "                , loss1: -8725.184375\n",
      "                , loss2: 1.0005461692810058\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2520 epoch, average loss: -169.1629150390625\n",
      "                , loss1: -8726.3234375\n",
      "                , loss2: 1.0004172325134277\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2530 epoch, average loss: -169.1646728515625\n",
      "                , loss1: -8726.38671875\n",
      "                , loss2: 0.9998798370361328\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2540 epoch, average loss: -169.1629150390625\n",
      "                , loss1: -8726.32578125\n",
      "                , loss2: 1.000434970855713\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2550 epoch, average loss: -169.16492919921876\n",
      "                , loss1: -8726.40546875\n",
      "                , loss2: 0.9999547004699707\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2560 epoch, average loss: -169.16455078125\n",
      "                , loss1: -8726.390625\n",
      "                , loss2: 1.0000848770141602\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2570 epoch, average loss: -169.16522216796875\n",
      "                , loss1: -8726.43359375\n",
      "                , loss2: 1.0002192497253417\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2580 epoch, average loss: -169.16466064453124\n",
      "                , loss1: -8726.396875\n",
      "                , loss2: 1.0000688552856445\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2590 epoch, average loss: -169.16517333984376\n",
      "                , loss1: -8726.41796875\n",
      "                , loss2: 0.9999767303466797\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2600 epoch, average loss: -169.16495361328126\n",
      "                , loss1: -8726.4015625\n",
      "                , loss2: 0.9998927116394043\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2610 epoch, average loss: -169.16507568359376\n",
      "                , loss1: -8726.428125\n",
      "                , loss2: 1.0002790451049806\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2620 epoch, average loss: -169.16385498046876\n",
      "                , loss1: -8726.3546875\n",
      "                , loss2: 1.0000726699829101\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2630 epoch, average loss: -169.16531982421876\n",
      "                , loss1: -8726.43125\n",
      "                , loss2: 1.0000995635986327\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2640 epoch, average loss: -169.16522216796875\n",
      "                , loss1: -8726.4296875\n",
      "                , loss2: 1.0001415252685546\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2650 epoch, average loss: -169.16483154296876\n",
      "                , loss1: -8726.4046875\n",
      "                , loss2: 1.0000857353210448\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2660 epoch, average loss: -169.16455078125\n",
      "                , loss1: -8726.39921875\n",
      "                , loss2: 1.000217819213867\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2670 epoch, average loss: -169.16536865234374\n",
      "                , loss1: -8726.4296875\n",
      "                , loss2: 1.0000121116638183\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2680 epoch, average loss: -169.16583251953125\n",
      "                , loss1: -8726.44921875\n",
      "                , loss2: 0.9999246597290039\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2690 epoch, average loss: -169.1650390625\n",
      "                , loss1: -8726.41640625\n",
      "                , loss2: 1.000067138671875\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2700 epoch, average loss: -169.16575927734374\n",
      "                , loss1: -8726.4546875\n",
      "                , loss2: 1.0001266479492188\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2710 epoch, average loss: -169.165576171875\n",
      "                , loss1: -8726.43984375\n",
      "                , loss2: 1.0000066757202148\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2720 epoch, average loss: -169.16533203125\n",
      "                , loss1: -8726.4359375\n",
      "                , loss2: 1.0001744270324706\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2730 epoch, average loss: -169.16533203125\n",
      "                , loss1: -8726.425\n",
      "                , loss2: 0.999973201751709\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2740 epoch, average loss: -169.16561279296874\n",
      "                , loss1: -8726.44140625\n",
      "                , loss2: 0.9999942779541016\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2750 epoch, average loss: -169.1654296875\n",
      "                , loss1: -8726.43515625\n",
      "                , loss2: 1.000046157836914\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2760 epoch, average loss: -169.16539306640624\n",
      "                , loss1: -8726.43046875\n",
      "                , loss2: 1.0000067710876466\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2770 epoch, average loss: -169.1647216796875\n",
      "                , loss1: -8726.3984375\n",
      "                , loss2: 1.0000624656677246\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2780 epoch, average loss: -169.165283203125\n",
      "                , loss1: -8726.41953125\n",
      "                , loss2: 0.9998924255371093\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2790 epoch, average loss: -169.1651611328125\n",
      "                , loss1: -8726.4328125\n",
      "                , loss2: 1.000293254852295\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2800 epoch, average loss: -169.16580810546876\n",
      "                , loss1: -8726.43671875\n",
      "                , loss2: 0.9997117996215821\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2810 epoch, average loss: -169.1650634765625\n",
      "                , loss1: -8726.40703125\n",
      "                , loss2: 0.9998693466186523\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2820 epoch, average loss: -169.1665771484375\n",
      "                , loss1: -8726.49140625\n",
      "                , loss2: 1.0000040054321289\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2830 epoch, average loss: -169.16619873046875\n",
      "                , loss1: -8726.48046875\n",
      "                , loss2: 1.000173568725586\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2840 epoch, average loss: -169.1652099609375\n",
      "                , loss1: -8726.42109375\n",
      "                , loss2: 1.000028133392334\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2850 epoch, average loss: -169.16650390625\n",
      "                , loss1: -8726.4890625\n",
      "                , loss2: 1.0000415802001954\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2860 epoch, average loss: -169.16605224609376\n",
      "                , loss1: -8726.45\n",
      "                , loss2: 0.9997369766235351\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2870 epoch, average loss: -169.1661865234375\n",
      "                , loss1: -8726.45859375\n",
      "                , loss2: 0.9997689247131347\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2880 epoch, average loss: -169.16611328125\n",
      "                , loss1: -8726.47109375\n",
      "                , loss2: 1.0000805854797363\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2890 epoch, average loss: -169.1646728515625\n",
      "                , loss1: -8726.371875\n",
      "                , loss2: 0.9995837211608887\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2900 epoch, average loss: -169.16591796875\n",
      "                , loss1: -8726.42578125\n",
      "                , loss2: 0.9994129180908203\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2910 epoch, average loss: -169.1663330078125\n",
      "                , loss1: -8726.4703125\n",
      "                , loss2: 0.9998601913452149\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2920 epoch, average loss: -169.1668701171875\n",
      "                , loss1: -8726.50234375\n",
      "                , loss2: 0.9999301910400391\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2930 epoch, average loss: -169.16640625\n",
      "                , loss1: -8726.48046875\n",
      "                , loss2: 0.9999765396118164\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2940 epoch, average loss: -169.1659423828125\n",
      "                , loss1: -8726.45546875\n",
      "                , loss2: 0.9999517440795899\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2950 epoch, average loss: -169.16639404296876\n",
      "                , loss1: -8726.478125\n",
      "                , loss2: 0.9999028205871582\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2960 epoch, average loss: -169.1659423828125\n",
      "                , loss1: -8726.4328125\n",
      "                , loss2: 0.9994976043701171\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2970 epoch, average loss: -169.165966796875\n",
      "                , loss1: -8726.44375\n",
      "                , loss2: 0.9997063636779785\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2980 epoch, average loss: -169.1662353515625\n",
      "                , loss1: -8726.4796875\n",
      "                , loss2: 1.0001014709472655\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2990 epoch, average loss: -169.1666259765625\n",
      "                , loss1: -8726.4875\n",
      "                , loss2: 0.9998979568481445\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3000 epoch, average loss: -169.1656982421875\n",
      "                , loss1: -8726.44140625\n",
      "                , loss2: 0.999931812286377\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3010 epoch, average loss: -169.16473388671875\n",
      "                , loss1: -8726.40859375\n",
      "                , loss2: 1.0002365112304688\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3020 epoch, average loss: -169.16663818359376\n",
      "                , loss1: -8726.48828125\n",
      "                , loss2: 0.9998920440673829\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3030 epoch, average loss: -169.16700439453126\n",
      "                , loss1: -8726.50234375\n",
      "                , loss2: 0.9998065948486328\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3040 epoch, average loss: -169.16875\n",
      "                , loss1: -8726.3734375\n",
      "                , loss2: 0.9955497741699219\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3050 epoch, average loss: -169.1675537109375\n",
      "                , loss1: -8726.53671875\n",
      "                , loss2: 0.9999248504638671\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3060 epoch, average loss: -169.16630859375\n",
      "                , loss1: -8726.47421875\n",
      "                , loss2: 0.9999431610107422\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3070 epoch, average loss: -169.16807861328124\n",
      "                , loss1: -8726.38984375\n",
      "                , loss2: 0.9965333938598633\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3080 epoch, average loss: -169.1669677734375\n",
      "                , loss1: -8726.46796875\n",
      "                , loss2: 0.999180793762207\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3090 epoch, average loss: -169.267431640625\n",
      "                , loss1: -8725.36484375\n",
      "                , loss2: 0.877195930480957\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3100 epoch, average loss: -169.7878662109375\n",
      "                , loss1: -8724.5578125\n",
      "                , loss2: 0.34100568294525146\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3110 epoch, average loss: -169.79927978515624\n",
      "                , loss1: -8726.090625\n",
      "                , loss2: 0.35947260856628416\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3120 epoch, average loss: -169.83121337890626\n",
      "                , loss1: -8726.58515625\n",
      "                , loss2: 0.33720648288726807\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3130 epoch, average loss: -169.84906005859375\n",
      "                , loss1: -8727.31171875\n",
      "                , loss2: 0.3335071802139282\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3140 epoch, average loss: -169.8514892578125\n",
      "                , loss1: -8727.4359375\n",
      "                , loss2: 0.33351502418518064\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3150 epoch, average loss: -169.8509521484375\n",
      "                , loss1: -8727.40234375\n",
      "                , loss2: 0.33339858055114746\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3160 epoch, average loss: -169.8520751953125\n",
      "                , loss1: -8727.459375\n",
      "                , loss2: 0.33341012001037595\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3170 epoch, average loss: -169.838037109375\n",
      "                , loss1: -8726.93984375\n",
      "                , loss2: 0.3373004913330078\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3180 epoch, average loss: -169.84866943359376\n",
      "                , loss1: -8727.29453125\n",
      "                , loss2: 0.3335717678070068\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3190 epoch, average loss: -169.84833984375\n",
      "                , loss1: -8727.2796875\n",
      "                , loss2: 0.3336085081100464\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3200 epoch, average loss: -169.84439697265626\n",
      "                , loss1: -8727.08203125\n",
      "                , loss2: 0.3337052345275879\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3210 epoch, average loss: -169.85086669921876\n",
      "                , loss1: -8727.3984375\n",
      "                , loss2: 0.3333900928497314\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3220 epoch, average loss: -169.8512451171875\n",
      "                , loss1: -8727.41875\n",
      "                , loss2: 0.33342363834381106\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3230 epoch, average loss: -169.8513916015625\n",
      "                , loss1: -8727.425\n",
      "                , loss2: 0.3334109544754028\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3240 epoch, average loss: -169.8520751953125\n",
      "                , loss1: -8727.45859375\n",
      "                , loss2: 0.3333718776702881\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3250 epoch, average loss: -169.8521484375\n",
      "                , loss1: -8727.46171875\n",
      "                , loss2: 0.3333543300628662\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3260 epoch, average loss: -169.85152587890624\n",
      "                , loss1: -8727.43203125\n",
      "                , loss2: 0.3334080696105957\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3270 epoch, average loss: -169.85206298828126\n",
      "                , loss1: -8727.45625\n",
      "                , loss2: 0.3333369255065918\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3280 epoch, average loss: -169.8525390625\n",
      "                , loss1: -8727.4828125\n",
      "                , loss2: 0.3333805799484253\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3290 epoch, average loss: -169.852392578125\n",
      "                , loss1: -8727.4703125\n",
      "                , loss2: 0.3332951545715332\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3300 epoch, average loss: -169.85125732421875\n",
      "                , loss1: -8727.41796875\n",
      "                , loss2: 0.33340771198272706\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3310 epoch, average loss: -169.85244140625\n",
      "                , loss1: -8727.4765625\n",
      "                , loss2: 0.3333528995513916\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3320 epoch, average loss: -169.85137939453125\n",
      "                , loss1: -8727.42265625\n",
      "                , loss2: 0.33337059020996096\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3330 epoch, average loss: -169.8516845703125\n",
      "                , loss1: -8727.4328125\n",
      "                , loss2: 0.33324902057647704\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3340 epoch, average loss: -169.85279541015626\n",
      "                , loss1: -8727.496875\n",
      "                , loss2: 0.33340630531311033\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3350 epoch, average loss: -169.85235595703125\n",
      "                , loss1: -8727.48046875\n",
      "                , loss2: 0.33350720405578616\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3360 epoch, average loss: -169.85289306640624\n",
      "                , loss1: -8727.50078125\n",
      "                , loss2: 0.33337950706481934\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3370 epoch, average loss: -169.85159912109376\n",
      "                , loss1: -8727.43203125\n",
      "                , loss2: 0.3333261013031006\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3380 epoch, average loss: -169.8525390625\n",
      "                , loss1: -8727.48046875\n",
      "                , loss2: 0.333350396156311\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3390 epoch, average loss: -169.8524658203125\n",
      "                , loss1: -8727.47734375\n",
      "                , loss2: 0.33332672119140627\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3400 epoch, average loss: -169.85284423828125\n",
      "                , loss1: -8727.4984375\n",
      "                , loss2: 0.3333866834640503\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3410 epoch, average loss: -169.8521484375\n",
      "                , loss1: -8727.4640625\n",
      "                , loss2: 0.33341031074523925\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3420 epoch, average loss: -169.852783203125\n",
      "                , loss1: -8727.4953125\n",
      "                , loss2: 0.33337788581848143\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3430 epoch, average loss: -169.8521240234375\n",
      "                , loss1: -8727.4625\n",
      "                , loss2: 0.333408784866333\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3440 epoch, average loss: -169.85262451171874\n",
      "                , loss1: -8727.490625\n",
      "                , loss2: 0.3334455966949463\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3450 epoch, average loss: -169.85299072265624\n",
      "                , loss1: -8727.5015625\n",
      "                , loss2: 0.3332974910736084\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3460 epoch, average loss: -169.85250244140624\n",
      "                , loss1: -8727.4796875\n",
      "                , loss2: 0.3333735942840576\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3470 epoch, average loss: -169.853076171875\n",
      "                , loss1: -8727.5109375\n",
      "                , loss2: 0.3334106206893921\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3480 epoch, average loss: -169.85306396484376\n",
      "                , loss1: -8727.509375\n",
      "                , loss2: 0.33337256908416746\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3490 epoch, average loss: -169.85230712890626\n",
      "                , loss1: -8727.4734375\n",
      "                , loss2: 0.3334120035171509\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3500 epoch, average loss: -169.8532470703125\n",
      "                , loss1: -8727.51796875\n",
      "                , loss2: 0.33335413932800295\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3510 epoch, average loss: -169.8521240234375\n",
      "                , loss1: -8727.465625\n",
      "                , loss2: 0.3334731340408325\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3520 epoch, average loss: -169.85360107421874\n",
      "                , loss1: -8727.5375\n",
      "                , loss2: 0.33338313102722167\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3530 epoch, average loss: -169.852099609375\n",
      "                , loss1: -8727.4578125\n",
      "                , loss2: 0.3333279609680176\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3540 epoch, average loss: -169.8531982421875\n",
      "                , loss1: -8727.5125\n",
      "                , loss2: 0.33331224918365476\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3550 epoch, average loss: -169.85313720703124\n",
      "                , loss1: -8727.509375\n",
      "                , loss2: 0.333279013633728\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3560 epoch, average loss: -169.8529541015625\n",
      "                , loss1: -8727.503125\n",
      "                , loss2: 0.3333763122558594\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3570 epoch, average loss: -169.8532470703125\n",
      "                , loss1: -8727.5203125\n",
      "                , loss2: 0.33342738151550294\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3580 epoch, average loss: -169.852783203125\n",
      "                , loss1: -8727.49609375\n",
      "                , loss2: 0.3333645582199097\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3590 epoch, average loss: -169.85230712890626\n",
      "                , loss1: -8727.4671875\n",
      "                , loss2: 0.33332290649414065\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3600 epoch, average loss: -169.8529296875\n",
      "                , loss1: -8727.503125\n",
      "                , loss2: 0.3333897590637207\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3610 epoch, average loss: -169.85367431640626\n",
      "                , loss1: -8727.53828125\n",
      "                , loss2: 0.3333150863647461\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3620 epoch, average loss: -169.85316162109376\n",
      "                , loss1: -8727.5109375\n",
      "                , loss2: 0.3333263635635376\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3630 epoch, average loss: -169.853955078125\n",
      "                , loss1: -8727.55390625\n",
      "                , loss2: 0.3333268165588379\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3640 epoch, average loss: -169.8532470703125\n",
      "                , loss1: -8727.5140625\n",
      "                , loss2: 0.33327112197875974\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3650 epoch, average loss: -169.85311279296874\n",
      "                , loss1: -8727.5140625\n",
      "                , loss2: 0.3333993196487427\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3660 epoch, average loss: -169.8522216796875\n",
      "                , loss1: -8727.4640625\n",
      "                , loss2: 0.3333423614501953\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3670 epoch, average loss: -169.853076171875\n",
      "                , loss1: -8727.509375\n",
      "                , loss2: 0.33335607051849364\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3680 epoch, average loss: -169.85343017578126\n",
      "                , loss1: -8727.528125\n",
      "                , loss2: 0.3333689451217651\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3690 epoch, average loss: -169.85379638671876\n",
      "                , loss1: -8727.546875\n",
      "                , loss2: 0.333371639251709\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3700 epoch, average loss: -169.85347900390624\n",
      "                , loss1: -8727.528125\n",
      "                , loss2: 0.33331406116485596\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3710 epoch, average loss: -169.853173828125\n",
      "                , loss1: -8727.51484375\n",
      "                , loss2: 0.3333646059036255\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3720 epoch, average loss: -169.8529541015625\n",
      "                , loss1: -8727.50546875\n",
      "                , loss2: 0.33340179920196533\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3730 epoch, average loss: -169.84827880859376\n",
      "                , loss1: -8727.3015625\n",
      "                , loss2: 0.3341159105300903\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3740 epoch, average loss: -169.85335693359374\n",
      "                , loss1: -8727.52265625\n",
      "                , loss2: 0.33335204124450685\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3750 epoch, average loss: -169.8523681640625\n",
      "                , loss1: -8727.47578125\n",
      "                , loss2: 0.3334126710891724\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3760 epoch, average loss: -169.85362548828124\n",
      "                , loss1: -8727.5375\n",
      "                , loss2: 0.3333440780639648\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3770 epoch, average loss: -169.85328369140626\n",
      "                , loss1: -8727.52109375\n",
      "                , loss2: 0.3333789348602295\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3780 epoch, average loss: -169.85350341796874\n",
      "                , loss1: -8727.53125\n",
      "                , loss2: 0.3333573341369629\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3790 epoch, average loss: -169.8529296875\n",
      "                , loss1: -8727.50234375\n",
      "                , loss2: 0.33338000774383547\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3800 epoch, average loss: -169.853271484375\n",
      "                , loss1: -8727.51953125\n",
      "                , loss2: 0.33336141109466555\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3810 epoch, average loss: -169.85333251953125\n",
      "                , loss1: -8727.525\n",
      "                , loss2: 0.33339591026306153\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3820 epoch, average loss: -169.852978515625\n",
      "                , loss1: -8727.5046875\n",
      "                , loss2: 0.33336448669433594\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3830 epoch, average loss: -169.85379638671876\n",
      "                , loss1: -8727.54609375\n",
      "                , loss2: 0.3333839178085327\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3840 epoch, average loss: -169.853759765625\n",
      "                , loss1: -8727.54609375\n",
      "                , loss2: 0.33337233066558836\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3850 epoch, average loss: -169.8533203125\n",
      "                , loss1: -8727.52265625\n",
      "                , loss2: 0.33338274955749514\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3860 epoch, average loss: -169.85322265625\n",
      "                , loss1: -8727.51484375\n",
      "                , loss2: 0.33329899311065675\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3870 epoch, average loss: -169.8534423828125\n",
      "                , loss1: -8727.528125\n",
      "                , loss2: 0.3333608865737915\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3880 epoch, average loss: -169.8539306640625\n",
      "                , loss1: -8727.553125\n",
      "                , loss2: 0.33337059020996096\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3890 epoch, average loss: -169.85364990234376\n",
      "                , loss1: -8727.53828125\n",
      "                , loss2: 0.3333688020706177\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3900 epoch, average loss: -169.8538330078125\n",
      "                , loss1: -8727.546875\n",
      "                , loss2: 0.3333196878433228\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3910 epoch, average loss: -169.8529052734375\n",
      "                , loss1: -8727.5015625\n",
      "                , loss2: 0.333390474319458\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3920 epoch, average loss: -169.853955078125\n",
      "                , loss1: -8727.553125\n",
      "                , loss2: 0.3333531141281128\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3930 epoch, average loss: -169.85369873046875\n",
      "                , loss1: -8727.540625\n",
      "                , loss2: 0.33333210945129393\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3940 epoch, average loss: -169.85377197265626\n",
      "                , loss1: -8727.540625\n",
      "                , loss2: 0.33327808380126955\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3950 epoch, average loss: -169.8533447265625\n",
      "                , loss1: -8727.51953125\n",
      "                , loss2: 0.33328943252563475\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3960 epoch, average loss: -169.8541015625\n",
      "                , loss1: -8727.56015625\n",
      "                , loss2: 0.3333288192749023\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3970 epoch, average loss: -169.85380859375\n",
      "                , loss1: -8727.546875\n",
      "                , loss2: 0.33335118293762206\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3980 epoch, average loss: -169.85347900390624\n",
      "                , loss1: -8727.53046875\n",
      "                , loss2: 0.33337037563323973\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3990 epoch, average loss: -169.8539306640625\n",
      "                , loss1: -8727.5546875\n",
      "                , loss2: 0.3333580017089844\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4000 epoch, average loss: -169.8540283203125\n",
      "                , loss1: -8727.5578125\n",
      "                , loss2: 0.33335027694702146\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4010 epoch, average loss: -169.8542724609375\n",
      "                , loss1: -8727.56953125\n",
      "                , loss2: 0.3333308458328247\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4020 epoch, average loss: -169.85382080078125\n",
      "                , loss1: -8727.5453125\n",
      "                , loss2: 0.3333280563354492\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4030 epoch, average loss: -169.85419921875\n",
      "                , loss1: -8727.5640625\n",
      "                , loss2: 0.3333247423171997\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4040 epoch, average loss: -169.854296875\n",
      "                , loss1: -8727.5734375\n",
      "                , loss2: 0.333381199836731\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4050 epoch, average loss: -169.852490234375\n",
      "                , loss1: -8727.478125\n",
      "                , loss2: 0.333347749710083\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4060 epoch, average loss: -169.85374755859374\n",
      "                , loss1: -8727.54296875\n",
      "                , loss2: 0.3333446502685547\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4070 epoch, average loss: -169.85389404296876\n",
      "                , loss1: -8727.5515625\n",
      "                , loss2: 0.3333547830581665\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4080 epoch, average loss: -169.85325927734374\n",
      "                , loss1: -8727.5171875\n",
      "                , loss2: 0.3333331823348999\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4090 epoch, average loss: -169.85426025390626\n",
      "                , loss1: -8727.565625\n",
      "                , loss2: 0.33328163623809814\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4100 epoch, average loss: -169.85411376953124\n",
      "                , loss1: -8727.5625\n",
      "                , loss2: 0.333347225189209\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4110 epoch, average loss: -169.84664306640624\n",
      "                , loss1: -8727.1828125\n",
      "                , loss2: 0.3334156036376953\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4120 epoch, average loss: -169.85325927734374\n",
      "                , loss1: -8727.51328125\n",
      "                , loss2: 0.3332517623901367\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4130 epoch, average loss: -169.8536865234375\n",
      "                , loss1: -8727.540625\n",
      "                , loss2: 0.33336758613586426\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4140 epoch, average loss: -169.853515625\n",
      "                , loss1: -8727.534375\n",
      "                , loss2: 0.33340742588043215\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4150 epoch, average loss: -169.8543212890625\n",
      "                , loss1: -8727.57265625\n",
      "                , loss2: 0.3333484411239624\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4160 epoch, average loss: -169.85140380859374\n",
      "                , loss1: -8727.42421875\n",
      "                , loss2: 0.3333438396453857\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4170 epoch, average loss: -169.85462646484376\n",
      "                , loss1: -8727.58828125\n",
      "                , loss2: 0.33334100246429443\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4180 epoch, average loss: -169.8540771484375\n",
      "                , loss1: -8727.5625\n",
      "                , loss2: 0.33338949680328367\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4190 epoch, average loss: -169.853857421875\n",
      "                , loss1: -8727.546875\n",
      "                , loss2: 0.33333017826080324\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4200 epoch, average loss: -169.85421142578124\n",
      "                , loss1: -8727.56953125\n",
      "                , loss2: 0.3333897113800049\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4210 epoch, average loss: -169.85433349609374\n",
      "                , loss1: -8727.57265625\n",
      "                , loss2: 0.3333364248275757\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4220 epoch, average loss: -169.85426025390626\n",
      "                , loss1: -8727.56796875\n",
      "                , loss2: 0.33331029415130614\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4230 epoch, average loss: -169.85450439453126\n",
      "                , loss1: -8727.5828125\n",
      "                , loss2: 0.3333559274673462\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4240 epoch, average loss: -169.85428466796876\n",
      "                , loss1: -8727.5703125\n",
      "                , loss2: 0.3333414554595947\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4250 epoch, average loss: -169.854345703125\n",
      "                , loss1: -8727.57578125\n",
      "                , loss2: 0.33335731029510496\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4260 epoch, average loss: -169.854638671875\n",
      "                , loss1: -8727.58828125\n",
      "                , loss2: 0.33333008289337157\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4270 epoch, average loss: -169.8545166015625\n",
      "                , loss1: -8727.58359375\n",
      "                , loss2: 0.3333665609359741\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4280 epoch, average loss: -169.8544677734375\n",
      "                , loss1: -8727.578125\n",
      "                , loss2: 0.33330163955688474\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4290 epoch, average loss: -169.8545166015625\n",
      "                , loss1: -8727.58203125\n",
      "                , loss2: 0.3333344221115112\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4300 epoch, average loss: -169.85447998046874\n",
      "                , loss1: -8727.58046875\n",
      "                , loss2: 0.3333369493484497\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4310 epoch, average loss: -169.85458984375\n",
      "                , loss1: -8727.584375\n",
      "                , loss2: 0.33330669403076174\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4320 epoch, average loss: -169.85428466796876\n",
      "                , loss1: -8727.571875\n",
      "                , loss2: 0.3333836317062378\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4330 epoch, average loss: -169.8542724609375\n",
      "                , loss1: -8727.56796875\n",
      "                , loss2: 0.3333163022994995\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4340 epoch, average loss: -169.854296875\n",
      "                , loss1: -8727.56953125\n",
      "                , loss2: 0.3333038091659546\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4350 epoch, average loss: -169.8548828125\n",
      "                , loss1: -8727.6015625\n",
      "                , loss2: 0.3333736896514893\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4360 epoch, average loss: -169.85447998046874\n",
      "                , loss1: -8727.5765625\n",
      "                , loss2: 0.33328406810760497\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4370 epoch, average loss: -169.85491943359375\n",
      "                , loss1: -8727.603125\n",
      "                , loss2: 0.3333602428436279\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4380 epoch, average loss: -169.85499267578126\n",
      "                , loss1: -8727.6046875\n",
      "                , loss2: 0.33329675197601316\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4390 epoch, average loss: -169.85479736328125\n",
      "                , loss1: -8727.5921875\n",
      "                , loss2: 0.333280086517334\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4400 epoch, average loss: -169.85484619140624\n",
      "                , loss1: -8727.59609375\n",
      "                , loss2: 0.3332916259765625\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4410 epoch, average loss: -169.85479736328125\n",
      "                , loss1: -8727.59609375\n",
      "                , loss2: 0.33333094120025636\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4420 epoch, average loss: -169.8546630859375\n",
      "                , loss1: -8727.5890625\n",
      "                , loss2: 0.33332359790802\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4430 epoch, average loss: -169.85457763671874\n",
      "                , loss1: -8727.5859375\n",
      "                , loss2: 0.33333961963653563\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4440 epoch, average loss: -169.85458984375\n",
      "                , loss1: -8727.5828125\n",
      "                , loss2: 0.33328821659088137\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4450 epoch, average loss: -169.8551025390625\n",
      "                , loss1: -8727.6109375\n",
      "                , loss2: 0.3333099603652954\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4460 epoch, average loss: -169.85477294921876\n",
      "                , loss1: -8727.5953125\n",
      "                , loss2: 0.33332931995391846\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4470 epoch, average loss: -169.8545654296875\n",
      "                , loss1: -8727.58359375\n",
      "                , loss2: 0.33329780101776124\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4480 epoch, average loss: -169.8552978515625\n",
      "                , loss1: -8727.621875\n",
      "                , loss2: 0.3333226442337036\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4490 epoch, average loss: -169.8551025390625\n",
      "                , loss1: -8727.61015625\n",
      "                , loss2: 0.33328886032104493\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4500 epoch, average loss: -169.85496826171874\n",
      "                , loss1: -8727.603125\n",
      "                , loss2: 0.3332916975021362\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4510 epoch, average loss: -169.85504150390625\n",
      "                , loss1: -8727.60703125\n",
      "                , loss2: 0.3333118915557861\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4520 epoch, average loss: -169.8551025390625\n",
      "                , loss1: -8727.6109375\n",
      "                , loss2: 0.3333221673965454\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4530 epoch, average loss: -169.85484619140624\n",
      "                , loss1: -8727.5984375\n",
      "                , loss2: 0.3333338975906372\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4540 epoch, average loss: -169.85482177734374\n",
      "                , loss1: -8727.596875\n",
      "                , loss2: 0.33332004547119143\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4550 epoch, average loss: -169.85484619140624\n",
      "                , loss1: -8727.5984375\n",
      "                , loss2: 0.3333255767822266\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4560 epoch, average loss: -169.8546875\n",
      "                , loss1: -8727.59375\n",
      "                , loss2: 0.3333859920501709\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4570 epoch, average loss: -169.8438232421875\n",
      "                , loss1: -8727.0453125\n",
      "                , loss2: 0.3335516691207886\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4580 epoch, average loss: -169.8490478515625\n",
      "                , loss1: -8727.30078125\n",
      "                , loss2: 0.33333406448364256\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[614], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      6\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 7\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[609], line 31\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[0;32m---> 31\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mloss_bs_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[608], line 11\u001b[0m, in \u001b[0;36mloss_bs_matrix\u001b[0;34m(outs, hg, device, weight)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m对于超图的损失函数的矩阵形式.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    ``hg``(`Hypergraph`):  超图对象.  \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m outs \u001b[38;5;241m=\u001b[39m outs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m nn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(outs, (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(outs, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(1,20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "    hgnn_trainer.train()\n",
    "    # if loss_1 < -8500 and loss_2 < 2 and cut() < 5072:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5095"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([60., 61., 61., 60.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004132231404958678"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
