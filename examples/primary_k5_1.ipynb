{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 5\n",
    "\n",
    "weight = 0.93\n",
    "lr = 4e-3\n",
    "sub = 0.001\n",
    "limit = 0.01\n",
    "\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 242, \"out_channels\": 256, \"use_bn\": True, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\":256, \"out_channels\": 256, \"use_bn\":  True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers141\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\":  True, \"drop_rate\": 0.05}\n",
    "# h_hyper_prmts[\"convlayers142\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers143\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "\n",
    "\n",
    "\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":64, \"out_channels\":5, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12704, 242)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/primary\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=242, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=64, out_features=5, bias=True)\n",
       "  (9): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut():\n",
    "    hgnn_trainer.eval()\n",
    "    outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "    outs_straight = StraightThroughEstimator.apply(outs)\n",
    "    G_clone = G.clone()\n",
    "    edges, _  = G_clone.e\n",
    "    cut = 0\n",
    "    for vertices in edges:\n",
    "        if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "            cut += 1\n",
    "        else:\n",
    "            G_clone.remove_hyperedges(vertices)\n",
    "    assert cut == G_clone.num_e\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 10 epoch, average loss: -2423.2291015625\n",
      "                , loss1: -2711.746875\n",
      "                , loss2: 79.62192993164062\n",
      "                , weight: 0.92\n",
      "=================================\n",
      "in 20 epoch, average loss: -6133.216015625\n",
      "                , loss1: -6727.48359375\n",
      "                , loss2: 16.551904296875\n",
      "                , weight: 0.91\n",
      "=================================\n",
      "in 30 epoch, average loss: -7602.490625\n",
      "                , loss1: -8409.6625\n",
      "                , loss2: 3.5903060913085936\n",
      "                , weight: 0.9\n",
      "=================================\n",
      "in 40 epoch, average loss: -7740.0578125\n",
      "                , loss1: -8657.2125\n",
      "                , loss2: 3.7572555541992188\n",
      "                , weight: 0.89\n",
      "=================================\n",
      "in 50 epoch, average loss: -7690.0625\n",
      "                , loss1: -8698.5453125\n",
      "                , loss2: 3.788782501220703\n",
      "                , weight: 0.88\n",
      "=================================\n",
      "in 60 epoch, average loss: -7612.409375\n",
      "                , loss1: -8709.2140625\n",
      "                , loss2: 3.7948429107666017\n",
      "                , weight: 0.87\n",
      "=================================\n",
      "in 70 epoch, average loss: -7530.09921875\n",
      "                , loss1: -8714.74375\n",
      "                , loss2: 3.793833541870117\n",
      "                , weight: 0.86\n",
      "=================================\n",
      "in 80 epoch, average loss: -7445.2546875\n",
      "                , loss1: -8717.44453125\n",
      "                , loss2: 3.79940185546875\n",
      "                , weight: 0.85\n",
      "=================================\n",
      "in 90 epoch, average loss: -7359.8765625\n",
      "                , loss1: -8719.56875\n",
      "                , loss2: 3.798340606689453\n",
      "                , weight: 0.84\n",
      "=================================\n",
      "in 100 epoch, average loss: -7273.41796875\n",
      "                , loss1: -8720.453125\n",
      "                , loss2: 3.800089645385742\n",
      "                , weight: 0.83\n",
      "=================================\n",
      "in 110 epoch, average loss: -7187.5203125\n",
      "                , loss1: -8722.03046875\n",
      "                , loss2: 3.7941436767578125\n",
      "                , weight: 0.82\n",
      "=================================\n",
      "in 120 epoch, average loss: -7101.03671875\n",
      "                , loss1: -8722.93671875\n",
      "                , loss2: 3.7949905395507812\n",
      "                , weight: 0.8099999999999999\n",
      "=================================\n",
      "in 130 epoch, average loss: -7014.6734375\n",
      "                , loss1: -8724.01328125\n",
      "                , loss2: 3.7957508087158205\n",
      "                , weight: 0.7999999999999999\n",
      "=================================\n",
      "in 140 epoch, average loss: -6927.859375\n",
      "                , loss1: -8724.55234375\n",
      "                , loss2: 3.796000671386719\n",
      "                , weight: 0.7899999999999999\n",
      "=================================\n",
      "in 150 epoch, average loss: -6841.50078125\n",
      "                , loss1: -8725.68671875\n",
      "                , loss2: 3.79797477722168\n",
      "                , weight: 0.7799999999999999\n",
      "=================================\n",
      "in 160 epoch, average loss: -6754.834375\n",
      "                , loss1: -8726.4484375\n",
      "                , loss2: 3.799117660522461\n",
      "                , weight: 0.7699999999999999\n",
      "=================================\n",
      "in 170 epoch, average loss: -6668.3546875\n",
      "                , loss1: -8727.47421875\n",
      "                , loss2: 3.7984245300292967\n",
      "                , weight: 0.7599999999999999\n",
      "=================================\n",
      "in 180 epoch, average loss: -6581.03984375\n",
      "                , loss1: -8727.41875\n",
      "                , loss2: 3.7973480224609375\n",
      "                , weight: 0.7499999999999999\n",
      "=================================\n",
      "in 190 epoch, average loss: -6494.37578125\n",
      "                , loss1: -8728.2390625\n",
      "                , loss2: 3.7979496002197264\n",
      "                , weight: 0.7399999999999999\n",
      "=================================\n",
      "in 200 epoch, average loss: -6407.2\n",
      "                , loss1: -8728.3890625\n",
      "                , loss2: 3.7993408203125\n",
      "                , weight: 0.7299999999999999\n",
      "=================================\n",
      "in 210 epoch, average loss: -6320.094140625\n",
      "                , loss1: -8728.63359375\n",
      "                , loss2: 3.8003963470458983\n",
      "                , weight: 0.7199999999999999\n",
      "=================================\n",
      "in 220 epoch, average loss: -6232.9\n",
      "                , loss1: -8728.7625\n",
      "                , loss2: 3.7992919921875\n",
      "                , weight: 0.7099999999999999\n",
      "=================================\n",
      "in 230 epoch, average loss: -6146.16640625\n",
      "                , loss1: -8729.5484375\n",
      "                , loss2: 3.7992603302001955\n",
      "                , weight: 0.6999999999999998\n",
      "=================================\n",
      "in 240 epoch, average loss: -6058.88828125\n",
      "                , loss1: -8729.571875\n",
      "                , loss2: 3.7991973876953127\n",
      "                , weight: 0.6899999999999998\n",
      "=================================\n",
      "in 250 epoch, average loss: -5971.89765625\n",
      "                , loss1: -8730.01875\n",
      "                , loss2: 3.799799346923828\n",
      "                , weight: 0.6799999999999998\n",
      "=================================\n",
      "in 260 epoch, average loss: -5884.708984375\n",
      "                , loss1: -8730.1828125\n",
      "                , loss2: 3.79918212890625\n",
      "                , weight: 0.6699999999999998\n",
      "=================================\n",
      "in 270 epoch, average loss: -5797.7453125\n",
      "                , loss1: -8730.68828125\n",
      "                , loss2: 3.7976932525634766\n",
      "                , weight: 0.6599999999999998\n",
      "=================================\n",
      "in 280 epoch, average loss: -5710.480859375\n",
      "                , loss1: -8730.7578125\n",
      "                , loss2: 3.799983596801758\n",
      "                , weight: 0.6499999999999998\n",
      "=================================\n",
      "in 290 epoch, average loss: -5623.4390625\n",
      "                , loss1: -8731.16953125\n",
      "                , loss2: 3.7994178771972655\n",
      "                , weight: 0.6399999999999998\n",
      "=================================\n",
      "in 300 epoch, average loss: -5536.021875\n",
      "                , loss1: -8731.0015625\n",
      "                , loss2: 3.7984592437744142\n",
      "                , weight: 0.6299999999999998\n",
      "=================================\n",
      "in 310 epoch, average loss: -5448.865625\n",
      "                , loss1: -8731.24765625\n",
      "                , loss2: 3.7987388610839843\n",
      "                , weight: 0.6199999999999998\n",
      "=================================\n",
      "in 320 epoch, average loss: -5361.647265625\n",
      "                , loss1: -8731.4015625\n",
      "                , loss2: 3.7988971710205077\n",
      "                , weight: 0.6099999999999998\n",
      "=================================\n",
      "in 330 epoch, average loss: -5274.447265625\n",
      "                , loss1: -8731.590625\n",
      "                , loss2: 3.799205017089844\n",
      "                , weight: 0.5999999999999998\n",
      "=================================\n",
      "in 340 epoch, average loss: -5187.2203125\n",
      "                , loss1: -8731.7421875\n",
      "                , loss2: 3.800209808349609\n",
      "                , weight: 0.5899999999999997\n",
      "=================================\n",
      "in 350 epoch, average loss: -5099.95625\n",
      "                , loss1: -8731.83125\n",
      "                , loss2: 3.7993442535400392\n",
      "                , weight: 0.5799999999999997\n",
      "=================================\n",
      "in 360 epoch, average loss: -5012.687890625\n",
      "                , loss1: -8731.9203125\n",
      "                , loss2: 3.7991527557373046\n",
      "                , weight: 0.5699999999999997\n",
      "=================================\n",
      "in 370 epoch, average loss: -4925.423046875\n",
      "                , loss1: -8732.0171875\n",
      "                , loss2: 3.8001209259033204\n",
      "                , weight: 0.5599999999999997\n",
      "=================================\n",
      "in 380 epoch, average loss: -4838.168359375\n",
      "                , loss1: -8732.1328125\n",
      "                , loss2: 3.800164794921875\n",
      "                , weight: 0.5499999999999997\n",
      "=================================\n",
      "in 390 epoch, average loss: -4750.934375\n",
      "                , loss1: -8732.29375\n",
      "                , loss2: 3.8000606536865233\n",
      "                , weight: 0.5399999999999997\n",
      "=================================\n",
      "in 400 epoch, average loss: -4663.630859375\n",
      "                , loss1: -8732.33125\n",
      "                , loss2: 3.8003494262695314\n",
      "                , weight: 0.5299999999999997\n",
      "=================================\n",
      "in 410 epoch, average loss: -4576.3203125\n",
      "                , loss1: -8732.35390625\n",
      "                , loss2: 3.799515151977539\n",
      "                , weight: 0.5199999999999997\n",
      "=================================\n",
      "in 420 epoch, average loss: -4488.960546875\n",
      "                , loss1: -8732.2828125\n",
      "                , loss2: 3.799514389038086\n",
      "                , weight: 0.5099999999999997\n",
      "=================================\n",
      "in 430 epoch, average loss: -4401.757421875\n",
      "                , loss1: -8732.52109375\n",
      "                , loss2: 3.799486541748047\n",
      "                , weight: 0.49999999999999967\n",
      "=================================\n",
      "in 440 epoch, average loss: -4314.53125\n",
      "                , loss1: -8732.71953125\n",
      "                , loss2: 3.7993610382080076\n",
      "                , weight: 0.48999999999999966\n",
      "=================================\n",
      "in 450 epoch, average loss: -4227.261328125\n",
      "                , loss1: -8732.84140625\n",
      "                , loss2: 3.800020217895508\n",
      "                , weight: 0.47999999999999965\n",
      "=================================\n",
      "in 460 epoch, average loss: -4139.955078125\n",
      "                , loss1: -8732.8859375\n",
      "                , loss2: 3.7994155883789062\n",
      "                , weight: 0.46999999999999964\n",
      "=================================\n",
      "in 470 epoch, average loss: -4052.442578125\n",
      "                , loss1: -8732.49375\n",
      "                , loss2: 3.8002628326416015\n",
      "                , weight: 0.45999999999999963\n",
      "=================================\n",
      "in 480 epoch, average loss: -3965.372265625\n",
      "                , loss1: -8733.053125\n",
      "                , loss2: 3.7996356964111326\n",
      "                , weight: 0.4499999999999996\n",
      "=================================\n",
      "in 490 epoch, average loss: -3878.05078125\n",
      "                , loss1: -8733.071875\n",
      "                , loss2: 3.799521636962891\n",
      "                , weight: 0.4399999999999996\n",
      "=================================\n",
      "in 500 epoch, average loss: -3790.7125\n",
      "                , loss1: -8733.05625\n",
      "                , loss2: 3.8002197265625\n",
      "                , weight: 0.4299999999999996\n",
      "=================================\n",
      "in 510 epoch, average loss: -3703.483984375\n",
      "                , loss1: -8733.29296875\n",
      "                , loss2: 3.799308013916016\n",
      "                , weight: 0.4199999999999996\n",
      "=================================\n",
      "in 520 epoch, average loss: -3616.074609375\n",
      "                , loss1: -8733.1109375\n",
      "                , loss2: 3.7998725891113283\n",
      "                , weight: 0.4099999999999996\n",
      "=================================\n",
      "in 530 epoch, average loss: -3528.76484375\n",
      "                , loss1: -8733.1671875\n",
      "                , loss2: 3.800966262817383\n",
      "                , weight: 0.3999999999999996\n",
      "=================================\n",
      "in 540 epoch, average loss: -3441.466796875\n",
      "                , loss1: -8733.2515625\n",
      "                , loss2: 3.8002368927001955\n",
      "                , weight: 0.38999999999999957\n",
      "=================================\n",
      "in 550 epoch, average loss: -3354.1859375\n",
      "                , loss1: -8733.3828125\n",
      "                , loss2: 3.7993095397949217\n",
      "                , weight: 0.37999999999999956\n",
      "=================================\n",
      "in 560 epoch, average loss: -3266.8349609375\n",
      "                , loss1: -8733.3359375\n",
      "                , loss2: 3.7998279571533202\n",
      "                , weight: 0.36999999999999955\n",
      "=================================\n",
      "in 570 epoch, average loss: -3179.5447265625\n",
      "                , loss1: -8733.45546875\n",
      "                , loss2: 3.7998397827148436\n",
      "                , weight: 0.35999999999999954\n",
      "=================================\n",
      "in 580 epoch, average loss: -3092.2396484375\n",
      "                , loss1: -8733.53671875\n",
      "                , loss2: 3.7989662170410154\n",
      "                , weight: 0.34999999999999953\n",
      "=================================\n",
      "in 590 epoch, average loss: -3004.8994140625\n",
      "                , loss1: -8733.5265625\n",
      "                , loss2: 3.799967575073242\n",
      "                , weight: 0.3399999999999995\n",
      "=================================\n",
      "in 600 epoch, average loss: -2917.57109375\n",
      "                , loss1: -8733.546875\n",
      "                , loss2: 3.799835205078125\n",
      "                , weight: 0.3299999999999995\n",
      "=================================\n",
      "in 610 epoch, average loss: -2830.1685546875\n",
      "                , loss1: -8733.3390625\n",
      "                , loss2: 3.7997745513916015\n",
      "                , weight: 0.3199999999999995\n",
      "=================================\n",
      "in 620 epoch, average loss: -2742.8568359375\n",
      "                , loss1: -8733.40859375\n",
      "                , loss2: 3.8002185821533203\n",
      "                , weight: 0.3099999999999995\n",
      "=================================\n",
      "in 630 epoch, average loss: -2655.5998046875\n",
      "                , loss1: -8733.65859375\n",
      "                , loss2: 3.7989994049072267\n",
      "                , weight: 0.2999999999999995\n",
      "=================================\n",
      "in 640 epoch, average loss: -2568.259765625\n",
      "                , loss1: -8733.646875\n",
      "                , loss2: 3.7992347717285155\n",
      "                , weight: 0.2899999999999995\n",
      "=================================\n",
      "in 650 epoch, average loss: -2480.923046875\n",
      "                , loss1: -8733.6484375\n",
      "                , loss2: 3.7996116638183595\n",
      "                , weight: 0.27999999999999947\n",
      "=================================\n",
      "in 660 epoch, average loss: -2393.5783203125\n",
      "                , loss1: -8733.6171875\n",
      "                , loss2: 3.799138641357422\n",
      "                , weight: 0.26999999999999946\n",
      "=================================\n",
      "in 670 epoch, average loss: -2306.2828125\n",
      "                , loss1: -8733.76953125\n",
      "                , loss2: 3.7991939544677735\n",
      "                , weight: 0.25999999999999945\n",
      "=================================\n",
      "in 680 epoch, average loss: -2218.966796875\n",
      "                , loss1: -8733.85703125\n",
      "                , loss2: 3.799515151977539\n",
      "                , weight: 0.24999999999999944\n",
      "=================================\n",
      "in 690 epoch, average loss: -2131.5802734375\n",
      "                , loss1: -8733.66015625\n",
      "                , loss2: 3.7992786407470702\n",
      "                , weight: 0.23999999999999944\n",
      "=================================\n",
      "in 700 epoch, average loss: -2044.2634765625\n",
      "                , loss1: -8733.7453125\n",
      "                , loss2: 3.799900436401367\n",
      "                , weight: 0.22999999999999943\n",
      "=================================\n",
      "in 710 epoch, average loss: -1956.9189453125\n",
      "                , loss1: -8733.715625\n",
      "                , loss2: 3.800070571899414\n",
      "                , weight: 0.21999999999999942\n",
      "=================================\n",
      "in 720 epoch, average loss: -1869.6240234375\n",
      "                , loss1: -8733.9109375\n",
      "                , loss2: 3.7996986389160154\n",
      "                , weight: 0.2099999999999994\n",
      "=================================\n",
      "in 730 epoch, average loss: -1782.2736328125\n",
      "                , loss1: -8733.853125\n",
      "                , loss2: 3.7992443084716796\n",
      "                , weight: 0.1999999999999994\n",
      "=================================\n",
      "in 740 epoch, average loss: -1694.933203125\n",
      "                , loss1: -8733.84453125\n",
      "                , loss2: 3.7995979309082033\n",
      "                , weight: 0.1899999999999994\n",
      "=================================\n",
      "in 750 epoch, average loss: -1607.598828125\n",
      "                , loss1: -8733.865625\n",
      "                , loss2: 3.7994861602783203\n",
      "                , weight: 0.17999999999999938\n",
      "=================================\n",
      "in 760 epoch, average loss: -1520.26845703125\n",
      "                , loss1: -8733.91484375\n",
      "                , loss2: 3.7994052886962892\n",
      "                , weight: 0.16999999999999937\n",
      "=================================\n",
      "in 770 epoch, average loss: -1432.92265625\n",
      "                , loss1: -8733.86953125\n",
      "                , loss2: 3.7989776611328123\n",
      "                , weight: 0.15999999999999936\n",
      "=================================\n",
      "in 780 epoch, average loss: -1345.57021484375\n",
      "                , loss1: -8733.78515625\n",
      "                , loss2: 3.799517822265625\n",
      "                , weight: 0.14999999999999936\n",
      "=================================\n",
      "in 790 epoch, average loss: -1258.24443359375\n",
      "                , loss1: -8733.86953125\n",
      "                , loss2: 3.799494171142578\n",
      "                , weight: 0.13999999999999935\n",
      "=================================\n",
      "in 800 epoch, average loss: -1170.91025390625\n",
      "                , loss1: -8733.90234375\n",
      "                , loss2: 3.799785614013672\n",
      "                , weight: 0.12999999999999934\n",
      "=================================\n",
      "in 810 epoch, average loss: -1083.58525390625\n",
      "                , loss1: -8734.01640625\n",
      "                , loss2: 3.7998424530029298\n",
      "                , weight: 0.11999999999999933\n",
      "=================================\n",
      "in 820 epoch, average loss: -996.2349609375\n",
      "                , loss1: -8733.9234375\n",
      "                , loss2: 3.7992298126220705\n",
      "                , weight: 0.10999999999999932\n",
      "=================================\n",
      "in 830 epoch, average loss: -908.90546875\n",
      "                , loss1: -8734.025\n",
      "                , loss2: 3.7999649047851562\n",
      "                , weight: 0.09999999999999931\n",
      "=================================\n",
      "in 840 epoch, average loss: -821.551953125\n",
      "                , loss1: -8733.88515625\n",
      "                , loss2: 3.8001777648925783\n",
      "                , weight: 0.0899999999999993\n",
      "=================================\n",
      "in 850 epoch, average loss: -734.222998046875\n",
      "                , loss1: -8733.9984375\n",
      "                , loss2: 3.799616241455078\n",
      "                , weight: 0.0799999999999993\n",
      "=================================\n",
      "in 860 epoch, average loss: -646.876953125\n",
      "                , loss1: -8733.915625\n",
      "                , loss2: 3.7997726440429687\n",
      "                , weight: 0.06999999999999929\n",
      "=================================\n",
      "in 870 epoch, average loss: -559.53955078125\n",
      "                , loss1: -8733.94140625\n",
      "                , loss2: 3.799512481689453\n",
      "                , weight: 0.059999999999999276\n",
      "=================================\n",
      "in 880 epoch, average loss: -472.20458984375\n",
      "                , loss1: -8734.021875\n",
      "                , loss2: 3.799365997314453\n",
      "                , weight: 0.04999999999999927\n",
      "=================================\n",
      "in 890 epoch, average loss: -384.865966796875\n",
      "                , loss1: -8734.05546875\n",
      "                , loss2: 3.799655532836914\n",
      "                , weight: 0.03999999999999926\n",
      "=================================\n",
      "in 900 epoch, average loss: -297.519482421875\n",
      "                , loss1: -8733.8984375\n",
      "                , loss2: 3.799679183959961\n",
      "                , weight: 0.02999999999999925\n",
      "=================================\n",
      "in 910 epoch, average loss: -210.1837890625\n",
      "                , loss1: -8734.0296875\n",
      "                , loss2: 3.799754333496094\n",
      "                , weight: 0.01999999999999924\n",
      "=================================\n",
      "in 920 epoch, average loss: -122.8426513671875\n",
      "                , loss1: -8733.9375\n",
      "                , loss2: 3.799640655517578\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 930 epoch, average loss: -83.54115600585938\n",
      "                , loss1: -8734.078125\n",
      "                , loss2: 3.799633026123047\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 940 epoch, average loss: -83.54003295898437\n",
      "                , loss1: -8733.9890625\n",
      "                , loss2: 3.799862289428711\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 950 epoch, average loss: -83.5402099609375\n",
      "                , loss1: -8734.0109375\n",
      "                , loss2: 3.7999011993408205\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 960 epoch, average loss: -83.54131469726562\n",
      "                , loss1: -8734.0734375\n",
      "                , loss2: 3.799404525756836\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 970 epoch, average loss: -83.54122924804688\n",
      "                , loss1: -8734.09375\n",
      "                , loss2: 3.7997058868408202\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 980 epoch, average loss: -83.54087524414062\n",
      "                , loss1: -8734.03046875\n",
      "                , loss2: 3.799422836303711\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 990 epoch, average loss: -83.54082641601562\n",
      "                , loss1: -8734.00625\n",
      "                , loss2: 3.799237060546875\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1000 epoch, average loss: -83.53948974609375\n",
      "                , loss1: -8733.88125\n",
      "                , loss2: 3.7993274688720704\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1010 epoch, average loss: -83.54076538085937\n",
      "                , loss1: -8734.05390625\n",
      "                , loss2: 3.7997756958007813\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1020 epoch, average loss: -83.54083862304688\n",
      "                , loss1: -8734.03046875\n",
      "                , loss2: 3.799472427368164\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1030 epoch, average loss: -83.5412109375\n",
      "                , loss1: -8734.0390625\n",
      "                , loss2: 3.7991729736328126\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1040 epoch, average loss: -83.54072265625\n",
      "                , loss1: -8733.971875\n",
      "                , loss2: 3.79901008605957\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1050 epoch, average loss: -83.54065551757813\n",
      "                , loss1: -8734.05859375\n",
      "                , loss2: 3.799928665161133\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1060 epoch, average loss: -83.53991088867187\n",
      "                , loss1: -8733.940625\n",
      "                , loss2: 3.799495315551758\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1070 epoch, average loss: -83.54134521484374\n",
      "                , loss1: -8734.0796875\n",
      "                , loss2: 3.7994663238525392\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1080 epoch, average loss: -83.53976440429688\n",
      "                , loss1: -8733.96171875\n",
      "                , loss2: 3.7998577117919923\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1090 epoch, average loss: -83.53992919921875\n",
      "                , loss1: -8733.93984375\n",
      "                , loss2: 3.7994609832763673\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1100 epoch, average loss: -83.541650390625\n",
      "                , loss1: -8734.1140625\n",
      "                , loss2: 3.799485778808594\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1110 epoch, average loss: -83.54030151367188\n",
      "                , loss1: -8733.98125\n",
      "                , loss2: 3.7995063781738283\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1120 epoch, average loss: -83.54102783203125\n",
      "                , loss1: -8734.01015625\n",
      "                , loss2: 3.7990798950195312\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1130 epoch, average loss: -83.54105224609376\n",
      "                , loss1: -8734.04140625\n",
      "                , loss2: 3.799351119995117\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1140 epoch, average loss: -83.54137573242187\n",
      "                , loss1: -8734.06640625\n",
      "                , loss2: 3.7992885589599608\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1150 epoch, average loss: -83.54218139648438\n",
      "                , loss1: -8734.10703125\n",
      "                , loss2: 3.798885726928711\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1160 epoch, average loss: -83.541796875\n",
      "                , loss1: -8734.0546875\n",
      "                , loss2: 3.7987445831298827\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1170 epoch, average loss: -83.54044189453126\n",
      "                , loss1: -8733.990625\n",
      "                , loss2: 3.799454116821289\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1180 epoch, average loss: -83.54110717773438\n",
      "                , loss1: -8734.0296875\n",
      "                , loss2: 3.7991867065429688\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1190 epoch, average loss: -83.54091186523438\n",
      "                , loss1: -8733.99921875\n",
      "                , loss2: 3.7990768432617186\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1200 epoch, average loss: -83.53964233398438\n",
      "                , loss1: -8733.88828125\n",
      "                , loss2: 3.7992271423339843\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1210 epoch, average loss: -83.541015625\n",
      "                , loss1: -8734.059375\n",
      "                , loss2: 3.7995883941650392\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1220 epoch, average loss: -83.54219970703124\n",
      "                , loss1: -8734.10859375\n",
      "                , loss2: 3.7988800048828124\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1230 epoch, average loss: -83.54066162109375\n",
      "                , loss1: -8733.9796875\n",
      "                , loss2: 3.799136734008789\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1240 epoch, average loss: -83.54132690429688\n",
      "                , loss1: -8734.0671875\n",
      "                , loss2: 3.7993396759033202\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1250 epoch, average loss: -83.5402587890625\n",
      "                , loss1: -8733.9421875\n",
      "                , loss2: 3.7991653442382813\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1260 epoch, average loss: -83.54153442382812\n",
      "                , loss1: -8734.02265625\n",
      "                , loss2: 3.7986846923828126\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1270 epoch, average loss: -83.5420166015625\n",
      "                , loss1: -8734.1265625\n",
      "                , loss2: 3.7992622375488283\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1280 epoch, average loss: -83.5418212890625\n",
      "                , loss1: -8734.07734375\n",
      "                , loss2: 3.798953628540039\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1290 epoch, average loss: -83.5396484375\n",
      "                , loss1: -8733.9640625\n",
      "                , loss2: 3.7999832153320314\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1300 epoch, average loss: -83.54093017578126\n",
      "                , loss1: -8734.03359375\n",
      "                , loss2: 3.7994007110595702\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1310 epoch, average loss: -83.54185180664062\n",
      "                , loss1: -8733.9953125\n",
      "                , loss2: 3.798093795776367\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1320 epoch, average loss: -83.54031372070312\n",
      "                , loss1: -8733.9265625\n",
      "                , loss2: 3.7989456176757814\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1330 epoch, average loss: -83.5408447265625\n",
      "                , loss1: -8733.98671875\n",
      "                , loss2: 3.799024963378906\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1340 epoch, average loss: -83.54118041992187\n",
      "                , loss1: -8733.99921875\n",
      "                , loss2: 3.798808288574219\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1350 epoch, average loss: -83.54085693359374\n",
      "                , loss1: -8734.01953125\n",
      "                , loss2: 3.799343490600586\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1360 epoch, average loss: -83.54179077148437\n",
      "                , loss1: -8734.0546875\n",
      "                , loss2: 3.7987434387207033\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1370 epoch, average loss: -83.53927612304688\n",
      "                , loss1: -8733.86328125\n",
      "                , loss2: 3.799357223510742\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1380 epoch, average loss: -83.54183349609374\n",
      "                , loss1: -8734.084375\n",
      "                , loss2: 3.7990047454833986\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1390 epoch, average loss: -83.54227905273437\n",
      "                , loss1: -8734.12578125\n",
      "                , loss2: 3.7989845275878906\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1400 epoch, average loss: -83.53975219726563\n",
      "                , loss1: -8733.915625\n",
      "                , loss2: 3.799409866333008\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1410 epoch, average loss: -83.5409912109375\n",
      "                , loss1: -8733.9625\n",
      "                , loss2: 3.798635482788086\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1420 epoch, average loss: -83.54182739257813\n",
      "                , loss1: -8734.0484375\n",
      "                , loss2: 3.7986507415771484\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1430 epoch, average loss: -83.54114990234375\n",
      "                , loss1: -8733.99296875\n",
      "                , loss2: 3.7987812042236326\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1440 epoch, average loss: -83.54122924804688\n",
      "                , loss1: -8734.0421875\n",
      "                , loss2: 3.799185943603516\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1450 epoch, average loss: -83.54232788085938\n",
      "                , loss1: -8734.1234375\n",
      "                , loss2: 3.798900604248047\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1460 epoch, average loss: -83.54257202148438\n",
      "                , loss1: -8734.08125\n",
      "                , loss2: 3.798249053955078\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1470 epoch, average loss: -83.54224853515625\n",
      "                , loss1: -8734.05390625\n",
      "                , loss2: 3.798284149169922\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1480 epoch, average loss: -83.54256591796874\n",
      "                , loss1: -8734.0703125\n",
      "                , loss2: 3.7981498718261717\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1490 epoch, average loss: -83.54285278320313\n",
      "                , loss1: -8734.09375\n",
      "                , loss2: 3.7980804443359375\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1500 epoch, average loss: -83.54203491210937\n",
      "                , loss1: -8733.96875\n",
      "                , loss2: 3.7976470947265626\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1510 epoch, average loss: -83.54140014648438\n",
      "                , loss1: -8733.86796875\n",
      "                , loss2: 3.7972774505615234\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1520 epoch, average loss: -83.97864379882813\n",
      "                , loss1: -8708.04765625\n",
      "                , loss2: 3.101828193664551\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1530 epoch, average loss: -85.02628173828126\n",
      "                , loss1: -8683.66015625\n",
      "                , loss2: 1.8103178024291993\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1540 epoch, average loss: -85.0433837890625\n",
      "                , loss1: -8684.22890625\n",
      "                , loss2: 1.7989025115966797\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1550 epoch, average loss: -85.04485473632812\n",
      "                , loss1: -8684.36484375\n",
      "                , loss2: 1.798786735534668\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1560 epoch, average loss: -85.04765014648437\n",
      "                , loss1: -8684.6359375\n",
      "                , loss2: 1.7987154006958008\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1570 epoch, average loss: -85.04888305664062\n",
      "                , loss1: -8684.69140625\n",
      "                , loss2: 1.7980195999145507\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1580 epoch, average loss: -85.04735717773437\n",
      "                , loss1: -8684.57578125\n",
      "                , loss2: 1.7983909606933595\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1590 epoch, average loss: -85.03551635742187\n",
      "                , loss1: -8685.53203125\n",
      "                , loss2: 1.8197999954223634\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1600 epoch, average loss: -85.03670654296874\n",
      "                , loss1: -8683.559375\n",
      "                , loss2: 1.7988805770874023\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1610 epoch, average loss: -85.0474609375\n",
      "                , loss1: -8684.53984375\n",
      "                , loss2: 1.7979541778564454\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1620 epoch, average loss: -85.04662475585937\n",
      "                , loss1: -8684.553125\n",
      "                , loss2: 1.7989032745361329\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1630 epoch, average loss: -85.04877319335938\n",
      "                , loss1: -8684.6703125\n",
      "                , loss2: 1.7979345321655273\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1640 epoch, average loss: -85.0474365234375\n",
      "                , loss1: -8684.55234375\n",
      "                , loss2: 1.7980749130249023\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1650 epoch, average loss: -85.0496337890625\n",
      "                , loss1: -8684.5921875\n",
      "                , loss2: 1.7962947845458985\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1660 epoch, average loss: -85.02030639648437\n",
      "                , loss1: -8686.653125\n",
      "                , loss2: 1.8462255477905274\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1670 epoch, average loss: -85.029345703125\n",
      "                , loss1: -8682.74921875\n",
      "                , loss2: 1.798141860961914\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1680 epoch, average loss: -85.0492919921875\n",
      "                , loss1: -8684.721875\n",
      "                , loss2: 1.7979183197021484\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1690 epoch, average loss: -85.04998779296875\n",
      "                , loss1: -8684.553125\n",
      "                , loss2: 1.7955520629882813\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1700 epoch, average loss: -85.04801025390626\n",
      "                , loss1: -8684.63203125\n",
      "                , loss2: 1.7983121871948242\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1710 epoch, average loss: -85.04910278320312\n",
      "                , loss1: -8684.659375\n",
      "                , loss2: 1.7974985122680665\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1720 epoch, average loss: -85.0341796875\n",
      "                , loss1: -8685.70390625\n",
      "                , loss2: 1.8228612899780274\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1730 epoch, average loss: -85.04706420898438\n",
      "                , loss1: -8684.38125\n",
      "                , loss2: 1.7967432022094727\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1740 epoch, average loss: -85.04714965820312\n",
      "                , loss1: -8684.33125\n",
      "                , loss2: 1.7961698532104493\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1750 epoch, average loss: -85.04736328125\n",
      "                , loss1: -8684.2765625\n",
      "                , loss2: 1.7954061508178711\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1760 epoch, average loss: -85.04857177734375\n",
      "                , loss1: -8684.19375\n",
      "                , loss2: 1.7933555603027345\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1770 epoch, average loss: -85.05712890625\n",
      "                , loss1: -8683.55546875\n",
      "                , loss2: 1.7784156799316406\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1780 epoch, average loss: -85.25399780273438\n",
      "                , loss1: -8661.5765625\n",
      "                , loss2: 1.3617828369140625\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1790 epoch, average loss: -85.81611328125\n",
      "                , loss1: -8640.3625\n",
      "                , loss2: 0.5875066757202149\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1800 epoch, average loss: -86.00186157226562\n",
      "                , loss1: -8641.240625\n",
      "                , loss2: 0.4105393886566162\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1810 epoch, average loss: -86.01783447265625\n",
      "                , loss1: -8642.72421875\n",
      "                , loss2: 0.40940470695495607\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1820 epoch, average loss: -86.0691162109375\n",
      "                , loss1: -8640.50703125\n",
      "                , loss2: 0.33595051765441897\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1830 epoch, average loss: -86.096484375\n",
      "                , loss1: -8639.7453125\n",
      "                , loss2: 0.30096142292022704\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1840 epoch, average loss: -86.09374389648437\n",
      "                , loss1: -8639.71875\n",
      "                , loss2: 0.3034400224685669\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1850 epoch, average loss: -86.10640869140624\n",
      "                , loss1: -8640.5578125\n",
      "                , loss2: 0.2991718530654907\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1860 epoch, average loss: -86.10934448242188\n",
      "                , loss1: -8640.88515625\n",
      "                , loss2: 0.2995142459869385\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1870 epoch, average loss: -86.10978393554687\n",
      "                , loss1: -8640.88828125\n",
      "                , loss2: 0.2990862846374512\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1880 epoch, average loss: -86.110693359375\n",
      "                , loss1: -8640.9484375\n",
      "                , loss2: 0.29878897666931153\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1890 epoch, average loss: -86.10704345703125\n",
      "                , loss1: -8640.74765625\n",
      "                , loss2: 0.30043318271636965\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1900 epoch, average loss: -86.10807495117187\n",
      "                , loss1: -8640.509375\n",
      "                , loss2: 0.2970231294631958\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1910 epoch, average loss: -86.10905151367187\n",
      "                , loss1: -8640.81796875\n",
      "                , loss2: 0.2991161823272705\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1920 epoch, average loss: -86.11065673828125\n",
      "                , loss1: -8640.925\n",
      "                , loss2: 0.2986001491546631\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1930 epoch, average loss: -86.10039672851562\n",
      "                , loss1: -8641.2171875\n",
      "                , loss2: 0.3117835998535156\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1940 epoch, average loss: -86.10599365234376\n",
      "                , loss1: -8640.37265625\n",
      "                , loss2: 0.29772822856903075\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1950 epoch, average loss: -86.10816040039063\n",
      "                , loss1: -8640.684375\n",
      "                , loss2: 0.2986724853515625\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1960 epoch, average loss: -86.10924682617187\n",
      "                , loss1: -8640.8125\n",
      "                , loss2: 0.29887640476226807\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1970 epoch, average loss: -86.10933227539063\n",
      "                , loss1: -8640.83828125\n",
      "                , loss2: 0.2990497350692749\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1980 epoch, average loss: -86.10945434570313\n",
      "                , loss1: -8640.84453125\n",
      "                , loss2: 0.2989872694015503\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 1990 epoch, average loss: -86.11128540039063\n",
      "                , loss1: -8640.85625\n",
      "                , loss2: 0.2972637891769409\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2000 epoch, average loss: -86.111767578125\n",
      "                , loss1: -8640.86640625\n",
      "                , loss2: 0.29689319133758546\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2010 epoch, average loss: -86.11295166015626\n",
      "                , loss1: -8640.53984375\n",
      "                , loss2: 0.29245624542236326\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2020 epoch, average loss: -86.13777465820313\n",
      "                , loss1: -8638.259375\n",
      "                , loss2: 0.24481492042541503\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2030 epoch, average loss: -85.95411376953125\n",
      "                , loss1: -8639.38203125\n",
      "                , loss2: 0.43970479965209963\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2040 epoch, average loss: -86.10596313476563\n",
      "                , loss1: -8640.39609375\n",
      "                , loss2: 0.29799742698669435\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2050 epoch, average loss: -86.1082275390625\n",
      "                , loss1: -8640.7140625\n",
      "                , loss2: 0.29890663623809816\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2060 epoch, average loss: -86.11033325195312\n",
      "                , loss1: -8640.975\n",
      "                , loss2: 0.2994087219238281\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2070 epoch, average loss: -86.109521484375\n",
      "                , loss1: -8640.91796875\n",
      "                , loss2: 0.29966576099395753\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2080 epoch, average loss: -86.11002197265626\n",
      "                , loss1: -8640.9359375\n",
      "                , loss2: 0.2993335247039795\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2090 epoch, average loss: -86.09906005859375\n",
      "                , loss1: -8641.74140625\n",
      "                , loss2: 0.3183577060699463\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2100 epoch, average loss: -86.10989990234376\n",
      "                , loss1: -8640.9\n",
      "                , loss2: 0.2990913391113281\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2110 epoch, average loss: -86.10916137695312\n",
      "                , loss1: -8640.81015625\n",
      "                , loss2: 0.29893696308135986\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2120 epoch, average loss: -86.10814208984375\n",
      "                , loss1: -8640.6953125\n",
      "                , loss2: 0.2988054037094116\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2130 epoch, average loss: -86.11021728515625\n",
      "                , loss1: -8640.93203125\n",
      "                , loss2: 0.2991014003753662\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2140 epoch, average loss: -86.10980224609375\n",
      "                , loss1: -8640.921875\n",
      "                , loss2: 0.2994017362594604\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2150 epoch, average loss: -86.11098022460938\n",
      "                , loss1: -8641.01328125\n",
      "                , loss2: 0.29914164543151855\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2160 epoch, average loss: -86.10988159179688\n",
      "                , loss1: -8640.93359375\n",
      "                , loss2: 0.29945125579833987\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2170 epoch, average loss: -86.110888671875\n",
      "                , loss1: -8641.03203125\n",
      "                , loss2: 0.29943170547485354\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2180 epoch, average loss: -86.10870971679688\n",
      "                , loss1: -8640.8640625\n",
      "                , loss2: 0.29991908073425294\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2190 epoch, average loss: -86.11064453125\n",
      "                , loss1: -8641.01640625\n",
      "                , loss2: 0.2995173931121826\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2200 epoch, average loss: -86.11083984375\n",
      "                , loss1: -8641.03828125\n",
      "                , loss2: 0.29954335689544676\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2210 epoch, average loss: -86.11171264648438\n",
      "                , loss1: -8641.11640625\n",
      "                , loss2: 0.29944415092468263\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2220 epoch, average loss: -86.11080932617188\n",
      "                , loss1: -8641.01484375\n",
      "                , loss2: 0.29933786392211914\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2230 epoch, average loss: -86.112109375\n",
      "                , loss1: -8641.1609375\n",
      "                , loss2: 0.2994958162307739\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2240 epoch, average loss: -86.11190795898438\n",
      "                , loss1: -8641.13203125\n",
      "                , loss2: 0.29939889907836914\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2250 epoch, average loss: -86.11181030273437\n",
      "                , loss1: -8641.1171875\n",
      "                , loss2: 0.2993606090545654\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2260 epoch, average loss: -86.11148681640626\n",
      "                , loss1: -8641.06640625\n",
      "                , loss2: 0.29917116165161134\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2270 epoch, average loss: -86.11150512695312\n",
      "                , loss1: -8641.07578125\n",
      "                , loss2: 0.2992542266845703\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2280 epoch, average loss: -86.1121826171875\n",
      "                , loss1: -8641.134375\n",
      "                , loss2: 0.29915993213653563\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2290 epoch, average loss: -86.110595703125\n",
      "                , loss1: -8640.9640625\n",
      "                , loss2: 0.2990431547164917\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2300 epoch, average loss: -86.11182861328125\n",
      "                , loss1: -8641.10234375\n",
      "                , loss2: 0.2991976737976074\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2310 epoch, average loss: -86.11181030273437\n",
      "                , loss1: -8641.09453125\n",
      "                , loss2: 0.2991352558135986\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2320 epoch, average loss: -86.11116333007813\n",
      "                , loss1: -8641.03125\n",
      "                , loss2: 0.2991407632827759\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2330 epoch, average loss: -86.11176147460938\n",
      "                , loss1: -8641.075\n",
      "                , loss2: 0.2989834785461426\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2340 epoch, average loss: -86.111962890625\n",
      "                , loss1: -8641.1015625\n",
      "                , loss2: 0.29904904365539553\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2350 epoch, average loss: -86.11276245117188\n",
      "                , loss1: -8641.1515625\n",
      "                , loss2: 0.2987487554550171\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2360 epoch, average loss: -86.112744140625\n",
      "                , loss1: -8641.02421875\n",
      "                , loss2: 0.2974966526031494\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2370 epoch, average loss: -86.11064453125\n",
      "                , loss1: -8640.94296875\n",
      "                , loss2: 0.29878251552581786\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2380 epoch, average loss: -86.11263427734374\n",
      "                , loss1: -8641.1203125\n",
      "                , loss2: 0.29856874942779543\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2390 epoch, average loss: -86.11192016601562\n",
      "                , loss1: -8640.940625\n",
      "                , loss2: 0.29748594760894775\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2400 epoch, average loss: -86.10914916992188\n",
      "                , loss1: -8641.0578125\n",
      "                , loss2: 0.3014350414276123\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2410 epoch, average loss: -86.1126953125\n",
      "                , loss1: -8641.16875\n",
      "                , loss2: 0.29898319244384763\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2420 epoch, average loss: -86.1111328125\n",
      "                , loss1: -8641.0484375\n",
      "                , loss2: 0.2993431091308594\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2430 epoch, average loss: -86.11222534179687\n",
      "                , loss1: -8641.090625\n",
      "                , loss2: 0.29868526458740235\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2440 epoch, average loss: -86.11060791015625\n",
      "                , loss1: -8640.98046875\n",
      "                , loss2: 0.29919073581695554\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2450 epoch, average loss: -86.110546875\n",
      "                , loss1: -8640.96640625\n",
      "                , loss2: 0.29910078048706057\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2460 epoch, average loss: -86.11170043945313\n",
      "                , loss1: -8641.06328125\n",
      "                , loss2: 0.2989256143569946\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2470 epoch, average loss: -86.11138305664062\n",
      "                , loss1: -8641.0921875\n",
      "                , loss2: 0.2995413541793823\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2480 epoch, average loss: -86.11185302734376\n",
      "                , loss1: -8641.071875\n",
      "                , loss2: 0.29886293411254883\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2490 epoch, average loss: -86.1121337890625\n",
      "                , loss1: -8641.12265625\n",
      "                , loss2: 0.29908525943756104\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2500 epoch, average loss: -86.111865234375\n",
      "                , loss1: -8641.06640625\n",
      "                , loss2: 0.2988002300262451\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2510 epoch, average loss: -86.11226196289063\n",
      "                , loss1: -8641.1125\n",
      "                , loss2: 0.29885475635528563\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2520 epoch, average loss: -86.1133056640625\n",
      "                , loss1: -8641.08359375\n",
      "                , loss2: 0.2975334405899048\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2530 epoch, average loss: -86.11419677734375\n",
      "                , loss1: -8641.19609375\n",
      "                , loss2: 0.2977603435516357\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2540 epoch, average loss: -86.1131591796875\n",
      "                , loss1: -8640.94921875\n",
      "                , loss2: 0.2963418006896973\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2550 epoch, average loss: -86.1162841796875\n",
      "                , loss1: -8640.4078125\n",
      "                , loss2: 0.2877943515777588\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2560 epoch, average loss: -86.12158203125\n",
      "                , loss1: -8640.19375\n",
      "                , loss2: 0.2803558111190796\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2570 epoch, average loss: -86.12962646484375\n",
      "                , loss1: -8638.353125\n",
      "                , loss2: 0.25390594005584716\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2580 epoch, average loss: -86.16528930664063\n",
      "                , loss1: -8635.9171875\n",
      "                , loss2: 0.19388397932052612\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2590 epoch, average loss: -86.16771850585937\n",
      "                , loss1: -8635.49375\n",
      "                , loss2: 0.18722054958343506\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2600 epoch, average loss: -86.15941162109375\n",
      "                , loss1: -8635.94375\n",
      "                , loss2: 0.20001533031463622\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2610 epoch, average loss: -86.14859619140626\n",
      "                , loss1: -8637.78359375\n",
      "                , loss2: 0.22925214767456054\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2620 epoch, average loss: -86.1670166015625\n",
      "                , loss1: -8635.815625\n",
      "                , loss2: 0.1911403179168701\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2630 epoch, average loss: -86.1704833984375\n",
      "                , loss1: -8635.85078125\n",
      "                , loss2: 0.18801937103271485\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2640 epoch, average loss: -86.167626953125\n",
      "                , loss1: -8635.96640625\n",
      "                , loss2: 0.19204803705215454\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2650 epoch, average loss: -86.16964111328124\n",
      "                , loss1: -8636.3765625\n",
      "                , loss2: 0.19411548376083373\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2660 epoch, average loss: -86.17435913085937\n",
      "                , loss1: -8635.565625\n",
      "                , loss2: 0.18128434419631959\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2670 epoch, average loss: -86.17178955078126\n",
      "                , loss1: -8636.06875\n",
      "                , loss2: 0.1889028787612915\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2680 epoch, average loss: -86.17138061523437\n",
      "                , loss1: -8636.409375\n",
      "                , loss2: 0.19271985292434693\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2690 epoch, average loss: -86.14767456054688\n",
      "                , loss1: -8636.8296875\n",
      "                , loss2: 0.22061288356781006\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2700 epoch, average loss: -86.14672241210937\n",
      "                , loss1: -8638.125\n",
      "                , loss2: 0.23452556133270264\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2710 epoch, average loss: -86.1714111328125\n",
      "                , loss1: -8635.8765625\n",
      "                , loss2: 0.18734999895095825\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2720 epoch, average loss: -86.17163696289063\n",
      "                , loss1: -8636.1890625\n",
      "                , loss2: 0.19025943279266358\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2730 epoch, average loss: -86.1740966796875\n",
      "                , loss1: -8635.75234375\n",
      "                , loss2: 0.1834293484687805\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2740 epoch, average loss: -86.17040405273437\n",
      "                , loss1: -8636.1578125\n",
      "                , loss2: 0.1911760687828064\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2750 epoch, average loss: -86.177783203125\n",
      "                , loss1: -8635.5640625\n",
      "                , loss2: 0.177862286567688\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2760 epoch, average loss: -86.17373046875\n",
      "                , loss1: -8635.928125\n",
      "                , loss2: 0.18555030822753907\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2770 epoch, average loss: -86.17344970703125\n",
      "                , loss1: -8636.0078125\n",
      "                , loss2: 0.18663378953933715\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2780 epoch, average loss: -86.1766357421875\n",
      "                , loss1: -8636.09453125\n",
      "                , loss2: 0.1843089461326599\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2790 epoch, average loss: -86.17762451171875\n",
      "                , loss1: -8636.03515625\n",
      "                , loss2: 0.1827294111251831\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2800 epoch, average loss: -86.1736572265625\n",
      "                , loss1: -8636.54609375\n",
      "                , loss2: 0.19179937839508057\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2810 epoch, average loss: -86.28242797851563\n",
      "                , loss1: -8655.04921875\n",
      "                , loss2: 0.2680635929107666\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2820 epoch, average loss: -86.32633666992187\n",
      "                , loss1: -8666.43203125\n",
      "                , loss2: 0.33798580169677733\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2830 epoch, average loss: -86.38299560546875\n",
      "                , loss1: -8668.77109375\n",
      "                , loss2: 0.30471761226654054\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2840 epoch, average loss: -86.39205932617188\n",
      "                , loss1: -8669.2109375\n",
      "                , loss2: 0.300054144859314\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2850 epoch, average loss: -86.39317626953125\n",
      "                , loss1: -8669.3734375\n",
      "                , loss2: 0.30055620670318606\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2860 epoch, average loss: -86.35621337890625\n",
      "                , loss1: -8669.35390625\n",
      "                , loss2: 0.33732242584228517\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2870 epoch, average loss: -86.38786010742187\n",
      "                , loss1: -8668.78046875\n",
      "                , loss2: 0.2999410152435303\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2880 epoch, average loss: -86.39208374023437\n",
      "                , loss1: -8669.159375\n",
      "                , loss2: 0.29950966835021975\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2890 epoch, average loss: -86.3936767578125\n",
      "                , loss1: -8669.4\n",
      "                , loss2: 0.3003039836883545\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2900 epoch, average loss: -86.39597778320312\n",
      "                , loss1: -8669.575\n",
      "                , loss2: 0.29977967739105227\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2910 epoch, average loss: -86.39600219726563\n",
      "                , loss1: -8669.5890625\n",
      "                , loss2: 0.29989147186279297\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2920 epoch, average loss: -86.39571533203124\n",
      "                , loss1: -8669.5890625\n",
      "                , loss2: 0.30018086433410646\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2930 epoch, average loss: -86.39583740234374\n",
      "                , loss1: -8669.5953125\n",
      "                , loss2: 0.3001105308532715\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2940 epoch, average loss: -86.39632568359374\n",
      "                , loss1: -8669.63203125\n",
      "                , loss2: 0.2999912977218628\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2950 epoch, average loss: -86.39601440429688\n",
      "                , loss1: -8669.6078125\n",
      "                , loss2: 0.30004403591156004\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2960 epoch, average loss: -86.39531860351562\n",
      "                , loss1: -8669.5578125\n",
      "                , loss2: 0.3002709627151489\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2970 epoch, average loss: -86.39491577148438\n",
      "                , loss1: -8669.5484375\n",
      "                , loss2: 0.3005698204040527\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2980 epoch, average loss: -86.3954345703125\n",
      "                , loss1: -8669.55234375\n",
      "                , loss2: 0.30009419918060304\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 2990 epoch, average loss: -86.39556884765625\n",
      "                , loss1: -8669.56796875\n",
      "                , loss2: 0.3001044750213623\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3000 epoch, average loss: -86.396435546875\n",
      "                , loss1: -8669.66875\n",
      "                , loss2: 0.30024755001068115\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3010 epoch, average loss: -86.39210205078125\n",
      "                , loss1: -8669.4375\n",
      "                , loss2: 0.30228121280670167\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3020 epoch, average loss: -86.39678955078125\n",
      "                , loss1: -8669.6765625\n",
      "                , loss2: 0.29996094703674314\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3030 epoch, average loss: -86.39451904296875\n",
      "                , loss1: -8669.4796875\n",
      "                , loss2: 0.300272536277771\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3040 epoch, average loss: -86.39631958007813\n",
      "                , loss1: -8669.6265625\n",
      "                , loss2: 0.29995007514953614\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3050 epoch, average loss: -86.3975830078125\n",
      "                , loss1: -8669.75859375\n",
      "                , loss2: 0.3000077486038208\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3060 epoch, average loss: -86.39614868164062\n",
      "                , loss1: -8669.59453125\n",
      "                , loss2: 0.29979419708251953\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3070 epoch, average loss: -86.39638671875\n",
      "                , loss1: -8669.64375\n",
      "                , loss2: 0.30004751682281494\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3080 epoch, average loss: -86.395947265625\n",
      "                , loss1: -8669.6125\n",
      "                , loss2: 0.30017900466918945\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3090 epoch, average loss: -86.3955322265625\n",
      "                , loss1: -8669.525\n",
      "                , loss2: 0.2997143268585205\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3100 epoch, average loss: -86.39571533203124\n",
      "                , loss1: -8669.5859375\n",
      "                , loss2: 0.30013511180877683\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3110 epoch, average loss: -86.3966552734375\n",
      "                , loss1: -8669.67265625\n",
      "                , loss2: 0.3000591993331909\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3120 epoch, average loss: -86.39563598632813\n",
      "                , loss1: -8669.5953125\n",
      "                , loss2: 0.30032005310058596\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3130 epoch, average loss: -86.39630737304688\n",
      "                , loss1: -8669.63359375\n",
      "                , loss2: 0.3000291347503662\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3140 epoch, average loss: -86.39473876953124\n",
      "                , loss1: -8669.5046875\n",
      "                , loss2: 0.3003074169158936\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3150 epoch, average loss: -86.3975830078125\n",
      "                , loss1: -8669.7734375\n",
      "                , loss2: 0.30014867782592775\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3160 epoch, average loss: -86.39612426757813\n",
      "                , loss1: -8669.60703125\n",
      "                , loss2: 0.2999402046203613\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3170 epoch, average loss: -86.39724731445312\n",
      "                , loss1: -8669.7421875\n",
      "                , loss2: 0.3001713275909424\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3180 epoch, average loss: -86.3962646484375\n",
      "                , loss1: -8669.6421875\n",
      "                , loss2: 0.300164794921875\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3190 epoch, average loss: -86.39647216796875\n",
      "                , loss1: -8669.6609375\n",
      "                , loss2: 0.30013954639434814\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3200 epoch, average loss: -86.39501342773437\n",
      "                , loss1: -8669.5421875\n",
      "                , loss2: 0.3004074811935425\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3210 epoch, average loss: -86.39713134765626\n",
      "                , loss1: -8669.715625\n",
      "                , loss2: 0.30002079010009763\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3220 epoch, average loss: -86.39647216796875\n",
      "                , loss1: -8669.67265625\n",
      "                , loss2: 0.30025267601013184\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3230 epoch, average loss: -86.39663696289062\n",
      "                , loss1: -8669.66171875\n",
      "                , loss2: 0.2999914884567261\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3240 epoch, average loss: -86.396435546875\n",
      "                , loss1: -8669.66796875\n",
      "                , loss2: 0.300246524810791\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3250 epoch, average loss: -86.3969482421875\n",
      "                , loss1: -8669.7046875\n",
      "                , loss2: 0.300080680847168\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3260 epoch, average loss: -86.39630737304688\n",
      "                , loss1: -8669.6328125\n",
      "                , loss2: 0.3000218152999878\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3270 epoch, average loss: -86.39725952148437\n",
      "                , loss1: -8669.7359375\n",
      "                , loss2: 0.3000990152359009\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3280 epoch, average loss: -86.39761352539062\n",
      "                , loss1: -8669.76328125\n",
      "                , loss2: 0.30002238750457766\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3290 epoch, average loss: -86.39752197265625\n",
      "                , loss1: -8669.771875\n",
      "                , loss2: 0.3001874923706055\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3300 epoch, average loss: -86.39681396484374\n",
      "                , loss1: -8669.6578125\n",
      "                , loss2: 0.29977633953094485\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3310 epoch, average loss: -86.39690551757812\n",
      "                , loss1: -8669.6921875\n",
      "                , loss2: 0.3000157594680786\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3320 epoch, average loss: -86.3974853515625\n",
      "                , loss1: -8669.75078125\n",
      "                , loss2: 0.3000311374664307\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3330 epoch, average loss: -86.39788818359375\n",
      "                , loss1: -8669.8015625\n",
      "                , loss2: 0.30012485980987547\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3340 epoch, average loss: -86.39719848632812\n",
      "                , loss1: -8669.74375\n",
      "                , loss2: 0.3002361536026001\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3350 epoch, average loss: -86.396923828125\n",
      "                , loss1: -8669.70234375\n",
      "                , loss2: 0.3001018285751343\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3360 epoch, average loss: -86.396630859375\n",
      "                , loss1: -8669.6671875\n",
      "                , loss2: 0.3000334739685059\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3370 epoch, average loss: -86.39805908203125\n",
      "                , loss1: -8669.8203125\n",
      "                , loss2: 0.30013070106506345\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3380 epoch, average loss: -86.39798583984376\n",
      "                , loss1: -8669.815625\n",
      "                , loss2: 0.3001718521118164\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3390 epoch, average loss: -86.39759521484375\n",
      "                , loss1: -8669.7765625\n",
      "                , loss2: 0.3001569747924805\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3400 epoch, average loss: -86.39797973632812\n",
      "                , loss1: -8669.80234375\n",
      "                , loss2: 0.3000471591949463\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3410 epoch, average loss: -86.39801025390625\n",
      "                , loss1: -8669.81796875\n",
      "                , loss2: 0.30016160011291504\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3420 epoch, average loss: -86.39756469726562\n",
      "                , loss1: -8669.778125\n",
      "                , loss2: 0.3002166271209717\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3430 epoch, average loss: -86.3974609375\n",
      "                , loss1: -8669.775\n",
      "                , loss2: 0.3002760887145996\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3440 epoch, average loss: -86.3980224609375\n",
      "                , loss1: -8669.809375\n",
      "                , loss2: 0.3000657081604004\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3450 epoch, average loss: -86.3979736328125\n",
      "                , loss1: -8669.79453125\n",
      "                , loss2: 0.2999835252761841\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3460 epoch, average loss: -86.39777221679688\n",
      "                , loss1: -8669.78203125\n",
      "                , loss2: 0.30004515647888186\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3470 epoch, average loss: -86.39081420898438\n",
      "                , loss1: -8669.48828125\n",
      "                , loss2: 0.3040708065032959\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3480 epoch, average loss: -86.38097534179687\n",
      "                , loss1: -8669.05078125\n",
      "                , loss2: 0.309541654586792\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3490 epoch, average loss: -86.38983764648438\n",
      "                , loss1: -8669.3328125\n",
      "                , loss2: 0.30349204540252683\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3500 epoch, average loss: -86.39738159179687\n",
      "                , loss1: -8669.76171875\n",
      "                , loss2: 0.3002224683761597\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3510 epoch, average loss: -86.39759521484375\n",
      "                , loss1: -8669.7828125\n",
      "                , loss2: 0.3002419948577881\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3520 epoch, average loss: -86.39719848632812\n",
      "                , loss1: -8669.76640625\n",
      "                , loss2: 0.3004701852798462\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3530 epoch, average loss: -86.39337158203125\n",
      "                , loss1: -8669.5921875\n",
      "                , loss2: 0.30255656242370604\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3540 epoch, average loss: -86.3941650390625\n",
      "                , loss1: -8669.11328125\n",
      "                , loss2: 0.2969659805297852\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3550 epoch, average loss: -86.39824829101562\n",
      "                , loss1: -8669.8265625\n",
      "                , loss2: 0.30001139640808105\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3560 epoch, average loss: -86.39814453125\n",
      "                , loss1: -8669.82109375\n",
      "                , loss2: 0.30007596015930177\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3570 epoch, average loss: -86.39822998046876\n",
      "                , loss1: -8669.828125\n",
      "                , loss2: 0.3000571012496948\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3580 epoch, average loss: -86.39765625\n",
      "                , loss1: -8669.76328125\n",
      "                , loss2: 0.2999743461608887\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3590 epoch, average loss: -86.39827270507813\n",
      "                , loss1: -8669.8375\n",
      "                , loss2: 0.30010285377502444\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3600 epoch, average loss: -86.39774780273437\n",
      "                , loss1: -8669.7828125\n",
      "                , loss2: 0.3000751256942749\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3610 epoch, average loss: -86.39760131835938\n",
      "                , loss1: -8669.796875\n",
      "                , loss2: 0.30035934448242185\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3620 epoch, average loss: -86.39835205078126\n",
      "                , loss1: -8669.84609375\n",
      "                , loss2: 0.3001131534576416\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3630 epoch, average loss: -86.39830322265625\n",
      "                , loss1: -8669.8234375\n",
      "                , loss2: 0.29993104934692383\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3640 epoch, average loss: -86.3974853515625\n",
      "                , loss1: -8669.74453125\n",
      "                , loss2: 0.29996790885925295\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3650 epoch, average loss: -86.39850463867188\n",
      "                , loss1: -8669.8640625\n",
      "                , loss2: 0.3001424551010132\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3660 epoch, average loss: -86.39824829101562\n",
      "                , loss1: -8669.828125\n",
      "                , loss2: 0.30003302097320556\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3670 epoch, average loss: -86.39837036132812\n",
      "                , loss1: -8669.8578125\n",
      "                , loss2: 0.30021238327026367\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3680 epoch, average loss: -86.39799194335937\n",
      "                , loss1: -8669.80625\n",
      "                , loss2: 0.3000629425048828\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3690 epoch, average loss: -86.39758911132813\n",
      "                , loss1: -8669.76875\n",
      "                , loss2: 0.3000960111618042\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3700 epoch, average loss: -86.39884033203126\n",
      "                , loss1: -8669.89765625\n",
      "                , loss2: 0.30013694763183596\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3710 epoch, average loss: -86.39842529296875\n",
      "                , loss1: -8669.85703125\n",
      "                , loss2: 0.30013360977172854\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3720 epoch, average loss: -86.39780883789062\n",
      "                , loss1: -8669.80390625\n",
      "                , loss2: 0.3002263784408569\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3730 epoch, average loss: -86.39822998046876\n",
      "                , loss1: -8669.8328125\n",
      "                , loss2: 0.3000887393951416\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3740 epoch, average loss: -86.39830932617187\n",
      "                , loss1: -8669.83125\n",
      "                , loss2: 0.30000355243682864\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3750 epoch, average loss: -86.39873046875\n",
      "                , loss1: -8669.88125\n",
      "                , loss2: 0.3000813961029053\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3760 epoch, average loss: -86.39893188476563\n",
      "                , loss1: -8669.89453125\n",
      "                , loss2: 0.3000153064727783\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3770 epoch, average loss: -86.397314453125\n",
      "                , loss1: -8669.74921875\n",
      "                , loss2: 0.3001713275909424\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3780 epoch, average loss: -86.39810180664062\n",
      "                , loss1: -8669.825\n",
      "                , loss2: 0.30014011859893797\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3790 epoch, average loss: -86.39837646484375\n",
      "                , loss1: -8669.8390625\n",
      "                , loss2: 0.30001044273376465\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3800 epoch, average loss: -86.39925537109374\n",
      "                , loss1: -8669.9375\n",
      "                , loss2: 0.3001157522201538\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3810 epoch, average loss: -86.39844360351563\n",
      "                , loss1: -8669.85390625\n",
      "                , loss2: 0.30008444786071775\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3820 epoch, average loss: -86.39848022460937\n",
      "                , loss1: -8669.86875\n",
      "                , loss2: 0.30020163059234617\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3830 epoch, average loss: -86.39861450195312\n",
      "                , loss1: -8669.87421875\n",
      "                , loss2: 0.3001355409622192\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3840 epoch, average loss: -86.3986328125\n",
      "                , loss1: -8669.86640625\n",
      "                , loss2: 0.3000360012054443\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3850 epoch, average loss: -86.39833374023438\n",
      "                , loss1: -8669.84765625\n",
      "                , loss2: 0.3001443862915039\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3860 epoch, average loss: -86.3989501953125\n",
      "                , loss1: -8669.9078125\n",
      "                , loss2: 0.30012123584747313\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3870 epoch, average loss: -86.39891967773437\n",
      "                , loss1: -8669.89375\n",
      "                , loss2: 0.3000182628631592\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3880 epoch, average loss: -86.398876953125\n",
      "                , loss1: -8669.89375\n",
      "                , loss2: 0.30005731582641604\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3890 epoch, average loss: -86.3985107421875\n",
      "                , loss1: -8669.846875\n",
      "                , loss2: 0.2999556064605713\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3900 epoch, average loss: -86.39935302734375\n",
      "                , loss1: -8669.94140625\n",
      "                , loss2: 0.30006103515625\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3910 epoch, average loss: -86.39967041015625\n",
      "                , loss1: -8669.9671875\n",
      "                , loss2: 0.299997615814209\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3920 epoch, average loss: -86.3993408203125\n",
      "                , loss1: -8669.93359375\n",
      "                , loss2: 0.2999929904937744\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3930 epoch, average loss: -86.3989501953125\n",
      "                , loss1: -8669.89609375\n",
      "                , loss2: 0.30001277923583985\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3940 epoch, average loss: -86.3987548828125\n",
      "                , loss1: -8669.865625\n",
      "                , loss2: 0.29989333152770997\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3950 epoch, average loss: -86.39829711914062\n",
      "                , loss1: -8669.83046875\n",
      "                , loss2: 0.3000041961669922\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3960 epoch, average loss: -86.39963989257812\n",
      "                , loss1: -8669.9671875\n",
      "                , loss2: 0.3000191688537598\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3970 epoch, average loss: -86.39885864257812\n",
      "                , loss1: -8669.89140625\n",
      "                , loss2: 0.3000500679016113\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3980 epoch, average loss: -86.39947509765625\n",
      "                , loss1: -8669.9546875\n",
      "                , loss2: 0.3000720262527466\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 3990 epoch, average loss: -86.39882202148438\n",
      "                , loss1: -8669.8953125\n",
      "                , loss2: 0.30011112689971925\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4000 epoch, average loss: -86.398974609375\n",
      "                , loss1: -8669.896875\n",
      "                , loss2: 0.29998881816864015\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4010 epoch, average loss: -86.39891967773437\n",
      "                , loss1: -8669.8859375\n",
      "                , loss2: 0.2999281644821167\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4020 epoch, average loss: -86.39852294921874\n",
      "                , loss1: -8669.85546875\n",
      "                , loss2: 0.30003821849823\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4030 epoch, average loss: -86.3991455078125\n",
      "                , loss1: -8669.9203125\n",
      "                , loss2: 0.3000599145889282\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4040 epoch, average loss: -86.39854736328125\n",
      "                , loss1: -8669.859375\n",
      "                , loss2: 0.3000559568405151\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4050 epoch, average loss: -86.3995849609375\n",
      "                , loss1: -8669.9640625\n",
      "                , loss2: 0.3000631809234619\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4060 epoch, average loss: -86.3990966796875\n",
      "                , loss1: -8669.91171875\n",
      "                , loss2: 0.3000186920166016\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4070 epoch, average loss: -86.39806518554687\n",
      "                , loss1: -8669.81171875\n",
      "                , loss2: 0.3000403165817261\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4080 epoch, average loss: -86.39962768554688\n",
      "                , loss1: -8669.9796875\n",
      "                , loss2: 0.30017025470733644\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4090 epoch, average loss: -86.39996337890625\n",
      "                , loss1: -8669.99921875\n",
      "                , loss2: 0.3000153064727783\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4100 epoch, average loss: -86.3994873046875\n",
      "                , loss1: -8669.95859375\n",
      "                , loss2: 0.3000905513763428\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4110 epoch, average loss: -86.399267578125\n",
      "                , loss1: -8669.94296875\n",
      "                , loss2: 0.3001526117324829\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4120 epoch, average loss: -86.39942626953125\n",
      "                , loss1: -8669.9453125\n",
      "                , loss2: 0.3000267267227173\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4130 epoch, average loss: -86.39898681640625\n",
      "                , loss1: -8669.9140625\n",
      "                , loss2: 0.3001547336578369\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4140 epoch, average loss: -86.39876708984374\n",
      "                , loss1: -8669.9015625\n",
      "                , loss2: 0.30024237632751466\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4150 epoch, average loss: -86.39954223632813\n",
      "                , loss1: -8669.94921875\n",
      "                , loss2: 0.299951958656311\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4160 epoch, average loss: -86.40029907226562\n",
      "                , loss1: -8670.0265625\n",
      "                , loss2: 0.2999593734741211\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4170 epoch, average loss: -86.399951171875\n",
      "                , loss1: -8669.9984375\n",
      "                , loss2: 0.3000205039978027\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4180 epoch, average loss: -86.40044555664062\n",
      "                , loss1: -8670.0484375\n",
      "                , loss2: 0.3000476598739624\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4190 epoch, average loss: -86.39977416992187\n",
      "                , loss1: -8669.98984375\n",
      "                , loss2: 0.3001218795776367\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4200 epoch, average loss: -86.39974365234374\n",
      "                , loss1: -8669.9875\n",
      "                , loss2: 0.3001311540603638\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4210 epoch, average loss: -86.39902954101562\n",
      "                , loss1: -8669.9140625\n",
      "                , loss2: 0.3001123905181885\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4220 epoch, average loss: -86.399609375\n",
      "                , loss1: -8669.9484375\n",
      "                , loss2: 0.2998717546463013\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4230 epoch, average loss: -86.39957885742187\n",
      "                , loss1: -8669.95625\n",
      "                , loss2: 0.29997251033782957\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4240 epoch, average loss: -86.3993896484375\n",
      "                , loss1: -8669.93515625\n",
      "                , loss2: 0.2999558925628662\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4250 epoch, average loss: -86.39999389648438\n",
      "                , loss1: -8670.00625\n",
      "                , loss2: 0.30006775856018064\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4260 epoch, average loss: -86.3998291015625\n",
      "                , loss1: -8669.9765625\n",
      "                , loss2: 0.2999326229095459\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4270 epoch, average loss: -86.39950561523438\n",
      "                , loss1: -8669.9625\n",
      "                , loss2: 0.3001147747039795\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4280 epoch, average loss: -86.3997314453125\n",
      "                , loss1: -8669.9890625\n",
      "                , loss2: 0.300152063369751\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4290 epoch, average loss: -86.40045776367188\n",
      "                , loss1: -8670.05\n",
      "                , loss2: 0.3000423192977905\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4300 epoch, average loss: -86.3998779296875\n",
      "                , loss1: -8669.9796875\n",
      "                , loss2: 0.29992125034332273\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4310 epoch, average loss: -86.40084838867188\n",
      "                , loss1: -8670.07578125\n",
      "                , loss2: 0.29990198612213137\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4320 epoch, average loss: -86.400732421875\n",
      "                , loss1: -8670.08046875\n",
      "                , loss2: 0.30007190704345704\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4330 epoch, average loss: -86.40028686523438\n",
      "                , loss1: -8670.04375\n",
      "                , loss2: 0.3001530885696411\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4340 epoch, average loss: -86.40006713867187\n",
      "                , loss1: -8670.0015625\n",
      "                , loss2: 0.2999490976333618\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4350 epoch, average loss: -86.40015869140625\n",
      "                , loss1: -8670.01875\n",
      "                , loss2: 0.30002365112304685\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4360 epoch, average loss: -86.4001953125\n",
      "                , loss1: -8670.021875\n",
      "                , loss2: 0.3000213384628296\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4370 epoch, average loss: -86.4001220703125\n",
      "                , loss1: -8670.01015625\n",
      "                , loss2: 0.2999913692474365\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4380 epoch, average loss: -86.40101318359375\n",
      "                , loss1: -8670.0984375\n",
      "                , loss2: 0.29996767044067385\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4390 epoch, average loss: -86.40101928710938\n",
      "                , loss1: -8670.1046875\n",
      "                , loss2: 0.30003180503845217\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4400 epoch, average loss: -86.40001831054687\n",
      "                , loss1: -8670.009375\n",
      "                , loss2: 0.3000737190246582\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4410 epoch, average loss: -86.40054321289062\n",
      "                , loss1: -8670.046875\n",
      "                , loss2: 0.2999216794967651\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4420 epoch, average loss: -86.40026245117187\n",
      "                , loss1: -8670.028125\n",
      "                , loss2: 0.30002944469451903\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4430 epoch, average loss: -86.40003662109375\n",
      "                , loss1: -8670.003125\n",
      "                , loss2: 0.29999961853027346\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4440 epoch, average loss: -86.39993286132812\n",
      "                , loss1: -8669.99453125\n",
      "                , loss2: 0.2999978303909302\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4450 epoch, average loss: -86.4008056640625\n",
      "                , loss1: -8670.078125\n",
      "                , loss2: 0.29997613430023196\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4460 epoch, average loss: -86.40087890625\n",
      "                , loss1: -8670.0921875\n",
      "                , loss2: 0.3000267267227173\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4470 epoch, average loss: -86.40090942382812\n",
      "                , loss1: -8670.09609375\n",
      "                , loss2: 0.3000436305999756\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4480 epoch, average loss: -86.40067138671876\n",
      "                , loss1: -8670.0703125\n",
      "                , loss2: 0.3000298023223877\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4490 epoch, average loss: -86.40035400390624\n",
      "                , loss1: -8670.078125\n",
      "                , loss2: 0.30042123794555664\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4500 epoch, average loss: -86.4004638671875\n",
      "                , loss1: -8670.04296875\n",
      "                , loss2: 0.29996178150177\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4510 epoch, average loss: -86.40118408203125\n",
      "                , loss1: -8670.115625\n",
      "                , loss2: 0.2999565601348877\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4520 epoch, average loss: -86.40146484375\n",
      "                , loss1: -8670.14140625\n",
      "                , loss2: 0.29994769096374513\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4530 epoch, average loss: -86.40010375976563\n",
      "                , loss1: -8670.009375\n",
      "                , loss2: 0.2999730587005615\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4540 epoch, average loss: -86.40049438476562\n",
      "                , loss1: -8670.0453125\n",
      "                , loss2: 0.29996070861816404\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4550 epoch, average loss: -86.40031127929687\n",
      "                , loss1: -8670.02265625\n",
      "                , loss2: 0.29990861415863035\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4560 epoch, average loss: -86.40123291015625\n",
      "                , loss1: -8670.1234375\n",
      "                , loss2: 0.2999944448471069\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4570 epoch, average loss: -86.40086669921875\n",
      "                , loss1: -8670.08359375\n",
      "                , loss2: 0.2999764680862427\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n",
      "in 4580 epoch, average loss: -86.4010009765625\n",
      "                , loss1: -8670.103125\n",
      "                , loss2: 0.30003082752227783\n",
      "                , weight: 0.009999999999999232\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      6\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 7\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[32], line 32\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     31\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), loss_1\u001b[38;5;241m.\u001b[39mitem(), loss_2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(1,20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "    hgnn_trainer.train()\n",
    "    # if loss_1 < -8500 and loss_2 < 2 and cut() < 5072:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5181"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48., 49., 48., 49., 48.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004132231404958678"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
