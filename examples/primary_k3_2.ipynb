{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 3\n",
    "\n",
    "weight = 0.93\n",
    "lr = 4e-3\n",
    "sub = 0.009\n",
    "limit = 0.01\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 242, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\":256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers141\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "# h_hyper_prmts[\"convlayers142\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers143\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "\n",
    "\n",
    "# l_hyper_prmts[\"linerlayer113\"] = {\"in_channels\":2048, \"out_channels\":2048, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer13\"] = {\"in_channels\":2048, \"out_channels\":1024, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer12334\"] = {\"in_channels\":512, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":128, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer121\"] = {\"in_channels\":128, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":64, \"out_channels\":3, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12704, 242)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/primary\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=242, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.05, inplace=False)\n",
       "  (12): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (13): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: -99.88945922851562\n",
      "                , loss1: -110.6760498046875\n",
      "                , loss2: 2.0431819915771485\n",
      "                , weight: 0.921\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 10 epoch, average loss: -3840.975390625\n",
      "                , loss1: -4511.032421875\n",
      "                , loss2: 32.1191162109375\n",
      "                , weight: 0.831\n",
      "=================================\n",
      "in 20 epoch, average loss: -6996.7140625\n",
      "                , loss1: -8992.18046875\n",
      "                , loss2: 21.40860595703125\n",
      "                , weight: 0.7409999999999999\n",
      "=================================\n",
      "in 30 epoch, average loss: -6537.169140625\n",
      "                , loss1: -9477.25390625\n",
      "                , loss2: 15.357682800292968\n",
      "                , weight: 0.6509999999999998\n",
      "=================================\n",
      "in 40 epoch, average loss: -5726.045703125\n",
      "                , loss1: -9540.52421875\n",
      "                , loss2: 12.383376312255859\n",
      "                , weight: 0.5609999999999997\n",
      "=================================\n",
      "in 50 epoch, average loss: -4874.952734375\n",
      "                , loss1: -9554.8640625\n",
      "                , loss2: 12.305961608886719\n",
      "                , weight: 0.47099999999999964\n",
      "=================================\n",
      "in 60 epoch, average loss: -4016.80546875\n",
      "                , loss1: -9559.06875\n",
      "                , loss2: 12.323222351074218\n",
      "                , weight: 0.38099999999999956\n",
      "=================================\n",
      "in 70 epoch, average loss: -3157.1236328125\n",
      "                , loss1: -9560.9640625\n",
      "                , loss2: 12.331044769287109\n",
      "                , weight: 0.2909999999999995\n",
      "=================================\n",
      "in 80 epoch, average loss: -2296.8599609375\n",
      "                , loss1: -9561.81484375\n",
      "                , loss2: 12.31378173828125\n",
      "                , weight: 0.2009999999999994\n",
      "=================================\n",
      "in 90 epoch, average loss: -1436.29462890625\n",
      "                , loss1: -9561.45703125\n",
      "                , loss2: 12.261487579345703\n",
      "                , weight: 0.11099999999999935\n",
      "=================================\n",
      "in 100 epoch, average loss: -575.761572265625\n",
      "                , loss1: -9562.415625\n",
      "                , loss2: 12.329470825195312\n",
      "                , weight: 0.020999999999999373\n",
      "=================================\n",
      "in 110 epoch, average loss: -25.140904235839844\n",
      "                , loss1: -9554.41328125\n",
      "                , loss2: 12.128376770019532\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 120 epoch, average loss: -15.194091796875\n",
      "                , loss1: -9558.25078125\n",
      "                , loss2: 13.480659484863281\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 130 epoch, average loss: -15.514753723144532\n",
      "                , loss1: -9553.54453125\n",
      "                , loss2: 13.145881652832031\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 140 epoch, average loss: -16.42487030029297\n",
      "                , loss1: -9561.2390625\n",
      "                , loss2: 12.25884780883789\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 150 epoch, average loss: -18.681126403808594\n",
      "                , loss1: -9534.99453125\n",
      "                , loss2: 9.923857879638671\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 160 epoch, average loss: -13.241305541992187\n",
      "                , loss1: -9550.46875\n",
      "                , loss2: 15.410105895996093\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 170 epoch, average loss: -16.14468994140625\n",
      "                , loss1: -9551.43203125\n",
      "                , loss2: 12.509605407714844\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 180 epoch, average loss: -17.674641418457032\n",
      "                , loss1: -9509.5015625\n",
      "                , loss2: 10.853866577148438\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 190 epoch, average loss: -18.667207336425783\n",
      "                , loss1: -9524.10625\n",
      "                , loss2: 9.905113220214844\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 200 epoch, average loss: -21.775181579589844\n",
      "                , loss1: -9315.14609375\n",
      "                , loss2: 6.170259475708008\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 210 epoch, average loss: -18.764759826660157\n",
      "                , loss1: -9522.0\n",
      "                , loss2: 9.801238250732421\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 220 epoch, average loss: -23.985597229003908\n",
      "                , loss1: -9390.21171875\n",
      "                , loss2: 4.185038375854492\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 230 epoch, average loss: -25.123837280273438\n",
      "                , loss1: -9414.8375\n",
      "                , loss2: 3.1206756591796876\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 240 epoch, average loss: -26.866897583007812\n",
      "                , loss1: -9411.1234375\n",
      "                , loss2: 1.36647367477417\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 250 epoch, average loss: -26.517617797851564\n",
      "                , loss1: -9419.18046875\n",
      "                , loss2: 1.7399234771728516\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 260 epoch, average loss: -27.355258178710937\n",
      "                , loss1: -9435.471875\n",
      "                , loss2: 0.9511558532714843\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 270 epoch, average loss: -27.347503662109375\n",
      "                , loss1: -9446.4453125\n",
      "                , loss2: 0.9918308258056641\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 280 epoch, average loss: -28.127841186523437\n",
      "                , loss1: -9468.45703125\n",
      "                , loss2: 0.27753481864929197\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 290 epoch, average loss: -28.047525024414064\n",
      "                , loss1: -9469.775\n",
      "                , loss2: 0.36179840564727783\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 300 epoch, average loss: -28.14836730957031\n",
      "                , loss1: -9479.4546875\n",
      "                , loss2: 0.2899944543838501\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 310 epoch, average loss: -28.156280517578125\n",
      "                , loss1: -9476.2421875\n",
      "                , loss2: 0.27244277000427247\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 320 epoch, average loss: -28.29456481933594\n",
      "                , loss1: -9491.66875\n",
      "                , loss2: 0.18043991327285766\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 330 epoch, average loss: -28.291598510742187\n",
      "                , loss1: -9488.15625\n",
      "                , loss2: 0.17287023067474366\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 340 epoch, average loss: -28.268182373046876\n",
      "                , loss1: -9483.534375\n",
      "                , loss2: 0.18242236375808715\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 350 epoch, average loss: -28.314642333984374\n",
      "                , loss1: -9488.1296875\n",
      "                , loss2: 0.14974762201309205\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 360 epoch, average loss: -28.332992553710938\n",
      "                , loss1: -9490.03046875\n",
      "                , loss2: 0.13710011243820192\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 370 epoch, average loss: -28.293869018554688\n",
      "                , loss1: -9486.73203125\n",
      "                , loss2: 0.16632951498031617\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 380 epoch, average loss: -28.362466430664064\n",
      "                , loss1: -9487.7234375\n",
      "                , loss2: 0.10070422887802125\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 390 epoch, average loss: -28.34064636230469\n",
      "                , loss1: -9487.7359375\n",
      "                , loss2: 0.12256003618240356\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 400 epoch, average loss: -28.325546264648438\n",
      "                , loss1: -9488.8375\n",
      "                , loss2: 0.14096453189849853\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 410 epoch, average loss: -28.348648071289062\n",
      "                , loss1: -9490.6296875\n",
      "                , loss2: 0.12324255704879761\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 420 epoch, average loss: -28.340682983398438\n",
      "                , loss1: -9488.1484375\n",
      "                , loss2: 0.1237646460533142\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 430 epoch, average loss: -28.337802124023437\n",
      "                , loss1: -9490.26875\n",
      "                , loss2: 0.1330045461654663\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 440 epoch, average loss: -28.331753540039063\n",
      "                , loss1: -9493.7546875\n",
      "                , loss2: 0.14950844049453735\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 450 epoch, average loss: -28.371426391601563\n",
      "                , loss1: -9487.74296875\n",
      "                , loss2: 0.09180471897125245\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 460 epoch, average loss: -28.368487548828124\n",
      "                , loss1: -9486.2140625\n",
      "                , loss2: 0.09015535116195679\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 470 epoch, average loss: -28.349896240234376\n",
      "                , loss1: -9491.234375\n",
      "                , loss2: 0.12381137609481811\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 480 epoch, average loss: -28.37528076171875\n",
      "                , loss1: -9490.3046875\n",
      "                , loss2: 0.09563320875167847\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 490 epoch, average loss: -28.36528625488281\n",
      "                , loss1: -9493.17734375\n",
      "                , loss2: 0.11424647569656372\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 500 epoch, average loss: -28.369097900390624\n",
      "                , loss1: -9489.2375\n",
      "                , loss2: 0.09861401915550232\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 510 epoch, average loss: -28.349777221679688\n",
      "                , loss1: -9489.734375\n",
      "                , loss2: 0.11942585706710815\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 520 epoch, average loss: -28.3349853515625\n",
      "                , loss1: -9488.98984375\n",
      "                , loss2: 0.13198505640029906\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 530 epoch, average loss: -28.341580200195313\n",
      "                , loss1: -9493.24453125\n",
      "                , loss2: 0.13815268278121948\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 540 epoch, average loss: -28.3451416015625\n",
      "                , loss1: -9492.05703125\n",
      "                , loss2: 0.1310309052467346\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 550 epoch, average loss: -28.35596923828125\n",
      "                , loss1: -9493.37265625\n",
      "                , loss2: 0.12414554357528687\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 560 epoch, average loss: -28.31781005859375\n",
      "                , loss1: -9488.97421875\n",
      "                , loss2: 0.14911577701568604\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 570 epoch, average loss: -28.296649169921874\n",
      "                , loss1: -9492.5578125\n",
      "                , loss2: 0.1810245156288147\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 580 epoch, average loss: -28.31263122558594\n",
      "                , loss1: -9493.08203125\n",
      "                , loss2: 0.16661369800567627\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 590 epoch, average loss: -28.33372802734375\n",
      "                , loss1: -9501.365625\n",
      "                , loss2: 0.1703664779663086\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 600 epoch, average loss: -28.33757629394531\n",
      "                , loss1: -9493.7046875\n",
      "                , loss2: 0.14354065656661988\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 610 epoch, average loss: -28.381256103515625\n",
      "                , loss1: -9488.96484375\n",
      "                , loss2: 0.08564010262489319\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 620 epoch, average loss: -28.38177490234375\n",
      "                , loss1: -9489.33828125\n",
      "                , loss2: 0.08624154329299927\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 630 epoch, average loss: -28.363427734375\n",
      "                , loss1: -9493.98515625\n",
      "                , loss2: 0.11852705478668213\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 640 epoch, average loss: -28.36102294921875\n",
      "                , loss1: -9498.1515625\n",
      "                , loss2: 0.13342825174331666\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 650 epoch, average loss: -28.3706298828125\n",
      "                , loss1: -9487.78671875\n",
      "                , loss2: 0.09272838234901429\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 660 epoch, average loss: -28.37484130859375\n",
      "                , loss1: -9496.94375\n",
      "                , loss2: 0.11599125862121581\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 670 epoch, average loss: -28.378692626953125\n",
      "                , loss1: -9493.671875\n",
      "                , loss2: 0.10232392549514771\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 680 epoch, average loss: -28.373959350585938\n",
      "                , loss1: -9495.24453125\n",
      "                , loss2: 0.11177314519882202\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 690 epoch, average loss: -28.35218200683594\n",
      "                , loss1: -9498.4125\n",
      "                , loss2: 0.14305691719055175\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 700 epoch, average loss: -28.356591796875\n",
      "                , loss1: -9494.409375\n",
      "                , loss2: 0.12663519382476807\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 710 epoch, average loss: -28.389752197265626\n",
      "                , loss1: -9492.93515625\n",
      "                , loss2: 0.08905340433120727\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 720 epoch, average loss: -28.372552490234376\n",
      "                , loss1: -9490.69921875\n",
      "                , loss2: 0.09954652190208435\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 730 epoch, average loss: -28.35780029296875\n",
      "                , loss1: -9501.92890625\n",
      "                , loss2: 0.14798778295516968\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 740 epoch, average loss: -28.367886352539063\n",
      "                , loss1: -9491.36875\n",
      "                , loss2: 0.1062188982963562\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 750 epoch, average loss: -28.382174682617187\n",
      "                , loss1: -9491.74765625\n",
      "                , loss2: 0.09306550025939941\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 760 epoch, average loss: -28.359893798828125\n",
      "                , loss1: -9499.53125\n",
      "                , loss2: 0.13869960308074952\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 770 epoch, average loss: -28.398779296875\n",
      "                , loss1: -9493.8953125\n",
      "                , loss2: 0.08290631175041199\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 780 epoch, average loss: -28.372128295898438\n",
      "                , loss1: -9493.5359375\n",
      "                , loss2: 0.10847636461257934\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 790 epoch, average loss: -28.389898681640624\n",
      "                , loss1: -9491.70234375\n",
      "                , loss2: 0.08520863652229309\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 800 epoch, average loss: -28.417190551757812\n",
      "                , loss1: -9489.9171875\n",
      "                , loss2: 0.05256400108337402\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 810 epoch, average loss: -28.410406494140624\n",
      "                , loss1: -9489.53046875\n",
      "                , loss2: 0.05818560123443604\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 820 epoch, average loss: -28.362869262695312\n",
      "                , loss1: -9499.4890625\n",
      "                , loss2: 0.1355960726737976\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 830 epoch, average loss: -28.359439086914062\n",
      "                , loss1: -9494.48046875\n",
      "                , loss2: 0.12399928569793701\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 840 epoch, average loss: -28.365292358398438\n",
      "                , loss1: -9491.64453125\n",
      "                , loss2: 0.10963904857635498\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 850 epoch, average loss: -28.385028076171874\n",
      "                , loss1: -9498.2421875\n",
      "                , loss2: 0.10969880819320679\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 860 epoch, average loss: -28.419216918945313\n",
      "                , loss1: -9490.49375\n",
      "                , loss2: 0.052261841297149655\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 870 epoch, average loss: -28.357073974609374\n",
      "                , loss1: -9495.465625\n",
      "                , loss2: 0.1293245315551758\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 880 epoch, average loss: -28.371502685546876\n",
      "                , loss1: -9502.31953125\n",
      "                , loss2: 0.13545690774917601\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 890 epoch, average loss: -28.390304565429688\n",
      "                , loss1: -9497.3\n",
      "                , loss2: 0.10159562826156616\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 900 epoch, average loss: -28.416213989257812\n",
      "                , loss1: -9493.4375\n",
      "                , loss2: 0.06409969925880432\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 910 epoch, average loss: -28.365689086914063\n",
      "                , loss1: -9492.7359375\n",
      "                , loss2: 0.11251943111419678\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 920 epoch, average loss: -28.376531982421874\n",
      "                , loss1: -9496.88671875\n",
      "                , loss2: 0.11412911415100098\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 930 epoch, average loss: -28.39237060546875\n",
      "                , loss1: -9499.61484375\n",
      "                , loss2: 0.10647159814834595\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 940 epoch, average loss: -28.403375244140626\n",
      "                , loss1: -9493.403125\n",
      "                , loss2: 0.07683382630348205\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 950 epoch, average loss: -28.41597900390625\n",
      "                , loss1: -9487.91640625\n",
      "                , loss2: 0.04776991605758667\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 960 epoch, average loss: -28.402438354492187\n",
      "                , loss1: -9494.48984375\n",
      "                , loss2: 0.08103063106536865\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 970 epoch, average loss: -28.41584167480469\n",
      "                , loss1: -9494.7359375\n",
      "                , loss2: 0.06836575269699097\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 980 epoch, average loss: -28.396133422851562\n",
      "                , loss1: -9498.8265625\n",
      "                , loss2: 0.1003455400466919\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 990 epoch, average loss: -28.414352416992188\n",
      "                , loss1: -9494.8\n",
      "                , loss2: 0.07004790306091309\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1000 epoch, average loss: -28.41063232421875\n",
      "                , loss1: -9492.6078125\n",
      "                , loss2: 0.06719282865524293\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1010 epoch, average loss: -28.405999755859376\n",
      "                , loss1: -9500.92734375\n",
      "                , loss2: 0.09678456783294678\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1020 epoch, average loss: -28.424041748046875\n",
      "                , loss1: -9494.2828125\n",
      "                , loss2: 0.05880540609359741\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1030 epoch, average loss: -28.424530029296875\n",
      "                , loss1: -9498.38515625\n",
      "                , loss2: 0.07062946557998658\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1040 epoch, average loss: -28.42230224609375\n",
      "                , loss1: -9496.5640625\n",
      "                , loss2: 0.06739201545715331\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1050 epoch, average loss: -28.419253540039062\n",
      "                , loss1: -9493.42265625\n",
      "                , loss2: 0.061018311977386476\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1060 epoch, average loss: -28.421063232421876\n",
      "                , loss1: -9504.3\n",
      "                , loss2: 0.0918358325958252\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1070 epoch, average loss: -28.441851806640624\n",
      "                , loss1: -9501.09375\n",
      "                , loss2: 0.06143091917037964\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1080 epoch, average loss: -28.412298583984374\n",
      "                , loss1: -9494.96796875\n",
      "                , loss2: 0.07260310053825378\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1090 epoch, average loss: -28.441372680664063\n",
      "                , loss1: -9501.28125\n",
      "                , loss2: 0.062470662593841556\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1100 epoch, average loss: -28.427120971679688\n",
      "                , loss1: -9503.17109375\n",
      "                , loss2: 0.08238733410835267\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1110 epoch, average loss: -28.448318481445312\n",
      "                , loss1: -9498.425\n",
      "                , loss2: 0.04695630669593811\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1120 epoch, average loss: -28.4260009765625\n",
      "                , loss1: -9509.1078125\n",
      "                , loss2: 0.10132158994674682\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1130 epoch, average loss: -28.40526123046875\n",
      "                , loss1: -9506.9859375\n",
      "                , loss2: 0.11569790840148926\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1140 epoch, average loss: -28.36475524902344\n",
      "                , loss1: -9501.18671875\n",
      "                , loss2: 0.13880327939987183\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1150 epoch, average loss: -28.421697998046874\n",
      "                , loss1: -9511.67578125\n",
      "                , loss2: 0.11332893371582031\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1160 epoch, average loss: -28.4175537109375\n",
      "                , loss1: -9512.9125\n",
      "                , loss2: 0.12118347883224487\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1170 epoch, average loss: -28.422915649414062\n",
      "                , loss1: -9511.8\n",
      "                , loss2: 0.11248456239700318\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1180 epoch, average loss: -28.46361083984375\n",
      "                , loss1: -9502.565625\n",
      "                , loss2: 0.044088628888130185\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1190 epoch, average loss: -28.42547607421875\n",
      "                , loss1: -9502.39453125\n",
      "                , loss2: 0.0817114531993866\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1200 epoch, average loss: -28.41390380859375\n",
      "                , loss1: -9513.665625\n",
      "                , loss2: 0.12709349393844604\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1210 epoch, average loss: -28.420346069335938\n",
      "                , loss1: -9509.90703125\n",
      "                , loss2: 0.1093744158744812\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1220 epoch, average loss: -28.424771118164063\n",
      "                , loss1: -9502.67109375\n",
      "                , loss2: 0.08324147462844848\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1230 epoch, average loss: -28.439846801757813\n",
      "                , loss1: -9505.9703125\n",
      "                , loss2: 0.0780623197555542\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1240 epoch, average loss: -28.442172241210937\n",
      "                , loss1: -9505.24375\n",
      "                , loss2: 0.07356142997741699\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1250 epoch, average loss: -28.4404541015625\n",
      "                , loss1: -9501.91328125\n",
      "                , loss2: 0.06528199315071107\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1260 epoch, average loss: -28.451318359375\n",
      "                , loss1: -9503.43203125\n",
      "                , loss2: 0.058976387977600096\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1270 epoch, average loss: -28.44276123046875\n",
      "                , loss1: -9508.95234375\n",
      "                , loss2: 0.0840959370136261\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1280 epoch, average loss: -28.47301330566406\n",
      "                , loss1: -9502.57890625\n",
      "                , loss2: 0.03472411930561066\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1290 epoch, average loss: -28.45601806640625\n",
      "                , loss1: -9506.5890625\n",
      "                , loss2: 0.06374832391738891\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1300 epoch, average loss: -28.473770141601562\n",
      "                , loss1: -9505.55\n",
      "                , loss2: 0.04288085699081421\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1310 epoch, average loss: -28.439956665039062\n",
      "                , loss1: -9505.46328125\n",
      "                , loss2: 0.07643288969993592\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1320 epoch, average loss: -28.4303466796875\n",
      "                , loss1: -9511.7046875\n",
      "                , loss2: 0.10476610660552979\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1330 epoch, average loss: -28.454879760742188\n",
      "                , loss1: -9510.99375\n",
      "                , loss2: 0.07810027599334717\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1340 epoch, average loss: -28.46983642578125\n",
      "                , loss1: -9506.36953125\n",
      "                , loss2: 0.04927342534065247\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1350 epoch, average loss: -28.454953002929688\n",
      "                , loss1: -9505.1859375\n",
      "                , loss2: 0.060605567693710324\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1360 epoch, average loss: -28.454757690429688\n",
      "                , loss1: -9505.3359375\n",
      "                , loss2: 0.06125380396842957\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1370 epoch, average loss: -28.459014892578125\n",
      "                , loss1: -9506.209375\n",
      "                , loss2: 0.05961155891418457\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1380 epoch, average loss: -28.460269165039062\n",
      "                , loss1: -9508.421875\n",
      "                , loss2: 0.06499847173690795\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1390 epoch, average loss: -28.470382690429688\n",
      "                , loss1: -9506.7578125\n",
      "                , loss2: 0.04988972544670105\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1400 epoch, average loss: -28.442611694335938\n",
      "                , loss1: -9504.45703125\n",
      "                , loss2: 0.07075822353363037\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1410 epoch, average loss: -28.432553100585938\n",
      "                , loss1: -9512.81640625\n",
      "                , loss2: 0.10589995384216308\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1420 epoch, average loss: -28.422637939453125\n",
      "                , loss1: -9515.35546875\n",
      "                , loss2: 0.1234276294708252\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1430 epoch, average loss: -28.448760986328125\n",
      "                , loss1: -9511.2828125\n",
      "                , loss2: 0.08508814573287964\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1440 epoch, average loss: -28.453289794921876\n",
      "                , loss1: -9503.20859375\n",
      "                , loss2: 0.056338316202163695\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1450 epoch, average loss: -28.47452392578125\n",
      "                , loss1: -9508.8203125\n",
      "                , loss2: 0.05194028615951538\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1460 epoch, average loss: -28.461581420898437\n",
      "                , loss1: -9508.79296875\n",
      "                , loss2: 0.06479663252830506\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1470 epoch, average loss: -28.463949584960936\n",
      "                , loss1: -9504.8984375\n",
      "                , loss2: 0.050746607780456546\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1480 epoch, average loss: -28.47590026855469\n",
      "                , loss1: -9506.8953125\n",
      "                , loss2: 0.044786003232002256\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1490 epoch, average loss: -28.463699340820312\n",
      "                , loss1: -9510.48203125\n",
      "                , loss2: 0.0677439272403717\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1500 epoch, average loss: -28.475802612304687\n",
      "                , loss1: -9504.98515625\n",
      "                , loss2: 0.039155760407447816\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1510 epoch, average loss: -28.42851867675781\n",
      "                , loss1: -9512.2265625\n",
      "                , loss2: 0.10816433429718017\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1520 epoch, average loss: -28.4369873046875\n",
      "                , loss1: -9513.8234375\n",
      "                , loss2: 0.10448071956634522\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1530 epoch, average loss: -28.453973388671876\n",
      "                , loss1: -9513.3984375\n",
      "                , loss2: 0.0862247109413147\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1540 epoch, average loss: -28.471307373046876\n",
      "                , loss1: -9510.85390625\n",
      "                , loss2: 0.06125369668006897\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1550 epoch, average loss: -28.443646240234376\n",
      "                , loss1: -9504.2578125\n",
      "                , loss2: 0.06912887096405029\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1560 epoch, average loss: -28.451065063476562\n",
      "                , loss1: -9513.3984375\n",
      "                , loss2: 0.08913458585739135\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1570 epoch, average loss: -28.479885864257813\n",
      "                , loss1: -9508.74296875\n",
      "                , loss2: 0.04634007215499878\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1580 epoch, average loss: -28.471273803710936\n",
      "                , loss1: -9504.9015625\n",
      "                , loss2: 0.04343307912349701\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1590 epoch, average loss: -28.445938110351562\n",
      "                , loss1: -9505.67265625\n",
      "                , loss2: 0.07107779383659363\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1600 epoch, average loss: -28.45679626464844\n",
      "                , loss1: -9515.47578125\n",
      "                , loss2: 0.0896323263645172\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1610 epoch, average loss: -28.440383911132812\n",
      "                , loss1: -9515.9625\n",
      "                , loss2: 0.10750412940979004\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1620 epoch, average loss: -28.470721435546874\n",
      "                , loss1: -9513.3796875\n",
      "                , loss2: 0.0694158136844635\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1630 epoch, average loss: -28.45767822265625\n",
      "                , loss1: -9510.775\n",
      "                , loss2: 0.0746443212032318\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1640 epoch, average loss: -28.4870361328125\n",
      "                , loss1: -9503.11640625\n",
      "                , loss2: 0.02231275141239166\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1650 epoch, average loss: -28.455535888671875\n",
      "                , loss1: -9510.70078125\n",
      "                , loss2: 0.07656867504119873\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1660 epoch, average loss: -28.435760498046875\n",
      "                , loss1: -9515.51328125\n",
      "                , loss2: 0.11078112125396729\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1670 epoch, average loss: -28.468255615234376\n",
      "                , loss1: -9504.5625\n",
      "                , loss2: 0.04543121457099915\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1680 epoch, average loss: -28.478408813476562\n",
      "                , loss1: -9512.3515625\n",
      "                , loss2: 0.05864630341529846\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1690 epoch, average loss: -28.479672241210938\n",
      "                , loss1: -9512.753125\n",
      "                , loss2: 0.058587729930877686\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1700 epoch, average loss: -28.463009643554688\n",
      "                , loss1: -9504.6078125\n",
      "                , loss2: 0.05081599950790405\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1710 epoch, average loss: -28.475503540039064\n",
      "                , loss1: -9511.77578125\n",
      "                , loss2: 0.0598225474357605\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1720 epoch, average loss: -28.473785400390625\n",
      "                , loss1: -9511.49296875\n",
      "                , loss2: 0.060691159963607785\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1730 epoch, average loss: -28.457855224609375\n",
      "                , loss1: -9505.73515625\n",
      "                , loss2: 0.05935052633285522\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1740 epoch, average loss: -28.476629638671874\n",
      "                , loss1: -9509.0265625\n",
      "                , loss2: 0.05045546889305115\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1750 epoch, average loss: -28.47158203125\n",
      "                , loss1: -9509.92265625\n",
      "                , loss2: 0.05818586349487305\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1760 epoch, average loss: -28.458294677734376\n",
      "                , loss1: -9507.00390625\n",
      "                , loss2: 0.06271862983703613\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1770 epoch, average loss: -28.47199401855469\n",
      "                , loss1: -9514.01171875\n",
      "                , loss2: 0.07004136443138123\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1780 epoch, average loss: -28.461331176757813\n",
      "                , loss1: -9511.91015625\n",
      "                , loss2: 0.07440177798271179\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1790 epoch, average loss: -28.47376708984375\n",
      "                , loss1: -9510.48671875\n",
      "                , loss2: 0.05769301652908325\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1800 epoch, average loss: -28.46532287597656\n",
      "                , loss1: -9507.4265625\n",
      "                , loss2: 0.056955426931381226\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1810 epoch, average loss: -28.4744384765625\n",
      "                , loss1: -9506.33984375\n",
      "                , loss2: 0.04457816183567047\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1820 epoch, average loss: -28.485693359375\n",
      "                , loss1: -9507.77109375\n",
      "                , loss2: 0.03762062191963196\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1830 epoch, average loss: -28.4822021484375\n",
      "                , loss1: -9511.5609375\n",
      "                , loss2: 0.052485603094100955\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1840 epoch, average loss: -28.46711120605469\n",
      "                , loss1: -9508.75703125\n",
      "                , loss2: 0.059161603450775146\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1850 epoch, average loss: -28.482562255859374\n",
      "                , loss1: -9508.00078125\n",
      "                , loss2: 0.041441765427589414\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1860 epoch, average loss: -28.475668334960936\n",
      "                , loss1: -9508.93046875\n",
      "                , loss2: 0.051124167442321775\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1870 epoch, average loss: -28.476400756835936\n",
      "                , loss1: -9508.01015625\n",
      "                , loss2: 0.0476323664188385\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1880 epoch, average loss: -28.466644287109375\n",
      "                , loss1: -9511.515625\n",
      "                , loss2: 0.06790288686752319\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1890 epoch, average loss: -28.474664306640626\n",
      "                , loss1: -9507.25625\n",
      "                , loss2: 0.04710426926612854\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1900 epoch, average loss: -28.48455810546875\n",
      "                , loss1: -9511.68828125\n",
      "                , loss2: 0.05050627589225769\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1910 epoch, average loss: -28.477157592773438\n",
      "                , loss1: -9511.2625\n",
      "                , loss2: 0.056630825996398924\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1920 epoch, average loss: -28.4906005859375\n",
      "                , loss1: -9503.340625\n",
      "                , loss2: 0.019422684609889985\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1930 epoch, average loss: -28.475918579101563\n",
      "                , loss1: -9511.62109375\n",
      "                , loss2: 0.058946633338928224\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1940 epoch, average loss: -28.47957763671875\n",
      "                , loss1: -9508.81796875\n",
      "                , loss2: 0.04687663316726685\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1950 epoch, average loss: -28.486740112304688\n",
      "                , loss1: -9507.56328125\n",
      "                , loss2: 0.03594869077205658\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1960 epoch, average loss: -28.483953857421874\n",
      "                , loss1: -9509.603125\n",
      "                , loss2: 0.04485434293746948\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1970 epoch, average loss: -28.487847900390626\n",
      "                , loss1: -9508.22578125\n",
      "                , loss2: 0.036826491355895996\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1980 epoch, average loss: -28.487811279296874\n",
      "                , loss1: -9507.509375\n",
      "                , loss2: 0.03471631407737732\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 1990 epoch, average loss: -28.470968627929686\n",
      "                , loss1: -9509.24609375\n",
      "                , loss2: 0.056768155097961424\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2000 epoch, average loss: -28.477880859375\n",
      "                , loss1: -9513.8265625\n",
      "                , loss2: 0.0635989785194397\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2010 epoch, average loss: -28.48340759277344\n",
      "                , loss1: -9509.9015625\n",
      "                , loss2: 0.046303564310073854\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2020 epoch, average loss: -28.48052978515625\n",
      "                , loss1: -9506.65390625\n",
      "                , loss2: 0.039432868361473083\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2030 epoch, average loss: -28.482009887695312\n",
      "                , loss1: -9513.35625\n",
      "                , loss2: 0.05806182622909546\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2040 epoch, average loss: -28.500155639648437\n",
      "                , loss1: -9506.38828125\n",
      "                , loss2: 0.019008079171180726\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2050 epoch, average loss: -28.477322387695313\n",
      "                , loss1: -9508.578125\n",
      "                , loss2: 0.04841111302375793\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2060 epoch, average loss: -28.478753662109376\n",
      "                , loss1: -9510.959375\n",
      "                , loss2: 0.05412572026252747\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2070 epoch, average loss: -28.481268310546874\n",
      "                , loss1: -9510.428125\n",
      "                , loss2: 0.05001330375671387\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2080 epoch, average loss: -28.486566162109376\n",
      "                , loss1: -9506.4859375\n",
      "                , loss2: 0.032892906665802\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2090 epoch, average loss: -28.4824951171875\n",
      "                , loss1: -9511.0625\n",
      "                , loss2: 0.050691884756088254\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2100 epoch, average loss: -28.47132263183594\n",
      "                , loss1: -9516.08828125\n",
      "                , loss2: 0.07694571018218994\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2110 epoch, average loss: -28.48421630859375\n",
      "                , loss1: -9511.26171875\n",
      "                , loss2: 0.04957118928432465\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2120 epoch, average loss: -28.464999389648437\n",
      "                , loss1: -9506.2171875\n",
      "                , loss2: 0.05365204215049744\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2130 epoch, average loss: -28.448919677734374\n",
      "                , loss1: -9516.92578125\n",
      "                , loss2: 0.10185952186584472\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2140 epoch, average loss: -28.448593139648438\n",
      "                , loss1: -9516.953125\n",
      "                , loss2: 0.10226861238479615\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2150 epoch, average loss: -28.459539794921874\n",
      "                , loss1: -9517.07109375\n",
      "                , loss2: 0.09167343378067017\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2160 epoch, average loss: -28.48101806640625\n",
      "                , loss1: -9511.43046875\n",
      "                , loss2: 0.05327450037002564\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2170 epoch, average loss: -28.495114135742188\n",
      "                , loss1: -9505.30390625\n",
      "                , loss2: 0.020793651044368745\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2180 epoch, average loss: -28.452615356445314\n",
      "                , loss1: -9513.3453125\n",
      "                , loss2: 0.0874180793762207\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2190 epoch, average loss: -28.4423583984375\n",
      "                , loss1: -9519.4671875\n",
      "                , loss2: 0.1160447359085083\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2200 epoch, average loss: -28.45702209472656\n",
      "                , loss1: -9519.1140625\n",
      "                , loss2: 0.1003190517425537\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2210 epoch, average loss: -28.450701904296874\n",
      "                , loss1: -9519.346875\n",
      "                , loss2: 0.10733821392059326\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2220 epoch, average loss: -28.471530151367187\n",
      "                , loss1: -9517.7015625\n",
      "                , loss2: 0.0815756618976593\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2230 epoch, average loss: -28.475372314453125\n",
      "                , loss1: -9515.62734375\n",
      "                , loss2: 0.07150900959968567\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2240 epoch, average loss: -28.483370971679687\n",
      "                , loss1: -9509.69609375\n",
      "                , loss2: 0.045715779066085815\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2250 epoch, average loss: -28.478643798828124\n",
      "                , loss1: -9511.128125\n",
      "                , loss2: 0.05474768280982971\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2260 epoch, average loss: -28.462603759765624\n",
      "                , loss1: -9518.4640625\n",
      "                , loss2: 0.09279141426086426\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2270 epoch, average loss: -28.4623291015625\n",
      "                , loss1: -9518.03671875\n",
      "                , loss2: 0.09177895188331604\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2280 epoch, average loss: -28.46998291015625\n",
      "                , loss1: -9517.64921875\n",
      "                , loss2: 0.0829682171344757\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2290 epoch, average loss: -28.48834228515625\n",
      "                , loss1: -9511.28125\n",
      "                , loss2: 0.045500960946083066\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2300 epoch, average loss: -28.4697265625\n",
      "                , loss1: -9507.4453125\n",
      "                , loss2: 0.052610081434249875\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2310 epoch, average loss: -28.468814086914062\n",
      "                , loss1: -9515.2359375\n",
      "                , loss2: 0.07689871788024902\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2320 epoch, average loss: -28.469204711914063\n",
      "                , loss1: -9507.65859375\n",
      "                , loss2: 0.053769803047180174\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2330 epoch, average loss: -28.480712890625\n",
      "                , loss1: -9512.496875\n",
      "                , loss2: 0.05677595138549805\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2340 epoch, average loss: -28.4822265625\n",
      "                , loss1: -9510.93125\n",
      "                , loss2: 0.0505684494972229\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2350 epoch, average loss: -28.48336181640625\n",
      "                , loss1: -9513.6015625\n",
      "                , loss2: 0.0574390709400177\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2360 epoch, average loss: -28.475668334960936\n",
      "                , loss1: -9508.80078125\n",
      "                , loss2: 0.05073651075363159\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2370 epoch, average loss: -28.4783203125\n",
      "                , loss1: -9516.71796875\n",
      "                , loss2: 0.07183688879013062\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2380 epoch, average loss: -28.47764892578125\n",
      "                , loss1: -9517.490625\n",
      "                , loss2: 0.07482854127883912\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2390 epoch, average loss: -28.481732177734376\n",
      "                , loss1: -9514.975\n",
      "                , loss2: 0.06319301724433898\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2400 epoch, average loss: -28.5027587890625\n",
      "                , loss1: -9508.62265625\n",
      "                , loss2: 0.02311186194419861\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2410 epoch, average loss: -28.475143432617188\n",
      "                , loss1: -9509.14921875\n",
      "                , loss2: 0.05230208039283753\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2420 epoch, average loss: -28.48446044921875\n",
      "                , loss1: -9514.71484375\n",
      "                , loss2: 0.05968433618545532\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2430 epoch, average loss: -28.481201171875\n",
      "                , loss1: -9515.690625\n",
      "                , loss2: 0.06587033271789551\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2440 epoch, average loss: -28.498626708984375\n",
      "                , loss1: -9508.290625\n",
      "                , loss2: 0.026246267557144164\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2450 epoch, average loss: -28.48543701171875\n",
      "                , loss1: -9508.47109375\n",
      "                , loss2: 0.03998223245143891\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2460 epoch, average loss: -28.486184692382814\n",
      "                , loss1: -9514.0234375\n",
      "                , loss2: 0.05588628053665161\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2470 epoch, average loss: -28.495465087890626\n",
      "                , loss1: -9513.684375\n",
      "                , loss2: 0.045584496855735776\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2480 epoch, average loss: -28.489224243164063\n",
      "                , loss1: -9507.375\n",
      "                , loss2: 0.03289989531040192\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2490 epoch, average loss: -28.488552856445313\n",
      "                , loss1: -9509.3140625\n",
      "                , loss2: 0.039387327432632444\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2500 epoch, average loss: -28.479489135742188\n",
      "                , loss1: -9515.596875\n",
      "                , loss2: 0.06730331778526306\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2510 epoch, average loss: -28.491748046875\n",
      "                , loss1: -9514.3796875\n",
      "                , loss2: 0.05139123797416687\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2520 epoch, average loss: -28.488064575195313\n",
      "                , loss1: -9509.6328125\n",
      "                , loss2: 0.040833193063735965\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2530 epoch, average loss: -28.477685546875\n",
      "                , loss1: -9516.58984375\n",
      "                , loss2: 0.07208656072616577\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2540 epoch, average loss: -28.486920166015626\n",
      "                , loss1: -9512.48203125\n",
      "                , loss2: 0.05052418708801269\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2550 epoch, average loss: -28.496917724609375\n",
      "                , loss1: -9509.85390625\n",
      "                , loss2: 0.032642093300819394\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2560 epoch, average loss: -28.496365356445313\n",
      "                , loss1: -9511.07890625\n",
      "                , loss2: 0.03686840832233429\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2570 epoch, average loss: -28.499517822265624\n",
      "                , loss1: -9507.91953125\n",
      "                , loss2: 0.024243104457855224\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2580 epoch, average loss: -28.49439697265625\n",
      "                , loss1: -9514.1375\n",
      "                , loss2: 0.048017221689224246\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2590 epoch, average loss: -28.497784423828126\n",
      "                , loss1: -9507.0421875\n",
      "                , loss2: 0.02334255278110504\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2600 epoch, average loss: -28.47593994140625\n",
      "                , loss1: -9515.528125\n",
      "                , loss2: 0.07064474821090698\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2610 epoch, average loss: -28.498519897460938\n",
      "                , loss1: -9512.4796875\n",
      "                , loss2: 0.03892010450363159\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2620 epoch, average loss: -28.493008422851563\n",
      "                , loss1: -9509.140625\n",
      "                , loss2: 0.03441203534603119\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2630 epoch, average loss: -28.47744140625\n",
      "                , loss1: -9517.63359375\n",
      "                , loss2: 0.07545575499534607\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2640 epoch, average loss: -28.487820434570313\n",
      "                , loss1: -9513.278125\n",
      "                , loss2: 0.05201480388641357\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2650 epoch, average loss: -28.4757080078125\n",
      "                , loss1: -9506.08671875\n",
      "                , loss2: 0.042552560567855835\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2660 epoch, average loss: -28.457424926757813\n",
      "                , loss1: -9519.665625\n",
      "                , loss2: 0.10156947374343872\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2670 epoch, average loss: -28.462771606445312\n",
      "                , loss1: -9519.8265625\n",
      "                , loss2: 0.09671046137809754\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2680 epoch, average loss: -28.46361389160156\n",
      "                , loss1: -9520.39453125\n",
      "                , loss2: 0.09756988286972046\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2690 epoch, average loss: -28.477374267578124\n",
      "                , loss1: -9518.96171875\n",
      "                , loss2: 0.07951121330261231\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2700 epoch, average loss: -28.478170776367186\n",
      "                , loss1: -9517.12265625\n",
      "                , loss2: 0.0731942117214203\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2710 epoch, average loss: -28.4935302734375\n",
      "                , loss1: -9509.821875\n",
      "                , loss2: 0.03593403995037079\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2720 epoch, average loss: -28.497860717773438\n",
      "                , loss1: -9510.1609375\n",
      "                , loss2: 0.03262097835540771\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2730 epoch, average loss: -28.493548583984374\n",
      "                , loss1: -9514.1984375\n",
      "                , loss2: 0.049050965905189516\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2740 epoch, average loss: -28.500082397460936\n",
      "                , loss1: -9510.8359375\n",
      "                , loss2: 0.03242473006248474\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2750 epoch, average loss: -28.486251831054688\n",
      "                , loss1: -9510.09140625\n",
      "                , loss2: 0.044024378061294556\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2760 epoch, average loss: -28.480255126953125\n",
      "                , loss1: -9518.978125\n",
      "                , loss2: 0.076680988073349\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2770 epoch, average loss: -28.47769775390625\n",
      "                , loss1: -9517.5171875\n",
      "                , loss2: 0.07485538125038146\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2780 epoch, average loss: -28.49058837890625\n",
      "                , loss1: -9516.3453125\n",
      "                , loss2: 0.05844940543174744\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2790 epoch, average loss: -28.453958129882814\n",
      "                , loss1: -9511.0953125\n",
      "                , loss2: 0.07932588458061218\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2800 epoch, average loss: -28.421340942382812\n",
      "                , loss1: -9520.09921875\n",
      "                , loss2: 0.1389594316482544\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2810 epoch, average loss: -28.45909423828125\n",
      "                , loss1: -9520.946875\n",
      "                , loss2: 0.10374251604080201\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2820 epoch, average loss: -28.475387573242188\n",
      "                , loss1: -9519.33359375\n",
      "                , loss2: 0.0826100766658783\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2830 epoch, average loss: -28.483670043945313\n",
      "                , loss1: -9515.97734375\n",
      "                , loss2: 0.06426242589950562\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2840 epoch, average loss: -28.474993896484374\n",
      "                , loss1: -9515.359375\n",
      "                , loss2: 0.07108728289604187\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2850 epoch, average loss: -28.495831298828126\n",
      "                , loss1: -9510.74375\n",
      "                , loss2: 0.036404192447662354\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2860 epoch, average loss: -28.497198486328124\n",
      "                , loss1: -9512.2109375\n",
      "                , loss2: 0.039437702298164366\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2870 epoch, average loss: -28.484597778320314\n",
      "                , loss1: -9513.36796875\n",
      "                , loss2: 0.0555087149143219\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2880 epoch, average loss: -28.47480163574219\n",
      "                , loss1: -9517.2640625\n",
      "                , loss2: 0.07698657512664794\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2890 epoch, average loss: -28.49268798828125\n",
      "                , loss1: -9516.39375\n",
      "                , loss2: 0.05649168491363525\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2900 epoch, average loss: -28.496231079101562\n",
      "                , loss1: -9508.26640625\n",
      "                , loss2: 0.028570255637168883\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2910 epoch, average loss: -28.496697998046876\n",
      "                , loss1: -9512.5578125\n",
      "                , loss2: 0.04097639918327332\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2920 epoch, average loss: -28.494778442382813\n",
      "                , loss1: -9512.27421875\n",
      "                , loss2: 0.04204481542110443\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2930 epoch, average loss: -28.503115844726562\n",
      "                , loss1: -9513.60234375\n",
      "                , loss2: 0.037690120935440066\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2940 epoch, average loss: -28.48753967285156\n",
      "                , loss1: -9507.06484375\n",
      "                , loss2: 0.03364922702312469\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2950 epoch, average loss: -28.474267578125\n",
      "                , loss1: -9518.94453125\n",
      "                , loss2: 0.08256438970565796\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2960 epoch, average loss: -28.465969848632813\n",
      "                , loss1: -9520.2828125\n",
      "                , loss2: 0.09487586617469787\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2970 epoch, average loss: -28.4697021484375\n",
      "                , loss1: -9521.0359375\n",
      "                , loss2: 0.0934041440486908\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2980 epoch, average loss: -28.46126708984375\n",
      "                , loss1: -9519.63828125\n",
      "                , loss2: 0.09764780402183533\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 2990 epoch, average loss: -28.47557678222656\n",
      "                , loss1: -9520.00546875\n",
      "                , loss2: 0.0844372570514679\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3000 epoch, average loss: -28.47352294921875\n",
      "                , loss1: -9520.41328125\n",
      "                , loss2: 0.08771587014198304\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3010 epoch, average loss: -28.475949096679688\n",
      "                , loss1: -9518.2234375\n",
      "                , loss2: 0.07872240543365479\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3020 epoch, average loss: -28.484054565429688\n",
      "                , loss1: -9517.95625\n",
      "                , loss2: 0.06981397867202759\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3030 epoch, average loss: -28.4899169921875\n",
      "                , loss1: -9513.209375\n",
      "                , loss2: 0.049712204933166505\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3040 epoch, average loss: -28.498773193359376\n",
      "                , loss1: -9506.5171875\n",
      "                , loss2: 0.020779453217983246\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3050 epoch, average loss: -28.505743408203124\n",
      "                , loss1: -9513.109375\n",
      "                , loss2: 0.033586549758911136\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3060 epoch, average loss: -28.485140991210937\n",
      "                , loss1: -9514.2359375\n",
      "                , loss2: 0.0575692892074585\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3070 epoch, average loss: -28.490921020507812\n",
      "                , loss1: -9507.7453125\n",
      "                , loss2: 0.03231066763401032\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3080 epoch, average loss: -28.496115112304686\n",
      "                , loss1: -9513.3640625\n",
      "                , loss2: 0.04397632777690887\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3090 epoch, average loss: -28.480877685546876\n",
      "                , loss1: -9512.8\n",
      "                , loss2: 0.05752256512641907\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3100 epoch, average loss: -28.464450073242187\n",
      "                , loss1: -9518.80625\n",
      "                , loss2: 0.09196581840515136\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3110 epoch, average loss: -28.47928466796875\n",
      "                , loss1: -9519.1328125\n",
      "                , loss2: 0.078116774559021\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3120 epoch, average loss: -28.47785339355469\n",
      "                , loss1: -9519.18203125\n",
      "                , loss2: 0.07969803214073182\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3130 epoch, average loss: -28.49698486328125\n",
      "                , loss1: -9513.815625\n",
      "                , loss2: 0.04446559548377991\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3140 epoch, average loss: -28.501541137695312\n",
      "                , loss1: -9508.54609375\n",
      "                , loss2: 0.024097719788551332\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3150 epoch, average loss: -28.49954833984375\n",
      "                , loss1: -9510.7765625\n",
      "                , loss2: 0.032781189680099486\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3160 epoch, average loss: -28.495217895507814\n",
      "                , loss1: -9515.79140625\n",
      "                , loss2: 0.052153372764587404\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3170 epoch, average loss: -28.4993408203125\n",
      "                , loss1: -9514.30625\n",
      "                , loss2: 0.04357692301273346\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3180 epoch, average loss: -28.494708251953124\n",
      "                , loss1: -9508.41953125\n",
      "                , loss2: 0.030550038814544676\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3190 epoch, average loss: -28.499844360351563\n",
      "                , loss1: -9515.8984375\n",
      "                , loss2: 0.047849759459495544\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3200 epoch, average loss: -28.50153503417969\n",
      "                , loss1: -9510.11953125\n",
      "                , loss2: 0.02882513403892517\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3210 epoch, average loss: -28.506976318359374\n",
      "                , loss1: -9512.075\n",
      "                , loss2: 0.029244047403335572\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3220 epoch, average loss: -28.498623657226563\n",
      "                , loss1: -9508.6453125\n",
      "                , loss2: 0.02731585204601288\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3230 epoch, average loss: -28.490625\n",
      "                , loss1: -9518.30234375\n",
      "                , loss2: 0.0642815351486206\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3240 epoch, average loss: -28.49476013183594\n",
      "                , loss1: -9510.9890625\n",
      "                , loss2: 0.03821014165878296\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3250 epoch, average loss: -28.49619140625\n",
      "                , loss1: -9517.3140625\n",
      "                , loss2: 0.055750519037246704\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3260 epoch, average loss: -28.497604370117188\n",
      "                , loss1: -9511.3421875\n",
      "                , loss2: 0.03642363548278808\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3270 epoch, average loss: -28.491287231445312\n",
      "                , loss1: -9517.09375\n",
      "                , loss2: 0.0599999725818634\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3280 epoch, average loss: -28.490786743164062\n",
      "                , loss1: -9510.403125\n",
      "                , loss2: 0.04042075574398041\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3290 epoch, average loss: -28.500909423828126\n",
      "                , loss1: -9514.6359375\n",
      "                , loss2: 0.04299800992012024\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3300 epoch, average loss: -28.49881591796875\n",
      "                , loss1: -9512.53828125\n",
      "                , loss2: 0.03879804313182831\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3310 epoch, average loss: -28.473056030273437\n",
      "                , loss1: -9510.90859375\n",
      "                , loss2: 0.05966953635215759\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3320 epoch, average loss: -28.49019775390625\n",
      "                , loss1: -9517.64609375\n",
      "                , loss2: 0.06274012327194214\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3330 epoch, average loss: -28.496987915039064\n",
      "                , loss1: -9515.62890625\n",
      "                , loss2: 0.04989607632160187\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3340 epoch, average loss: -28.512139892578126\n",
      "                , loss1: -9509.12265625\n",
      "                , loss2: 0.015228617191314697\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3350 epoch, average loss: -28.508395385742187\n",
      "                , loss1: -9508.70078125\n",
      "                , loss2: 0.01770551800727844\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3360 epoch, average loss: -28.5045654296875\n",
      "                , loss1: -9512.815625\n",
      "                , loss2: 0.033882513642311096\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3370 epoch, average loss: -28.50567626953125\n",
      "                , loss1: -9510.5109375\n",
      "                , loss2: 0.02585468292236328\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3380 epoch, average loss: -28.497683715820312\n",
      "                , loss1: -9512.815625\n",
      "                , loss2: 0.04076290726661682\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3390 epoch, average loss: -28.5017333984375\n",
      "                , loss1: -9515.4328125\n",
      "                , loss2: 0.04456169009208679\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3400 epoch, average loss: -28.506072998046875\n",
      "                , loss1: -9511.09296875\n",
      "                , loss2: 0.027204281091690062\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3410 epoch, average loss: -28.50079345703125\n",
      "                , loss1: -9509.85\n",
      "                , loss2: 0.02875572144985199\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3420 epoch, average loss: -28.50460205078125\n",
      "                , loss1: -9511.40625\n",
      "                , loss2: 0.02961665391921997\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3430 epoch, average loss: -28.500900268554688\n",
      "                , loss1: -9510.81875\n",
      "                , loss2: 0.03155450522899628\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3440 epoch, average loss: -28.51165771484375\n",
      "                , loss1: -9513.5921875\n",
      "                , loss2: 0.02912222743034363\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3450 epoch, average loss: -28.506466674804688\n",
      "                , loss1: -9512.1296875\n",
      "                , loss2: 0.0299251526594162\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3460 epoch, average loss: -28.505709838867187\n",
      "                , loss1: -9506.4546875\n",
      "                , loss2: 0.013653181493282318\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3470 epoch, average loss: -28.496026611328126\n",
      "                , loss1: -9516.99453125\n",
      "                , loss2: 0.05495543479919433\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3480 epoch, average loss: -28.492001342773438\n",
      "                , loss1: -9516.9765625\n",
      "                , loss2: 0.05892918705940246\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3490 epoch, average loss: -28.496844482421874\n",
      "                , loss1: -9512.08046875\n",
      "                , loss2: 0.03939477801322937\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3500 epoch, average loss: -28.503091430664064\n",
      "                , loss1: -9511.4453125\n",
      "                , loss2: 0.031246218085289\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3510 epoch, average loss: -28.500799560546874\n",
      "                , loss1: -9508.18046875\n",
      "                , loss2: 0.023740112781524658\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3520 epoch, average loss: -28.498208618164064\n",
      "                , loss1: -9517.4921875\n",
      "                , loss2: 0.054266542196273804\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3530 epoch, average loss: -28.497991943359374\n",
      "                , loss1: -9515.8734375\n",
      "                , loss2: 0.04962620735168457\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3540 epoch, average loss: -28.50031433105469\n",
      "                , loss1: -9510.28515625\n",
      "                , loss2: 0.03054078221321106\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3550 epoch, average loss: -28.506655883789062\n",
      "                , loss1: -9513.94375\n",
      "                , loss2: 0.03517544865608215\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3560 epoch, average loss: -28.497543334960938\n",
      "                , loss1: -9511.25625\n",
      "                , loss2: 0.036225694417953494\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3570 epoch, average loss: -28.487136840820312\n",
      "                , loss1: -9518.15234375\n",
      "                , loss2: 0.06732112765312195\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3580 epoch, average loss: -28.503912353515624\n",
      "                , loss1: -9511.9359375\n",
      "                , loss2: 0.03189713060855866\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3590 epoch, average loss: -28.501251220703125\n",
      "                , loss1: -9513.92265625\n",
      "                , loss2: 0.04051562249660492\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3600 epoch, average loss: -28.511749267578125\n",
      "                , loss1: -9511.47578125\n",
      "                , loss2: 0.022682537138462067\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3610 epoch, average loss: -28.506256103515625\n",
      "                , loss1: -9511.4453125\n",
      "                , loss2: 0.028076696395874023\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3620 epoch, average loss: -28.5124267578125\n",
      "                , loss1: -9512.2859375\n",
      "                , loss2: 0.024434301257133483\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3630 epoch, average loss: -28.510638427734374\n",
      "                , loss1: -9510.53359375\n",
      "                , loss2: 0.020960724353790282\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3640 epoch, average loss: -28.507525634765624\n",
      "                , loss1: -9511.50703125\n",
      "                , loss2: 0.026996809244155883\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3650 epoch, average loss: -28.503195190429686\n",
      "                , loss1: -9513.59765625\n",
      "                , loss2: 0.037597909569740295\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3660 epoch, average loss: -28.513507080078124\n",
      "                , loss1: -9511.0484375\n",
      "                , loss2: 0.01963711977005005\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3670 epoch, average loss: -28.514227294921874\n",
      "                , loss1: -9511.88671875\n",
      "                , loss2: 0.021436408162117004\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3680 epoch, average loss: -28.507086181640624\n",
      "                , loss1: -9509.34765625\n",
      "                , loss2: 0.020955799520015715\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3690 epoch, average loss: -28.505410766601564\n",
      "                , loss1: -9513.3015625\n",
      "                , loss2: 0.034495490789413455\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3700 epoch, average loss: -28.49698486328125\n",
      "                , loss1: -9509.21171875\n",
      "                , loss2: 0.03064633011817932\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3710 epoch, average loss: -28.49205627441406\n",
      "                , loss1: -9518.34765625\n",
      "                , loss2: 0.06298865675926209\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3720 epoch, average loss: -28.49267578125\n",
      "                , loss1: -9517.64375\n",
      "                , loss2: 0.06025390028953552\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3730 epoch, average loss: -28.5067626953125\n",
      "                , loss1: -9510.71015625\n",
      "                , loss2: 0.02537132203578949\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3740 epoch, average loss: -28.51007995605469\n",
      "                , loss1: -9512.0015625\n",
      "                , loss2: 0.025928467512130737\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3750 epoch, average loss: -28.505352783203126\n",
      "                , loss1: -9511.125\n",
      "                , loss2: 0.028019383549690247\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3760 epoch, average loss: -28.509039306640624\n",
      "                , loss1: -9513.13828125\n",
      "                , loss2: 0.03037198483943939\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3770 epoch, average loss: -28.503933715820313\n",
      "                , loss1: -9510.6953125\n",
      "                , loss2: 0.02815258502960205\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3780 epoch, average loss: -28.51192626953125\n",
      "                , loss1: -9511.91953125\n",
      "                , loss2: 0.02383432984352112\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3790 epoch, average loss: -28.51007995605469\n",
      "                , loss1: -9510.71328125\n",
      "                , loss2: 0.022058215737342835\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3800 epoch, average loss: -28.5137939453125\n",
      "                , loss1: -9509.6734375\n",
      "                , loss2: 0.015230536460876465\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3810 epoch, average loss: -28.50910339355469\n",
      "                , loss1: -9513.7796875\n",
      "                , loss2: 0.032237273454666135\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3820 epoch, average loss: -28.50804748535156\n",
      "                , loss1: -9509.97421875\n",
      "                , loss2: 0.02187393307685852\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3830 epoch, average loss: -28.51109619140625\n",
      "                , loss1: -9513.41484375\n",
      "                , loss2: 0.029152894020080568\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3840 epoch, average loss: -28.506982421875\n",
      "                , loss1: -9513.0734375\n",
      "                , loss2: 0.03223813772201538\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3850 epoch, average loss: -28.51197509765625\n",
      "                , loss1: -9509.33515625\n",
      "                , loss2: 0.01603170335292816\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3860 epoch, average loss: -28.505987548828124\n",
      "                , loss1: -9515.3546875\n",
      "                , loss2: 0.04007709324359894\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3870 epoch, average loss: -28.509524536132812\n",
      "                , loss1: -9510.803125\n",
      "                , loss2: 0.02288784384727478\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3880 epoch, average loss: -28.514846801757812\n",
      "                , loss1: -9511.57109375\n",
      "                , loss2: 0.019868619740009308\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3890 epoch, average loss: -28.51276550292969\n",
      "                , loss1: -9512.80703125\n",
      "                , loss2: 0.025658100843429565\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3900 epoch, average loss: -28.50859680175781\n",
      "                , loss1: -9509.540625\n",
      "                , loss2: 0.020027735829353334\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3910 epoch, average loss: -28.497137451171874\n",
      "                , loss1: -9518.4234375\n",
      "                , loss2: 0.058132481575012204\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3920 epoch, average loss: -28.48584899902344\n",
      "                , loss1: -9512.9390625\n",
      "                , loss2: 0.052969503402709964\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3930 epoch, average loss: -28.481185913085938\n",
      "                , loss1: -9520.8484375\n",
      "                , loss2: 0.0813619077205658\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3940 epoch, average loss: -28.4866943359375\n",
      "                , loss1: -9517.3765625\n",
      "                , loss2: 0.06543422341346741\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3950 epoch, average loss: -28.489132690429688\n",
      "                , loss1: -9516.3453125\n",
      "                , loss2: 0.05990897417068482\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3960 epoch, average loss: -28.5039306640625\n",
      "                , loss1: -9510.08203125\n",
      "                , loss2: 0.02631329298019409\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3970 epoch, average loss: -28.51656494140625\n",
      "                , loss1: -9511.5625\n",
      "                , loss2: 0.018119581043720245\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3980 epoch, average loss: -28.509274291992188\n",
      "                , loss1: -9512.25390625\n",
      "                , loss2: 0.02748630940914154\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 3990 epoch, average loss: -28.510723876953126\n",
      "                , loss1: -9512.6484375\n",
      "                , loss2: 0.02722178101539612\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4000 epoch, average loss: -28.504852294921875\n",
      "                , loss1: -9510.8765625\n",
      "                , loss2: 0.027778810262680052\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4010 epoch, average loss: -28.505349731445314\n",
      "                , loss1: -9513.16875\n",
      "                , loss2: 0.034157711267471316\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4020 epoch, average loss: -28.49876708984375\n",
      "                , loss1: -9509.9234375\n",
      "                , loss2: 0.03100098967552185\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4030 epoch, average loss: -28.50025329589844\n",
      "                , loss1: -9516.07890625\n",
      "                , loss2: 0.04798173606395721\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4040 epoch, average loss: -28.511495971679686\n",
      "                , loss1: -9511.4453125\n",
      "                , loss2: 0.02284127622842789\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4050 epoch, average loss: -28.507659912109375\n",
      "                , loss1: -9511.275\n",
      "                , loss2: 0.026164060831069945\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4060 epoch, average loss: -28.500042724609376\n",
      "                , loss1: -9511.896875\n",
      "                , loss2: 0.03564887940883636\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4070 epoch, average loss: -28.50738525390625\n",
      "                , loss1: -9513.321875\n",
      "                , loss2: 0.03258454203605652\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4080 epoch, average loss: -28.50511779785156\n",
      "                , loss1: -9509.2171875\n",
      "                , loss2: 0.022537389397621156\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4090 epoch, average loss: -28.512518310546874\n",
      "                , loss1: -9512.20390625\n",
      "                , loss2: 0.024092793464660645\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4100 epoch, average loss: -28.50946960449219\n",
      "                , loss1: -9511.9234375\n",
      "                , loss2: 0.026298493146896362\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4110 epoch, average loss: -28.51256103515625\n",
      "                , loss1: -9512.61484375\n",
      "                , loss2: 0.02528139054775238\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4120 epoch, average loss: -28.506790161132812\n",
      "                , loss1: -9511.70078125\n",
      "                , loss2: 0.02831510901451111\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4130 epoch, average loss: -28.50396728515625\n",
      "                , loss1: -9515.490625\n",
      "                , loss2: 0.0425020307302475\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4140 epoch, average loss: -28.508871459960936\n",
      "                , loss1: -9510.7578125\n",
      "                , loss2: 0.023403003811836243\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4150 epoch, average loss: -28.516900634765626\n",
      "                , loss1: -9509.7734375\n",
      "                , loss2: 0.012420333176851272\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4160 epoch, average loss: -28.50557861328125\n",
      "                , loss1: -9513.6625\n",
      "                , loss2: 0.03540839552879334\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4170 epoch, average loss: -28.515814208984374\n",
      "                , loss1: -9509.728125\n",
      "                , loss2: 0.013369683921337128\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4180 epoch, average loss: -28.515255737304688\n",
      "                , loss1: -9514.06953125\n",
      "                , loss2: 0.026953327655792236\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4190 epoch, average loss: -28.510769653320313\n",
      "                , loss1: -9511.84609375\n",
      "                , loss2: 0.02476600855588913\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4200 epoch, average loss: -28.515789794921876\n",
      "                , loss1: -9512.19765625\n",
      "                , loss2: 0.020802533626556395\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4210 epoch, average loss: -28.512606811523437\n",
      "                , loss1: -9510.046875\n",
      "                , loss2: 0.017530074715614317\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4220 epoch, average loss: -28.498236083984374\n",
      "                , loss1: -9517.58984375\n",
      "                , loss2: 0.05452979803085327\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4230 epoch, average loss: -28.508050537109376\n",
      "                , loss1: -9517.2875\n",
      "                , loss2: 0.04381291270256042\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4240 epoch, average loss: -28.51294860839844\n",
      "                , loss1: -9509.42578125\n",
      "                , loss2: 0.015326733887195586\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4250 epoch, average loss: -28.51390380859375\n",
      "                , loss1: -9511.5375\n",
      "                , loss2: 0.020711651444435118\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4260 epoch, average loss: -28.502362060546876\n",
      "                , loss1: -9515.84765625\n",
      "                , loss2: 0.045182859897613524\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4270 epoch, average loss: -28.5153564453125\n",
      "                , loss1: -9511.1796875\n",
      "                , loss2: 0.018181474506855012\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4280 epoch, average loss: -28.5206787109375\n",
      "                , loss1: -9511.0359375\n",
      "                , loss2: 0.012426447123289108\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4290 epoch, average loss: -28.507037353515624\n",
      "                , loss1: -9512.6\n",
      "                , loss2: 0.03076786398887634\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4300 epoch, average loss: -28.512841796875\n",
      "                , loss1: -9512.05390625\n",
      "                , loss2: 0.023319360613822938\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4310 epoch, average loss: -28.512979125976564\n",
      "                , loss1: -9511.8234375\n",
      "                , loss2: 0.022495068609714508\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4320 epoch, average loss: -28.509912109375\n",
      "                , loss1: -9512.0890625\n",
      "                , loss2: 0.026353701949119568\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4330 epoch, average loss: -28.515625\n",
      "                , loss1: -9514.08125\n",
      "                , loss2: 0.02662346661090851\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4340 epoch, average loss: -28.513360595703126\n",
      "                , loss1: -9509.47265625\n",
      "                , loss2: 0.015058815479278564\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4350 epoch, average loss: -28.504736328125\n",
      "                , loss1: -9517.615625\n",
      "                , loss2: 0.048111343383789064\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4360 epoch, average loss: -28.516763305664064\n",
      "                , loss1: -9512.77734375\n",
      "                , loss2: 0.02157067507505417\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4370 epoch, average loss: -28.517532348632812\n",
      "                , loss1: -9511.22421875\n",
      "                , loss2: 0.016141335666179656\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4380 epoch, average loss: -28.5060546875\n",
      "                , loss1: -9514.57578125\n",
      "                , loss2: 0.03767848014831543\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4390 epoch, average loss: -28.516250610351562\n",
      "                , loss1: -9511.646875\n",
      "                , loss2: 0.018694253265857698\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4400 epoch, average loss: -28.5142333984375\n",
      "                , loss1: -9513.3234375\n",
      "                , loss2: 0.025734546780586242\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4410 epoch, average loss: -28.513800048828124\n",
      "                , loss1: -9510.11953125\n",
      "                , loss2: 0.016561463475227356\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4420 epoch, average loss: -28.515875244140624\n",
      "                , loss1: -9515.92421875\n",
      "                , loss2: 0.031898051500320435\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4430 epoch, average loss: -28.51253662109375\n",
      "                , loss1: -9512.934375\n",
      "                , loss2: 0.02626679837703705\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4440 epoch, average loss: -28.517208862304688\n",
      "                , loss1: -9512.90703125\n",
      "                , loss2: 0.021511273086071016\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4450 epoch, average loss: -28.5099365234375\n",
      "                , loss1: -9511.72421875\n",
      "                , loss2: 0.025234198570251463\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4460 epoch, average loss: -28.516766357421876\n",
      "                , loss1: -9512.565625\n",
      "                , loss2: 0.020928727090358736\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4470 epoch, average loss: -28.50749816894531\n",
      "                , loss1: -9511.49921875\n",
      "                , loss2: 0.02700149118900299\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4480 epoch, average loss: -28.507086181640624\n",
      "                , loss1: -9514.13828125\n",
      "                , loss2: 0.035328063368797305\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4490 epoch, average loss: -28.513992309570312\n",
      "                , loss1: -9513.11875\n",
      "                , loss2: 0.025364688038825987\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4500 epoch, average loss: -28.512783813476563\n",
      "                , loss1: -9510.51015625\n",
      "                , loss2: 0.018748511373996735\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4510 epoch, average loss: -28.511984252929686\n",
      "                , loss1: -9516.11328125\n",
      "                , loss2: 0.03635777533054352\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4520 epoch, average loss: -28.518435668945312\n",
      "                , loss1: -9511.84609375\n",
      "                , loss2: 0.01710560917854309\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4530 epoch, average loss: -28.516641235351564\n",
      "                , loss1: -9511.440625\n",
      "                , loss2: 0.01768181025981903\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4540 epoch, average loss: -28.5140380859375\n",
      "                , loss1: -9512.25703125\n",
      "                , loss2: 0.02273734360933304\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4550 epoch, average loss: -28.517306518554687\n",
      "                , loss1: -9512.9078125\n",
      "                , loss2: 0.021418873965740205\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4560 epoch, average loss: -28.513388061523436\n",
      "                , loss1: -9512.74609375\n",
      "                , loss2: 0.024851098656654358\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4570 epoch, average loss: -28.515658569335937\n",
      "                , loss1: -9513.71640625\n",
      "                , loss2: 0.025487709045410156\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4580 epoch, average loss: -28.510177612304688\n",
      "                , loss1: -9510.2125\n",
      "                , loss2: 0.020462086796760558\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4590 epoch, average loss: -28.516189575195312\n",
      "                , loss1: -9514.603125\n",
      "                , loss2: 0.027618247270584106\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4600 epoch, average loss: -28.50847473144531\n",
      "                , loss1: -9511.875\n",
      "                , loss2: 0.027149319648742676\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4610 epoch, average loss: -28.516262817382813\n",
      "                , loss1: -9512.9109375\n",
      "                , loss2: 0.022473672032356264\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4620 epoch, average loss: -28.51036682128906\n",
      "                , loss1: -9513.8015625\n",
      "                , loss2: 0.031037813425064086\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4630 epoch, average loss: -28.5206787109375\n",
      "                , loss1: -9511.9640625\n",
      "                , loss2: 0.015214520692825317\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4640 epoch, average loss: -28.51746520996094\n",
      "                , loss1: -9511.415625\n",
      "                , loss2: 0.01678008884191513\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4650 epoch, average loss: -28.516372680664062\n",
      "                , loss1: -9515.1671875\n",
      "                , loss2: 0.029131513833999634\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4660 epoch, average loss: -28.513406372070314\n",
      "                , loss1: -9512.3359375\n",
      "                , loss2: 0.02360149025917053\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4670 epoch, average loss: -28.5048095703125\n",
      "                , loss1: -9517.6046875\n",
      "                , loss2: 0.04800421595573425\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4680 epoch, average loss: -28.516921997070312\n",
      "                , loss1: -9513.709375\n",
      "                , loss2: 0.024201735854148865\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4690 epoch, average loss: -28.507174682617187\n",
      "                , loss1: -9512.2078125\n",
      "                , loss2: 0.02944754660129547\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4700 epoch, average loss: -28.502325439453124\n",
      "                , loss1: -9519.2375\n",
      "                , loss2: 0.0553816020488739\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4710 epoch, average loss: -28.508328247070313\n",
      "                , loss1: -9514.3609375\n",
      "                , loss2: 0.03475358486175537\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4720 epoch, average loss: -28.51714172363281\n",
      "                , loss1: -9514.2625\n",
      "                , loss2: 0.025643232464790344\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4730 epoch, average loss: -28.5166015625\n",
      "                , loss1: -9512.18203125\n",
      "                , loss2: 0.019947341084480284\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4740 epoch, average loss: -28.516650390625\n",
      "                , loss1: -9515.47890625\n",
      "                , loss2: 0.029791730642318725\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4750 epoch, average loss: -28.519900512695312\n",
      "                , loss1: -9511.8421875\n",
      "                , loss2: 0.015626341104507446\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4760 epoch, average loss: -28.516378784179686\n",
      "                , loss1: -9512.75625\n",
      "                , loss2: 0.02189142256975174\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4770 epoch, average loss: -28.519091796875\n",
      "                , loss1: -9513.0171875\n",
      "                , loss2: 0.019959822297096252\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4780 epoch, average loss: -28.52078857421875\n",
      "                , loss1: -9513.6265625\n",
      "                , loss2: 0.02009166479110718\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4790 epoch, average loss: -28.518133544921874\n",
      "                , loss1: -9513.21953125\n",
      "                , loss2: 0.021520204842090607\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4800 epoch, average loss: -28.521563720703124\n",
      "                , loss1: -9512.7578125\n",
      "                , loss2: 0.01671038568019867\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4810 epoch, average loss: -28.52112731933594\n",
      "                , loss1: -9512.50390625\n",
      "                , loss2: 0.01638382375240326\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4820 epoch, average loss: -28.522955322265624\n",
      "                , loss1: -9512.83046875\n",
      "                , loss2: 0.015535940229892731\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4830 epoch, average loss: -28.51588134765625\n",
      "                , loss1: -9512.28671875\n",
      "                , loss2: 0.020977960526943208\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4840 epoch, average loss: -28.518148803710936\n",
      "                , loss1: -9515.66875\n",
      "                , loss2: 0.028858742117881774\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4850 epoch, average loss: -28.521145629882813\n",
      "                , loss1: -9511.6484375\n",
      "                , loss2: 0.013801155984401703\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4860 epoch, average loss: -28.515582275390624\n",
      "                , loss1: -9510.95\n",
      "                , loss2: 0.017264688014984132\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4870 epoch, average loss: -28.51734619140625\n",
      "                , loss1: -9514.52265625\n",
      "                , loss2: 0.026224911212921143\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4880 epoch, average loss: -28.52098693847656\n",
      "                , loss1: -9512.2359375\n",
      "                , loss2: 0.015725062787532808\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4890 epoch, average loss: -28.51702880859375\n",
      "                , loss1: -9513.3453125\n",
      "                , loss2: 0.023005834221839903\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4900 epoch, average loss: -28.5161865234375\n",
      "                , loss1: -9511.746875\n",
      "                , loss2: 0.0190547376871109\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4910 epoch, average loss: -28.518695068359374\n",
      "                , loss1: -9513.540625\n",
      "                , loss2: 0.021923637390136717\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4920 epoch, average loss: -28.521160888671876\n",
      "                , loss1: -9512.0078125\n",
      "                , loss2: 0.014858856797218323\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4930 epoch, average loss: -28.518157958984375\n",
      "                , loss1: -9515.2703125\n",
      "                , loss2: 0.027653267979621886\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4940 epoch, average loss: -28.505776977539064\n",
      "                , loss1: -9512.57109375\n",
      "                , loss2: 0.03193830549716949\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4950 epoch, average loss: -28.506729125976562\n",
      "                , loss1: -9519.5734375\n",
      "                , loss2: 0.0519902229309082\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4960 epoch, average loss: -28.506201171875\n",
      "                , loss1: -9514.3171875\n",
      "                , loss2: 0.036750054359436034\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4970 epoch, average loss: -28.516415405273438\n",
      "                , loss1: -9516.5359375\n",
      "                , loss2: 0.033191993832588196\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4980 epoch, average loss: -28.51468505859375\n",
      "                , loss1: -9511.4140625\n",
      "                , loss2: 0.019552204012870788\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 4990 epoch, average loss: -28.513848876953126\n",
      "                , loss1: -9512.8953125\n",
      "                , loss2: 0.024840162694454195\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5000 epoch, average loss: -28.51641845703125\n",
      "                , loss1: -9513.39921875\n",
      "                , loss2: 0.02378155440092087\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5010 epoch, average loss: -28.516281127929688\n",
      "                , loss1: -9514.4734375\n",
      "                , loss2: 0.027137500047683717\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5020 epoch, average loss: -28.520977783203126\n",
      "                , loss1: -9511.9671875\n",
      "                , loss2: 0.014927144348621368\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5030 epoch, average loss: -28.521621704101562\n",
      "                , loss1: -9513.3484375\n",
      "                , loss2: 0.018426275253295897\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5040 epoch, average loss: -28.51715087890625\n",
      "                , loss1: -9513.80625\n",
      "                , loss2: 0.024267658591270447\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5050 epoch, average loss: -28.520004272460938\n",
      "                , loss1: -9511.9765625\n",
      "                , loss2: 0.015925867855548857\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5060 epoch, average loss: -28.518466186523437\n",
      "                , loss1: -9514.7203125\n",
      "                , loss2: 0.025697186589241028\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5070 epoch, average loss: -28.520037841796874\n",
      "                , loss1: -9512.7859375\n",
      "                , loss2: 0.018322175741195677\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5080 epoch, average loss: -28.51191101074219\n",
      "                , loss1: -9515.0734375\n",
      "                , loss2: 0.033306241035461426\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5090 epoch, average loss: -28.520388793945312\n",
      "                , loss1: -9513.29921875\n",
      "                , loss2: 0.01951002925634384\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5100 epoch, average loss: -28.52080078125\n",
      "                , loss1: -9513.06640625\n",
      "                , loss2: 0.01840115189552307\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5110 epoch, average loss: -28.523904418945314\n",
      "                , loss1: -9512.53671875\n",
      "                , loss2: 0.013707926869392395\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5120 epoch, average loss: -28.51933898925781\n",
      "                , loss1: -9512.14921875\n",
      "                , loss2: 0.017108710110187532\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5130 epoch, average loss: -28.518386840820312\n",
      "                , loss1: -9514.63515625\n",
      "                , loss2: 0.025516441464424132\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5140 epoch, average loss: -28.51182861328125\n",
      "                , loss1: -9513.9140625\n",
      "                , loss2: 0.02991533875465393\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5150 epoch, average loss: -28.51046142578125\n",
      "                , loss1: -9515.128125\n",
      "                , loss2: 0.034920650720596316\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5160 epoch, average loss: -28.51212158203125\n",
      "                , loss1: -9511.80078125\n",
      "                , loss2: 0.023284003138542175\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5170 epoch, average loss: -28.5146728515625\n",
      "                , loss1: -9516.44453125\n",
      "                , loss2: 0.034662464261054994\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5180 epoch, average loss: -28.52165832519531\n",
      "                , loss1: -9511.928125\n",
      "                , loss2: 0.014129914343357086\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5190 epoch, average loss: -28.525601196289063\n",
      "                , loss1: -9513.72265625\n",
      "                , loss2: 0.015571358799934387\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5200 epoch, average loss: -28.51754150390625\n",
      "                , loss1: -9512.55390625\n",
      "                , loss2: 0.020123450458049773\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5210 epoch, average loss: -28.523007202148438\n",
      "                , loss1: -9513.64921875\n",
      "                , loss2: 0.017938822507858276\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5220 epoch, average loss: -28.51766357421875\n",
      "                , loss1: -9512.65546875\n",
      "                , loss2: 0.020302656292915344\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5230 epoch, average loss: -28.5200927734375\n",
      "                , loss1: -9513.553125\n",
      "                , loss2: 0.020562225580215455\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5240 epoch, average loss: -28.524630737304687\n",
      "                , loss1: -9512.878125\n",
      "                , loss2: 0.014004233479499816\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5250 epoch, average loss: -28.516143798828125\n",
      "                , loss1: -9513.284375\n",
      "                , loss2: 0.023710434138774873\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5260 epoch, average loss: -28.520135498046876\n",
      "                , loss1: -9512.409375\n",
      "                , loss2: 0.017092061042785645\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5270 epoch, average loss: -28.51764831542969\n",
      "                , loss1: -9516.35859375\n",
      "                , loss2: 0.03142802715301514\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5280 epoch, average loss: -28.526025390625\n",
      "                , loss1: -9511.05\n",
      "                , loss2: 0.007129555940628052\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5290 epoch, average loss: -28.520098876953124\n",
      "                , loss1: -9515.61015625\n",
      "                , loss2: 0.02673535645008087\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5300 epoch, average loss: -28.519717407226562\n",
      "                , loss1: -9515.5140625\n",
      "                , loss2: 0.02682468295097351\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5310 epoch, average loss: -28.52158203125\n",
      "                , loss1: -9513.1078125\n",
      "                , loss2: 0.017743724584579467\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5320 epoch, average loss: -28.5177490234375\n",
      "                , loss1: -9516.465625\n",
      "                , loss2: 0.031647172570228574\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5330 epoch, average loss: -28.523056030273438\n",
      "                , loss1: -9511.9109375\n",
      "                , loss2: 0.012677101790904999\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5340 epoch, average loss: -28.52642822265625\n",
      "                , loss1: -9514.28125\n",
      "                , loss2: 0.016414874792099\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5350 epoch, average loss: -28.514828491210938\n",
      "                , loss1: -9514.24140625\n",
      "                , loss2: 0.027894073724746705\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5360 epoch, average loss: -28.517355346679686\n",
      "                , loss1: -9516.003125\n",
      "                , loss2: 0.0306549072265625\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5370 epoch, average loss: -28.520693969726562\n",
      "                , loss1: -9512.840625\n",
      "                , loss2: 0.017831194400787353\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5380 epoch, average loss: -28.5203857421875\n",
      "                , loss1: -9513.940625\n",
      "                , loss2: 0.021437181532382964\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5390 epoch, average loss: -28.516970825195312\n",
      "                , loss1: -9514.4671875\n",
      "                , loss2: 0.026430413126945496\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5400 epoch, average loss: -28.520233154296875\n",
      "                , loss1: -9512.328125\n",
      "                , loss2: 0.016753318905830383\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5410 epoch, average loss: -28.517034912109374\n",
      "                , loss1: -9517.83515625\n",
      "                , loss2: 0.036474040150642394\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5420 epoch, average loss: -28.524966430664062\n",
      "                , loss1: -9512.11484375\n",
      "                , loss2: 0.011379493772983551\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5430 epoch, average loss: -28.5258056640625\n",
      "                , loss1: -9513.99609375\n",
      "                , loss2: 0.01618363559246063\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5440 epoch, average loss: -28.52381591796875\n",
      "                , loss1: -9512.92421875\n",
      "                , loss2: 0.01495925486087799\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5450 epoch, average loss: -28.51988525390625\n",
      "                , loss1: -9513.52890625\n",
      "                , loss2: 0.0206983283162117\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5460 epoch, average loss: -28.525836181640624\n",
      "                , loss1: -9515.58359375\n",
      "                , loss2: 0.02091144025325775\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5470 epoch, average loss: -28.519393920898438\n",
      "                , loss1: -9512.60234375\n",
      "                , loss2: 0.018412573635578154\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5480 epoch, average loss: -28.523724365234376\n",
      "                , loss1: -9515.6671875\n",
      "                , loss2: 0.023274880647659302\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5490 epoch, average loss: -28.525363159179687\n",
      "                , loss1: -9512.52109375\n",
      "                , loss2: 0.012204290926456451\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5500 epoch, average loss: -28.525210571289062\n",
      "                , loss1: -9515.1109375\n",
      "                , loss2: 0.020118166506290436\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5510 epoch, average loss: -28.522967529296874\n",
      "                , loss1: -9513.3171875\n",
      "                , loss2: 0.01698203682899475\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5520 epoch, average loss: -28.52348937988281\n",
      "                , loss1: -9516.07265625\n",
      "                , loss2: 0.024731585383415224\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5530 epoch, average loss: -28.518246459960938\n",
      "                , loss1: -9514.3625\n",
      "                , loss2: 0.024842676520347596\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5540 epoch, average loss: -28.52554931640625\n",
      "                , loss1: -9514.38828125\n",
      "                , loss2: 0.017620739340782166\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5550 epoch, average loss: -28.5191650390625\n",
      "                , loss1: -9513.98046875\n",
      "                , loss2: 0.022771833837032317\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5560 epoch, average loss: -28.52515563964844\n",
      "                , loss1: -9516.96953125\n",
      "                , loss2: 0.025752881169319154\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5570 epoch, average loss: -28.52205810546875\n",
      "                , loss1: -9512.6796875\n",
      "                , loss2: 0.015983569622039794\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5580 epoch, average loss: -28.499313354492188\n",
      "                , loss1: -9519.390625\n",
      "                , loss2: 0.05886392593383789\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5590 epoch, average loss: -28.51658935546875\n",
      "                , loss1: -9516.31171875\n",
      "                , loss2: 0.03234654366970062\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5600 epoch, average loss: -28.519796752929686\n",
      "                , loss1: -9512.4890625\n",
      "                , loss2: 0.017671333253383638\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5610 epoch, average loss: -28.524481201171874\n",
      "                , loss1: -9513.84140625\n",
      "                , loss2: 0.01704426258802414\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5620 epoch, average loss: -28.523211669921874\n",
      "                , loss1: -9514.0734375\n",
      "                , loss2: 0.019007520377635957\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5630 epoch, average loss: -28.525485229492187\n",
      "                , loss1: -9513.98203125\n",
      "                , loss2: 0.01646127849817276\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5640 epoch, average loss: -28.523648071289063\n",
      "                , loss1: -9514.06875\n",
      "                , loss2: 0.018559756875038146\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5650 epoch, average loss: -28.527938842773438\n",
      "                , loss1: -9512.7734375\n",
      "                , loss2: 0.010382115095853805\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5660 epoch, average loss: -28.518841552734376\n",
      "                , loss1: -9515.0609375\n",
      "                , loss2: 0.026338744163513183\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5670 epoch, average loss: -28.515158081054686\n",
      "                , loss1: -9515.0203125\n",
      "                , loss2: 0.029902780055999757\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5680 epoch, average loss: -28.516659545898438\n",
      "                , loss1: -9517.2828125\n",
      "                , loss2: 0.03518840670585632\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5690 epoch, average loss: -28.521347045898438\n",
      "                , loss1: -9512.79140625\n",
      "                , loss2: 0.017027612030506133\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5700 epoch, average loss: -28.520138549804688\n",
      "                , loss1: -9514.5828125\n",
      "                , loss2: 0.023611193895339964\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5710 epoch, average loss: -28.523724365234376\n",
      "                , loss1: -9515.3359375\n",
      "                , loss2: 0.022283822298049927\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5720 epoch, average loss: -28.522216796875\n",
      "                , loss1: -9513.3640625\n",
      "                , loss2: 0.017872820794582366\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5730 epoch, average loss: -28.523580932617186\n",
      "                , loss1: -9515.128125\n",
      "                , loss2: 0.02180624008178711\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5740 epoch, average loss: -28.522149658203126\n",
      "                , loss1: -9512.4734375\n",
      "                , loss2: 0.015273147821426391\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5750 epoch, average loss: -28.521539306640626\n",
      "                , loss1: -9515.48125\n",
      "                , loss2: 0.024905520677566528\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5760 epoch, average loss: -28.523529052734375\n",
      "                , loss1: -9512.6\n",
      "                , loss2: 0.014267002046108247\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5770 epoch, average loss: -28.51695556640625\n",
      "                , loss1: -9516.859375\n",
      "                , loss2: 0.033619892597198484\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5780 epoch, average loss: -28.5213623046875\n",
      "                , loss1: -9514.7375\n",
      "                , loss2: 0.02285119742155075\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5790 epoch, average loss: -28.523086547851562\n",
      "                , loss1: -9512.896875\n",
      "                , loss2: 0.015605179965496064\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5800 epoch, average loss: -28.515017700195312\n",
      "                , loss1: -9518.06015625\n",
      "                , loss2: 0.03916270136833191\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5810 epoch, average loss: -28.518612670898438\n",
      "                , loss1: -9513.30234375\n",
      "                , loss2: 0.021293288469314574\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5820 epoch, average loss: -28.51944580078125\n",
      "                , loss1: -9515.82109375\n",
      "                , loss2: 0.028017622232437134\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5830 epoch, average loss: -28.523281860351563\n",
      "                , loss1: -9514.3125\n",
      "                , loss2: 0.019655804336071014\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5840 epoch, average loss: -28.508132934570312\n",
      "                , loss1: -9516.15\n",
      "                , loss2: 0.04031615257263184\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5850 epoch, average loss: -28.514605712890624\n",
      "                , loss1: -9514.9984375\n",
      "                , loss2: 0.03038465976715088\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5860 epoch, average loss: -28.525491333007814\n",
      "                , loss1: -9512.8265625\n",
      "                , loss2: 0.012987513840198518\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5870 epoch, average loss: -28.521383666992186\n",
      "                , loss1: -9517.9046875\n",
      "                , loss2: 0.03232806622982025\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5880 epoch, average loss: -28.5230712890625\n",
      "                , loss1: -9513.034375\n",
      "                , loss2: 0.01603521704673767\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5890 epoch, average loss: -28.521017456054686\n",
      "                , loss1: -9514.8390625\n",
      "                , loss2: 0.02349855750799179\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5900 epoch, average loss: -28.521484375\n",
      "                , loss1: -9514.0125\n",
      "                , loss2: 0.020550258457660675\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5910 epoch, average loss: -28.5274169921875\n",
      "                , loss1: -9513.9796875\n",
      "                , loss2: 0.014521212875843048\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5920 epoch, average loss: -28.52188720703125\n",
      "                , loss1: -9515.58125\n",
      "                , loss2: 0.024853016436100005\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5930 epoch, average loss: -28.517623901367188\n",
      "                , loss1: -9514.22890625\n",
      "                , loss2: 0.025062498450279237\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5940 epoch, average loss: -28.524713134765626\n",
      "                , loss1: -9513.3640625\n",
      "                , loss2: 0.015379609167575836\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5950 epoch, average loss: -28.5280029296875\n",
      "                , loss1: -9513.3953125\n",
      "                , loss2: 0.012180805951356889\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5960 epoch, average loss: -28.513027954101563\n",
      "                , loss1: -9517.7828125\n",
      "                , loss2: 0.040319448709487914\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5970 epoch, average loss: -28.520245361328126\n",
      "                , loss1: -9515.1171875\n",
      "                , loss2: 0.025108000636100768\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5980 epoch, average loss: -28.519915771484374\n",
      "                , loss1: -9514.9703125\n",
      "                , loss2: 0.024995911121368408\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 5990 epoch, average loss: -28.524691772460937\n",
      "                , loss1: -9514.965625\n",
      "                , loss2: 0.020204928517341614\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6000 epoch, average loss: -28.52167663574219\n",
      "                , loss1: -9513.7390625\n",
      "                , loss2: 0.019540615379810333\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6010 epoch, average loss: -28.525021362304688\n",
      "                , loss1: -9513.25390625\n",
      "                , loss2: 0.0147404283285141\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6020 epoch, average loss: -28.522784423828124\n",
      "                , loss1: -9515.1125\n",
      "                , loss2: 0.022555860877037048\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6030 epoch, average loss: -28.52594909667969\n",
      "                , loss1: -9513.69296875\n",
      "                , loss2: 0.015133094787597657\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6040 epoch, average loss: -28.52457275390625\n",
      "                , loss1: -9514.815625\n",
      "                , loss2: 0.019878223538398743\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6050 epoch, average loss: -28.525308227539064\n",
      "                , loss1: -9513.61015625\n",
      "                , loss2: 0.015521840751171112\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6060 epoch, average loss: -28.523956298828125\n",
      "                , loss1: -9516.26875\n",
      "                , loss2: 0.024857372045516968\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6070 epoch, average loss: -28.486178588867187\n",
      "                , loss1: -9517.64609375\n",
      "                , loss2: 0.0667590081691742\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n",
      "in 6080 epoch, average loss: -28.5010986328125\n",
      "                , loss1: -9517.89375\n",
      "                , loss2: 0.05258113741874695\n",
      "                , weight: 0.0029999999999993747\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      6\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 7\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[56], line 32\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     31\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), loss_1\u001b[38;5;241m.\u001b[39mitem(), loss_2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([81., 80., 81.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004132231404958678"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
