{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 2\n",
    "\n",
    "weight = 900\n",
    "limit = 20\n",
    "sub = 1.2\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 2048, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "# h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 2048, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 2048, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "\n",
    "l_hyper_prmts[\"linerlayer0\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":128, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer121\"] = {\"in_channels\":128, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":64, \"out_channels\":2, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7403, 2755)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dhg \n",
    "from dhg.data import Cooking200\n",
    "data = Cooking200()\n",
    "e_list = data[\"edge_list\"]\n",
    "num_v = data[\"num_vertices\"]\n",
    "G = dhg.Hypergraph(data[\"num_vertices\"],data[\"edge_list\"])\n",
    "num_v, data[\"num_edges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.05, inplace=False)\n",
       "  (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Dropout(p=0.05, inplace=False)\n",
       "  (16): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.05, inplace=False)\n",
       "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (21): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: -23899.803125\n",
      "                , loss1: -23.96666259765625\n",
      "                , loss2: 4831.434765625\n",
      "                , weight: 1198.8\n",
      "=================================\n",
      "in 10 epoch, average loss: -383862.3\n",
      "                , loss1: -386.8396484375\n",
      "                , loss2: 77037.48125\n",
      "                , weight: 1186.7999999999995\n",
      "=================================\n",
      "in 20 epoch, average loss: -868540.6\n",
      "                , loss1: -739.132958984375\n",
      "                , loss2: 3379.97578125\n",
      "                , weight: 1174.799999999999\n",
      "=================================\n",
      "in 30 epoch, average loss: -1267350.0\n",
      "                , loss1: -1088.45380859375\n",
      "                , loss2: 3901.349609375\n",
      "                , weight: 1162.7999999999986\n",
      "=================================\n",
      "in 40 epoch, average loss: -1520338.2\n",
      "                , loss1: -1317.2970703125\n",
      "                , loss2: 2566.4724609375\n",
      "                , weight: 1150.7999999999981\n",
      "=================================\n",
      "in 50 epoch, average loss: -1610115.8\n",
      "                , loss1: -1408.16923828125\n",
      "                , loss2: 1071.7515625\n",
      "                , weight: 1138.7999999999977\n",
      "=================================\n",
      "in 60 epoch, average loss: -1629193.6\n",
      "                , loss1: -1439.3765625\n",
      "                , loss2: 446.8763671875\n",
      "                , weight: 1126.7999999999972\n",
      "=================================\n",
      "in 70 epoch, average loss: -1632925.4\n",
      "                , loss1: -1457.91728515625\n",
      "                , loss2: 221.752490234375\n",
      "                , weight: 1114.7999999999968\n",
      "=================================\n",
      "in 80 epoch, average loss: -1628322.8\n",
      "                , loss1: -1469.66298828125\n",
      "                , loss2: 349.244677734375\n",
      "                , weight: 1102.7999999999963\n",
      "=================================\n",
      "in 90 epoch, average loss: -1618479.6\n",
      "                , loss1: -1476.78056640625\n",
      "                , loss2: 362.8499267578125\n",
      "                , weight: 1090.7999999999959\n",
      "=================================\n",
      "in 100 epoch, average loss: -1604263.9\n",
      "                , loss1: -1479.725\n",
      "                , loss2: 51.28236694335938\n",
      "                , weight: 1078.7999999999954\n",
      "=================================\n",
      "in 110 epoch, average loss: -1590237.1\n",
      "                , loss1: -1483.260546875\n",
      "                , loss2: 110.68294677734374\n",
      "                , weight: 1066.799999999995\n",
      "=================================\n",
      "in 120 epoch, average loss: -1575031.8\n",
      "                , loss1: -1485.7357421875\n",
      "                , loss2: 143.9388427734375\n",
      "                , weight: 1054.7999999999945\n",
      "=================================\n",
      "in 130 epoch, average loss: -1559275.9\n",
      "                , loss1: -1487.6771484375\n",
      "                , loss2: 104.669091796875\n",
      "                , weight: 1042.799999999994\n",
      "=================================\n",
      "in 140 epoch, average loss: -1542802.7\n",
      "                , loss1: -1488.9353515625\n",
      "                , loss2: 31.59870300292969\n",
      "                , weight: 1030.7999999999936\n",
      "=================================\n",
      "in 150 epoch, average loss: -1525268.9\n",
      "                , loss1: -1489.2396484375\n",
      "                , loss2: 10.115284729003907\n",
      "                , weight: 1018.7999999999931\n",
      "=================================\n",
      "in 160 epoch, average loss: -1507652.7\n",
      "                , loss1: -1489.49208984375\n",
      "                , loss2: 10.77846908569336\n",
      "                , weight: 1006.7999999999927\n",
      "=================================\n",
      "in 170 epoch, average loss: -1489947.3\n",
      "                , loss1: -1489.68369140625\n",
      "                , loss2: 34.03614501953125\n",
      "                , weight: 994.7999999999922\n",
      "=================================\n",
      "in 180 epoch, average loss: -1472237.3\n",
      "                , loss1: -1489.855078125\n",
      "                , loss2: 37.20430297851563\n",
      "                , weight: 982.7999999999918\n",
      "=================================\n",
      "in 190 epoch, average loss: -1454525.4\n",
      "                , loss1: -1490.00576171875\n",
      "                , loss2: 18.048493957519533\n",
      "                , weight: 970.7999999999913\n",
      "=================================\n",
      "in 200 epoch, average loss: -1436617.8\n",
      "                , loss1: -1489.9884765625\n",
      "                , loss2: 29.226129150390626\n",
      "                , weight: 958.7999999999909\n",
      "=================================\n",
      "in 210 epoch, average loss: -1418732.0\n",
      "                , loss1: -1490.01796875\n",
      "                , loss2: 62.96656494140625\n",
      "                , weight: 946.7999999999904\n",
      "=================================\n",
      "in 220 epoch, average loss: -1401114.7\n",
      "                , loss1: -1490.269921875\n",
      "                , loss2: 36.40391540527344\n",
      "                , weight: 934.79999999999\n",
      "=================================\n",
      "in 230 epoch, average loss: -1383902.2\n",
      "                , loss1: -1491.0712890625\n",
      "                , loss2: 109.9781005859375\n",
      "                , weight: 922.7999999999895\n",
      "=================================\n",
      "in 240 epoch, average loss: -1366251.8\n",
      "                , loss1: -1491.26962890625\n",
      "                , loss2: 49.2356201171875\n",
      "                , weight: 910.799999999989\n",
      "=================================\n",
      "in 250 epoch, average loss: -1348507.8\n",
      "                , loss1: -1491.3986328125\n",
      "                , loss2: 14.828764343261719\n",
      "                , weight: 898.7999999999886\n",
      "=================================\n",
      "in 260 epoch, average loss: -1330700.8\n",
      "                , loss1: -1491.50986328125\n",
      "                , loss2: 24.153369140625\n",
      "                , weight: 886.7999999999881\n",
      "=================================\n",
      "in 270 epoch, average loss: -1312880.2\n",
      "                , loss1: -1491.58818359375\n",
      "                , loss2: 15.679472351074219\n",
      "                , weight: 874.7999999999877\n",
      "=================================\n",
      "in 280 epoch, average loss: -1295027.7\n",
      "                , loss1: -1491.6658203125\n",
      "                , loss2: 36.385650634765625\n",
      "                , weight: 862.7999999999872\n",
      "=================================\n",
      "in 290 epoch, average loss: -1277677.8\n",
      "                , loss1: -1492.35546875\n",
      "                , loss2: 74.59570922851563\n",
      "                , weight: 850.7999999999868\n",
      "=================================\n",
      "in 300 epoch, average loss: -1260460.5\n",
      "                , loss1: -1493.49365234375\n",
      "                , loss2: 346.8063720703125\n",
      "                , weight: 838.7999999999863\n",
      "=================================\n",
      "in 310 epoch, average loss: -1242661.3\n",
      "                , loss1: -1493.5435546875\n",
      "                , loss2: 265.584814453125\n",
      "                , weight: 826.7999999999859\n",
      "=================================\n",
      "in 320 epoch, average loss: -1224989.6\n",
      "                , loss1: -1493.615234375\n",
      "                , loss2: 73.3885009765625\n",
      "                , weight: 814.7999999999854\n",
      "=================================\n",
      "in 330 epoch, average loss: -1207176.4\n",
      "                , loss1: -1493.68095703125\n",
      "                , loss2: 16.290019226074218\n",
      "                , weight: 802.799999999985\n",
      "=================================\n",
      "in 340 epoch, average loss: -1189350.5\n",
      "                , loss1: -1493.7951171875\n",
      "                , loss2: 9.033959197998048\n",
      "                , weight: 790.7999999999845\n",
      "=================================\n",
      "in 350 epoch, average loss: -1171461.2\n",
      "                , loss1: -1493.83583984375\n",
      "                , loss2: 4.9407402038574215\n",
      "                , weight: 778.799999999984\n",
      "=================================\n",
      "in 360 epoch, average loss: -1153843.3\n",
      "                , loss1: -1494.23837890625\n",
      "                , loss2: 5.759576416015625\n",
      "                , weight: 766.7999999999836\n",
      "=================================\n",
      "in 370 epoch, average loss: -1136372.4\n",
      "                , loss1: -1494.8814453125\n",
      "                , loss2: 37.58800048828125\n",
      "                , weight: 754.7999999999831\n",
      "=================================\n",
      "in 380 epoch, average loss: -1118906.9\n",
      "                , loss1: -1495.4966796875\n",
      "                , loss2: 23.439617919921876\n",
      "                , weight: 742.7999999999827\n",
      "=================================\n",
      "in 390 epoch, average loss: -1101130.1\n",
      "                , loss1: -1495.76005859375\n",
      "                , loss2: 48.405145263671876\n",
      "                , weight: 730.7999999999822\n",
      "=================================\n",
      "in 400 epoch, average loss: -1083253.2\n",
      "                , loss1: -1495.8341796875\n",
      "                , loss2: 29.894268798828126\n",
      "                , weight: 718.7999999999818\n",
      "=================================\n",
      "in 410 epoch, average loss: -1065426.3\n",
      "                , loss1: -1496.03818359375\n",
      "                , loss2: 51.36217041015625\n",
      "                , weight: 706.7999999999813\n",
      "=================================\n",
      "in 420 epoch, average loss: -1048026.4\n",
      "                , loss1: -1496.80830078125\n",
      "                , loss2: 38.673406982421874\n",
      "                , weight: 694.7999999999809\n",
      "=================================\n",
      "in 430 epoch, average loss: -1030119.8\n",
      "                , loss1: -1496.863671875\n",
      "                , loss2: 21.74803009033203\n",
      "                , weight: 682.7999999999804\n",
      "=================================\n",
      "in 440 epoch, average loss: -1012750.7\n",
      "                , loss1: -1497.73828125\n",
      "                , loss2: 19.400518798828124\n",
      "                , weight: 670.79999999998\n",
      "=================================\n",
      "in 450 epoch, average loss: -994877.9\n",
      "                , loss1: -1497.87978515625\n",
      "                , loss2: 13.883682250976562\n",
      "                , weight: 658.7999999999795\n",
      "=================================\n",
      "in 460 epoch, average loss: -976933.5\n",
      "                , loss1: -1497.937109375\n",
      "                , loss2: 20.995280456542968\n",
      "                , weight: 646.799999999979\n",
      "=================================\n",
      "in 470 epoch, average loss: -958964.8\n",
      "                , loss1: -1497.97001953125\n",
      "                , loss2: 35.556341552734374\n",
      "                , weight: 634.7999999999786\n",
      "=================================\n",
      "in 480 epoch, average loss: -941023.2\n",
      "                , loss1: -1497.9873046875\n",
      "                , loss2: 12.388465118408202\n",
      "                , weight: 622.7999999999781\n",
      "=================================\n",
      "in 490 epoch, average loss: -923062.7\n",
      "                , loss1: -1498.00244140625\n",
      "                , loss2: 6.423020935058593\n",
      "                , weight: 610.7999999999777\n",
      "=================================\n",
      "in 500 epoch, average loss: -905095.7\n",
      "                , loss1: -1498.01953125\n",
      "                , loss2: 7.612728881835937\n",
      "                , weight: 598.7999999999772\n",
      "=================================\n",
      "in 510 epoch, average loss: -887132.0\n",
      "                , loss1: -1498.03203125\n",
      "                , loss2: 2.58568115234375\n",
      "                , weight: 586.7999999999768\n",
      "=================================\n",
      "in 520 epoch, average loss: -869182.9\n",
      "                , loss1: -1498.0822265625\n",
      "                , loss2: 4.1259815216064455\n",
      "                , weight: 574.7999999999763\n",
      "=================================\n",
      "in 530 epoch, average loss: -849119.5\n",
      "                , loss1: -1498.616796875\n",
      "                , loss2: 2395.7265625\n",
      "                , weight: 562.7999999999759\n",
      "=================================\n",
      "in 540 epoch, average loss: -825262.85\n",
      "                , loss1: -1487.0275390625\n",
      "                , loss2: 1820.168359375\n",
      "                , weight: 550.7999999999754\n",
      "=================================\n",
      "in 550 epoch, average loss: -806144.4\n",
      "                , loss1: -1485.59248046875\n",
      "                , loss2: 2330.4078125\n",
      "                , weight: 538.799999999975\n",
      "=================================\n",
      "in 560 epoch, average loss: -787001.25\n",
      "                , loss1: -1480.5693359375\n",
      "                , loss2: 964.28779296875\n",
      "                , weight: 526.7999999999745\n",
      "=================================\n",
      "in 570 epoch, average loss: -770366.9\n",
      "                , loss1: -1481.2783203125\n",
      "                , loss2: 189.8289794921875\n",
      "                , weight: 514.799999999974\n",
      "=================================\n",
      "in 580 epoch, average loss: -756856.6\n",
      "                , loss1: -1489.99638671875\n",
      "                , loss2: 351.9549072265625\n",
      "                , weight: 502.79999999997403\n",
      "=================================\n",
      "in 590 epoch, average loss: -741226.9\n",
      "                , loss1: -1493.96806640625\n",
      "                , loss2: 77.75927124023437\n",
      "                , weight: 490.79999999997415\n",
      "=================================\n",
      "in 600 epoch, average loss: -724549.45\n",
      "                , loss1: -1496.42939453125\n",
      "                , loss2: 21.57323303222656\n",
      "                , weight: 478.79999999997426\n",
      "=================================\n",
      "in 610 epoch, average loss: -706909.15\n",
      "                , loss1: -1497.29052734375\n",
      "                , loss2: 111.5206787109375\n",
      "                , weight: 466.7999999999744\n",
      "=================================\n",
      "in 620 epoch, average loss: -689408.2\n",
      "                , loss1: -1498.23798828125\n",
      "                , loss2: 80.2718017578125\n",
      "                , weight: 454.7999999999745\n",
      "=================================\n",
      "in 630 epoch, average loss: -671689.5\n",
      "                , loss1: -1498.7814453125\n",
      "                , loss2: 63.02403564453125\n",
      "                , weight: 442.7999999999746\n",
      "=================================\n",
      "in 640 epoch, average loss: -654173.55\n",
      "                , loss1: -1500.37705078125\n",
      "                , loss2: 289.828955078125\n",
      "                , weight: 430.7999999999747\n",
      "=================================\n",
      "in 650 epoch, average loss: -636741.55\n",
      "                , loss1: -1501.20947265625\n",
      "                , loss2: 71.24256591796875\n",
      "                , weight: 418.79999999997483\n",
      "=================================\n",
      "in 660 epoch, average loss: -618811.65\n",
      "                , loss1: -1501.340625\n",
      "                , loss2: 40.88807067871094\n",
      "                , weight: 406.79999999997494\n",
      "=================================\n",
      "in 670 epoch, average loss: -600954.8\n",
      "                , loss1: -1501.65712890625\n",
      "                , loss2: 7.157619476318359\n",
      "                , weight: 394.79999999997506\n",
      "=================================\n",
      "in 680 epoch, average loss: -583463.95\n",
      "                , loss1: -1503.12197265625\n",
      "                , loss2: 47.482687377929686\n",
      "                , weight: 382.79999999997517\n",
      "=================================\n",
      "in 690 epoch, average loss: -565499.85\n",
      "                , loss1: -1503.2412109375\n",
      "                , loss2: 19.277023315429688\n",
      "                , weight: 370.7999999999753\n",
      "=================================\n",
      "in 700 epoch, average loss: -547637.3\n",
      "                , loss1: -1503.8537109375\n",
      "                , loss2: 64.925146484375\n",
      "                , weight: 358.7999999999754\n",
      "=================================\n",
      "in 710 epoch, average loss: -529780.1\n",
      "                , loss1: -1504.26904296875\n",
      "                , loss2: 23.406150817871094\n",
      "                , weight: 346.7999999999755\n",
      "=================================\n",
      "in 720 epoch, average loss: -511758.55\n",
      "                , loss1: -1504.32412109375\n",
      "                , loss2: 12.466129302978516\n",
      "                , weight: 334.7999999999756\n",
      "=================================\n",
      "in 730 epoch, average loss: -493724.8\n",
      "                , loss1: -1504.3486328125\n",
      "                , loss2: 2.3830604553222656\n",
      "                , weight: 322.79999999997574\n",
      "=================================\n",
      "in 740 epoch, average loss: -475681.25\n",
      "                , loss1: -1504.3783203125\n",
      "                , loss2: 3.175588607788086\n",
      "                , weight: 310.79999999997585\n",
      "=================================\n",
      "in 750 epoch, average loss: -457634.15\n",
      "                , loss1: -1504.39306640625\n",
      "                , loss2: 2.181397247314453\n",
      "                , weight: 298.79999999997597\n",
      "=================================\n",
      "in 760 epoch, average loss: -439765.6\n",
      "                , loss1: -1505.048828125\n",
      "                , loss2: 8.81606216430664\n",
      "                , weight: 286.7999999999761\n",
      "=================================\n",
      "in 770 epoch, average loss: -421768.25\n",
      "                , loss1: -1505.2708984375\n",
      "                , loss2: 8.414190673828125\n",
      "                , weight: 274.7999999999762\n",
      "=================================\n",
      "in 780 epoch, average loss: -403890.5\n",
      "                , loss1: -1506.0234375\n",
      "                , loss2: 24.997752380371093\n",
      "                , weight: 262.7999999999763\n",
      "=================================\n",
      "in 790 epoch, average loss: -385835.825\n",
      "                , loss1: -1506.02353515625\n",
      "                , loss2: 7.409325408935547\n",
      "                , weight: 250.79999999997642\n",
      "=================================\n",
      "in 800 epoch, average loss: -367772.325\n",
      "                , loss1: -1506.045703125\n",
      "                , loss2: 4.020235443115235\n",
      "                , weight: 238.79999999997654\n",
      "=================================\n",
      "in 810 epoch, average loss: -349698.05\n",
      "                , loss1: -1506.04033203125\n",
      "                , loss2: 4.47491683959961\n",
      "                , weight: 226.79999999997665\n",
      "=================================\n",
      "in 820 epoch, average loss: -331634.45\n",
      "                , loss1: -1506.06982421875\n",
      "                , loss2: 2.0957441329956055\n",
      "                , weight: 214.79999999997676\n",
      "=================================\n",
      "in 830 epoch, average loss: -313569.725\n",
      "                , loss1: -1506.10517578125\n",
      "                , loss2: 1.3310006141662598\n",
      "                , weight: 202.79999999997688\n",
      "=================================\n",
      "in 840 epoch, average loss: -295609.15\n",
      "                , loss1: -1506.6830078125\n",
      "                , loss2: 0.8128109931945801\n",
      "                , weight: 190.799999999977\n",
      "=================================\n",
      "in 850 epoch, average loss: -277588.65\n",
      "                , loss1: -1507.009765625\n",
      "                , loss2: 2.5755285263061523\n",
      "                , weight: 178.7999999999771\n",
      "=================================\n",
      "in 860 epoch, average loss: -259505.0\n",
      "                , loss1: -1507.0201171875\n",
      "                , loss2: 3.8540138244628905\n",
      "                , weight: 166.79999999997722\n",
      "=================================\n",
      "in 870 epoch, average loss: -241421.7\n",
      "                , loss1: -1507.0234375\n",
      "                , loss2: 3.4069019317626954\n",
      "                , weight: 154.79999999997733\n",
      "=================================\n",
      "in 880 epoch, average loss: -223335.65\n",
      "                , loss1: -1507.03037109375\n",
      "                , loss2: 6.270778656005859\n",
      "                , weight: 142.79999999997744\n",
      "=================================\n",
      "in 890 epoch, average loss: -205257.775\n",
      "                , loss1: -1507.04130859375\n",
      "                , loss2: 1.1969732284545898\n",
      "                , weight: 130.79999999997756\n",
      "=================================\n",
      "in 900 epoch, average loss: -187178.6\n",
      "                , loss1: -1507.08505859375\n",
      "                , loss2: 1.339137077331543\n",
      "                , weight: 118.79999999997756\n",
      "=================================\n",
      "in 910 epoch, average loss: -169094.4625\n",
      "                , loss1: -1507.088671875\n",
      "                , loss2: 0.8826627731323242\n",
      "                , weight: 106.79999999997753\n",
      "=================================\n",
      "in 920 epoch, average loss: -151010.3125\n",
      "                , loss1: -1507.09140625\n",
      "                , loss2: 0.23923788070678711\n",
      "                , weight: 94.7999999999775\n",
      "=================================\n",
      "in 930 epoch, average loss: -132925.3375\n",
      "                , loss1: -1507.0916015625\n",
      "                , loss2: 0.14066513776779174\n",
      "                , weight: 82.79999999997747\n",
      "=================================\n",
      "in 940 epoch, average loss: -114840.25\n",
      "                , loss1: -1507.09365234375\n",
      "                , loss2: 0.2910912990570068\n",
      "                , weight: 70.79999999997744\n",
      "=================================\n",
      "in 950 epoch, average loss: -96755.0125\n",
      "                , loss1: -1507.094921875\n",
      "                , loss2: 0.4687929153442383\n",
      "                , weight: 58.799999999977416\n",
      "=================================\n",
      "in 960 epoch, average loss: -78670.075\n",
      "                , loss1: -1507.0951171875\n",
      "                , loss2: 0.2821136474609375\n",
      "                , weight: 46.79999999997739\n",
      "=================================\n",
      "in 970 epoch, average loss: -60584.5\n",
      "                , loss1: -1507.09423828125\n",
      "                , loss2: 0.677543830871582\n",
      "                , weight: 34.79999999997736\n",
      "=================================\n",
      "in 980 epoch, average loss: -42499.45625\n",
      "                , loss1: -1507.0998046875\n",
      "                , loss2: 0.7516968250274658\n",
      "                , weight: 22.79999999997736\n",
      "=================================\n",
      "in 990 epoch, average loss: -29478.634375\n",
      "                , loss1: -1507.1005859375\n",
      "                , loss2: 0.252703857421875\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1000 epoch, average loss: -28936.009375\n",
      "                , loss1: -1507.10009765625\n",
      "                , loss2: 0.3139307737350464\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1010 epoch, average loss: -28936.096875\n",
      "                , loss1: -1507.10185546875\n",
      "                , loss2: 0.26048572063446046\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1020 epoch, average loss: -28935.959375\n",
      "                , loss1: -1507.09892578125\n",
      "                , loss2: 0.34150142669677735\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1030 epoch, average loss: -28936.071875\n",
      "                , loss1: -1507.096875\n",
      "                , loss2: 0.18939114809036256\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1040 epoch, average loss: -28936.01875\n",
      "                , loss1: -1507.1\n",
      "                , loss2: 0.3034195423126221\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1050 epoch, average loss: -28936.115625\n",
      "                , loss1: -1507.104296875\n",
      "                , loss2: 0.28714914321899415\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1060 epoch, average loss: -28936.10625\n",
      "                , loss1: -1507.10390625\n",
      "                , loss2: 0.29076669216156004\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1070 epoch, average loss: -28936.009375\n",
      "                , loss1: -1507.10146484375\n",
      "                , loss2: 0.3390993118286133\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1080 epoch, average loss: -28936.08125\n",
      "                , loss1: -1507.100390625\n",
      "                , loss2: 0.2483757972717285\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1090 epoch, average loss: -28935.909375\n",
      "                , loss1: -1507.1037109375\n",
      "                , loss2: 0.4837659358978271\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1100 epoch, average loss: -28935.9125\n",
      "                , loss1: -1507.10068359375\n",
      "                , loss2: 0.42222795486450193\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1110 epoch, average loss: -28936.159375\n",
      "                , loss1: -1507.1021484375\n",
      "                , loss2: 0.20052385330200195\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1120 epoch, average loss: -28936.18125\n",
      "                , loss1: -1507.10556640625\n",
      "                , loss2: 0.2471019744873047\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1130 epoch, average loss: -28936.203125\n",
      "                , loss1: -1507.1025390625\n",
      "                , loss2: 0.1676254987716675\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1140 epoch, average loss: -28936.209375\n",
      "                , loss1: -1507.10322265625\n",
      "                , loss2: 0.17162348031997682\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1150 epoch, average loss: -28936.20625\n",
      "                , loss1: -1507.105078125\n",
      "                , loss2: 0.21373488903045654\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1160 epoch, average loss: -28936.215625\n",
      "                , loss1: -1507.10859375\n",
      "                , loss2: 0.26965692043304446\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1170 epoch, average loss: -28936.290625\n",
      "                , loss1: -1507.105078125\n",
      "                , loss2: 0.12676047086715697\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1180 epoch, average loss: -28936.271875\n",
      "                , loss1: -1507.1064453125\n",
      "                , loss2: 0.1779826045036316\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1190 epoch, average loss: -28936.028125\n",
      "                , loss1: -1507.104296875\n",
      "                , loss2: 0.3716005325317383\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1200 epoch, average loss: -28935.928125\n",
      "                , loss1: -1507.10576171875\n",
      "                , loss2: 0.5017342567443848\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1210 epoch, average loss: -28936.175\n",
      "                , loss1: -1507.10615234375\n",
      "                , loss2: 0.2647854804992676\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1220 epoch, average loss: -28935.7625\n",
      "                , loss1: -1507.10693359375\n",
      "                , loss2: 0.6900509834289551\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1230 epoch, average loss: -28936.25\n",
      "                , loss1: -1507.10703125\n",
      "                , loss2: 0.203786039352417\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1240 epoch, average loss: -28935.425\n",
      "                , loss1: -1507.10537109375\n",
      "                , loss2: 0.9999892234802246\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1250 epoch, average loss: -28936.01875\n",
      "                , loss1: -1507.10458984375\n",
      "                , loss2: 0.39254300594329833\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1260 epoch, average loss: -28936.0375\n",
      "                , loss1: -1507.102734375\n",
      "                , loss2: 0.3385923385620117\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1270 epoch, average loss: -28936.19375\n",
      "                , loss1: -1507.10537109375\n",
      "                , loss2: 0.22998738288879395\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1280 epoch, average loss: -28935.91875\n",
      "                , loss1: -1507.10625\n",
      "                , loss2: 0.5237892627716064\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1290 epoch, average loss: -28936.234375\n",
      "                , loss1: -1507.1052734375\n",
      "                , loss2: 0.1889454960823059\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1300 epoch, average loss: -28935.990625\n",
      "                , loss1: -1507.1087890625\n",
      "                , loss2: 0.5026587963104248\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1310 epoch, average loss: -28935.85625\n",
      "                , loss1: -1507.1072265625\n",
      "                , loss2: 0.6061463356018066\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1320 epoch, average loss: -28936.209375\n",
      "                , loss1: -1507.1099609375\n",
      "                , loss2: 0.3078120946884155\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1330 epoch, average loss: -28935.9\n",
      "                , loss1: -1507.1078125\n",
      "                , loss2: 0.5705965042114258\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1340 epoch, average loss: -28936.19375\n",
      "                , loss1: -1507.110546875\n",
      "                , loss2: 0.32775096893310546\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1350 epoch, average loss: -28936.18125\n",
      "                , loss1: -1507.10947265625\n",
      "                , loss2: 0.3211430311203003\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1360 epoch, average loss: -28936.153125\n",
      "                , loss1: -1507.1125\n",
      "                , loss2: 0.4094816207885742\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1370 epoch, average loss: -28936.253125\n",
      "                , loss1: -1507.10869140625\n",
      "                , loss2: 0.23265175819396972\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1380 epoch, average loss: -28936.28125\n",
      "                , loss1: -1507.1130859375\n",
      "                , loss2: 0.2942155361175537\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1390 epoch, average loss: -28936.3875\n",
      "                , loss1: -1507.1107421875\n",
      "                , loss2: 0.13680024147033693\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1400 epoch, average loss: -28936.134375\n",
      "                , loss1: -1507.11259765625\n",
      "                , loss2: 0.42732486724853513\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1410 epoch, average loss: -28936.471875\n",
      "                , loss1: -1507.1169921875\n",
      "                , loss2: 0.17419527769088744\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1420 epoch, average loss: -28936.375\n",
      "                , loss1: -1507.1130859375\n",
      "                , loss2: 0.19799503087997436\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1430 epoch, average loss: -28936.09375\n",
      "                , loss1: -1507.10986328125\n",
      "                , loss2: 0.41500115394592285\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1440 epoch, average loss: -28936.08125\n",
      "                , loss1: -1507.113671875\n",
      "                , loss2: 0.5009370803833008\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1450 epoch, average loss: -28936.284375\n",
      "                , loss1: -1507.11240234375\n",
      "                , loss2: 0.2746501684188843\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1460 epoch, average loss: -28936.309375\n",
      "                , loss1: -1507.1134765625\n",
      "                , loss2: 0.27124433517456054\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1470 epoch, average loss: -28936.3875\n",
      "                , loss1: -1507.11279296875\n",
      "                , loss2: 0.178990638256073\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1480 epoch, average loss: -28936.309375\n",
      "                , loss1: -1507.1150390625\n",
      "                , loss2: 0.30305612087249756\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1490 epoch, average loss: -28936.50625\n",
      "                , loss1: -1507.11552734375\n",
      "                , loss2: 0.11608761548995972\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1500 epoch, average loss: -28936.33125\n",
      "                , loss1: -1507.11689453125\n",
      "                , loss2: 0.31673517227172854\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1510 epoch, average loss: -28936.56875\n",
      "                , loss1: -1507.11923828125\n",
      "                , loss2: 0.11766458749771118\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1520 epoch, average loss: -28936.4875\n",
      "                , loss1: -1507.115625\n",
      "                , loss2: 0.13113117218017578\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1530 epoch, average loss: -28936.384375\n",
      "                , loss1: -1507.11533203125\n",
      "                , loss2: 0.22945594787597656\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1540 epoch, average loss: -28936.38125\n",
      "                , loss1: -1507.12041015625\n",
      "                , loss2: 0.3331695556640625\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1550 epoch, average loss: -28936.415625\n",
      "                , loss1: -1507.1166015625\n",
      "                , loss2: 0.2230081558227539\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1560 epoch, average loss: -28936.35625\n",
      "                , loss1: -1507.1150390625\n",
      "                , loss2: 0.25502805709838866\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1570 epoch, average loss: -28936.39375\n",
      "                , loss1: -1507.116796875\n",
      "                , loss2: 0.24871337413787842\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1580 epoch, average loss: -28936.296875\n",
      "                , loss1: -1507.11953125\n",
      "                , loss2: 0.40087180137634276\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1590 epoch, average loss: -28936.528125\n",
      "                , loss1: -1507.11884765625\n",
      "                , loss2: 0.1541400671005249\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1600 epoch, average loss: -28936.55625\n",
      "                , loss1: -1507.1189453125\n",
      "                , loss2: 0.12950652837753296\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1610 epoch, average loss: -28936.15\n",
      "                , loss1: -1507.1208984375\n",
      "                , loss2: 0.5722485542297363\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1620 epoch, average loss: -28936.446875\n",
      "                , loss1: -1507.12021484375\n",
      "                , loss2: 0.2605896472930908\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1630 epoch, average loss: -28936.34375\n",
      "                , loss1: -1507.11875\n",
      "                , loss2: 0.3379024028778076\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1640 epoch, average loss: -28936.490625\n",
      "                , loss1: -1507.12060546875\n",
      "                , loss2: 0.228371524810791\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1650 epoch, average loss: -28936.11875\n",
      "                , loss1: -1507.119140625\n",
      "                , loss2: 0.5704650402069091\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1660 epoch, average loss: -28936.478125\n",
      "                , loss1: -1507.1220703125\n",
      "                , loss2: 0.2654597282409668\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1670 epoch, average loss: -28936.571875\n",
      "                , loss1: -1507.1212890625\n",
      "                , loss2: 0.15746076107025148\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1680 epoch, average loss: -28936.65625\n",
      "                , loss1: -1507.12314453125\n",
      "                , loss2: 0.10926637649536133\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1690 epoch, average loss: -28936.68125\n",
      "                , loss1: -1507.1232421875\n",
      "                , loss2: 0.08688654899597167\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1700 epoch, average loss: -28936.44375\n",
      "                , loss1: -1507.11865234375\n",
      "                , loss2: 0.2399600028991699\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1710 epoch, average loss: -28936.5375\n",
      "                , loss1: -1507.12138671875\n",
      "                , loss2: 0.1952645182609558\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1720 epoch, average loss: -28936.5375\n",
      "                , loss1: -1507.121484375\n",
      "                , loss2: 0.19465792179107666\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1730 epoch, average loss: -28936.609375\n",
      "                , loss1: -1507.12216796875\n",
      "                , loss2: 0.14085493087768555\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1740 epoch, average loss: -28936.165625\n",
      "                , loss1: -1507.12119140625\n",
      "                , loss2: 0.5617430686950684\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1750 epoch, average loss: -28936.53125\n",
      "                , loss1: -1507.12763671875\n",
      "                , loss2: 0.31792640686035156\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1760 epoch, average loss: -28936.61875\n",
      "                , loss1: -1507.1263671875\n",
      "                , loss2: 0.20808594226837157\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1770 epoch, average loss: -28936.421875\n",
      "                , loss1: -1507.1255859375\n",
      "                , loss2: 0.39163742065429685\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1780 epoch, average loss: -28936.478125\n",
      "                , loss1: -1507.125390625\n",
      "                , loss2: 0.32892093658447263\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1790 epoch, average loss: -28936.36875\n",
      "                , loss1: -1507.12314453125\n",
      "                , loss2: 0.3949193716049194\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1800 epoch, average loss: -28936.728125\n",
      "                , loss1: -1507.12568359375\n",
      "                , loss2: 0.0860521674156189\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1810 epoch, average loss: -28936.28125\n",
      "                , loss1: -1507.125390625\n",
      "                , loss2: 0.5273340225219727\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1820 epoch, average loss: -28936.459375\n",
      "                , loss1: -1507.12890625\n",
      "                , loss2: 0.41620311737060545\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1830 epoch, average loss: -28936.734375\n",
      "                , loss1: -1507.1294921875\n",
      "                , loss2: 0.1538327932357788\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1840 epoch, average loss: -28936.71875\n",
      "                , loss1: -1507.13046875\n",
      "                , loss2: 0.1851790428161621\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1850 epoch, average loss: -28936.665625\n",
      "                , loss1: -1507.1275390625\n",
      "                , loss2: 0.18378281593322754\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1860 epoch, average loss: -28936.678125\n",
      "                , loss1: -1507.12822265625\n",
      "                , loss2: 0.18533554077148437\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1870 epoch, average loss: -28936.78125\n",
      "                , loss1: -1507.1306640625\n",
      "                , loss2: 0.12781040668487548\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1880 epoch, average loss: -28936.675\n",
      "                , loss1: -1507.129296875\n",
      "                , loss2: 0.2099781036376953\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1890 epoch, average loss: -28936.784375\n",
      "                , loss1: -1507.1287109375\n",
      "                , loss2: 0.09080844521522521\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1900 epoch, average loss: -28936.753125\n",
      "                , loss1: -1507.13017578125\n",
      "                , loss2: 0.1489913582801819\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1910 epoch, average loss: -28936.590625\n",
      "                , loss1: -1507.13037109375\n",
      "                , loss2: 0.3154894351959229\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1920 epoch, average loss: -28936.73125\n",
      "                , loss1: -1507.130859375\n",
      "                , loss2: 0.17923760414123535\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1930 epoch, average loss: -28936.78125\n",
      "                , loss1: -1507.1306640625\n",
      "                , loss2: 0.1261119842529297\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1940 epoch, average loss: -28936.08125\n",
      "                , loss1: -1507.13115234375\n",
      "                , loss2: 0.8393438339233399\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1950 epoch, average loss: -28936.859375\n",
      "                , loss1: -1507.132421875\n",
      "                , loss2: 0.08553793430328369\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1960 epoch, average loss: -28936.790625\n",
      "                , loss1: -1507.13193359375\n",
      "                , loss2: 0.1442495107650757\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1970 epoch, average loss: -28936.425\n",
      "                , loss1: -1507.13466796875\n",
      "                , loss2: 0.5607810020446777\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1980 epoch, average loss: -28936.734375\n",
      "                , loss1: -1507.132421875\n",
      "                , loss2: 0.20751481056213378\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 1990 epoch, average loss: -28936.675\n",
      "                , loss1: -1507.13330078125\n",
      "                , loss2: 0.2839270830154419\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2000 epoch, average loss: -28936.8125\n",
      "                , loss1: -1507.13408203125\n",
      "                , loss2: 0.16334817409515381\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2010 epoch, average loss: -28936.690625\n",
      "                , loss1: -1507.13271484375\n",
      "                , loss2: 0.2589739799499512\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2020 epoch, average loss: -28936.74375\n",
      "                , loss1: -1507.13251953125\n",
      "                , loss2: 0.20294950008392335\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2030 epoch, average loss: -28936.6875\n",
      "                , loss1: -1507.13681640625\n",
      "                , loss2: 0.3409167766571045\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2040 epoch, average loss: -28936.8625\n",
      "                , loss1: -1507.137890625\n",
      "                , loss2: 0.18668885231018068\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2050 epoch, average loss: -28936.98125\n",
      "                , loss1: -1507.1388671875\n",
      "                , loss2: 0.08529433012008666\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2060 epoch, average loss: -28936.46875\n",
      "                , loss1: -1507.1375\n",
      "                , loss2: 0.5751482009887695\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2070 epoch, average loss: -28936.478125\n",
      "                , loss1: -1507.1376953125\n",
      "                , loss2: 0.5677902221679687\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2080 epoch, average loss: -28936.69375\n",
      "                , loss1: -1507.13486328125\n",
      "                , loss2: 0.30136110782623293\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2090 epoch, average loss: -28936.7625\n",
      "                , loss1: -1507.13955078125\n",
      "                , loss2: 0.31663103103637696\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2100 epoch, average loss: -28936.984375\n",
      "                , loss1: -1507.1390625\n",
      "                , loss2: 0.08622626066207886\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2110 epoch, average loss: -28936.696875\n",
      "                , loss1: -1507.139453125\n",
      "                , loss2: 0.3803720235824585\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2120 epoch, average loss: -28936.809375\n",
      "                , loss1: -1507.13916015625\n",
      "                , loss2: 0.2640796899795532\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2130 epoch, average loss: -28936.940625\n",
      "                , loss1: -1507.1384765625\n",
      "                , loss2: 0.12007629871368408\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2140 epoch, average loss: -28936.86875\n",
      "                , loss1: -1507.140625\n",
      "                , loss2: 0.22867870330810547\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2150 epoch, average loss: -28936.896875\n",
      "                , loss1: -1507.14189453125\n",
      "                , loss2: 0.22815427780151368\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2160 epoch, average loss: -28936.93125\n",
      "                , loss1: -1507.14287109375\n",
      "                , loss2: 0.2119915008544922\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2170 epoch, average loss: -28936.803125\n",
      "                , loss1: -1507.1412109375\n",
      "                , loss2: 0.3081726789474487\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2180 epoch, average loss: -28936.875\n",
      "                , loss1: -1507.1400390625\n",
      "                , loss2: 0.21357121467590331\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2190 epoch, average loss: -28936.715625\n",
      "                , loss1: -1507.143359375\n",
      "                , loss2: 0.43860764503479005\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2200 epoch, average loss: -28936.9375\n",
      "                , loss1: -1507.14140625\n",
      "                , loss2: 0.17494261264801025\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2210 epoch, average loss: -28936.496875\n",
      "                , loss1: -1507.1423828125\n",
      "                , loss2: 0.6388267517089844\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2220 epoch, average loss: -28936.8875\n",
      "                , loss1: -1507.14462890625\n",
      "                , loss2: 0.292110538482666\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2230 epoch, average loss: -28936.790625\n",
      "                , loss1: -1507.142578125\n",
      "                , loss2: 0.3483414649963379\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2240 epoch, average loss: -28937.0125\n",
      "                , loss1: -1507.14404296875\n",
      "                , loss2: 0.15449899435043335\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2250 epoch, average loss: -28936.8875\n",
      "                , loss1: -1507.14326171875\n",
      "                , loss2: 0.2668196678161621\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2260 epoch, average loss: -28936.959375\n",
      "                , loss1: -1507.1474609375\n",
      "                , loss2: 0.27211010456085205\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2270 epoch, average loss: -28936.971875\n",
      "                , loss1: -1507.14248046875\n",
      "                , loss2: 0.16168203353881835\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2280 epoch, average loss: -28937.075\n",
      "                , loss1: -1507.147265625\n",
      "                , loss2: 0.15200436115264893\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2290 epoch, average loss: -28937.11875\n",
      "                , loss1: -1507.14931640625\n",
      "                , loss2: 0.15078340768814086\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2300 epoch, average loss: -28936.9625\n",
      "                , loss1: -1507.147265625\n",
      "                , loss2: 0.26678972244262694\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2310 epoch, average loss: -28936.984375\n",
      "                , loss1: -1507.1474609375\n",
      "                , loss2: 0.24979114532470703\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2320 epoch, average loss: -28937.096875\n",
      "                , loss1: -1507.1509765625\n",
      "                , loss2: 0.20222210884094238\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2330 epoch, average loss: -28937.109375\n",
      "                , loss1: -1507.1478515625\n",
      "                , loss2: 0.13165488243103027\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2340 epoch, average loss: -28937.15\n",
      "                , loss1: -1507.149609375\n",
      "                , loss2: 0.12315846681594848\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2350 epoch, average loss: -28937.11875\n",
      "                , loss1: -1507.147265625\n",
      "                , loss2: 0.10467033386230469\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2360 epoch, average loss: -28937.05625\n",
      "                , loss1: -1507.14951171875\n",
      "                , loss2: 0.21665282249450685\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2370 epoch, average loss: -28937.165625\n",
      "                , loss1: -1507.151171875\n",
      "                , loss2: 0.1388866424560547\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2380 epoch, average loss: -28937.234375\n",
      "                , loss1: -1507.153125\n",
      "                , loss2: 0.10708310604095458\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2390 epoch, average loss: -28937.14375\n",
      "                , loss1: -1507.151171875\n",
      "                , loss2: 0.15981385707855225\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2400 epoch, average loss: -28937.225\n",
      "                , loss1: -1507.15263671875\n",
      "                , loss2: 0.10317772626876831\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2410 epoch, average loss: -28937.109375\n",
      "                , loss1: -1507.1521484375\n",
      "                , loss2: 0.2135931968688965\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2420 epoch, average loss: -28937.0\n",
      "                , loss1: -1507.15244140625\n",
      "                , loss2: 0.3263345956802368\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2430 epoch, average loss: -28937.053125\n",
      "                , loss1: -1507.15390625\n",
      "                , loss2: 0.30149667263031005\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2440 epoch, average loss: -28937.1625\n",
      "                , loss1: -1507.1525390625\n",
      "                , loss2: 0.1656983494758606\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2450 epoch, average loss: -28937.240625\n",
      "                , loss1: -1507.15546875\n",
      "                , loss2: 0.14749082326889038\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2460 epoch, average loss: -28937.140625\n",
      "                , loss1: -1507.15478515625\n",
      "                , loss2: 0.2312304735183716\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2470 epoch, average loss: -28937.171875\n",
      "                , loss1: -1507.151171875\n",
      "                , loss2: 0.1348242163658142\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2480 epoch, average loss: -28937.18125\n",
      "                , loss1: -1507.15234375\n",
      "                , loss2: 0.14452289342880248\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2490 epoch, average loss: -28937.271875\n",
      "                , loss1: -1507.153125\n",
      "                , loss2: 0.06895902752876282\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2500 epoch, average loss: -28936.984375\n",
      "                , loss1: -1507.1560546875\n",
      "                , loss2: 0.4130257129669189\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2510 epoch, average loss: -28937.196875\n",
      "                , loss1: -1507.15478515625\n",
      "                , loss2: 0.17482442855834962\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2520 epoch, average loss: -28937.1\n",
      "                , loss1: -1507.15576171875\n",
      "                , loss2: 0.29210193157196046\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2530 epoch, average loss: -28937.1375\n",
      "                , loss1: -1507.15654296875\n",
      "                , loss2: 0.27017736434936523\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2540 epoch, average loss: -28937.203125\n",
      "                , loss1: -1507.15625\n",
      "                , loss2: 0.19910712242126466\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2550 epoch, average loss: -28937.196875\n",
      "                , loss1: -1507.15791015625\n",
      "                , loss2: 0.23442788124084474\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2560 epoch, average loss: -28937.15\n",
      "                , loss1: -1507.159375\n",
      "                , loss2: 0.30964674949646\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2570 epoch, average loss: -28937.353125\n",
      "                , loss1: -1507.1607421875\n",
      "                , loss2: 0.13455750942230224\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2580 epoch, average loss: -28937.253125\n",
      "                , loss1: -1507.1587890625\n",
      "                , loss2: 0.19769047498703002\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2590 epoch, average loss: -28937.26875\n",
      "                , loss1: -1507.1611328125\n",
      "                , loss2: 0.2255472183227539\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2600 epoch, average loss: -28937.365625\n",
      "                , loss1: -1507.16123046875\n",
      "                , loss2: 0.1335392713546753\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2610 epoch, average loss: -28937.165625\n",
      "                , loss1: -1507.16015625\n",
      "                , loss2: 0.3125629901885986\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2620 epoch, average loss: -28937.359375\n",
      "                , loss1: -1507.16171875\n",
      "                , loss2: 0.14561856985092164\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2630 epoch, average loss: -28937.34375\n",
      "                , loss1: -1507.1609375\n",
      "                , loss2: 0.15047447681427\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2640 epoch, average loss: -28937.353125\n",
      "                , loss1: -1507.1630859375\n",
      "                , loss2: 0.18034976720809937\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2650 epoch, average loss: -28937.19375\n",
      "                , loss1: -1507.1634765625\n",
      "                , loss2: 0.3467796802520752\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2660 epoch, average loss: -28937.434375\n",
      "                , loss1: -1507.16455078125\n",
      "                , loss2: 0.12303223609924316\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2670 epoch, average loss: -28937.078125\n",
      "                , loss1: -1507.16220703125\n",
      "                , loss2: 0.43588733673095703\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2680 epoch, average loss: -28937.278125\n",
      "                , loss1: -1507.1640625\n",
      "                , loss2: 0.274239182472229\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2690 epoch, average loss: -28937.38125\n",
      "                , loss1: -1507.16669921875\n",
      "                , loss2: 0.2198591947555542\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2700 epoch, average loss: -28937.55\n",
      "                , loss1: -1507.165625\n",
      "                , loss2: 0.028651276230812074\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2710 epoch, average loss: -28937.384375\n",
      "                , loss1: -1507.16708984375\n",
      "                , loss2: 0.22567529678344728\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2720 epoch, average loss: -28937.490625\n",
      "                , loss1: -1507.16494140625\n",
      "                , loss2: 0.08085215091705322\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2730 epoch, average loss: -28937.49375\n",
      "                , loss1: -1507.1673828125\n",
      "                , loss2: 0.11851359605789184\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2740 epoch, average loss: -28937.40625\n",
      "                , loss1: -1507.16455078125\n",
      "                , loss2: 0.15394490957260132\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2750 epoch, average loss: -28937.44375\n",
      "                , loss1: -1507.169921875\n",
      "                , loss2: 0.22129271030426026\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2760 epoch, average loss: -28937.2375\n",
      "                , loss1: -1507.1689453125\n",
      "                , loss2: 0.40795507431030276\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2770 epoch, average loss: -28937.346875\n",
      "                , loss1: -1507.1669921875\n",
      "                , loss2: 0.261433744430542\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2780 epoch, average loss: -28937.3875\n",
      "                , loss1: -1507.16748046875\n",
      "                , loss2: 0.2271780014038086\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2790 epoch, average loss: -28937.365625\n",
      "                , loss1: -1507.1689453125\n",
      "                , loss2: 0.2766232967376709\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2800 epoch, average loss: -28937.38125\n",
      "                , loss1: -1507.17021484375\n",
      "                , loss2: 0.2916425704956055\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2810 epoch, average loss: -28937.31875\n",
      "                , loss1: -1507.1673828125\n",
      "                , loss2: 0.29531610012054443\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2820 epoch, average loss: -28937.359375\n",
      "                , loss1: -1507.170703125\n",
      "                , loss2: 0.32026822566986085\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2830 epoch, average loss: -28937.471875\n",
      "                , loss1: -1507.1685546875\n",
      "                , loss2: 0.16513459682464598\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2840 epoch, average loss: -28937.45\n",
      "                , loss1: -1507.1626953125\n",
      "                , loss2: 0.07786104083061218\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2850 epoch, average loss: -28937.590625\n",
      "                , loss1: -1507.170703125\n",
      "                , loss2: 0.08968414068222046\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2860 epoch, average loss: -28937.4125\n",
      "                , loss1: -1507.1736328125\n",
      "                , loss2: 0.32086772918701173\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2870 epoch, average loss: -28937.3625\n",
      "                , loss1: -1507.172265625\n",
      "                , loss2: 0.34677340984344485\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2880 epoch, average loss: -28937.58125\n",
      "                , loss1: -1507.17421875\n",
      "                , loss2: 0.16438400745391846\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2890 epoch, average loss: -28937.13125\n",
      "                , loss1: -1507.17490234375\n",
      "                , loss2: 0.6263858318328858\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2900 epoch, average loss: -28937.515625\n",
      "                , loss1: -1507.17421875\n",
      "                , loss2: 0.23100686073303223\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2910 epoch, average loss: -28937.6875\n",
      "                , loss1: -1507.1744140625\n",
      "                , loss2: 0.06291478872299194\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2920 epoch, average loss: -28937.55\n",
      "                , loss1: -1507.17568359375\n",
      "                , loss2: 0.22209444046020507\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2930 epoch, average loss: -28937.3875\n",
      "                , loss1: -1507.1734375\n",
      "                , loss2: 0.3453498363494873\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2940 epoch, average loss: -28937.509375\n",
      "                , loss1: -1507.17763671875\n",
      "                , loss2: 0.3033886432647705\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2950 epoch, average loss: -28937.33125\n",
      "                , loss1: -1507.17314453125\n",
      "                , loss2: 0.3945138454437256\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2960 epoch, average loss: -28937.35\n",
      "                , loss1: -1507.1748046875\n",
      "                , loss2: 0.4089953422546387\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2970 epoch, average loss: -28937.70625\n",
      "                , loss1: -1507.1783203125\n",
      "                , loss2: 0.11846978664398193\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2980 epoch, average loss: -28937.609375\n",
      "                , loss1: -1507.17783203125\n",
      "                , loss2: 0.20709028244018554\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 2990 epoch, average loss: -28937.59375\n",
      "                , loss1: -1507.17548828125\n",
      "                , loss2: 0.17612706422805785\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3000 epoch, average loss: -28937.528125\n",
      "                , loss1: -1507.177734375\n",
      "                , loss2: 0.28668413162231443\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3010 epoch, average loss: -28937.596875\n",
      "                , loss1: -1507.17958984375\n",
      "                , loss2: 0.25264749526977537\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3020 epoch, average loss: -28937.409375\n",
      "                , loss1: -1507.17666015625\n",
      "                , loss2: 0.3828147888183594\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3030 epoch, average loss: -28937.225\n",
      "                , loss1: -1507.178125\n",
      "                , loss2: 0.5960400581359864\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3040 epoch, average loss: -28937.653125\n",
      "                , loss1: -1507.1798828125\n",
      "                , loss2: 0.20023670196533203\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3050 epoch, average loss: -28937.7125\n",
      "                , loss1: -1507.18046875\n",
      "                , loss2: 0.15382008552551268\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3060 epoch, average loss: -28937.815625\n",
      "                , loss1: -1507.18232421875\n",
      "                , loss2: 0.0847681701183319\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3070 epoch, average loss: -28937.271875\n",
      "                , loss1: -1507.1833984375\n",
      "                , loss2: 0.6486404418945313\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3080 epoch, average loss: -28937.603125\n",
      "                , loss1: -1507.17998046875\n",
      "                , loss2: 0.2548078536987305\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3090 epoch, average loss: -28937.603125\n",
      "                , loss1: -1507.18173828125\n",
      "                , loss2: 0.2874046802520752\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3100 epoch, average loss: -28937.75625\n",
      "                , loss1: -1507.1826171875\n",
      "                , loss2: 0.1514054298400879\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3110 epoch, average loss: -28937.7625\n",
      "                , loss1: -1507.18349609375\n",
      "                , loss2: 0.1643432378768921\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3120 epoch, average loss: -28937.728125\n",
      "                , loss1: -1507.184765625\n",
      "                , loss2: 0.21992263793945313\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3130 epoch, average loss: -28937.4\n",
      "                , loss1: -1507.1845703125\n",
      "                , loss2: 0.5410162448883057\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3140 epoch, average loss: -28937.809375\n",
      "                , loss1: -1507.187890625\n",
      "                , loss2: 0.2007282257080078\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3150 epoch, average loss: -28937.784375\n",
      "                , loss1: -1507.185546875\n",
      "                , loss2: 0.18166626691818238\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3160 epoch, average loss: -28937.8\n",
      "                , loss1: -1507.184375\n",
      "                , loss2: 0.1399381399154663\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3170 epoch, average loss: -28937.80625\n",
      "                , loss1: -1507.1873046875\n",
      "                , loss2: 0.18898122310638427\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3180 epoch, average loss: -28937.928125\n",
      "                , loss1: -1507.188671875\n",
      "                , loss2: 0.09508246183395386\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3190 epoch, average loss: -28937.61875\n",
      "                , loss1: -1507.1875\n",
      "                , loss2: 0.38381295204162597\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3200 epoch, average loss: -28937.228125\n",
      "                , loss1: -1507.18671875\n",
      "                , loss2: 0.7607816219329834\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3210 epoch, average loss: -28937.6625\n",
      "                , loss1: -1507.1892578125\n",
      "                , loss2: 0.37379376888275145\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3220 epoch, average loss: -28936.790625\n",
      "                , loss1: -1507.18876953125\n",
      "                , loss2: 1.233438491821289\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3230 epoch, average loss: -28937.24375\n",
      "                , loss1: -1507.187890625\n",
      "                , loss2: 0.7635686874389649\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3240 epoch, average loss: -28937.36875\n",
      "                , loss1: -1507.1904296875\n",
      "                , loss2: 0.6873672485351563\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3250 epoch, average loss: -28937.734375\n",
      "                , loss1: -1507.18837890625\n",
      "                , loss2: 0.2832717657089233\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3260 epoch, average loss: -28937.775\n",
      "                , loss1: -1507.18818359375\n",
      "                , loss2: 0.2373417377471924\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3270 epoch, average loss: -28937.6625\n",
      "                , loss1: -1507.192578125\n",
      "                , loss2: 0.43856520652770997\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3280 epoch, average loss: -28937.853125\n",
      "                , loss1: -1507.19375\n",
      "                , loss2: 0.266925573348999\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3290 epoch, average loss: -28937.978125\n",
      "                , loss1: -1507.19296875\n",
      "                , loss2: 0.12606755495071412\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3300 epoch, average loss: -28937.98125\n",
      "                , loss1: -1507.1912109375\n",
      "                , loss2: 0.08767297267913818\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3310 epoch, average loss: -28937.828125\n",
      "                , loss1: -1507.1919921875\n",
      "                , loss2: 0.26020236015319825\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3320 epoch, average loss: -28937.859375\n",
      "                , loss1: -1507.19189453125\n",
      "                , loss2: 0.22744925022125245\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3330 epoch, average loss: -28937.91875\n",
      "                , loss1: -1507.194140625\n",
      "                , loss2: 0.20932724475860595\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3340 epoch, average loss: -28937.940625\n",
      "                , loss1: -1507.1935546875\n",
      "                , loss2: 0.17258787155151367\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3350 epoch, average loss: -28937.675\n",
      "                , loss1: -1507.19453125\n",
      "                , loss2: 0.4614572048187256\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3360 epoch, average loss: -28938.025\n",
      "                , loss1: -1507.196875\n",
      "                , loss2: 0.15308364629745483\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3370 epoch, average loss: -28937.85625\n",
      "                , loss1: -1507.194140625\n",
      "                , loss2: 0.2720287322998047\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3380 epoch, average loss: -28938.003125\n",
      "                , loss1: -1507.194921875\n",
      "                , loss2: 0.14146503210067748\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3390 epoch, average loss: -28938.10625\n",
      "                , loss1: -1507.197265625\n",
      "                , loss2: 0.08549201488494873\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3400 epoch, average loss: -28937.703125\n",
      "                , loss1: -1507.19794921875\n",
      "                , loss2: 0.5002273559570313\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3410 epoch, average loss: -28937.859375\n",
      "                , loss1: -1507.1970703125\n",
      "                , loss2: 0.3271949291229248\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3420 epoch, average loss: -28937.9375\n",
      "                , loss1: -1507.19931640625\n",
      "                , loss2: 0.2906085968017578\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3430 epoch, average loss: -28937.946875\n",
      "                , loss1: -1507.2\n",
      "                , loss2: 0.2944328308105469\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3440 epoch, average loss: -28937.95\n",
      "                , loss1: -1507.19736328125\n",
      "                , loss2: 0.24180998802185058\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3450 epoch, average loss: -28938.146875\n",
      "                , loss1: -1507.20048828125\n",
      "                , loss2: 0.10494145154953002\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3460 epoch, average loss: -28937.96875\n",
      "                , loss1: -1507.201171875\n",
      "                , loss2: 0.2957437515258789\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3470 epoch, average loss: -28938.140625\n",
      "                , loss1: -1507.199609375\n",
      "                , loss2: 0.08742727041244507\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3480 epoch, average loss: -28938.125\n",
      "                , loss1: -1507.20146484375\n",
      "                , loss2: 0.1428199052810669\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3490 epoch, average loss: -28937.7875\n",
      "                , loss1: -1507.20224609375\n",
      "                , loss2: 0.49712061882019043\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3500 epoch, average loss: -28937.6\n",
      "                , loss1: -1507.20224609375\n",
      "                , loss2: 0.6833357810974121\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3510 epoch, average loss: -28937.725\n",
      "                , loss1: -1507.20390625\n",
      "                , loss2: 0.5907510757446289\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3520 epoch, average loss: -28937.984375\n",
      "                , loss1: -1507.20341796875\n",
      "                , loss2: 0.3227988719940186\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3530 epoch, average loss: -28938.0\n",
      "                , loss1: -1507.20322265625\n",
      "                , loss2: 0.30512051582336425\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3540 epoch, average loss: -28938.121875\n",
      "                , loss1: -1507.20537109375\n",
      "                , loss2: 0.22355666160583496\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3550 epoch, average loss: -28938.159375\n",
      "                , loss1: -1507.206640625\n",
      "                , loss2: 0.20857951641082764\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3560 epoch, average loss: -28937.890625\n",
      "                , loss1: -1507.20400390625\n",
      "                , loss2: 0.4288147449493408\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3570 epoch, average loss: -28938.059375\n",
      "                , loss1: -1507.20341796875\n",
      "                , loss2: 0.2475959300994873\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3580 epoch, average loss: -28937.825\n",
      "                , loss1: -1507.2052734375\n",
      "                , loss2: 0.516910171508789\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3590 epoch, average loss: -28938.0125\n",
      "                , loss1: -1507.2060546875\n",
      "                , loss2: 0.34525015354156496\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3600 epoch, average loss: -28938.26875\n",
      "                , loss1: -1507.2072265625\n",
      "                , loss2: 0.11480066776275635\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3610 epoch, average loss: -28938.053125\n",
      "                , loss1: -1507.2080078125\n",
      "                , loss2: 0.34152817726135254\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3620 epoch, average loss: -28938.221875\n",
      "                , loss1: -1507.207421875\n",
      "                , loss2: 0.16035122871398927\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3630 epoch, average loss: -28938.03125\n",
      "                , loss1: -1507.20966796875\n",
      "                , loss2: 0.39223804473876955\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3640 epoch, average loss: -28938.075\n",
      "                , loss1: -1507.207421875\n",
      "                , loss2: 0.3109470844268799\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3650 epoch, average loss: -28938.128125\n",
      "                , loss1: -1507.20927734375\n",
      "                , loss2: 0.29069955348968507\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3660 epoch, average loss: -28938.08125\n",
      "                , loss1: -1507.2064453125\n",
      "                , loss2: 0.2837110996246338\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3670 epoch, average loss: -28938.015625\n",
      "                , loss1: -1507.2115234375\n",
      "                , loss2: 0.4454971790313721\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3680 epoch, average loss: -28937.76875\n",
      "                , loss1: -1507.210546875\n",
      "                , loss2: 0.6732173442840577\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3690 epoch, average loss: -28938.040625\n",
      "                , loss1: -1507.2115234375\n",
      "                , loss2: 0.42180562019348145\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3700 epoch, average loss: -28938.23125\n",
      "                , loss1: -1507.21044921875\n",
      "                , loss2: 0.2108325481414795\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3710 epoch, average loss: -28938.2625\n",
      "                , loss1: -1507.2123046875\n",
      "                , loss2: 0.2182767629623413\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3720 epoch, average loss: -28938.371875\n",
      "                , loss1: -1507.212890625\n",
      "                , loss2: 0.11741364002227783\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3730 epoch, average loss: -28938.378125\n",
      "                , loss1: -1507.21328125\n",
      "                , loss2: 0.11602776050567627\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3740 epoch, average loss: -28937.88125\n",
      "                , loss1: -1507.215234375\n",
      "                , loss2: 0.6517767906188965\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3750 epoch, average loss: -28938.19375\n",
      "                , loss1: -1507.21630859375\n",
      "                , loss2: 0.36379327774047854\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3760 epoch, average loss: -28938.428125\n",
      "                , loss1: -1507.2158203125\n",
      "                , loss2: 0.12003945112228394\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3770 epoch, average loss: -28938.2\n",
      "                , loss1: -1507.216015625\n",
      "                , loss2: 0.3460553169250488\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3780 epoch, average loss: -28938.403125\n",
      "                , loss1: -1507.2185546875\n",
      "                , loss2: 0.19383984804153442\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3790 epoch, average loss: -28938.49375\n",
      "                , loss1: -1507.221484375\n",
      "                , loss2: 0.1616297960281372\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3800 epoch, average loss: -28938.5625\n",
      "                , loss1: -1507.22109375\n",
      "                , loss2: 0.08206956386566162\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3810 epoch, average loss: -28944.76875\n",
      "                , loss1: -1507.60556640625\n",
      "                , loss2: 1.2595149993896484\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3820 epoch, average loss: -28955.4625\n",
      "                , loss1: -1508.13076171875\n",
      "                , loss2: 0.6474993228912354\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3830 epoch, average loss: -28956.103125\n",
      "                , loss1: -1508.13173828125\n",
      "                , loss2: 0.028845664858818055\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3840 epoch, average loss: -28956.090625\n",
      "                , loss1: -1508.13046875\n",
      "                , loss2: 0.014870074391365052\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3850 epoch, average loss: -28956.04375\n",
      "                , loss1: -1508.13125\n",
      "                , loss2: 0.07626878023147583\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3860 epoch, average loss: -28956.084375\n",
      "                , loss1: -1508.1341796875\n",
      "                , loss2: 0.0939916729927063\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3870 epoch, average loss: -28956.153125\n",
      "                , loss1: -1508.1337890625\n",
      "                , loss2: 0.01792696714401245\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3880 epoch, average loss: -28956.16875\n",
      "                , loss1: -1508.13525390625\n",
      "                , loss2: 0.03093751072883606\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3890 epoch, average loss: -28956.178125\n",
      "                , loss1: -1508.13525390625\n",
      "                , loss2: 0.01895354688167572\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3900 epoch, average loss: -28956.209375\n",
      "                , loss1: -1508.13701171875\n",
      "                , loss2: 0.02182934880256653\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3910 epoch, average loss: -28955.99375\n",
      "                , loss1: -1508.1373046875\n",
      "                , loss2: 0.24159088134765624\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3920 epoch, average loss: -28956.21875\n",
      "                , loss1: -1508.138671875\n",
      "                , loss2: 0.04412335753440857\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3930 epoch, average loss: -28956.1875\n",
      "                , loss1: -1508.139453125\n",
      "                , loss2: 0.09211710095405579\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3940 epoch, average loss: -28956.2125\n",
      "                , loss1: -1508.1388671875\n",
      "                , loss2: 0.05305303335189819\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3950 epoch, average loss: -28956.25\n",
      "                , loss1: -1508.1392578125\n",
      "                , loss2: 0.02348824143409729\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3960 epoch, average loss: -28956.228125\n",
      "                , loss1: -1508.138671875\n",
      "                , loss2: 0.03726300597190857\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3970 epoch, average loss: -28956.23125\n",
      "                , loss1: -1508.13818359375\n",
      "                , loss2: 0.022464805841445924\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3980 epoch, average loss: -28956.265625\n",
      "                , loss1: -1508.14033203125\n",
      "                , loss2: 0.0318725734949112\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n",
      "in 3990 epoch, average loss: -28956.271875\n",
      "                , loss1: -1508.14130859375\n",
      "                , loss2: 0.041730889678001405\n",
      "                , weight: 19.19999999997736\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=4e-3, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(4000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3702., 3701.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
