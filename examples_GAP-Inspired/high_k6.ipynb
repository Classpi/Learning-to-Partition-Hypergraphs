{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycq/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) \n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed) \n",
    "random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 6\n",
    "\n",
    "\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 2048, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 2048, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers141\"] = {\"in_channels\": 1024, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 1024, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "l_hyper_prmts[\"linerlayer12334\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":512, \"out_channels\":327, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":327, \"out_channels\":6, \"use_bn\":True, \"drop_rate\":0.02}\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  \n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7818, 327)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/high\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (theta): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=327, bias=True)\n",
       "  (9): BatchNorm1d(327, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.02, inplace=False)\n",
       "  (12): Linear(in_features=327, out_features=6, bias=True)\n",
       "  (13): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: 15.775990295410157\n",
      "                , loss1: -19.622805786132812\n",
      "                , loss2: 18.309294128417967\n",
      "=================================\n",
      "in 10 epoch, average loss: -216.25390625\n",
      "                , loss1: -1970.3955078125\n",
      "                , loss2: 25.717547607421874\n",
      "=================================\n",
      "in 20 epoch, average loss: -526.48837890625\n",
      "                , loss1: -4612.91015625\n",
      "                , loss2: 3.9210540771484377\n",
      "=================================\n",
      "in 30 epoch, average loss: -557.9919921875\n",
      "                , loss1: -5294.223046875\n",
      "                , loss2: 3.628328323364258\n",
      "=================================\n",
      "in 40 epoch, average loss: -541.3025390625\n",
      "                , loss1: -5596.164453125\n",
      "                , loss2: 2.1980010986328127\n",
      "=================================\n",
      "in 50 epoch, average loss: -509.6544921875\n",
      "                , loss1: -5807.627734375\n",
      "                , loss2: 2.1599191665649413\n",
      "=================================\n",
      "in 60 epoch, average loss: -467.780322265625\n",
      "                , loss1: -5941.1609375\n",
      "                , loss2: 2.3924348831176756\n",
      "=================================\n",
      "in 70 epoch, average loss: -418.51953125\n",
      "                , loss1: -5994.31796875\n",
      "                , loss2: 1.9645252227783203\n",
      "=================================\n",
      "in 80 epoch, average loss: -367.062451171875\n",
      "                , loss1: -6027.176953125\n",
      "                , loss2: 1.479705238342285\n",
      "=================================\n",
      "in 90 epoch, average loss: -313.916845703125\n",
      "                , loss1: -6046.34140625\n",
      "                , loss2: 1.3882996559143066\n",
      "=================================\n",
      "in 100 epoch, average loss: -260.025341796875\n",
      "                , loss1: -6058.88359375\n",
      "                , loss2: 1.408587646484375\n",
      "=================================\n",
      "in 110 epoch, average loss: -205.806494140625\n",
      "                , loss1: -6064.446875\n",
      "                , loss2: 1.292311191558838\n",
      "=================================\n",
      "in 120 epoch, average loss: -151.758056640625\n",
      "                , loss1: -6060.571875\n",
      "                , loss2: 0.656595516204834\n",
      "=================================\n",
      "in 130 epoch, average loss: -97.45552368164063\n",
      "                , loss1: -6070.5671875\n",
      "                , loss2: 0.5829073429107666\n",
      "=================================\n",
      "in 140 epoch, average loss: -46.222042846679685\n",
      "                , loss1: -6069.5515625\n",
      "                , loss2: 0.45296459197998046\n",
      "=================================\n",
      "in 150 epoch, average loss: -34.9712646484375\n",
      "                , loss1: -6065.965234375\n",
      "                , loss2: 0.21133360862731934\n",
      "=================================\n",
      "in 160 epoch, average loss: -35.05661315917969\n",
      "                , loss1: -6063.271484375\n",
      "                , loss2: 0.11035720109939576\n",
      "=================================\n",
      "in 170 epoch, average loss: -35.076577758789064\n",
      "                , loss1: -6059.071875\n",
      "                , loss2: 0.06604052782058716\n",
      "=================================\n",
      "in 180 epoch, average loss: -35.08900756835938\n",
      "                , loss1: -6065.75\n",
      "                , loss2: 0.09234122037887574\n",
      "=================================\n",
      "in 190 epoch, average loss: -35.10077819824219\n",
      "                , loss1: -6064.48046875\n",
      "                , loss2: 0.07320753931999206\n",
      "=================================\n",
      "in 200 epoch, average loss: -35.10969848632813\n",
      "                , loss1: -6066.234375\n",
      "                , loss2: 0.0744591474533081\n",
      "=================================\n",
      "in 210 epoch, average loss: -35.1271728515625\n",
      "                , loss1: -6066.09140625\n",
      "                , loss2: 0.05615534782409668\n",
      "=================================\n",
      "in 220 epoch, average loss: -35.128744506835936\n",
      "                , loss1: -6066.969140625\n",
      "                , loss2: 0.05967251658439636\n",
      "=================================\n",
      "in 230 epoch, average loss: -35.14390563964844\n",
      "                , loss1: -6069.973046875\n",
      "                , loss2: 0.06193764209747314\n",
      "=================================\n",
      "in 240 epoch, average loss: -35.152069091796875\n",
      "                , loss1: -6069.351953125\n",
      "                , loss2: 0.05017046332359314\n",
      "=================================\n",
      "in 250 epoch, average loss: -35.154605102539065\n",
      "                , loss1: -6071.598046875\n",
      "                , loss2: 0.06066126823425293\n",
      "=================================\n",
      "in 260 epoch, average loss: -35.15823974609375\n",
      "                , loss1: -6070.591015625\n",
      "                , loss2: 0.05118888020515442\n",
      "=================================\n",
      "in 270 epoch, average loss: -35.15653991699219\n",
      "                , loss1: -6073.630859375\n",
      "                , loss2: 0.07051568627357482\n",
      "=================================\n",
      "in 280 epoch, average loss: -35.16902160644531\n",
      "                , loss1: -6072.3546875\n",
      "                , loss2: 0.0506342887878418\n",
      "=================================\n",
      "in 290 epoch, average loss: -35.178826904296876\n",
      "                , loss1: -6075.62734375\n",
      "                , loss2: 0.05981361269950867\n",
      "=================================\n",
      "in 300 epoch, average loss: -35.176571655273435\n",
      "                , loss1: -6074.1484375\n",
      "                , loss2: 0.053485751152038574\n",
      "=================================\n",
      "in 310 epoch, average loss: -35.176885986328124\n",
      "                , loss1: -6077.937890625\n",
      "                , loss2: 0.0751514971256256\n",
      "=================================\n",
      "in 320 epoch, average loss: -35.1871337890625\n",
      "                , loss1: -6075.24375\n",
      "                , loss2: 0.04928029179573059\n",
      "=================================\n",
      "in 330 epoch, average loss: -35.19013671875\n",
      "                , loss1: -6077.6703125\n",
      "                , loss2: 0.06034722924232483\n",
      "=================================\n",
      "in 340 epoch, average loss: -35.198236083984376\n",
      "                , loss1: -6078.498046875\n",
      "                , loss2: 0.05704721212387085\n",
      "=================================\n",
      "in 350 epoch, average loss: -35.21046447753906\n",
      "                , loss1: -6078.981640625\n",
      "                , loss2: 0.04763068854808807\n",
      "=================================\n",
      "in 360 epoch, average loss: -35.209799194335936\n",
      "                , loss1: -6078.33984375\n",
      "                , loss2: 0.044578182697296145\n",
      "=================================\n",
      "in 370 epoch, average loss: -35.219381713867186\n",
      "                , loss1: -6080.16640625\n",
      "                , loss2: 0.0455838143825531\n",
      "=================================\n",
      "in 380 epoch, average loss: -35.216162109375\n",
      "                , loss1: -6081.367578125\n",
      "                , loss2: 0.05576846599578857\n",
      "=================================\n",
      "in 390 epoch, average loss: -35.226568603515624\n",
      "                , loss1: -6081.15859375\n",
      "                , loss2: 0.0441509485244751\n",
      "=================================\n",
      "in 400 epoch, average loss: -35.235269165039064\n",
      "                , loss1: -6082.81796875\n",
      "                , loss2: 0.045073607563972475\n",
      "=================================\n",
      "in 410 epoch, average loss: -35.232748413085936\n",
      "                , loss1: -6082.96640625\n",
      "                , loss2: 0.04845718145370483\n",
      "=================================\n",
      "in 420 epoch, average loss: -35.23836059570313\n",
      "                , loss1: -6083.849609375\n",
      "                , loss2: 0.047968322038650514\n",
      "=================================\n",
      "in 430 epoch, average loss: -35.24355773925781\n",
      "                , loss1: -6084.193359375\n",
      "                , loss2: 0.044768476486206056\n",
      "=================================\n",
      "in 440 epoch, average loss: -35.249368286132814\n",
      "                , loss1: -6084.8859375\n",
      "                , loss2: 0.04297221302986145\n",
      "=================================\n",
      "in 450 epoch, average loss: -35.24943542480469\n",
      "                , loss1: -6084.6859375\n",
      "                , loss2: 0.041741886734962465\n",
      "=================================\n",
      "in 460 epoch, average loss: -35.25550537109375\n",
      "                , loss1: -6085.586328125\n",
      "                , loss2: 0.04089861512184143\n",
      "=================================\n",
      "in 470 epoch, average loss: -35.258950805664064\n",
      "                , loss1: -6086.51796875\n",
      "                , loss2: 0.04285326898097992\n",
      "=================================\n",
      "in 480 epoch, average loss: -35.2657470703125\n",
      "                , loss1: -6088.058203125\n",
      "                , loss2: 0.04499235153198242\n",
      "=================================\n",
      "in 490 epoch, average loss: -35.266903686523435\n",
      "                , loss1: -6088.01484375\n",
      "                , loss2: 0.04357887506484985\n",
      "=================================\n",
      "in 500 epoch, average loss: -35.275106811523436\n",
      "                , loss1: -6088.5984375\n",
      "                , loss2: 0.03876304626464844\n",
      "=================================\n",
      "in 510 epoch, average loss: -35.2791748046875\n",
      "                , loss1: -6089.04140625\n",
      "                , loss2: 0.03726434111595154\n",
      "=================================\n",
      "in 520 epoch, average loss: -35.28385620117187\n",
      "                , loss1: -6090.119140625\n",
      "                , loss2: 0.038839948177337644\n",
      "=================================\n",
      "in 530 epoch, average loss: -35.28736572265625\n",
      "                , loss1: -6089.2921875\n",
      "                , loss2: 0.030529880523681642\n",
      "=================================\n",
      "in 540 epoch, average loss: -35.28346557617188\n",
      "                , loss1: -6091.483203125\n",
      "                , loss2: 0.04713318943977356\n",
      "=================================\n",
      "in 550 epoch, average loss: -35.289605712890626\n",
      "                , loss1: -6091.648046875\n",
      "                , loss2: 0.04195356667041779\n",
      "=================================\n",
      "in 560 epoch, average loss: -35.29866943359375\n",
      "                , loss1: -6091.715625\n",
      "                , loss2: 0.03328369259834289\n",
      "=================================\n",
      "in 570 epoch, average loss: -35.30057373046875\n",
      "                , loss1: -6092.507421875\n",
      "                , loss2: 0.0359663724899292\n",
      "=================================\n",
      "in 580 epoch, average loss: -35.30791015625\n",
      "                , loss1: -6092.613671875\n",
      "                , loss2: 0.029252949357032775\n",
      "=================================\n",
      "in 590 epoch, average loss: -35.30910034179688\n",
      "                , loss1: -6094.076953125\n",
      "                , loss2: 0.03654741644859314\n",
      "=================================\n",
      "in 600 epoch, average loss: -35.31257934570313\n",
      "                , loss1: -6095.124609375\n",
      "                , loss2: 0.03914386034011841\n",
      "=================================\n",
      "in 610 epoch, average loss: -35.319338989257815\n",
      "                , loss1: -6094.894921875\n",
      "                , loss2: 0.03105289340019226\n",
      "=================================\n",
      "in 620 epoch, average loss: -35.31802062988281\n",
      "                , loss1: -6094.673046875\n",
      "                , loss2: 0.031081590056419372\n",
      "=================================\n",
      "in 630 epoch, average loss: -35.321676635742186\n",
      "                , loss1: -6096.84609375\n",
      "                , loss2: 0.040035417675971983\n",
      "=================================\n",
      "in 640 epoch, average loss: -35.32369384765625\n",
      "                , loss1: -6095.74453125\n",
      "                , loss2: 0.03162065744400024\n",
      "=================================\n",
      "in 650 epoch, average loss: -35.33204040527344\n",
      "                , loss1: -6097.469140625\n",
      "                , loss2: 0.03327918350696564\n",
      "=================================\n",
      "in 660 epoch, average loss: -35.332034301757815\n",
      "                , loss1: -6097.0234375\n",
      "                , loss2: 0.03069673776626587\n",
      "=================================\n",
      "in 670 epoch, average loss: -35.340911865234375\n",
      "                , loss1: -6097.11875\n",
      "                , loss2: 0.022375474870204925\n",
      "=================================\n",
      "in 680 epoch, average loss: -35.33933715820312\n",
      "                , loss1: -6098.5609375\n",
      "                , loss2: 0.03231365084648132\n",
      "=================================\n",
      "in 690 epoch, average loss: -35.34715881347656\n",
      "                , loss1: -6098.17265625\n",
      "                , loss2: 0.02224296033382416\n",
      "=================================\n",
      "in 700 epoch, average loss: -35.34535217285156\n",
      "                , loss1: -6100.435546875\n",
      "                , loss2: 0.037170854210853574\n",
      "=================================\n",
      "in 710 epoch, average loss: -35.34532470703125\n",
      "                , loss1: -6100.92734375\n",
      "                , loss2: 0.040058296918869016\n",
      "=================================\n",
      "in 720 epoch, average loss: -35.35649108886719\n",
      "                , loss1: -6100.53515625\n",
      "                , loss2: 0.026611709594726564\n",
      "=================================\n",
      "in 730 epoch, average loss: -35.362063598632815\n",
      "                , loss1: -6101.092578125\n",
      "                , loss2: 0.024276816844940187\n",
      "=================================\n",
      "in 740 epoch, average loss: -35.36667175292969\n",
      "                , loss1: -6100.37109375\n",
      "                , loss2: 0.015478567779064178\n",
      "=================================\n",
      "in 750 epoch, average loss: -35.362493896484374\n",
      "                , loss1: -6102.630859375\n",
      "                , loss2: 0.03276579976081848\n",
      "=================================\n",
      "in 760 epoch, average loss: -35.37234191894531\n",
      "                , loss1: -6101.69375\n",
      "                , loss2: 0.017479944229125976\n",
      "=================================\n",
      "in 770 epoch, average loss: -35.370932006835936\n",
      "                , loss1: -6104.45703125\n",
      "                , loss2: 0.03492152392864227\n",
      "=================================\n",
      "in 780 epoch, average loss: -35.369015502929685\n",
      "                , loss1: -6104.408203125\n",
      "                , loss2: 0.036548325419425966\n",
      "=================================\n",
      "in 790 epoch, average loss: -35.377401733398436\n",
      "                , loss1: -6103.938671875\n",
      "                , loss2: 0.02544592320919037\n",
      "=================================\n",
      "in 800 epoch, average loss: -35.3813720703125\n",
      "                , loss1: -6105.415625\n",
      "                , loss2: 0.030038994550704957\n",
      "=================================\n",
      "in 810 epoch, average loss: -35.38321228027344\n",
      "                , loss1: -6104.152734375\n",
      "                , loss2: 0.020873653888702392\n",
      "=================================\n",
      "in 820 epoch, average loss: -35.38223876953125\n",
      "                , loss1: -6105.670703125\n",
      "                , loss2: 0.030651181936264038\n",
      "=================================\n",
      "in 830 epoch, average loss: -35.38490600585938\n",
      "                , loss1: -6107.478125\n",
      "                , loss2: 0.03846681714057922\n",
      "=================================\n",
      "in 840 epoch, average loss: -35.39009094238281\n",
      "                , loss1: -6105.883984375\n",
      "                , loss2: 0.02403466999530792\n",
      "=================================\n",
      "in 850 epoch, average loss: -35.39258728027344\n",
      "                , loss1: -6107.025\n",
      "                , loss2: 0.02816189229488373\n",
      "=================================\n",
      "in 860 epoch, average loss: -35.398345947265625\n",
      "                , loss1: -6106.139453125\n",
      "                , loss2: 0.01726304888725281\n",
      "=================================\n",
      "in 870 epoch, average loss: -35.391543579101565\n",
      "                , loss1: -6107.65234375\n",
      "                , loss2: 0.032842743396759036\n",
      "=================================\n",
      "in 880 epoch, average loss: -35.392697143554685\n",
      "                , loss1: -6108.453125\n",
      "                , loss2: 0.03632849454879761\n",
      "=================================\n",
      "in 890 epoch, average loss: -35.39937744140625\n",
      "                , loss1: -6108.915625\n",
      "                , loss2: 0.032332542538642886\n",
      "=================================\n",
      "in 900 epoch, average loss: -35.39737243652344\n",
      "                , loss1: -6109.490625\n",
      "                , loss2: 0.03767247796058655\n",
      "=================================\n",
      "in 910 epoch, average loss: -35.394384765625\n",
      "                , loss1: -6111.27890625\n",
      "                , loss2: 0.05103250741958618\n",
      "=================================\n",
      "in 920 epoch, average loss: -35.40430603027344\n",
      "                , loss1: -6108.1796875\n",
      "                , loss2: 0.023136189579963683\n",
      "=================================\n",
      "in 930 epoch, average loss: -35.39582824707031\n",
      "                , loss1: -6112.64296875\n",
      "                , loss2: 0.05749962329864502\n",
      "=================================\n",
      "in 940 epoch, average loss: -35.40927734375\n",
      "                , loss1: -6109.7578125\n",
      "                , loss2: 0.027317124605178832\n",
      "=================================\n",
      "in 950 epoch, average loss: -35.413525390625\n",
      "                , loss1: -6111.503125\n",
      "                , loss2: 0.033192646503448484\n",
      "=================================\n",
      "in 960 epoch, average loss: -35.42036743164063\n",
      "                , loss1: -6110.184375\n",
      "                , loss2: 0.018698617815971375\n",
      "=================================\n",
      "in 970 epoch, average loss: -35.422552490234374\n",
      "                , loss1: -6111.527734375\n",
      "                , loss2: 0.02430506646633148\n",
      "=================================\n",
      "in 980 epoch, average loss: -35.422488403320315\n",
      "                , loss1: -6111.078125\n",
      "                , loss2: 0.021760791540145874\n",
      "=================================\n",
      "in 990 epoch, average loss: -35.424383544921874\n",
      "                , loss1: -6113.1796875\n",
      "                , loss2: 0.03205825388431549\n",
      "=================================\n",
      "in 1000 epoch, average loss: -35.42530212402344\n",
      "                , loss1: -6111.88046875\n",
      "                , loss2: 0.023606926202774048\n",
      "=================================\n",
      "in 1010 epoch, average loss: -35.424618530273435\n",
      "                , loss1: -6112.53046875\n",
      "                , loss2: 0.028056913614273073\n",
      "=================================\n",
      "in 1020 epoch, average loss: -35.42671508789063\n",
      "                , loss1: -6114.796875\n",
      "                , loss2: 0.03910500407218933\n",
      "=================================\n",
      "in 1030 epoch, average loss: -35.435733032226565\n",
      "                , loss1: -6112.56796875\n",
      "                , loss2: 0.017163801193237304\n",
      "=================================\n",
      "in 1040 epoch, average loss: -35.43717041015625\n",
      "                , loss1: -6113.8171875\n",
      "                , loss2: 0.022971437871456148\n",
      "=================================\n",
      "in 1050 epoch, average loss: -35.43509521484375\n",
      "                , loss1: -6113.386328125\n",
      "                , loss2: 0.022541968524456023\n",
      "=================================\n",
      "in 1060 epoch, average loss: -35.438272094726564\n",
      "                , loss1: -6115.117578125\n",
      "                , loss2: 0.02940804362297058\n",
      "=================================\n",
      "in 1070 epoch, average loss: -35.431646728515624\n",
      "                , loss1: -6115.027734375\n",
      "                , loss2: 0.03551308512687683\n",
      "=================================\n",
      "in 1080 epoch, average loss: -35.44386291503906\n",
      "                , loss1: -6113.565625\n",
      "                , loss2: 0.014816544950008392\n",
      "=================================\n",
      "in 1090 epoch, average loss: -35.44587707519531\n",
      "                , loss1: -6115.672265625\n",
      "                , loss2: 0.025026798248291016\n",
      "=================================\n",
      "in 1100 epoch, average loss: -35.44912414550781\n",
      "                , loss1: -6115.439453125\n",
      "                , loss2: 0.020422184467315675\n",
      "=================================\n",
      "in 1110 epoch, average loss: -35.43913879394531\n",
      "                , loss1: -6116.2078125\n",
      "                , loss2: 0.03486291766166687\n",
      "=================================\n",
      "in 1120 epoch, average loss: -35.449789428710936\n",
      "                , loss1: -6115.734375\n",
      "                , loss2: 0.021471379697322844\n",
      "=================================\n",
      "in 1130 epoch, average loss: -35.450924682617185\n",
      "                , loss1: -6116.56484375\n",
      "                , loss2: 0.025153514742851258\n",
      "=================================\n",
      "in 1140 epoch, average loss: -35.45338745117188\n",
      "                , loss1: -6116.187109375\n",
      "                , loss2: 0.020497044920921324\n",
      "=================================\n",
      "in 1150 epoch, average loss: -35.45817260742187\n",
      "                , loss1: -6116.30546875\n",
      "                , loss2: 0.01639905869960785\n",
      "=================================\n",
      "in 1160 epoch, average loss: -35.45387573242188\n",
      "                , loss1: -6118.636328125\n",
      "                , loss2: 0.034212926030159\n",
      "=================================\n",
      "in 1170 epoch, average loss: -35.46113586425781\n",
      "                , loss1: -6116.740234375\n",
      "                , loss2: 0.01595904529094696\n",
      "=================================\n",
      "in 1180 epoch, average loss: -35.460882568359374\n",
      "                , loss1: -6117.656640625\n",
      "                , loss2: 0.021522240340709688\n",
      "=================================\n",
      "in 1190 epoch, average loss: -35.45745849609375\n",
      "                , loss1: -6118.368359375\n",
      "                , loss2: 0.029078859090805053\n",
      "=================================\n",
      "in 1200 epoch, average loss: -35.466217041015625\n",
      "                , loss1: -6117.30390625\n",
      "                , loss2: 0.014147992432117461\n",
      "=================================\n",
      "in 1210 epoch, average loss: -35.47120361328125\n",
      "                , loss1: -6118.810546875\n",
      "                , loss2: 0.017902737855911253\n",
      "=================================\n",
      "in 1220 epoch, average loss: -35.46602783203125\n",
      "                , loss1: -6118.832421875\n",
      "                , loss2: 0.023201422393321992\n",
      "=================================\n",
      "in 1230 epoch, average loss: -35.47165222167969\n",
      "                , loss1: -6118.415234375\n",
      "                , loss2: 0.015159200131893157\n",
      "=================================\n",
      "in 1240 epoch, average loss: -35.47521057128906\n",
      "                , loss1: -6119.02109375\n",
      "                , loss2: 0.015116250514984131\n",
      "=================================\n",
      "in 1250 epoch, average loss: -35.47432250976563\n",
      "                , loss1: -6119.102734375\n",
      "                , loss2: 0.016472643613815306\n",
      "=================================\n",
      "in 1260 epoch, average loss: -35.47123413085937\n",
      "                , loss1: -6119.712890625\n",
      "                , loss2: 0.023101338744163515\n",
      "=================================\n",
      "in 1270 epoch, average loss: -35.47389526367188\n",
      "                , loss1: -6119.876171875\n",
      "                , loss2: 0.021386078000068663\n",
      "=================================\n",
      "in 1280 epoch, average loss: -35.47551574707031\n",
      "                , loss1: -6120.78515625\n",
      "                , loss2: 0.02503940463066101\n",
      "=================================\n",
      "in 1290 epoch, average loss: -35.47181396484375\n",
      "                , loss1: -6119.771875\n",
      "                , loss2: 0.022858443856239318\n",
      "=================================\n",
      "in 1300 epoch, average loss: -35.47736511230469\n",
      "                , loss1: -6122.0140625\n",
      "                , loss2: 0.03031766414642334\n",
      "=================================\n",
      "in 1310 epoch, average loss: -35.48030090332031\n",
      "                , loss1: -6120.755078125\n",
      "                , loss2: 0.020078782737255097\n",
      "=================================\n",
      "in 1320 epoch, average loss: -35.487954711914064\n",
      "                , loss1: -6120.478125\n",
      "                , loss2: 0.010816527158021927\n",
      "=================================\n",
      "in 1330 epoch, average loss: -35.481423950195314\n",
      "                , loss1: -6121.979296875\n",
      "                , loss2: 0.02605273425579071\n",
      "=================================\n",
      "in 1340 epoch, average loss: -35.489019775390624\n",
      "                , loss1: -6121.19609375\n",
      "                , loss2: 0.013916996121406556\n",
      "=================================\n",
      "in 1350 epoch, average loss: -35.4856689453125\n",
      "                , loss1: -6122.284765625\n",
      "                , loss2: 0.02358194887638092\n",
      "=================================\n",
      "in 1360 epoch, average loss: -35.48749694824219\n",
      "                , loss1: -6121.88125\n",
      "                , loss2: 0.019409456849098207\n",
      "=================================\n",
      "in 1370 epoch, average loss: -35.492984008789065\n",
      "                , loss1: -6121.66796875\n",
      "                , loss2: 0.012693631649017333\n",
      "=================================\n",
      "in 1380 epoch, average loss: -35.49094848632812\n",
      "                , loss1: -6122.159375\n",
      "                , loss2: 0.01757626235485077\n",
      "=================================\n",
      "in 1390 epoch, average loss: -35.48924560546875\n",
      "                , loss1: -6123.46015625\n",
      "                , loss2: 0.026821380853652953\n",
      "=================================\n",
      "in 1400 epoch, average loss: -35.4908447265625\n",
      "                , loss1: -6122.245703125\n",
      "                , loss2: 0.018180666863918303\n",
      "=================================\n",
      "in 1410 epoch, average loss: -35.49555358886719\n",
      "                , loss1: -6123.6671875\n",
      "                , loss2: 0.021716803312301636\n",
      "=================================\n",
      "in 1420 epoch, average loss: -35.49192810058594\n",
      "                , loss1: -6123.262109375\n",
      "                , loss2: 0.022990351915359496\n",
      "=================================\n",
      "in 1430 epoch, average loss: -35.495758056640625\n",
      "                , loss1: -6123.595703125\n",
      "                , loss2: 0.021090658009052278\n",
      "=================================\n",
      "in 1440 epoch, average loss: -35.50068359375\n",
      "                , loss1: -6123.553125\n",
      "                , loss2: 0.01592722237110138\n",
      "=================================\n",
      "in 1450 epoch, average loss: -35.504275512695315\n",
      "                , loss1: -6123.538671875\n",
      "                , loss2: 0.012251356244087219\n",
      "=================================\n",
      "in 1460 epoch, average loss: -35.502542114257814\n",
      "                , loss1: -6124.156640625\n",
      "                , loss2: 0.0175700381398201\n",
      "=================================\n",
      "in 1470 epoch, average loss: -35.50112609863281\n",
      "                , loss1: -6123.8328125\n",
      "                , loss2: 0.01710330694913864\n",
      "=================================\n",
      "in 1480 epoch, average loss: -35.50870361328125\n",
      "                , loss1: -6124.29765625\n",
      "                , loss2: 0.012223131209611892\n",
      "=================================\n",
      "in 1490 epoch, average loss: -35.505917358398435\n",
      "                , loss1: -6124.2890625\n",
      "                , loss2: 0.014960506558418274\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=4e-4, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(1500):\n",
    "    if hgnn_trainer.weight > 0.006:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - 0.0009\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2149"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([54., 55., 54., 55., 55., 54.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0030581039755351682"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
