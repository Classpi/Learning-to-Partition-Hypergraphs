{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) \n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "random.seed(seed) \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 3\n",
    "weight = 26\n",
    "limit = 0.3\n",
    "sub = 0.044\n",
    "lr = 4e-3\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers26\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers22\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers17\"] = {\"in_channels\": 327, \"out_channels\": 1024, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "\n",
    "# l_hyper_prmts[\"linerlayer13\"] = {\"in_channels\":1024, \"out_channels\":1024, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12334\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":256, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer121\"] = {\"in_channels\":256, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer1w2\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":32, \"out_channels\":3, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "  \n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss =  weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer1: torch.optim.Optimizer = optimizer\n",
    "        self.optimizer2: torch.optim.Optimizer = optimizer\n",
    "        self.convlayers = nn.ModuleList()\n",
    "        self.convlayers.append(net.to(DEVICE))\n",
    "        self.linearlayers = nn.ModuleList()\n",
    "        self.weight = 200\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.convlayers:\n",
    "            X = layer(X, self.hg)\n",
    "        for layer in self.linearlayers:\n",
    "            if isinstance(layer, nn.MultiheadAttention):\n",
    "                X,_ = layer(X, X, X)\n",
    "            else:\n",
    "                X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()\n",
    "        self.optimizer1.zero_grad()\n",
    "        self.optimizer2.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer1.step()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7818, 327)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/high\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.05, inplace=False)\n",
       "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.05, inplace=False)\n",
       "  (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU()\n",
       "  (10): Dropout(p=0.05, inplace=False)\n",
       "  (11): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): Dropout(p=0.05, inplace=False)\n",
       "  (15): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (16): ReLU()\n",
       "  (17): Dropout(p=0.05, inplace=False)\n",
       "  (18): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (19): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    if str.startswith(k,\"attn\"):\n",
    "        hgnn_trainer.linearlayers.append(nn.MultiheadAttention(embed_dim=v[\"in_channels\"], num_heads=2).to(DEVICE))\n",
    "    else:\n",
    "        hgnn_trainer.linearlayers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "        hgnn_trainer.linearlayers.append(nn.ReLU().to(DEVICE))\n",
    "        if v[\"drop_rate\"] > 0:\n",
    "            hgnn_trainer.linearlayers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "        hgnn_trainer.linearlayers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.linearlayers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: -1819.5630859375\n",
      "                , loss1: -70.12257080078125\n",
      "                , loss2: 0.5383008003234864\n",
      "                , loss2_weight: 25.956\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 10 epoch, average loss: -70997.00625\n",
      "                , loss1: -2824.479296875\n",
      "                , loss2: 1499.29736328125\n",
      "                , loss2_weight: 25.515999999999995\n",
      "=================================\n",
      "in 20 epoch, average loss: -153758.6375\n",
      "                , loss1: -6364.92265625\n",
      "                , loss2: 7025.240625\n",
      "                , loss2_weight: 25.07599999999999\n",
      "=================================\n",
      "in 30 epoch, average loss: -169656.6625\n",
      "                , loss1: -7203.8734375\n",
      "                , loss2: 9242.42578125\n",
      "                , loss2_weight: 24.635999999999985\n",
      "=================================\n",
      "in 40 epoch, average loss: -166816.4\n",
      "                , loss1: -7217.71953125\n",
      "                , loss2: 9252.640625\n",
      "                , loss2_weight: 24.19599999999998\n",
      "=================================\n",
      "in 50 epoch, average loss: -163647.05\n",
      "                , loss1: -7217.99609375\n",
      "                , loss2: 9252.8484375\n",
      "                , loss2_weight: 23.755999999999975\n",
      "=================================\n",
      "in 60 epoch, average loss: -160472.5\n",
      "                , loss1: -7218.06171875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 23.31599999999997\n",
      "=================================\n",
      "in 70 epoch, average loss: -157296.25\n",
      "                , loss1: -7218.04921875\n",
      "                , loss2: 9253.00625\n",
      "                , loss2_weight: 22.875999999999966\n",
      "=================================\n",
      "in 80 epoch, average loss: -154120.7\n",
      "                , loss1: -7218.065625\n",
      "                , loss2: 9253.00390625\n",
      "                , loss2_weight: 22.43599999999996\n",
      "=================================\n",
      "in 90 epoch, average loss: -150944.9625\n",
      "                , loss1: -7218.07578125\n",
      "                , loss2: 9253.00234375\n",
      "                , loss2_weight: 21.995999999999956\n",
      "=================================\n",
      "in 100 epoch, average loss: -147769.05\n",
      "                , loss1: -7218.07734375\n",
      "                , loss2: 9253.00234375\n",
      "                , loss2_weight: 21.55599999999995\n",
      "=================================\n",
      "in 110 epoch, average loss: -144592.9625\n",
      "                , loss1: -7218.0703125\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 21.115999999999946\n",
      "=================================\n",
      "in 120 epoch, average loss: -141417.025\n",
      "                , loss1: -7218.07109375\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 20.67599999999994\n",
      "=================================\n",
      "in 130 epoch, average loss: -138241.125\n",
      "                , loss1: -7218.07421875\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 20.235999999999937\n",
      "=================================\n",
      "in 140 epoch, average loss: -135065.2\n",
      "                , loss1: -7218.075\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 19.795999999999932\n",
      "=================================\n",
      "in 150 epoch, average loss: -131889.1\n",
      "                , loss1: -7218.06796875\n",
      "                , loss2: 9253.003125\n",
      "                , loss2_weight: 19.355999999999927\n",
      "=================================\n",
      "in 160 epoch, average loss: -128713.375\n",
      "                , loss1: -7218.0796875\n",
      "                , loss2: 9253.00234375\n",
      "                , loss2_weight: 18.915999999999922\n",
      "=================================\n",
      "in 170 epoch, average loss: -125537.375\n",
      "                , loss1: -7218.07734375\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 18.475999999999917\n",
      "=================================\n",
      "in 180 epoch, average loss: -122361.525\n",
      "                , loss1: -7218.0828125\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 18.035999999999913\n",
      "=================================\n",
      "in 190 epoch, average loss: -119185.4\n",
      "                , loss1: -7218.0734375\n",
      "                , loss2: 9253.00390625\n",
      "                , loss2_weight: 17.595999999999908\n",
      "=================================\n",
      "in 200 epoch, average loss: -116009.65\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 17.155999999999903\n",
      "=================================\n",
      "in 210 epoch, average loss: -112833.625\n",
      "                , loss1: -7218.08125\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 16.715999999999898\n",
      "=================================\n",
      "in 220 epoch, average loss: -109657.6625\n",
      "                , loss1: -7218.08046875\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 16.275999999999893\n",
      "=================================\n",
      "in 230 epoch, average loss: -106481.6125\n",
      "                , loss1: -7218.075\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 15.835999999999888\n",
      "=================================\n",
      "in 240 epoch, average loss: -103305.69375\n",
      "                , loss1: -7218.07734375\n",
      "                , loss2: 9253.003125\n",
      "                , loss2_weight: 15.395999999999884\n",
      "=================================\n",
      "in 250 epoch, average loss: -100129.7\n",
      "                , loss1: -7218.075\n",
      "                , loss2: 9253.00234375\n",
      "                , loss2_weight: 14.955999999999879\n",
      "=================================\n",
      "in 260 epoch, average loss: -96953.85625\n",
      "                , loss1: -7218.08125\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 14.515999999999874\n",
      "=================================\n",
      "in 270 epoch, average loss: -93777.925\n",
      "                , loss1: -7218.08359375\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 14.075999999999869\n",
      "=================================\n",
      "in 280 epoch, average loss: -90602.0625\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 13.635999999999864\n",
      "=================================\n",
      "in 290 epoch, average loss: -87426.0625\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 13.19599999999986\n",
      "=================================\n",
      "in 300 epoch, average loss: -84250.1\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 12.755999999999855\n",
      "=================================\n",
      "in 310 epoch, average loss: -81074.15625\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 12.31599999999985\n",
      "=================================\n",
      "in 320 epoch, average loss: -77898.2125\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 11.875999999999845\n",
      "=================================\n",
      "in 330 epoch, average loss: -74722.1625\n",
      "                , loss1: -7218.08203125\n",
      "                , loss2: 9253.00234375\n",
      "                , loss2_weight: 11.43599999999984\n",
      "=================================\n",
      "in 340 epoch, average loss: -71546.25625\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 10.995999999999835\n",
      "=================================\n",
      "in 350 epoch, average loss: -68370.35\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 10.55599999999983\n",
      "=================================\n",
      "in 360 epoch, average loss: -65194.33125\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 10.115999999999826\n",
      "=================================\n",
      "in 370 epoch, average loss: -62018.425\n",
      "                , loss1: -7218.08984375\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 9.67599999999982\n",
      "=================================\n",
      "in 380 epoch, average loss: -58842.44375\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 9.235999999999816\n",
      "=================================\n",
      "in 390 epoch, average loss: -55666.51875\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 8.795999999999811\n",
      "=================================\n",
      "in 400 epoch, average loss: -52490.43125\n",
      "                , loss1: -7218.07734375\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 8.355999999999806\n",
      "=================================\n",
      "in 410 epoch, average loss: -49314.540625\n",
      "                , loss1: -7218.084375\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 7.915999999999803\n",
      "=================================\n",
      "in 420 epoch, average loss: -46138.625\n",
      "                , loss1: -7218.08984375\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 7.475999999999807\n",
      "=================================\n",
      "in 430 epoch, average loss: -42962.7\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 7.035999999999811\n",
      "=================================\n",
      "in 440 epoch, average loss: -39786.703125\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 6.595999999999815\n",
      "=================================\n",
      "in 450 epoch, average loss: -36610.690625\n",
      "                , loss1: -7218.08203125\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 6.155999999999819\n",
      "=================================\n",
      "in 460 epoch, average loss: -33434.803125\n",
      "                , loss1: -7218.09296875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 5.7159999999998234\n",
      "=================================\n",
      "in 470 epoch, average loss: -30258.81875\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 5.2759999999998275\n",
      "=================================\n",
      "in 480 epoch, average loss: -27082.85625\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 4.8359999999998315\n",
      "=================================\n",
      "in 490 epoch, average loss: -23906.928125\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 4.395999999999836\n",
      "=================================\n",
      "in 500 epoch, average loss: -20730.93125\n",
      "                , loss1: -7218.08671875\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 3.9559999999998388\n",
      "=================================\n",
      "in 510 epoch, average loss: -17554.8515625\n",
      "                , loss1: -7218.053125\n",
      "                , loss2: 9253.0046875\n",
      "                , loss2_weight: 3.5159999999998384\n",
      "=================================\n",
      "in 520 epoch, average loss: -14378.9984375\n",
      "                , loss1: -7218.08203125\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 3.075999999999838\n",
      "=================================\n",
      "in 530 epoch, average loss: -11203.07109375\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 2.6359999999998376\n",
      "=================================\n",
      "in 540 epoch, average loss: -8027.1203125\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 2.195999999999837\n",
      "=================================\n",
      "in 550 epoch, average loss: -4851.158984375\n",
      "                , loss1: -7218.0953125\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 1.7559999999998368\n",
      "=================================\n",
      "in 560 epoch, average loss: -1675.1841796875\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 1.3159999999998364\n",
      "=================================\n",
      "in 570 epoch, average loss: 1500.7630859375\n",
      "                , loss1: -7218.09609375\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.875999999999836\n",
      "=================================\n",
      "in 580 epoch, average loss: 4676.7265625\n",
      "                , loss1: -7218.09296875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.43599999999983574\n",
      "=================================\n",
      "in 590 epoch, average loss: 7185.73515625\n",
      "                , loss1: -7218.09765625\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 600 epoch, average loss: 7376.29609375\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 610 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09765625\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 620 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.09296875\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 630 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 640 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 650 epoch, average loss: 7376.296875\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 660 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 670 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 680 epoch, average loss: 7376.3\n",
      "                , loss1: -7218.08359375\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 690 epoch, average loss: 7376.296875\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 700 epoch, average loss: 7376.29609375\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 710 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 720 epoch, average loss: 7376.29609375\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 730 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.09609375\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 740 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 750 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 760 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 770 epoch, average loss: 7376.29609375\n",
      "                , loss1: -7218.08671875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 780 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 790 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 800 epoch, average loss: 7376.2890625\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 810 epoch, average loss: 7376.29609375\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 820 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 830 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 840 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 850 epoch, average loss: 7376.2984375\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 860 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 870 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09609375\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 880 epoch, average loss: 7376.2984375\n",
      "                , loss1: -7218.08671875\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 890 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 900 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.0953125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 910 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.0953125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 920 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 930 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 940 epoch, average loss: 7376.2984375\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9253.0015625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 950 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 960 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 970 epoch, average loss: 7376.296875\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 980 epoch, average loss: 7376.296875\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9253.0\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 990 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1000 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1010 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1020 epoch, average loss: 7376.3\n",
      "                , loss1: -7218.08046875\n",
      "                , loss2: 9253.00078125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1030 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1040 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1050 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1060 epoch, average loss: 7376.2984375\n",
      "                , loss1: -7218.08359375\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1070 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.99609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1080 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.09296875\n",
      "                , loss2: 9252.99453125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1090 epoch, average loss: 7376.2890625\n",
      "                , loss1: -7218.09609375\n",
      "                , loss2: 9252.99453125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1100 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.99609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1110 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1120 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1130 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1140 epoch, average loss: 7376.28984375\n",
      "                , loss1: -7218.09921875\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1150 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1160 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.09375\n",
      "                , loss2: 9252.99609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1170 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.0953125\n",
      "                , loss2: 9252.9984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1180 epoch, average loss: 7376.28828125\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1190 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1200 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1210 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1220 epoch, average loss: 7376.28984375\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1230 epoch, average loss: 7376.29453125\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1240 epoch, average loss: 7376.2953125\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9252.99921875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1250 epoch, average loss: 7376.2921875\n",
      "                , loss1: -7218.090625\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1260 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1270 epoch, average loss: 7376.2875\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.990625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1280 epoch, average loss: 7376.28984375\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1290 epoch, average loss: 7376.290625\n",
      "                , loss1: -7218.0953125\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1300 epoch, average loss: 7376.29296875\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.996875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1310 epoch, average loss: 7376.29375\n",
      "                , loss1: -7218.0890625\n",
      "                , loss2: 9252.99765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1320 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.0921875\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1330 epoch, average loss: 7376.2890625\n",
      "                , loss1: -7218.09609375\n",
      "                , loss2: 9252.99453125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1340 epoch, average loss: 7376.3015625\n",
      "                , loss1: -7218.08203125\n",
      "                , loss2: 9253.003125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1350 epoch, average loss: 7376.28828125\n",
      "                , loss1: -7218.09453125\n",
      "                , loss2: 9252.99375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1360 epoch, average loss: 7376.28984375\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1370 epoch, average loss: 7376.29140625\n",
      "                , loss1: -7218.08828125\n",
      "                , loss2: 9252.9953125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1380 epoch, average loss: 7376.2890625\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1390 epoch, average loss: 7376.2890625\n",
      "                , loss1: -7218.09140625\n",
      "                , loss2: 9252.99296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1400 epoch, average loss: 7376.27109375\n",
      "                , loss1: -7218.0859375\n",
      "                , loss2: 9252.9734375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1410 epoch, average loss: 7376.2796875\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9252.98203125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1420 epoch, average loss: 7376.26640625\n",
      "                , loss1: -7218.0875\n",
      "                , loss2: 9252.96796875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1430 epoch, average loss: 7375.5796875\n",
      "                , loss1: -7217.540625\n",
      "                , loss2: 9252.13984375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1440 epoch, average loss: 7178.7890625\n",
      "                , loss1: -7158.1625\n",
      "                , loss2: 9039.9109375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1450 epoch, average loss: 7083.23515625\n",
      "                , loss1: -7148.571875\n",
      "                , loss2: 8941.8640625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1460 epoch, average loss: 7052.35\n",
      "                , loss1: -7149.63359375\n",
      "                , loss2: 8911.25546875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1470 epoch, average loss: 7047.88359375\n",
      "                , loss1: -7156.99375\n",
      "                , loss2: 8908.7015625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1480 epoch, average loss: 7047.7390625\n",
      "                , loss1: -7153.94765625\n",
      "                , loss2: 8907.765625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1490 epoch, average loss: 7045.47890625\n",
      "                , loss1: -7151.9421875\n",
      "                , loss2: 8904.98359375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1500 epoch, average loss: 7041.08515625\n",
      "                , loss1: -7142.22890625\n",
      "                , loss2: 8898.0640625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1510 epoch, average loss: 7023.7875\n",
      "                , loss1: -7121.80625\n",
      "                , loss2: 8875.45625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1520 epoch, average loss: 6981.55703125\n",
      "                , loss1: -7108.38984375\n",
      "                , loss2: 8829.73828125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1530 epoch, average loss: 5238.023828125\n",
      "                , loss1: -6845.36875\n",
      "                , loss2: 7017.8203125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1540 epoch, average loss: -80.93746337890624\n",
      "                , loss1: -6760.64140625\n",
      "                , loss2: 1676.829296875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1550 epoch, average loss: -1766.1765625\n",
      "                , loss1: -6849.5515625\n",
      "                , loss2: 14.706941223144531\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1560 epoch, average loss: -1818.4392578125\n",
      "                , loss1: -7105.7421875\n",
      "                , loss2: 29.0536865234375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1570 epoch, average loss: -1822.1458984375\n",
      "                , loss1: -7029.25859375\n",
      "                , loss2: 5.461390686035156\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1580 epoch, average loss: -1836.9650390625\n",
      "                , loss1: -7075.6484375\n",
      "                , loss2: 2.7032609939575196\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1590 epoch, average loss: -1844.2685546875\n",
      "                , loss1: -7102.66640625\n",
      "                , loss2: 2.4249191284179688\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1600 epoch, average loss: -1846.6056640625\n",
      "                , loss1: -7109.1734375\n",
      "                , loss2: 1.7792543411254882\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1610 epoch, average loss: -1849.769140625\n",
      "                , loss1: -7123.2328125\n",
      "                , loss2: 2.2712331771850587\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1620 epoch, average loss: -1852.07265625\n",
      "                , loss1: -7128.5375\n",
      "                , loss2: 1.3469660758972168\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1630 epoch, average loss: -1852.4091796875\n",
      "                , loss1: -7130.83359375\n",
      "                , loss2: 1.607491683959961\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1640 epoch, average loss: -1850.26953125\n",
      "                , loss1: -7123.1515625\n",
      "                , loss2: 1.7496963500976563\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1650 epoch, average loss: -1852.38359375\n",
      "                , loss1: -7129.984375\n",
      "                , loss2: 1.4123847961425782\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1660 epoch, average loss: -1854.16015625\n",
      "                , loss1: -7137.2984375\n",
      "                , loss2: 1.537244987487793\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1670 epoch, average loss: -1855.169140625\n",
      "                , loss1: -7139.9109375\n",
      "                , loss2: 1.2076115608215332\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1680 epoch, average loss: -1853.9501953125\n",
      "                , loss1: -7135.7828125\n",
      "                , loss2: 1.3533790588378907\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1690 epoch, average loss: -1855.362890625\n",
      "                , loss1: -7140.4\n",
      "                , loss2: 1.1409647941589356\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1700 epoch, average loss: -1854.9177734375\n",
      "                , loss1: -7139.16484375\n",
      "                , loss2: 1.264920711517334\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1710 epoch, average loss: -1855.5537109375\n",
      "                , loss1: -7140.91328125\n",
      "                , loss2: 1.0835061073303223\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1720 epoch, average loss: -1853.549609375\n",
      "                , loss1: -7135.196875\n",
      "                , loss2: 1.6014320373535156\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1730 epoch, average loss: -1854.91640625\n",
      "                , loss1: -7139.34921875\n",
      "                , loss2: 1.3144316673278809\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1740 epoch, average loss: -1855.74921875\n",
      "                , loss1: -7141.5359375\n",
      "                , loss2: 1.0500007629394532\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1750 epoch, average loss: -1855.9408203125\n",
      "                , loss1: -7142.5109375\n",
      "                , loss2: 1.1119986534118653\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1760 epoch, average loss: -1856.4123046875\n",
      "                , loss1: -7144.2328125\n",
      "                , loss2: 1.0884888648986817\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1770 epoch, average loss: -1856.1703125\n",
      "                , loss1: -7143.3796875\n",
      "                , loss2: 1.1081439971923828\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1780 epoch, average loss: -1856.1998046875\n",
      "                , loss1: -7143.4703125\n",
      "                , loss2: 1.102402114868164\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1790 epoch, average loss: -1855.56875\n",
      "                , loss1: -7141.27890625\n",
      "                , loss2: 1.1636530876159668\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1800 epoch, average loss: -1855.8208984375\n",
      "                , loss1: -7142.11796875\n",
      "                , loss2: 1.1296701431274414\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1810 epoch, average loss: -1856.35234375\n",
      "                , loss1: -7143.978125\n",
      "                , loss2: 1.082021141052246\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1820 epoch, average loss: -1856.2017578125\n",
      "                , loss1: -7143.83515625\n",
      "                , loss2: 1.1953932762145996\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1830 epoch, average loss: -1855.993359375\n",
      "                , loss1: -7142.671875\n",
      "                , loss2: 1.1013717651367188\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1840 epoch, average loss: -1856.5365234375\n",
      "                , loss1: -7144.646875\n",
      "                , loss2: 1.071767807006836\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1850 epoch, average loss: -1856.6431640625\n",
      "                , loss1: -7145.04453125\n",
      "                , loss2: 1.0686038970947265\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1860 epoch, average loss: -1856.016796875\n",
      "                , loss1: -7142.75390625\n",
      "                , loss2: 1.099270725250244\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1870 epoch, average loss: -1855.776953125\n",
      "                , loss1: -7141.96796875\n",
      "                , loss2: 1.1347672462463378\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1880 epoch, average loss: -1856.255078125\n",
      "                , loss1: -7143.79375\n",
      "                , loss2: 1.131456184387207\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1890 epoch, average loss: -1856.3802734375\n",
      "                , loss1: -7144.0671875\n",
      "                , loss2: 1.0771549224853516\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1900 epoch, average loss: -1856.87265625\n",
      "                , loss1: -7145.878125\n",
      "                , loss2: 1.0555217742919922\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1910 epoch, average loss: -1856.8185546875\n",
      "                , loss1: -7145.6484375\n",
      "                , loss2: 1.0496590614318848\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1920 epoch, average loss: -1856.615234375\n",
      "                , loss1: -7145.04296875\n",
      "                , loss2: 1.095956039428711\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1930 epoch, average loss: -1856.91015625\n",
      "                , loss1: -7145.90859375\n",
      "                , loss2: 1.026040267944336\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1940 epoch, average loss: -1855.82890625\n",
      "                , loss1: -7142.09296875\n",
      "                , loss2: 1.115116786956787\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1950 epoch, average loss: -1855.8466796875\n",
      "                , loss1: -7142.1375\n",
      "                , loss2: 1.1093477249145507\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1960 epoch, average loss: -1856.6947265625\n",
      "                , loss1: -7145.28125\n",
      "                , loss2: 1.0783926010131837\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1970 epoch, average loss: -1856.78203125\n",
      "                , loss1: -7145.5421875\n",
      "                , loss2: 1.0589911460876464\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1980 epoch, average loss: -1857.0822265625\n",
      "                , loss1: -7146.55390625\n",
      "                , loss2: 1.0214919090270995\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 1990 epoch, average loss: -1857.14453125\n",
      "                , loss1: -7146.76015625\n",
      "                , loss2: 1.012929630279541\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2000 epoch, average loss: -1857.0890625\n",
      "                , loss1: -7146.66484375\n",
      "                , loss2: 1.0438550949096679\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2010 epoch, average loss: -1856.88515625\n",
      "                , loss1: -7145.86875\n",
      "                , loss2: 1.040849781036377\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2020 epoch, average loss: -1856.95859375\n",
      "                , loss1: -7146.278125\n",
      "                , loss2: 1.0736330032348633\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2030 epoch, average loss: -1857.085546875\n",
      "                , loss1: -7146.65703125\n",
      "                , loss2: 1.0451954841613769\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2040 epoch, average loss: -1856.8494140625\n",
      "                , loss1: -7145.81796875\n",
      "                , loss2: 1.0633163452148438\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2050 epoch, average loss: -1856.99921875\n",
      "                , loss1: -7146.34375\n",
      "                , loss2: 1.0501476287841798\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2060 epoch, average loss: -1857.003515625\n",
      "                , loss1: -7146.28984375\n",
      "                , loss2: 1.031863307952881\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2070 epoch, average loss: -1857.116796875\n",
      "                , loss1: -7146.73671875\n",
      "                , loss2: 1.0347070693969727\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2080 epoch, average loss: -1857.127734375\n",
      "                , loss1: -7146.77421875\n",
      "                , loss2: 1.0336856842041016\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2090 epoch, average loss: -1856.914453125\n",
      "                , loss1: -7145.95234375\n",
      "                , loss2: 1.0332189559936524\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2100 epoch, average loss: -1857.292578125\n",
      "                , loss1: -7147.31796875\n",
      "                , loss2: 1.0100830078125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2110 epoch, average loss: -1857.1150390625\n",
      "                , loss1: -7146.7703125\n",
      "                , loss2: 1.045023250579834\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2120 epoch, average loss: -1857.1986328125\n",
      "                , loss1: -7147.03359375\n",
      "                , loss2: 1.029968547821045\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2130 epoch, average loss: -1857.04609375\n",
      "                , loss1: -7146.45703125\n",
      "                , loss2: 1.0326775550842284\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2140 epoch, average loss: -1856.6201171875\n",
      "                , loss1: -7144.93046875\n",
      "                , loss2: 1.0619545936584474\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2150 epoch, average loss: -1857.1126953125\n",
      "                , loss1: -7146.7078125\n",
      "                , loss2: 1.0311052322387695\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2160 epoch, average loss: -1857.076953125\n",
      "                , loss1: -7146.5734375\n",
      "                , loss2: 1.0321060180664063\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2170 epoch, average loss: -1856.7763671875\n",
      "                , loss1: -7145.4515625\n",
      "                , loss2: 1.0408710479736327\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2180 epoch, average loss: -1857.1369140625\n",
      "                , loss1: -7146.78828125\n",
      "                , loss2: 1.027857208251953\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2190 epoch, average loss: -1856.9125\n",
      "                , loss1: -7146.059375\n",
      "                , loss2: 1.0626700401306153\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2200 epoch, average loss: -1857.2431640625\n",
      "                , loss1: -7147.153125\n",
      "                , loss2: 1.016621208190918\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2210 epoch, average loss: -1857.048828125\n",
      "                , loss1: -7146.4890625\n",
      "                , loss2: 1.0381443977355957\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2220 epoch, average loss: -1857.182421875\n",
      "                , loss1: -7146.94765625\n",
      "                , loss2: 1.023831558227539\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2230 epoch, average loss: -1856.965234375\n",
      "                , loss1: -7146.24453125\n",
      "                , loss2: 1.0583740234375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2240 epoch, average loss: -1856.978515625\n",
      "                , loss1: -7146.2671875\n",
      "                , loss2: 1.0508188247680663\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2250 epoch, average loss: -1857.23515625\n",
      "                , loss1: -7147.1875\n",
      "                , loss2: 1.0335658073425293\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2260 epoch, average loss: -1857.3234375\n",
      "                , loss1: -7147.48046875\n",
      "                , loss2: 1.0213046073913574\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2270 epoch, average loss: -1857.0443359375\n",
      "                , loss1: -7146.51484375\n",
      "                , loss2: 1.0494285583496095\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2280 epoch, average loss: -1857.1484375\n",
      "                , loss1: -7146.7921875\n",
      "                , loss2: 1.0171666145324707\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2290 epoch, average loss: -1857.2986328125\n",
      "                , loss1: -7147.3375\n",
      "                , loss2: 1.0089651107788087\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2300 epoch, average loss: -1857.2265625\n",
      "                , loss1: -7147.10390625\n",
      "                , loss2: 1.020271110534668\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2310 epoch, average loss: -1857.2048828125\n",
      "                , loss1: -7147.05625\n",
      "                , loss2: 1.0295105934143067\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2320 epoch, average loss: -1857.347265625\n",
      "                , loss1: -7147.53828125\n",
      "                , loss2: 1.0127302169799806\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2330 epoch, average loss: -1857.3404296875\n",
      "                , loss1: -7147.52578125\n",
      "                , loss2: 1.0162818908691407\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2340 epoch, average loss: -1857.3404296875\n",
      "                , loss1: -7147.5078125\n",
      "                , loss2: 1.0115707397460938\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2350 epoch, average loss: -1857.3080078125\n",
      "                , loss1: -7147.41015625\n",
      "                , loss2: 1.0186185836791992\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2360 epoch, average loss: -1857.2240234375\n",
      "                , loss1: -7147.11484375\n",
      "                , loss2: 1.0256070137023925\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2370 epoch, average loss: -1857.157421875\n",
      "                , loss1: -7146.8734375\n",
      "                , loss2: 1.0298709869384766\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2380 epoch, average loss: -1857.280859375\n",
      "                , loss1: -7147.33671875\n",
      "                , loss2: 1.026625633239746\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2390 epoch, average loss: -1856.9447265625\n",
      "                , loss1: -7146.159375\n",
      "                , loss2: 1.0568438529968263\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2400 epoch, average loss: -1857.0392578125\n",
      "                , loss1: -7146.46796875\n",
      "                , loss2: 1.0421964645385742\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2410 epoch, average loss: -1857.3484375\n",
      "                , loss1: -7147.5453125\n",
      "                , loss2: 1.0132400512695312\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2420 epoch, average loss: -1857.3689453125\n",
      "                , loss1: -7147.5640625\n",
      "                , loss2: 0.9975978851318359\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2430 epoch, average loss: -1857.23046875\n",
      "                , loss1: -7147.1375\n",
      "                , loss2: 1.0251825332641602\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2440 epoch, average loss: -1857.0294921875\n",
      "                , loss1: -7146.4171875\n",
      "                , loss2: 1.0390371322631835\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2450 epoch, average loss: -1856.89375\n",
      "                , loss1: -7145.915625\n",
      "                , loss2: 1.044300365447998\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2460 epoch, average loss: -1857.27109375\n",
      "                , loss1: -7147.24375\n",
      "                , loss2: 1.0121280670166015\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2470 epoch, average loss: -1857.414453125\n",
      "                , loss1: -7147.775\n",
      "                , loss2: 1.0072737693786622\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2480 epoch, average loss: -1857.3322265625\n",
      "                , loss1: -7147.51015625\n",
      "                , loss2: 1.020294761657715\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2490 epoch, average loss: -1857.4513671875\n",
      "                , loss1: -7147.91171875\n",
      "                , loss2: 1.0057241439819335\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2500 epoch, average loss: -1857.383984375\n",
      "                , loss1: -7147.6265625\n",
      "                , loss2: 0.9987536430358886\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2510 epoch, average loss: -1857.4337890625\n",
      "                , loss1: -7147.7890625\n",
      "                , loss2: 0.9912897109985351\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2520 epoch, average loss: -1857.8134765625\n",
      "                , loss1: -7146.68359375\n",
      "                , loss2: 0.32409589290618895\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2530 epoch, average loss: -1856.636328125\n",
      "                , loss1: -7146.6109375\n",
      "                , loss2: 1.4824400901794434\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2540 epoch, average loss: -1854.090625\n",
      "                , loss1: -7157.11640625\n",
      "                , loss2: 6.7597412109375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2550 epoch, average loss: -1858.580859375\n",
      "                , loss1: -7152.23828125\n",
      "                , loss2: 1.001243495941162\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2560 epoch, average loss: -1859.2283203125\n",
      "                , loss1: -7154.8328125\n",
      "                , loss2: 1.0279945373535155\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2570 epoch, average loss: -1859.73046875\n",
      "                , loss1: -7156.74453125\n",
      "                , loss2: 1.0230847358703614\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2580 epoch, average loss: -1859.661328125\n",
      "                , loss1: -7156.51640625\n",
      "                , loss2: 1.0329764366149903\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2590 epoch, average loss: -1859.773828125\n",
      "                , loss1: -7156.771875\n",
      "                , loss2: 0.9866289138793946\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2600 epoch, average loss: -1859.64140625\n",
      "                , loss1: -7156.38359375\n",
      "                , loss2: 1.0184724807739258\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2610 epoch, average loss: -1859.718359375\n",
      "                , loss1: -7156.6625\n",
      "                , loss2: 1.013646125793457\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2620 epoch, average loss: -1859.8025390625\n",
      "                , loss1: -7156.9109375\n",
      "                , loss2: 0.9941824913024903\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2630 epoch, average loss: -1859.8783203125\n",
      "                , loss1: -7157.24921875\n",
      "                , loss2: 1.0065261840820312\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2640 epoch, average loss: -1859.666796875\n",
      "                , loss1: -7156.48125\n",
      "                , loss2: 1.0182482719421386\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2650 epoch, average loss: -1859.7890625\n",
      "                , loss1: -7156.91328125\n",
      "                , loss2: 1.0081398010253906\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2660 epoch, average loss: -1859.687109375\n",
      "                , loss1: -7156.590625\n",
      "                , loss2: 1.026340866088867\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2670 epoch, average loss: -1859.7021484375\n",
      "                , loss1: -7156.59609375\n",
      "                , loss2: 1.0125980377197266\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2680 epoch, average loss: -1859.7427734375\n",
      "                , loss1: -7156.73359375\n",
      "                , loss2: 1.0079476356506347\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2690 epoch, average loss: -1859.73203125\n",
      "                , loss1: -7156.71484375\n",
      "                , loss2: 1.0135634422302247\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2700 epoch, average loss: -1859.88046875\n",
      "                , loss1: -7157.2484375\n",
      "                , loss2: 1.0041669845581054\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2710 epoch, average loss: -1859.6951171875\n",
      "                , loss1: -7156.56171875\n",
      "                , loss2: 1.0108223915100099\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2720 epoch, average loss: -1859.719921875\n",
      "                , loss1: -7156.67890625\n",
      "                , loss2: 1.0164419174194337\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2730 epoch, average loss: -1859.70078125\n",
      "                , loss1: -7156.63125\n",
      "                , loss2: 1.0231261253356934\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2740 epoch, average loss: -1859.8173828125\n",
      "                , loss1: -7157.01328125\n",
      "                , loss2: 1.0060153007507324\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2750 epoch, average loss: -1859.8337890625\n",
      "                , loss1: -7157.06171875\n",
      "                , loss2: 1.0022625923156738\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2760 epoch, average loss: -1859.8349609375\n",
      "                , loss1: -7157.078125\n",
      "                , loss2: 1.0052356719970703\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2770 epoch, average loss: -1859.812109375\n",
      "                , loss1: -7157.009375\n",
      "                , loss2: 1.0101690292358398\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2780 epoch, average loss: -1859.90546875\n",
      "                , loss1: -7157.3234375\n",
      "                , loss2: 0.9987411499023438\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2790 epoch, average loss: -1859.81484375\n",
      "                , loss1: -7157.04765625\n",
      "                , loss2: 1.0173344612121582\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2800 epoch, average loss: -1859.835546875\n",
      "                , loss1: -7157.10546875\n",
      "                , loss2: 1.011873435974121\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2810 epoch, average loss: -1859.6974609375\n",
      "                , loss1: -7156.6078125\n",
      "                , loss2: 1.0203452110290527\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2820 epoch, average loss: -1859.88359375\n",
      "                , loss1: -7157.24609375\n",
      "                , loss2: 1.0003130912780762\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2830 epoch, average loss: -1859.42109375\n",
      "                , loss1: -7155.578125\n",
      "                , loss2: 1.029129981994629\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2840 epoch, average loss: -1859.8326171875\n",
      "                , loss1: -7157.07109375\n",
      "                , loss2: 1.0054255485534669\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2850 epoch, average loss: -1859.8693359375\n",
      "                , loss1: -7157.215625\n",
      "                , loss2: 1.0067164421081543\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2860 epoch, average loss: -1859.844140625\n",
      "                , loss1: -7157.09921875\n",
      "                , loss2: 1.001537036895752\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2870 epoch, average loss: -1859.8404296875\n",
      "                , loss1: -7157.10546875\n",
      "                , loss2: 1.006931686401367\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2880 epoch, average loss: -1859.8283203125\n",
      "                , loss1: -7157.08671875\n",
      "                , loss2: 1.0140052795410157\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2890 epoch, average loss: -1859.5341796875\n",
      "                , loss1: -7156.02421875\n",
      "                , loss2: 1.0318620681762696\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2900 epoch, average loss: -1859.8876953125\n",
      "                , loss1: -7157.271875\n",
      "                , loss2: 1.002903652191162\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2910 epoch, average loss: -1859.869140625\n",
      "                , loss1: -7157.203125\n",
      "                , loss2: 1.0035737037658692\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2920 epoch, average loss: -1859.8017578125\n",
      "                , loss1: -7156.9859375\n",
      "                , loss2: 1.0144808769226075\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2930 epoch, average loss: -1859.85625\n",
      "                , loss1: -7157.146875\n",
      "                , loss2: 1.002065658569336\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2940 epoch, average loss: -1859.8201171875\n",
      "                , loss1: -7157.04140625\n",
      "                , loss2: 1.0107436180114746\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2950 epoch, average loss: -1859.7576171875\n",
      "                , loss1: -7156.821875\n",
      "                , loss2: 1.0160134315490723\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2960 epoch, average loss: -1859.749609375\n",
      "                , loss1: -7156.7828125\n",
      "                , loss2: 1.013761615753174\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2970 epoch, average loss: -1859.8349609375\n",
      "                , loss1: -7157.0828125\n",
      "                , loss2: 1.0062520980834961\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2980 epoch, average loss: -1859.846484375\n",
      "                , loss1: -7157.1328125\n",
      "                , loss2: 1.0079541206359863\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 2990 epoch, average loss: -1859.82265625\n",
      "                , loss1: -7157.03671875\n",
      "                , loss2: 1.006888198852539\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3000 epoch, average loss: -1859.773828125\n",
      "                , loss1: -7156.87109375\n",
      "                , loss2: 1.0125407218933105\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3010 epoch, average loss: -1859.66484375\n",
      "                , loss1: -7156.47890625\n",
      "                , loss2: 1.0195345878601074\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3020 epoch, average loss: -1859.903515625\n",
      "                , loss1: -7157.334375\n",
      "                , loss2: 1.0033495903015137\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3030 epoch, average loss: -1859.7265625\n",
      "                , loss1: -7156.7015625\n",
      "                , loss2: 1.0157281875610351\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3040 epoch, average loss: -1859.8568359375\n",
      "                , loss1: -7157.18046875\n",
      "                , loss2: 1.0100742340087892\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3050 epoch, average loss: -1859.71875\n",
      "                , loss1: -7156.63671875\n",
      "                , loss2: 1.0065852165222169\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3060 epoch, average loss: -1859.8263671875\n",
      "                , loss1: -7157.0546875\n",
      "                , loss2: 1.0075506210327148\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3070 epoch, average loss: -1859.915625\n",
      "                , loss1: -7157.371875\n",
      "                , loss2: 1.0009756088256836\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3080 epoch, average loss: -1859.871875\n",
      "                , loss1: -7157.2140625\n",
      "                , loss2: 1.0036102294921876\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3090 epoch, average loss: -1859.6345703125\n",
      "                , loss1: -7156.35546875\n",
      "                , loss2: 1.0176966667175293\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3100 epoch, average loss: -1859.784765625\n",
      "                , loss1: -7156.9078125\n",
      "                , loss2: 1.0110119819641112\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3110 epoch, average loss: -1859.8646484375\n",
      "                , loss1: -7157.1890625\n",
      "                , loss2: 1.0044135093688964\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3120 epoch, average loss: -1859.8513671875\n",
      "                , loss1: -7157.09375\n",
      "                , loss2: 0.9928791999816895\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3130 epoch, average loss: -1859.7103515625\n",
      "                , loss1: -7156.70390625\n",
      "                , loss2: 1.032572078704834\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3140 epoch, average loss: -1859.8818359375\n",
      "                , loss1: -7157.2671875\n",
      "                , loss2: 1.0076141357421875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3150 epoch, average loss: -1859.827734375\n",
      "                , loss1: -7157.053125\n",
      "                , loss2: 1.0059550285339356\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3160 epoch, average loss: -1859.9060546875\n",
      "                , loss1: -7157.315625\n",
      "                , loss2: 0.9959808349609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3170 epoch, average loss: -1859.8556640625\n",
      "                , loss1: -7157.1953125\n",
      "                , loss2: 1.0148798942565918\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3180 epoch, average loss: -1859.8275390625\n",
      "                , loss1: -7157.07734375\n",
      "                , loss2: 1.012448215484619\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3190 epoch, average loss: -1859.81796875\n",
      "                , loss1: -7157.05078125\n",
      "                , loss2: 1.015130615234375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3200 epoch, average loss: -1859.894140625\n",
      "                , loss1: -7157.34921875\n",
      "                , loss2: 1.0164532661437988\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3210 epoch, average loss: -1859.8837890625\n",
      "                , loss1: -7157.26484375\n",
      "                , loss2: 1.0050898551940919\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3220 epoch, average loss: -1859.910546875\n",
      "                , loss1: -7157.39375\n",
      "                , loss2: 1.011874008178711\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3230 epoch, average loss: -1859.759375\n",
      "                , loss1: -7156.83203125\n",
      "                , loss2: 1.0167220115661622\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3240 epoch, average loss: -1859.8837890625\n",
      "                , loss1: -7157.25625\n",
      "                , loss2: 1.0029437065124511\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3250 epoch, average loss: -1859.91796875\n",
      "                , loss1: -7157.3921875\n",
      "                , loss2: 1.0038348197937013\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3260 epoch, average loss: -1859.83359375\n",
      "                , loss1: -7157.11796875\n",
      "                , loss2: 1.0168792724609375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3270 epoch, average loss: -1859.871484375\n",
      "                , loss1: -7157.23671875\n",
      "                , loss2: 1.009922409057617\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3280 epoch, average loss: -1859.917578125\n",
      "                , loss1: -7157.40078125\n",
      "                , loss2: 1.0066290855407716\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3290 epoch, average loss: -1859.7212890625\n",
      "                , loss1: -7156.66875\n",
      "                , loss2: 1.0122251510620117\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3300 epoch, average loss: -1859.8880859375\n",
      "                , loss1: -7157.27265625\n",
      "                , loss2: 1.002877902984619\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3310 epoch, average loss: -1859.69921875\n",
      "                , loss1: -7156.60078125\n",
      "                , loss2: 1.0169103622436524\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3320 epoch, average loss: -1859.9220703125\n",
      "                , loss1: -7157.40625\n",
      "                , loss2: 1.0032535552978517\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3330 epoch, average loss: -1859.8880859375\n",
      "                , loss1: -7157.27265625\n",
      "                , loss2: 1.0029440879821778\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3340 epoch, average loss: -1859.9232421875\n",
      "                , loss1: -7157.4015625\n",
      "                , loss2: 1.0011577606201172\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3350 epoch, average loss: -1859.798046875\n",
      "                , loss1: -7156.965625\n",
      "                , loss2: 1.0130085945129395\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3360 epoch, average loss: -1859.8958984375\n",
      "                , loss1: -7157.30625\n",
      "                , loss2: 1.0036190032958985\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3370 epoch, average loss: -1859.92578125\n",
      "                , loss1: -7157.4109375\n",
      "                , loss2: 1.0009970664978027\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3380 epoch, average loss: -1859.9021484375\n",
      "                , loss1: -7157.328125\n",
      "                , loss2: 1.0031916618347168\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3390 epoch, average loss: -1859.91953125\n",
      "                , loss1: -7157.3921875\n",
      "                , loss2: 1.0024270057678222\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3400 epoch, average loss: -1859.885546875\n",
      "                , loss1: -7157.2625\n",
      "                , loss2: 1.002705955505371\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3410 epoch, average loss: -1859.8890625\n",
      "                , loss1: -7157.28125\n",
      "                , loss2: 1.003812313079834\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3420 epoch, average loss: -1859.81875\n",
      "                , loss1: -7157.03203125\n",
      "                , loss2: 1.009379005432129\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3430 epoch, average loss: -1859.83984375\n",
      "                , loss1: -7157.10078125\n",
      "                , loss2: 1.0062565803527832\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3440 epoch, average loss: -1859.869921875\n",
      "                , loss1: -7157.21484375\n",
      "                , loss2: 1.0057759284973145\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3450 epoch, average loss: -1859.816015625\n",
      "                , loss1: -7157.0296875\n",
      "                , loss2: 1.0116081237792969\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3460 epoch, average loss: -1859.9091796875\n",
      "                , loss1: -7157.3609375\n",
      "                , loss2: 1.0046271324157714\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3470 epoch, average loss: -1859.898828125\n",
      "                , loss1: -7157.325\n",
      "                , loss2: 1.005643939971924\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3480 epoch, average loss: -1859.8984375\n",
      "                , loss1: -7157.30546875\n",
      "                , loss2: 1.0007908821105957\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3490 epoch, average loss: -1859.9009765625\n",
      "                , loss1: -7157.32265625\n",
      "                , loss2: 1.002798080444336\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3500 epoch, average loss: -1859.8830078125\n",
      "                , loss1: -7157.284375\n",
      "                , loss2: 1.0106760025024415\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3510 epoch, average loss: -1859.86171875\n",
      "                , loss1: -7157.190625\n",
      "                , loss2: 1.0078924179077149\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3520 epoch, average loss: -1859.7298828125\n",
      "                , loss1: -7156.68984375\n",
      "                , loss2: 1.0091599464416503\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3530 epoch, average loss: -1859.9078125\n",
      "                , loss1: -7157.34765625\n",
      "                , loss2: 1.0026216506958008\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3540 epoch, average loss: -1859.927734375\n",
      "                , loss1: -7157.421875\n",
      "                , loss2: 1.0019326210021973\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3550 epoch, average loss: -1859.8794921875\n",
      "                , loss1: -7157.2515625\n",
      "                , loss2: 1.0060171127319335\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3560 epoch, average loss: -1859.9326171875\n",
      "                , loss1: -7157.4375\n",
      "                , loss2: 1.001123046875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3570 epoch, average loss: -1859.9125\n",
      "                , loss1: -7157.36015625\n",
      "                , loss2: 1.0011798858642578\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3580 epoch, average loss: -1859.9044921875\n",
      "                , loss1: -7157.3375\n",
      "                , loss2: 1.003076171875\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3590 epoch, average loss: -1859.9181640625\n",
      "                , loss1: -7157.3796875\n",
      "                , loss2: 1.0004368782043458\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3600 epoch, average loss: -1859.9048828125\n",
      "                , loss1: -7157.34375\n",
      "                , loss2: 1.004258155822754\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3610 epoch, average loss: -1859.9\n",
      "                , loss1: -7157.3265625\n",
      "                , loss2: 1.0046218872070312\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3620 epoch, average loss: -1859.91953125\n",
      "                , loss1: -7157.3828125\n",
      "                , loss2: 0.9999112129211426\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3630 epoch, average loss: -1859.9138671875\n",
      "                , loss1: -7157.36953125\n",
      "                , loss2: 1.0022462844848632\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3640 epoch, average loss: -1859.907421875\n",
      "                , loss1: -7157.3578125\n",
      "                , loss2: 1.0054508209228517\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3650 epoch, average loss: -1859.9375\n",
      "                , loss1: -7157.45625\n",
      "                , loss2: 1.0011234283447266\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3660 epoch, average loss: -1859.9083984375\n",
      "                , loss1: -7157.3484375\n",
      "                , loss2: 1.0019634246826172\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3670 epoch, average loss: -1859.8638671875\n",
      "                , loss1: -7157.196875\n",
      "                , loss2: 1.0074209213256835\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3680 epoch, average loss: -1859.8759765625\n",
      "                , loss1: -7157.2359375\n",
      "                , loss2: 1.0054688453674316\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3690 epoch, average loss: -1859.82890625\n",
      "                , loss1: -7157.1375\n",
      "                , loss2: 1.0266156196594238\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3700 epoch, average loss: -1859.89453125\n",
      "                , loss1: -7157.2984375\n",
      "                , loss2: 1.0030914306640626\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3710 epoch, average loss: -1859.9337890625\n",
      "                , loss1: -7157.44296875\n",
      "                , loss2: 1.001182746887207\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3720 epoch, average loss: -1859.8236328125\n",
      "                , loss1: -7157.0546875\n",
      "                , loss2: 1.0104853630065918\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3730 epoch, average loss: -1859.945703125\n",
      "                , loss1: -7157.4828125\n",
      "                , loss2: 1.000082015991211\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3740 epoch, average loss: -1859.8498046875\n",
      "                , loss1: -7157.125\n",
      "                , loss2: 1.002548885345459\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3750 epoch, average loss: -1859.926953125\n",
      "                , loss1: -7157.42890625\n",
      "                , loss2: 1.0046488761901855\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3760 epoch, average loss: -1859.9193359375\n",
      "                , loss1: -7157.3890625\n",
      "                , loss2: 1.001685333251953\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3770 epoch, average loss: -1859.8380859375\n",
      "                , loss1: -7157.0875\n",
      "                , loss2: 1.0045610427856446\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3780 epoch, average loss: -1859.9248046875\n",
      "                , loss1: -7157.41484375\n",
      "                , loss2: 1.002921962738037\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3790 epoch, average loss: -1859.94140625\n",
      "                , loss1: -7157.4703125\n",
      "                , loss2: 1.0005932807922364\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3800 epoch, average loss: -1859.8455078125\n",
      "                , loss1: -7157.1390625\n",
      "                , loss2: 1.0102543830871582\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3810 epoch, average loss: -1859.91875\n",
      "                , loss1: -7157.390625\n",
      "                , loss2: 1.0028260231018067\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3820 epoch, average loss: -1859.9181640625\n",
      "                , loss1: -7157.384375\n",
      "                , loss2: 1.001713180541992\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3830 epoch, average loss: -1859.9505859375\n",
      "                , loss1: -7157.50234375\n",
      "                , loss2: 1.0000269889831543\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3840 epoch, average loss: -1859.9328125\n",
      "                , loss1: -7157.43671875\n",
      "                , loss2: 1.0006425857543946\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3850 epoch, average loss: -1859.8923828125\n",
      "                , loss1: -7157.290625\n",
      "                , loss2: 1.0031344413757324\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3860 epoch, average loss: -1859.8384765625\n",
      "                , loss1: -7157.0984375\n",
      "                , loss2: 1.0071172714233398\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3870 epoch, average loss: -1859.9322265625\n",
      "                , loss1: -7157.434375\n",
      "                , loss2: 1.000533390045166\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3880 epoch, average loss: -1859.9357421875\n",
      "                , loss1: -7157.45078125\n",
      "                , loss2: 1.0012448310852051\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3890 epoch, average loss: -1859.93828125\n",
      "                , loss1: -7157.4609375\n",
      "                , loss2: 1.001447582244873\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3900 epoch, average loss: -1859.942578125\n",
      "                , loss1: -7157.47734375\n",
      "                , loss2: 1.00166654586792\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3910 epoch, average loss: -1859.8978515625\n",
      "                , loss1: -7157.31328125\n",
      "                , loss2: 1.0033531188964844\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3920 epoch, average loss: -1859.9345703125\n",
      "                , loss1: -7157.44921875\n",
      "                , loss2: 1.0023565292358398\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3930 epoch, average loss: -1859.915625\n",
      "                , loss1: -7157.3765625\n",
      "                , loss2: 1.0023035049438476\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3940 epoch, average loss: -1859.94296875\n",
      "                , loss1: -7157.47734375\n",
      "                , loss2: 1.0011050224304199\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3950 epoch, average loss: -1859.803515625\n",
      "                , loss1: -7157.0015625\n",
      "                , loss2: 1.0168378829956055\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3960 epoch, average loss: -1859.91640625\n",
      "                , loss1: -7157.378125\n",
      "                , loss2: 1.001848316192627\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3970 epoch, average loss: -1859.9431640625\n",
      "                , loss1: -7157.490625\n",
      "                , loss2: 1.0039551734924317\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3980 epoch, average loss: -1859.9392578125\n",
      "                , loss1: -7157.4640625\n",
      "                , loss2: 1.001291847229004\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 3990 epoch, average loss: -1859.9400390625\n",
      "                , loss1: -7157.4671875\n",
      "                , loss2: 1.0013687133789062\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4000 epoch, average loss: -1859.8552734375\n",
      "                , loss1: -7157.178125\n",
      "                , loss2: 1.0108096122741699\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4010 epoch, average loss: -1859.9470703125\n",
      "                , loss1: -7157.49296875\n",
      "                , loss2: 1.000920581817627\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4020 epoch, average loss: -1859.746875\n",
      "                , loss1: -7156.81015625\n",
      "                , loss2: 1.023688793182373\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4030 epoch, average loss: -1859.8744140625\n",
      "                , loss1: -7157.2390625\n",
      "                , loss2: 1.007791805267334\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4040 epoch, average loss: -1859.808203125\n",
      "                , loss1: -7156.9921875\n",
      "                , loss2: 1.0097753524780273\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4050 epoch, average loss: -1859.89375\n",
      "                , loss1: -7157.296875\n",
      "                , loss2: 1.0032115936279298\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4060 epoch, average loss: -1859.9388671875\n",
      "                , loss1: -7157.4578125\n",
      "                , loss2: 1.0001959800720215\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4070 epoch, average loss: -1859.9322265625\n",
      "                , loss1: -7157.440625\n",
      "                , loss2: 1.0021069526672364\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4080 epoch, average loss: -1859.928515625\n",
      "                , loss1: -7157.4296875\n",
      "                , loss2: 1.003277587890625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4090 epoch, average loss: -1859.851171875\n",
      "                , loss1: -7157.14375\n",
      "                , loss2: 1.0061145782470704\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4100 epoch, average loss: -1859.919140625\n",
      "                , loss1: -7157.390625\n",
      "                , loss2: 1.0027707099914551\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4110 epoch, average loss: -1859.871875\n",
      "                , loss1: -7157.23984375\n",
      "                , loss2: 1.0103607177734375\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4120 epoch, average loss: -1859.946484375\n",
      "                , loss1: -7157.4953125\n",
      "                , loss2: 1.0021959304809571\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4130 epoch, average loss: -1859.941796875\n",
      "                , loss1: -7157.47734375\n",
      "                , loss2: 1.0024565696716308\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4140 epoch, average loss: -1859.939453125\n",
      "                , loss1: -7157.46640625\n",
      "                , loss2: 1.0016569137573241\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4150 epoch, average loss: -1859.951171875\n",
      "                , loss1: -7157.50703125\n",
      "                , loss2: 1.0007878303527833\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4160 epoch, average loss: -1859.93828125\n",
      "                , loss1: -7157.4625\n",
      "                , loss2: 1.0018918991088868\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4170 epoch, average loss: -1859.9462890625\n",
      "                , loss1: -7157.4890625\n",
      "                , loss2: 1.0008703231811524\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4180 epoch, average loss: -1859.9283203125\n",
      "                , loss1: -7157.42265625\n",
      "                , loss2: 1.0012947082519532\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4190 epoch, average loss: -1859.9470703125\n",
      "                , loss1: -7157.49140625\n",
      "                , loss2: 1.0007160186767579\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4200 epoch, average loss: -1859.924609375\n",
      "                , loss1: -7157.41875\n",
      "                , loss2: 1.0041285514831544\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4210 epoch, average loss: -1859.9546875\n",
      "                , loss1: -7157.52109375\n",
      "                , loss2: 1.0004768371582031\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4220 epoch, average loss: -1859.948828125\n",
      "                , loss1: -7157.49609375\n",
      "                , loss2: 1.000239658355713\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4230 epoch, average loss: -1859.9013671875\n",
      "                , loss1: -7157.3265625\n",
      "                , loss2: 1.0035997390747071\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4240 epoch, average loss: -1859.948828125\n",
      "                , loss1: -7157.5015625\n",
      "                , loss2: 1.001314926147461\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4250 epoch, average loss: -1859.951171875\n",
      "                , loss1: -7157.50703125\n",
      "                , loss2: 1.000593090057373\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4260 epoch, average loss: -1859.875390625\n",
      "                , loss1: -7157.23828125\n",
      "                , loss2: 1.006295871734619\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4270 epoch, average loss: -1859.856640625\n",
      "                , loss1: -7157.159375\n",
      "                , loss2: 1.0046977043151855\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4280 epoch, average loss: -1859.86015625\n",
      "                , loss1: -7157.175\n",
      "                , loss2: 1.005192470550537\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4290 epoch, average loss: -1859.8390625\n",
      "                , loss1: -7157.11015625\n",
      "                , loss2: 1.00933837890625\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4300 epoch, average loss: -1859.943359375\n",
      "                , loss1: -7157.47890625\n",
      "                , loss2: 1.001091480255127\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4310 epoch, average loss: -1859.533984375\n",
      "                , loss1: -7156.04296875\n",
      "                , loss2: 1.0373751640319824\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4320 epoch, average loss: -1859.8982421875\n",
      "                , loss1: -7157.3296875\n",
      "                , loss2: 1.0072282791137694\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4330 epoch, average loss: -1859.9189453125\n",
      "                , loss1: -7157.39375\n",
      "                , loss2: 1.0034123420715333\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4340 epoch, average loss: -1859.9435546875\n",
      "                , loss1: -7157.48125\n",
      "                , loss2: 1.0013158798217774\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4350 epoch, average loss: -1859.898046875\n",
      "                , loss1: -7157.31953125\n",
      "                , loss2: 1.0049436569213868\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4360 epoch, average loss: -1859.930859375\n",
      "                , loss1: -7157.43125\n",
      "                , loss2: 1.0008973121643066\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4370 epoch, average loss: -1859.9583984375\n",
      "                , loss1: -7157.5359375\n",
      "                , loss2: 1.0007954597473145\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4380 epoch, average loss: -1859.9265625\n",
      "                , loss1: -7157.43125\n",
      "                , loss2: 1.0054434776306151\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4390 epoch, average loss: -1859.8974609375\n",
      "                , loss1: -7157.3203125\n",
      "                , loss2: 1.0056588172912597\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4400 epoch, average loss: -1859.9078125\n",
      "                , loss1: -7157.353125\n",
      "                , loss2: 1.0038837432861327\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4410 epoch, average loss: -1859.9076171875\n",
      "                , loss1: -7157.3515625\n",
      "                , loss2: 1.0037405967712403\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4420 epoch, average loss: -1859.960546875\n",
      "                , loss1: -7157.5421875\n",
      "                , loss2: 1.0003372192382813\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4430 epoch, average loss: -1859.9416015625\n",
      "                , loss1: -7157.4734375\n",
      "                , loss2: 1.0012556076049806\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4440 epoch, average loss: -1859.9544921875\n",
      "                , loss1: -7157.51875\n",
      "                , loss2: 1.0001060485839843\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4450 epoch, average loss: -1859.9623046875\n",
      "                , loss1: -7157.5453125\n",
      "                , loss2: 0.9994583129882812\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4460 epoch, average loss: -1859.94765625\n",
      "                , loss1: -7157.50078125\n",
      "                , loss2: 1.0025409698486327\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4470 epoch, average loss: -1859.9642578125\n",
      "                , loss1: -7157.5546875\n",
      "                , loss2: 0.999884033203125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4480 epoch, average loss: -1859.94921875\n",
      "                , loss1: -7157.5140625\n",
      "                , loss2: 1.0045028686523438\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4490 epoch, average loss: -1859.9095703125\n",
      "                , loss1: -7157.3984375\n",
      "                , loss2: 1.0137800216674804\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4500 epoch, average loss: -1859.856640625\n",
      "                , loss1: -7157.1671875\n",
      "                , loss2: 1.0068572998046874\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4510 epoch, average loss: -1859.896484375\n",
      "                , loss1: -7157.33828125\n",
      "                , loss2: 1.0113595008850098\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4520 epoch, average loss: -1859.942578125\n",
      "                , loss1: -7157.47421875\n",
      "                , loss2: 1.0007291793823243\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4530 epoch, average loss: -1859.904296875\n",
      "                , loss1: -7157.3421875\n",
      "                , loss2: 1.0046231269836425\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4540 epoch, average loss: -1859.9390625\n",
      "                , loss1: -7157.46328125\n",
      "                , loss2: 1.001298427581787\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4550 epoch, average loss: -1859.956640625\n",
      "                , loss1: -7157.5265625\n",
      "                , loss2: 1.0001148223876952\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4560 epoch, average loss: -1859.940234375\n",
      "                , loss1: -7157.46640625\n",
      "                , loss2: 1.001112461090088\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4570 epoch, average loss: -1859.9130859375\n",
      "                , loss1: -7157.36953125\n",
      "                , loss2: 1.0029712677001954\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4580 epoch, average loss: -1859.954296875\n",
      "                , loss1: -7157.5171875\n",
      "                , loss2: 1.0003475189208983\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4590 epoch, average loss: -1859.9578125\n",
      "                , loss1: -7157.53046875\n",
      "                , loss2: 1.000112819671631\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4600 epoch, average loss: -1859.9515625\n",
      "                , loss1: -7157.51171875\n",
      "                , loss2: 1.0011026382446289\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4610 epoch, average loss: -1859.9548828125\n",
      "                , loss1: -7157.521875\n",
      "                , loss2: 1.0009862899780273\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4620 epoch, average loss: -1859.9541015625\n",
      "                , loss1: -7157.5203125\n",
      "                , loss2: 1.0009801864624024\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4630 epoch, average loss: -1859.9408203125\n",
      "                , loss1: -7157.475\n",
      "                , loss2: 1.0027085304260255\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4640 epoch, average loss: -1859.9154296875\n",
      "                , loss1: -7157.3796875\n",
      "                , loss2: 1.0033159255981445\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4650 epoch, average loss: -1859.9423828125\n",
      "                , loss1: -7157.475\n",
      "                , loss2: 1.0010621070861816\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4660 epoch, average loss: -1859.90703125\n",
      "                , loss1: -7157.3453125\n",
      "                , loss2: 1.0028564453125\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n",
      "in 4670 epoch, average loss: -1859.95703125\n",
      "                , loss1: -7157.53125\n",
      "                , loss2: 1.0010679244995118\n",
      "                , loss2_weight: 0.2599999999998358\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      8\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 9\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[17], line 38\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer2\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 38\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m, in \u001b[0;36mTrainer.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvlayers:\n\u001b[0;32m---> 26\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearlayers:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, nn\u001b[38;5;241m.\u001b[39mMultiheadAttention):\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/Hyper-Graph-Partition/examples/../hgp/models.py:174\u001b[0m, in \u001b[0;36mHGNNP.forward\u001b[0;34m(self, X, hg)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The forward function.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    ``X`` (``torch.Tensor``): Input vertex feature matrix. Size :math:`(N, C_{in})`.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    ``hg`` (``dhg.Hypergraph``): The hypergraph structure that contains :math:`N` vertices.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 174\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/dhg/nn/convs/hypergraphs/hgnnp_conv.py:62\u001b[0m, in \u001b[0;36mHGNNPConv.forward\u001b[0;34m(self, X, hg)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The forward function.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    X (``torch.Tensor``): Input vertex feature matrix. Size :math:`(|\\mathcal{V}|, C_{in})`.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    hg (``dhg.Hypergraph``): The hypergraph structure that contains :math:`|\\mathcal{V}|` vertices.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta(X)\n\u001b[0;32m---> 62\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv2v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_last:\n\u001b[1;32m     64\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(X)\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/dhg/structure/hypergraphs/hypergraph.py:1657\u001b[0m, in \u001b[0;36mHypergraph.v2v\u001b[0;34m(self, X, aggr, drop_rate, v2e_aggr, v2e_weight, v2e_drop_rate, e_weight, e2v_aggr, e2v_weight, e2v_drop_rate)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     e2v_drop_rate \u001b[38;5;241m=\u001b[39m drop_rate\n\u001b[1;32m   1656\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv2e(X, v2e_aggr, v2e_weight, e_weight, drop_rate\u001b[38;5;241m=\u001b[39mv2e_drop_rate)\n\u001b[0;32m-> 1657\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me2v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me2v_aggr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me2v_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me2v_drop_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/dhg/structure/hypergraphs/hypergraph.py:1595\u001b[0m, in \u001b[0;36mHypergraph.e2v\u001b[0;34m(self, X, aggr, e2v_weight, drop_rate)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21me2v\u001b[39m(\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor, aggr: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, e2v_weight: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, drop_rate: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m   1586\u001b[0m ):\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Message passing of ``hyperedges to vertices``. The combination of ``e2v_aggregation`` and ``e2v_update``.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m \n\u001b[1;32m   1589\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;124;03m        ``drop_rate`` (``float``): Dropout rate. Randomly dropout the connections in incidence matrix with probability ``drop_rate``. Default: ``0.0``.\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1595\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me2v_aggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me2v_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1596\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me2v_update(X)\n\u001b[1;32m   1597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/dhg/structure/hypergraphs/hypergraph.py:1466\u001b[0m, in \u001b[0;36mHypergraph.e2v_aggregation\u001b[0;34m(self, X, aggr, e2v_weight, drop_rate)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     P \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1466\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_v_neg_1, X)\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m aggr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.convlayers.parameters(), lr=lr, weight_decay=5e-8)\n",
    "optim2 = optim.Adam(hgnn_trainer.linearlayers.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer1 = optim1\n",
    "hgnn_trainer.optimizer2 = optim2\n",
    "for epoch in range(20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , loss2_weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([108., 110., 109.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0061162079510703364"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
