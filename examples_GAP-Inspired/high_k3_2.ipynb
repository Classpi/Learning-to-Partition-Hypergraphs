{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycq/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 3\n",
    "weight = 20\n",
    "limit = 0.3\n",
    "sub = 0.044\n",
    "lr = 4e-3\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers26\"] = {\"in_channels\": 327, \"out_channels\": 327, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers17\"] = {\"in_channels\": 327, \"out_channels\": 1024, \"use_bn\": True, \"drop_rate\": 0.05}\n",
    "\n",
    "# l_hyper_prmts[\"linerlayer13\"] = {\"in_channels\":1024, \"out_channels\":1024, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12334\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":256, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "# l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer121\"] = {\"in_channels\":256, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer1w2\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":32, \"out_channels\":3, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss =  weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer1: torch.optim.Optimizer = optimizer\n",
    "        self.optimizer2: torch.optim.Optimizer = optimizer\n",
    "        self.convlayers = nn.ModuleList()\n",
    "        self.convlayers.append(net.to(DEVICE))\n",
    "        self.linearlayers = nn.ModuleList()\n",
    "        self.weight = 200\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.convlayers:\n",
    "            X = layer(X, self.hg)\n",
    "        for layer in self.linearlayers:\n",
    "            if isinstance(layer, nn.MultiheadAttention):\n",
    "                X,_ = layer(X, X, X)\n",
    "            else:\n",
    "                X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()\n",
    "        self.optimizer1.zero_grad()\n",
    "        self.optimizer2.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer1.step()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7818, 327)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/high\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.05, inplace=False)\n",
       "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.05, inplace=False)\n",
       "  (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU()\n",
       "  (10): Dropout(p=0.05, inplace=False)\n",
       "  (11): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): Dropout(p=0.05, inplace=False)\n",
       "  (15): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (16): ReLU()\n",
       "  (17): Dropout(p=0.05, inplace=False)\n",
       "  (18): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (19): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    if str.startswith(k,\"attn\"):\n",
    "        hgnn_trainer.linearlayers.append(nn.MultiheadAttention(embed_dim=v[\"in_channels\"], num_heads=2).to(DEVICE))\n",
    "    else:\n",
    "        hgnn_trainer.linearlayers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "        hgnn_trainer.linearlayers.append(nn.ReLU().to(DEVICE))\n",
    "        if v[\"drop_rate\"] > 0:\n",
    "            hgnn_trainer.linearlayers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "        hgnn_trainer.linearlayers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.linearlayers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: -1396.66025390625\n",
      "                , loss1: -70.0277099609375\n",
      "                , loss2: 0.8127427101135254\n",
      "                , loss2_weight: 19.956\n",
      "=================================\n",
      "in 10 epoch, average loss: -59861.16875\n",
      "                , loss1: -3147.7966796875\n",
      "                , loss2: 2033.936328125\n",
      "                , loss2_weight: 19.515999999999995\n",
      "=================================\n",
      "in 20 epoch, average loss: -96475.325\n",
      "                , loss1: -5263.15078125\n",
      "                , loss2: 4926.898046875\n",
      "                , loss2_weight: 19.07599999999999\n",
      "=================================\n",
      "in 30 epoch, average loss: -123371.6\n",
      "                , loss1: -7016.74375\n",
      "                , loss2: 8759.121875\n",
      "                , loss2_weight: 18.635999999999985\n",
      "=================================\n",
      "in 40 epoch, average loss: -125063.625\n",
      "                , loss1: -7295.4859375\n",
      "                , loss2: 9127.875\n",
      "                , loss2_weight: 18.19599999999998\n",
      "=================================\n",
      "in 50 epoch, average loss: -122158.5125\n",
      "                , loss1: -7313.5390625\n",
      "                , loss2: 9148.7\n",
      "                , loss2_weight: 17.755999999999975\n",
      "=================================\n",
      "in 60 epoch, average loss: -118949.4125\n",
      "                , loss1: -7314.08828125\n",
      "                , loss2: 9149.54140625\n",
      "                , loss2_weight: 17.31599999999997\n",
      "=================================\n",
      "in 70 epoch, average loss: -115743.2125\n",
      "                , loss1: -7314.840625\n",
      "                , loss2: 9150.3703125\n",
      "                , loss2_weight: 16.875999999999966\n",
      "=================================\n",
      "in 80 epoch, average loss: -112526.3875\n",
      "                , loss1: -7314.95390625\n",
      "                , loss2: 9150.559375\n",
      "                , loss2_weight: 16.43599999999996\n",
      "=================================\n",
      "in 90 epoch, average loss: -109307.8\n",
      "                , loss1: -7314.94765625\n",
      "                , loss2: 9150.465625\n",
      "                , loss2_weight: 15.995999999999956\n",
      "=================================\n",
      "in 100 epoch, average loss: -106090.45\n",
      "                , loss1: -7315.0375\n",
      "                , loss2: 9150.6640625\n",
      "                , loss2_weight: 15.555999999999951\n",
      "=================================\n",
      "in 110 epoch, average loss: -102871.6875\n",
      "                , loss1: -7315.02734375\n",
      "                , loss2: 9150.63125\n",
      "                , loss2_weight: 15.115999999999946\n",
      "=================================\n",
      "in 120 epoch, average loss: -99652.75\n",
      "                , loss1: -7315.0\n",
      "                , loss2: 9150.5796875\n",
      "                , loss2_weight: 14.675999999999942\n",
      "=================================\n",
      "in 130 epoch, average loss: -96433.5875\n",
      "                , loss1: -7314.9640625\n",
      "                , loss2: 9150.63125\n",
      "                , loss2_weight: 14.235999999999937\n",
      "=================================\n",
      "in 140 epoch, average loss: -93217.49375\n",
      "                , loss1: -7315.153125\n",
      "                , loss2: 9150.7625\n",
      "                , loss2_weight: 13.795999999999932\n",
      "=================================\n",
      "in 150 epoch, average loss: -89998.3625\n",
      "                , loss1: -7315.11796875\n",
      "                , loss2: 9150.746875\n",
      "                , loss2_weight: 13.355999999999927\n",
      "=================================\n",
      "in 160 epoch, average loss: -86778.53125\n",
      "                , loss1: -7315.02421875\n",
      "                , loss2: 9150.6875\n",
      "                , loss2_weight: 12.915999999999922\n",
      "=================================\n",
      "in 170 epoch, average loss: -83561.81875\n",
      "                , loss1: -7315.18359375\n",
      "                , loss2: 9150.80859375\n",
      "                , loss2_weight: 12.475999999999917\n",
      "=================================\n",
      "in 180 epoch, average loss: -80343.3125\n",
      "                , loss1: -7315.196875\n",
      "                , loss2: 9150.803125\n",
      "                , loss2_weight: 12.035999999999913\n",
      "=================================\n",
      "in 190 epoch, average loss: -77123.8875\n",
      "                , loss1: -7315.13125\n",
      "                , loss2: 9150.76796875\n",
      "                , loss2_weight: 11.595999999999908\n",
      "=================================\n",
      "in 200 epoch, average loss: -73905.8\n",
      "                , loss1: -7315.18359375\n",
      "                , loss2: 9150.8046875\n",
      "                , loss2_weight: 11.155999999999903\n",
      "=================================\n",
      "in 210 epoch, average loss: -70687.1\n",
      "                , loss1: -7315.184375\n",
      "                , loss2: 9150.81953125\n",
      "                , loss2_weight: 10.715999999999898\n",
      "=================================\n",
      "in 220 epoch, average loss: -67467.69375\n",
      "                , loss1: -7315.1125\n",
      "                , loss2: 9150.77890625\n",
      "                , loss2_weight: 10.275999999999893\n",
      "=================================\n",
      "in 230 epoch, average loss: -64250.2\n",
      "                , loss1: -7315.234375\n",
      "                , loss2: 9150.8546875\n",
      "                , loss2_weight: 9.835999999999888\n",
      "=================================\n",
      "in 240 epoch, average loss: -61031.2625\n",
      "                , loss1: -7315.20859375\n",
      "                , loss2: 9150.83671875\n",
      "                , loss2_weight: 9.395999999999884\n",
      "=================================\n",
      "in 250 epoch, average loss: -57811.675\n",
      "                , loss1: -7315.10703125\n",
      "                , loss2: 9150.809375\n",
      "                , loss2_weight: 8.955999999999879\n",
      "=================================\n",
      "in 260 epoch, average loss: -54592.65\n",
      "                , loss1: -7315.05546875\n",
      "                , loss2: 9150.76953125\n",
      "                , loss2_weight: 8.515999999999874\n",
      "=================================\n",
      "in 270 epoch, average loss: -51375.334375\n",
      "                , loss1: -7315.22421875\n",
      "                , loss2: 9150.8390625\n",
      "                , loss2_weight: 8.075999999999869\n",
      "=================================\n",
      "in 280 epoch, average loss: -48156.73125\n",
      "                , loss1: -7315.240625\n",
      "                , loss2: 9150.86640625\n",
      "                , loss2_weight: 7.635999999999872\n",
      "=================================\n",
      "in 290 epoch, average loss: -44938.075\n",
      "                , loss1: -7315.25\n",
      "                , loss2: 9150.8796875\n",
      "                , loss2_weight: 7.195999999999876\n",
      "=================================\n",
      "in 300 epoch, average loss: -41719.3875\n",
      "                , loss1: -7315.25078125\n",
      "                , loss2: 9150.875\n",
      "                , loss2_weight: 6.75599999999988\n",
      "=================================\n",
      "in 310 epoch, average loss: -38500.46875\n",
      "                , loss1: -7315.21484375\n",
      "                , loss2: 9150.84375\n",
      "                , loss2_weight: 6.315999999999884\n",
      "=================================\n",
      "in 320 epoch, average loss: -35282.003125\n",
      "                , loss1: -7315.259375\n",
      "                , loss2: 9150.88046875\n",
      "                , loss2_weight: 5.875999999999888\n",
      "=================================\n",
      "in 330 epoch, average loss: -32063.021875\n",
      "                , loss1: -7315.20625\n",
      "                , loss2: 9150.8484375\n",
      "                , loss2_weight: 5.4359999999998925\n",
      "=================================\n",
      "in 340 epoch, average loss: -28844.075\n",
      "                , loss1: -7315.14453125\n",
      "                , loss2: 9150.803125\n",
      "                , loss2_weight: 4.9959999999998965\n",
      "=================================\n",
      "in 350 epoch, average loss: -25625.975\n",
      "                , loss1: -7315.28515625\n",
      "                , loss2: 9150.89375\n",
      "                , loss2_weight: 4.555999999999901\n",
      "=================================\n",
      "in 360 epoch, average loss: -22407.171875\n",
      "                , loss1: -7315.26796875\n",
      "                , loss2: 9150.89140625\n",
      "                , loss2_weight: 4.115999999999905\n",
      "=================================\n",
      "in 370 epoch, average loss: -19188.4984375\n",
      "                , loss1: -7315.28046875\n",
      "                , loss2: 9150.896875\n",
      "                , loss2_weight: 3.675999999999905\n",
      "=================================\n",
      "in 380 epoch, average loss: -15969.5890625\n",
      "                , loss1: -7315.2140625\n",
      "                , loss2: 9150.85234375\n",
      "                , loss2_weight: 3.2359999999999047\n",
      "=================================\n",
      "in 390 epoch, average loss: -12750.97109375\n",
      "                , loss1: -7315.240625\n",
      "                , loss2: 9150.85859375\n",
      "                , loss2_weight: 2.7959999999999043\n",
      "=================================\n",
      "in 400 epoch, average loss: -9527.44609375\n",
      "                , loss1: -7313.2171875\n",
      "                , loss2: 9150.2078125\n",
      "                , loss2_weight: 2.355999999999904\n",
      "=================================\n",
      "in 410 epoch, average loss: -6313.566796875\n",
      "                , loss1: -7315.2453125\n",
      "                , loss2: 9150.86484375\n",
      "                , loss2_weight: 1.9159999999999036\n",
      "=================================\n",
      "in 420 epoch, average loss: -3094.878515625\n",
      "                , loss1: -7315.278125\n",
      "                , loss2: 9150.89375\n",
      "                , loss2_weight: 1.4759999999999032\n",
      "=================================\n",
      "in 430 epoch, average loss: 123.835205078125\n",
      "                , loss1: -7315.2890625\n",
      "                , loss2: 9150.903125\n",
      "                , loss2_weight: 1.0359999999999028\n",
      "=================================\n",
      "in 440 epoch, average loss: 3342.557421875\n",
      "                , loss1: -7315.2421875\n",
      "                , loss2: 9150.86171875\n",
      "                , loss2_weight: 0.5959999999999024\n",
      "=================================\n",
      "in 450 epoch, average loss: 6368.13125\n",
      "                , loss1: -7315.18125\n",
      "                , loss2: 9150.8171875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 460 epoch, average loss: 7044.06640625\n",
      "                , loss1: -7315.19921875\n",
      "                , loss2: 9150.84453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 470 epoch, average loss: 7044.06171875\n",
      "                , loss1: -7315.17890625\n",
      "                , loss2: 9150.83359375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 480 epoch, average loss: 7044.07109375\n",
      "                , loss1: -7315.17890625\n",
      "                , loss2: 9150.84296875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 490 epoch, average loss: 7044.084375\n",
      "                , loss1: -7315.25625\n",
      "                , loss2: 9150.878125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 500 epoch, average loss: 7044.096875\n",
      "                , loss1: -7315.271875\n",
      "                , loss2: 9150.8953125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 510 epoch, average loss: 7044.1\n",
      "                , loss1: -7315.29140625\n",
      "                , loss2: 9150.90390625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 520 epoch, average loss: 7044.0703125\n",
      "                , loss1: -7315.178125\n",
      "                , loss2: 9150.840625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 530 epoch, average loss: 7044.05234375\n",
      "                , loss1: -7315.13046875\n",
      "                , loss2: 9150.81015625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 540 epoch, average loss: 7044.0734375\n",
      "                , loss1: -7315.23203125\n",
      "                , loss2: 9150.86015625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 550 epoch, average loss: 7044.07890625\n",
      "                , loss1: -7315.08671875\n",
      "                , loss2: 9150.82421875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 560 epoch, average loss: 7044.09453125\n",
      "                , loss1: -7315.284375\n",
      "                , loss2: 9150.89609375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 570 epoch, average loss: 7044.0890625\n",
      "                , loss1: -7315.28125\n",
      "                , loss2: 9150.88984375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 580 epoch, average loss: 7044.09765625\n",
      "                , loss1: -7315.28984375\n",
      "                , loss2: 9150.90078125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 590 epoch, average loss: 7044.07890625\n",
      "                , loss1: -7315.25546875\n",
      "                , loss2: 9150.87265625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 600 epoch, average loss: 7044.0796875\n",
      "                , loss1: -7315.23359375\n",
      "                , loss2: 9150.86796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 610 epoch, average loss: 7044.07265625\n",
      "                , loss1: -7315.1375\n",
      "                , loss2: 9150.83203125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 620 epoch, average loss: 7044.075\n",
      "                , loss1: -7315.2609375\n",
      "                , loss2: 9150.86953125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 630 epoch, average loss: 7044.08046875\n",
      "                , loss1: -7315.2453125\n",
      "                , loss2: 9150.87109375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 640 epoch, average loss: 7044.06953125\n",
      "                , loss1: -7315.2\n",
      "                , loss2: 9150.84765625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 650 epoch, average loss: 7044.0359375\n",
      "                , loss1: -7315.1859375\n",
      "                , loss2: 9150.809375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 660 epoch, average loss: 7044.071875\n",
      "                , loss1: -7315.23984375\n",
      "                , loss2: 9150.859375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 670 epoch, average loss: 7044.0578125\n",
      "                , loss1: -7315.2015625\n",
      "                , loss2: 9150.8359375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 680 epoch, average loss: 7044.0890625\n",
      "                , loss1: -7315.27890625\n",
      "                , loss2: 9150.8890625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 690 epoch, average loss: 7044.0671875\n",
      "                , loss1: -7315.20078125\n",
      "                , loss2: 9150.8453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 700 epoch, average loss: 7044.04765625\n",
      "                , loss1: -7315.221875\n",
      "                , loss2: 9150.83125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 710 epoch, average loss: 7044.0546875\n",
      "                , loss1: -7315.22421875\n",
      "                , loss2: 9150.8390625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 720 epoch, average loss: 7044.04765625\n",
      "                , loss1: -7315.1765625\n",
      "                , loss2: 9150.81875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 730 epoch, average loss: 7044.08359375\n",
      "                , loss1: -7315.2703125\n",
      "                , loss2: 9150.88046875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 740 epoch, average loss: 7044.07578125\n",
      "                , loss1: -7315.27421875\n",
      "                , loss2: 9150.87421875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 750 epoch, average loss: 7044.08359375\n",
      "                , loss1: -7315.26953125\n",
      "                , loss2: 9150.88125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 760 epoch, average loss: 7044.04453125\n",
      "                , loss1: -7315.215625\n",
      "                , loss2: 9150.8265625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 770 epoch, average loss: 7044.07890625\n",
      "                , loss1: -7315.259375\n",
      "                , loss2: 9150.8734375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 780 epoch, average loss: 7044.0671875\n",
      "                , loss1: -7315.1046875\n",
      "                , loss2: 9150.8171875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 790 epoch, average loss: 7044.0109375\n",
      "                , loss1: -7315.18046875\n",
      "                , loss2: 9150.78203125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 800 epoch, average loss: 7044.07109375\n",
      "                , loss1: -7315.221875\n",
      "                , loss2: 9150.8546875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 810 epoch, average loss: 7044.08125\n",
      "                , loss1: -7315.28046875\n",
      "                , loss2: 9150.88125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 820 epoch, average loss: 7044.06015625\n",
      "                , loss1: -7315.234375\n",
      "                , loss2: 9150.84765625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 830 epoch, average loss: 7044.06875\n",
      "                , loss1: -7315.259375\n",
      "                , loss2: 9150.86328125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 840 epoch, average loss: 7044.03671875\n",
      "                , loss1: -7315.18984375\n",
      "                , loss2: 9150.8125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 850 epoch, average loss: 7044.0671875\n",
      "                , loss1: -7315.24609375\n",
      "                , loss2: 9150.8578125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 860 epoch, average loss: 7044.0765625\n",
      "                , loss1: -7315.2625\n",
      "                , loss2: 9150.87265625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 870 epoch, average loss: 7044.059375\n",
      "                , loss1: -7315.165625\n",
      "                , loss2: 9150.8265625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 880 epoch, average loss: 7044.0578125\n",
      "                , loss1: -7315.23359375\n",
      "                , loss2: 9150.8453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 890 epoch, average loss: 7044.0515625\n",
      "                , loss1: -7315.22734375\n",
      "                , loss2: 9150.83671875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 900 epoch, average loss: 7044.0296875\n",
      "                , loss1: -7315.103125\n",
      "                , loss2: 9150.7796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 910 epoch, average loss: 7044.0453125\n",
      "                , loss1: -7315.23046875\n",
      "                , loss2: 9150.83203125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 920 epoch, average loss: 7044.03359375\n",
      "                , loss1: -7315.21953125\n",
      "                , loss2: 9150.81640625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 930 epoch, average loss: 7044.053125\n",
      "                , loss1: -7315.24609375\n",
      "                , loss2: 9150.84453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 940 epoch, average loss: 7044.00859375\n",
      "                , loss1: -7315.1765625\n",
      "                , loss2: 9150.77890625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 950 epoch, average loss: 7044.02578125\n",
      "                , loss1: -7315.20390625\n",
      "                , loss2: 9150.80390625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 960 epoch, average loss: 7044.0484375\n",
      "                , loss1: -7315.2359375\n",
      "                , loss2: 9150.8375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 970 epoch, average loss: 7044.05625\n",
      "                , loss1: -7315.25078125\n",
      "                , loss2: 9150.84765625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 980 epoch, average loss: 7044.04609375\n",
      "                , loss1: -7315.25703125\n",
      "                , loss2: 9150.83984375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 990 epoch, average loss: 7044.01953125\n",
      "                , loss1: -7315.21640625\n",
      "                , loss2: 9150.80234375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1000 epoch, average loss: 7044.0109375\n",
      "                , loss1: -7315.2203125\n",
      "                , loss2: 9150.79453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1010 epoch, average loss: 7044.0046875\n",
      "                , loss1: -7315.071875\n",
      "                , loss2: 9150.7453125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1020 epoch, average loss: 7044.00390625\n",
      "                , loss1: -7315.2015625\n",
      "                , loss2: 9150.78125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1030 epoch, average loss: 7044.01484375\n",
      "                , loss1: -7315.21171875\n",
      "                , loss2: 9150.796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1040 epoch, average loss: 7044.00625\n",
      "                , loss1: -7315.18515625\n",
      "                , loss2: 9150.7796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1050 epoch, average loss: 7044.05703125\n",
      "                , loss1: -7315.2671875\n",
      "                , loss2: 9150.85390625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1060 epoch, average loss: 7044.03828125\n",
      "                , loss1: -7315.22421875\n",
      "                , loss2: 9150.821875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1070 epoch, average loss: 7044.03359375\n",
      "                , loss1: -7315.23046875\n",
      "                , loss2: 9150.8203125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1080 epoch, average loss: 7044.0\n",
      "                , loss1: -7315.23046875\n",
      "                , loss2: 9150.7859375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1090 epoch, average loss: 7044.01875\n",
      "                , loss1: -7315.15\n",
      "                , loss2: 9150.78203125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1100 epoch, average loss: 7044.00234375\n",
      "                , loss1: -7315.2\n",
      "                , loss2: 9150.7796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1110 epoch, average loss: 7043.975\n",
      "                , loss1: -7315.1109375\n",
      "                , loss2: 9150.728125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1120 epoch, average loss: 7044.0\n",
      "                , loss1: -7315.16953125\n",
      "                , loss2: 9150.76875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1130 epoch, average loss: 7044.01796875\n",
      "                , loss1: -7315.23125\n",
      "                , loss2: 9150.8046875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1140 epoch, average loss: 7043.97578125\n",
      "                , loss1: -7315.1203125\n",
      "                , loss2: 9150.7296875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1150 epoch, average loss: 7043.9875\n",
      "                , loss1: -7315.171875\n",
      "                , loss2: 9150.75703125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1160 epoch, average loss: 7043.9484375\n",
      "                , loss1: -7315.15546875\n",
      "                , loss2: 9150.71328125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1170 epoch, average loss: 7044.01796875\n",
      "                , loss1: -7315.203125\n",
      "                , loss2: 9150.796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1180 epoch, average loss: 7043.9\n",
      "                , loss1: -7315.10234375\n",
      "                , loss2: 9150.64921875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1190 epoch, average loss: 7044.03671875\n",
      "                , loss1: -7315.234375\n",
      "                , loss2: 9150.825\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1200 epoch, average loss: 7043.89765625\n",
      "                , loss1: -7315.07265625\n",
      "                , loss2: 9150.6390625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1210 epoch, average loss: 7043.9734375\n",
      "                , loss1: -7315.0234375\n",
      "                , loss2: 9150.70078125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1220 epoch, average loss: 7043.98046875\n",
      "                , loss1: -7315.18046875\n",
      "                , loss2: 9150.753125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1230 epoch, average loss: 7044.01015625\n",
      "                , loss1: -7315.2046875\n",
      "                , loss2: 9150.7890625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1240 epoch, average loss: 7043.9203125\n",
      "                , loss1: -7315.1015625\n",
      "                , loss2: 9150.6703125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1250 epoch, average loss: 7043.9515625\n",
      "                , loss1: -7315.1546875\n",
      "                , loss2: 9150.7171875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1260 epoch, average loss: 7043.840625\n",
      "                , loss1: -7315.0390625\n",
      "                , loss2: 9150.571875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1270 epoch, average loss: 7043.8921875\n",
      "                , loss1: -7315.0375\n",
      "                , loss2: 9150.62265625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1280 epoch, average loss: 7043.8984375\n",
      "                , loss1: -7315.1171875\n",
      "                , loss2: 9150.65234375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1290 epoch, average loss: 7043.9859375\n",
      "                , loss1: -7315.21640625\n",
      "                , loss2: 9150.76875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1300 epoch, average loss: 7043.9203125\n",
      "                , loss1: -7315.06015625\n",
      "                , loss2: 9150.6578125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1310 epoch, average loss: 7043.925\n",
      "                , loss1: -7315.1703125\n",
      "                , loss2: 9150.69375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1320 epoch, average loss: 7043.790625\n",
      "                , loss1: -7314.975\n",
      "                , loss2: 9150.503125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1330 epoch, average loss: 7043.56015625\n",
      "                , loss1: -7314.9578125\n",
      "                , loss2: 9150.26796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1340 epoch, average loss: 7043.8421875\n",
      "                , loss1: -7315.1171875\n",
      "                , loss2: 9150.5953125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1350 epoch, average loss: 7043.72265625\n",
      "                , loss1: -7314.9703125\n",
      "                , loss2: 9150.43359375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1360 epoch, average loss: 7043.72734375\n",
      "                , loss1: -7315.0140625\n",
      "                , loss2: 9150.45078125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1370 epoch, average loss: 7043.84921875\n",
      "                , loss1: -7315.121875\n",
      "                , loss2: 9150.6046875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1380 epoch, average loss: 7043.7421875\n",
      "                , loss1: -7315.05390625\n",
      "                , loss2: 9150.47734375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1390 epoch, average loss: 7043.75390625\n",
      "                , loss1: -7315.05\n",
      "                , loss2: 9150.4875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1400 epoch, average loss: 7043.5125\n",
      "                , loss1: -7314.83203125\n",
      "                , loss2: 9150.184375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1410 epoch, average loss: 7043.36640625\n",
      "                , loss1: -7314.76875\n",
      "                , loss2: 9150.01953125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1420 epoch, average loss: 7042.871875\n",
      "                , loss1: -7314.2\n",
      "                , loss2: 9149.3625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1430 epoch, average loss: 7042.76953125\n",
      "                , loss1: -7314.2546875\n",
      "                , loss2: 9149.275\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1440 epoch, average loss: 7043.1765625\n",
      "                , loss1: -7313.83125\n",
      "                , loss2: 9149.56015625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1450 epoch, average loss: 7043.64921875\n",
      "                , loss1: -7314.99609375\n",
      "                , loss2: 9150.36796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1460 epoch, average loss: 7043.73125\n",
      "                , loss1: -7315.0234375\n",
      "                , loss2: 9150.4578125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1470 epoch, average loss: 7043.4359375\n",
      "                , loss1: -7314.80625\n",
      "                , loss2: 9150.1\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1480 epoch, average loss: 7034.184375\n",
      "                , loss1: -7312.5734375\n",
      "                , loss2: 9140.20546875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1490 epoch, average loss: 7012.5578125\n",
      "                , loss1: -7315.83203125\n",
      "                , loss2: 9119.5171875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1500 epoch, average loss: 6974.37734375\n",
      "                , loss1: -7299.65546875\n",
      "                , loss2: 9076.678125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1510 epoch, average loss: 6945.72265625\n",
      "                , loss1: -7275.24296875\n",
      "                , loss2: 9040.9921875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1520 epoch, average loss: 7333.2609375\n",
      "                , loss1: -7259.1171875\n",
      "                , loss2: 9423.88671875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1530 epoch, average loss: 6956.0546875\n",
      "                , loss1: -6870.1796875\n",
      "                , loss2: 8934.66640625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1540 epoch, average loss: 311.706640625\n",
      "                , loss1: -5161.8453125\n",
      "                , loss2: 1798.3177734375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1550 epoch, average loss: -1515.57861328125\n",
      "                , loss1: -6719.49140625\n",
      "                , loss2: 419.63486328125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1560 epoch, average loss: -1526.132421875\n",
      "                , loss1: -6890.51171875\n",
      "                , loss2: 458.33486328125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1570 epoch, average loss: -1663.18125\n",
      "                , loss1: -6183.677734375\n",
      "                , loss2: 117.7179443359375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1580 epoch, average loss: -1691.278125\n",
      "                , loss1: -6047.779296875\n",
      "                , loss2: 50.48235168457031\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1590 epoch, average loss: -1699.27578125\n",
      "                , loss1: -6097.96796875\n",
      "                , loss2: 56.938995361328125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1600 epoch, average loss: -1701.087109375\n",
      "                , loss1: -6020.241015625\n",
      "                , loss2: 32.74226684570313\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1610 epoch, average loss: -1705.343359375\n",
      "                , loss1: -6060.83046875\n",
      "                , loss2: 40.17550048828125\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1620 epoch, average loss: -1712.5587890625\n",
      "                , loss1: -6071.852734375\n",
      "                , loss2: 36.134716796875\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1630 epoch, average loss: -1710.629296875\n",
      "                , loss1: -6087.237109375\n",
      "                , loss2: 42.494879150390624\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1640 epoch, average loss: -1712.921484375\n",
      "                , loss1: -6066.87265625\n",
      "                , loss2: 34.337884521484376\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1650 epoch, average loss: -1716.423046875\n",
      "                , loss1: -6107.94765625\n",
      "                , loss2: 42.66580505371094\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1660 epoch, average loss: -1730.606640625\n",
      "                , loss1: -6113.0125\n",
      "                , loss2: 29.940771484375\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1670 epoch, average loss: -1861.6658203125\n",
      "                , loss1: -6495.387109375\n",
      "                , loss2: 9.00555191040039\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1680 epoch, average loss: -2010.52890625\n",
      "                , loss1: -7012.2359375\n",
      "                , loss2: 8.995026397705079\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1690 epoch, average loss: -2039.917578125\n",
      "                , loss1: -7101.73359375\n",
      "                , loss2: 5.38145866394043\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1700 epoch, average loss: -2046.644921875\n",
      "                , loss1: -7113.5890625\n",
      "                , loss2: 2.0685943603515624\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1710 epoch, average loss: -2050.678125\n",
      "                , loss1: -7121.18515625\n",
      "                , loss2: 0.2230008602142334\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1720 epoch, average loss: -2051.86953125\n",
      "                , loss1: -7124.7453125\n",
      "                , loss2: 0.05714782476425171\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1730 epoch, average loss: -2053.06015625\n",
      "                , loss1: -7128.73359375\n",
      "                , loss2: 0.014928975701332092\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1740 epoch, average loss: -2053.29140625\n",
      "                , loss1: -7129.52734375\n",
      "                , loss2: 0.012251701951026917\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1750 epoch, average loss: -2053.227734375\n",
      "                , loss1: -7129.32421875\n",
      "                , loss2: 0.017633195221424102\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1760 epoch, average loss: -2053.9376953125\n",
      "                , loss1: -7131.7546875\n",
      "                , loss2: 0.007545868307352066\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1770 epoch, average loss: -2053.8859375\n",
      "                , loss1: -7131.575\n",
      "                , loss2: 0.007710106670856476\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1780 epoch, average loss: -2054.317578125\n",
      "                , loss1: -7133.05859375\n",
      "                , loss2: 0.0029348254203796385\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1790 epoch, average loss: -2054.575390625\n",
      "                , loss1: -7133.9546875\n",
      "                , loss2: 0.0034062087535858153\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1800 epoch, average loss: -2054.0375\n",
      "                , loss1: -7132.10859375\n",
      "                , loss2: 0.00960637554526329\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1810 epoch, average loss: -2054.30078125\n",
      "                , loss1: -7133.00625\n",
      "                , loss2: 0.0046710878610610965\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1820 epoch, average loss: -2054.623046875\n",
      "                , loss1: -7134.11953125\n",
      "                , loss2: 0.003294011577963829\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1830 epoch, average loss: -2054.2060546875\n",
      "                , loss1: -7132.67421875\n",
      "                , loss2: 0.0039001647382974625\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1840 epoch, average loss: -2054.703125\n",
      "                , loss1: -7134.396875\n",
      "                , loss2: 0.0029641207307577132\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1850 epoch, average loss: -2054.22421875\n",
      "                , loss1: -7132.75546875\n",
      "                , loss2: 0.00924597606062889\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1860 epoch, average loss: -2054.71015625\n",
      "                , loss1: -7134.4234375\n",
      "                , loss2: 0.0037127897143363954\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1870 epoch, average loss: -2055.0208984375\n",
      "                , loss1: -7135.496875\n",
      "                , loss2: 0.002193642407655716\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1880 epoch, average loss: -2054.862890625\n",
      "                , loss1: -7134.953125\n",
      "                , loss2: 0.003579356148838997\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1890 epoch, average loss: -2054.95078125\n",
      "                , loss1: -7135.25390625\n",
      "                , loss2: 0.0022681919857859612\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1900 epoch, average loss: -2054.8591796875\n",
      "                , loss1: -7134.9390625\n",
      "                , loss2: 0.002900829166173935\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1910 epoch, average loss: -2054.9984375\n",
      "                , loss1: -7135.41875\n",
      "                , loss2: 0.002193567156791687\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1920 epoch, average loss: -2055.061328125\n",
      "                , loss1: -7135.63515625\n",
      "                , loss2: 0.0016463588923215865\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1930 epoch, average loss: -2055.2376953125\n",
      "                , loss1: -7136.24609375\n",
      "                , loss2: 0.001061613392084837\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1940 epoch, average loss: -2054.48046875\n",
      "                , loss1: -7133.625\n",
      "                , loss2: 0.003379876539111137\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1950 epoch, average loss: -2055.366796875\n",
      "                , loss1: -7136.69453125\n",
      "                , loss2: 0.0012826007790863515\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1960 epoch, average loss: -2055.4228515625\n",
      "                , loss1: -7136.890625\n",
      "                , loss2: 0.0014261620119214058\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1970 epoch, average loss: -2055.251171875\n",
      "                , loss1: -7136.29453125\n",
      "                , loss2: 0.0016462009400129319\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1980 epoch, average loss: -2055.31796875\n",
      "                , loss1: -7136.525\n",
      "                , loss2: 0.0010447384789586066\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 1990 epoch, average loss: -2055.258203125\n",
      "                , loss1: -7136.31640625\n",
      "                , loss2: 0.0008491135202348232\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2000 epoch, average loss: -2055.3171875\n",
      "                , loss1: -7136.52265625\n",
      "                , loss2: 0.0012943020090460777\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2010 epoch, average loss: -2055.41015625\n",
      "                , loss1: -7136.84609375\n",
      "                , loss2: 0.001251566968858242\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2020 epoch, average loss: -2055.3228515625\n",
      "                , loss1: -7136.5421875\n",
      "                , loss2: 0.0010145570151507855\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2030 epoch, average loss: -2055.21171875\n",
      "                , loss1: -7136.15625\n",
      "                , loss2: 0.0013632983900606632\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2040 epoch, average loss: -2055.6388671875\n",
      "                , loss1: -7137.6359375\n",
      "                , loss2: 0.0004132009111344814\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2050 epoch, average loss: -2055.4115234375\n",
      "                , loss1: -7136.8484375\n",
      "                , loss2: 0.0008543699048459529\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2060 epoch, average loss: -2055.5146484375\n",
      "                , loss1: -7137.20703125\n",
      "                , loss2: 0.000608876720070839\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2070 epoch, average loss: -2055.315234375\n",
      "                , loss1: -7136.5140625\n",
      "                , loss2: 0.0008573923259973526\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2080 epoch, average loss: -2055.426953125\n",
      "                , loss1: -7136.90078125\n",
      "                , loss2: 0.000413042725995183\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2090 epoch, average loss: -2055.575\n",
      "                , loss1: -7137.4140625\n",
      "                , loss2: 0.0003144016955047846\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2100 epoch, average loss: -2055.16328125\n",
      "                , loss1: -7135.98671875\n",
      "                , loss2: 0.0010159186087548733\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2110 epoch, average loss: -2055.4650390625\n",
      "                , loss1: -7137.03515625\n",
      "                , loss2: 0.0007971628569066524\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2120 epoch, average loss: -2055.506640625\n",
      "                , loss1: -7137.178125\n",
      "                , loss2: 0.0003951487131416798\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2130 epoch, average loss: -2055.39453125\n",
      "                , loss1: -7136.79140625\n",
      "                , loss2: 0.001493422593921423\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2140 epoch, average loss: -2055.57890625\n",
      "                , loss1: -7137.42890625\n",
      "                , loss2: 0.0004252437502145767\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2150 epoch, average loss: -2055.73515625\n",
      "                , loss1: -7137.97109375\n",
      "                , loss2: 0.00033982282038778064\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2160 epoch, average loss: -2055.619921875\n",
      "                , loss1: -7137.571875\n",
      "                , loss2: 0.000623380346223712\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2170 epoch, average loss: -2055.378515625\n",
      "                , loss1: -7136.7375\n",
      "                , loss2: 0.00157027468085289\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2180 epoch, average loss: -2055.473046875\n",
      "                , loss1: -7137.06171875\n",
      "                , loss2: 0.0009443651884794235\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2190 epoch, average loss: -2055.515625\n",
      "                , loss1: -7137.2109375\n",
      "                , loss2: 0.0009686419740319252\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2200 epoch, average loss: -2055.4658203125\n",
      "                , loss1: -7137.0375\n",
      "                , loss2: 0.00071234917268157\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2210 epoch, average loss: -2055.7203125\n",
      "                , loss1: -7137.91953125\n",
      "                , loss2: 0.0004208348225802183\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2220 epoch, average loss: -2055.6771484375\n",
      "                , loss1: -7137.76953125\n",
      "                , loss2: 0.00046281609684228897\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2230 epoch, average loss: -2055.455859375\n",
      "                , loss1: -7137.01875\n",
      "                , loss2: 0.005282936617732048\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2240 epoch, average loss: -2055.565625\n",
      "                , loss1: -7137.38515625\n",
      "                , loss2: 0.0014622174203395844\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2250 epoch, average loss: -2055.365625\n",
      "                , loss1: -7136.6953125\n",
      "                , loss2: 0.0028000839054584505\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2260 epoch, average loss: -2055.3890625\n",
      "                , loss1: -7136.7703125\n",
      "                , loss2: 0.0008769245818257332\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2270 epoch, average loss: -2055.8015625\n",
      "                , loss1: -7138.20078125\n",
      "                , loss2: 0.0003231259994208813\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2280 epoch, average loss: -2055.6931640625\n",
      "                , loss1: -7137.825\n",
      "                , loss2: 0.0005147573538124561\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2290 epoch, average loss: -2055.79375\n",
      "                , loss1: -7138.1734375\n",
      "                , loss2: 0.00027506202459335325\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2300 epoch, average loss: -2055.7859375\n",
      "                , loss1: -7138.14609375\n",
      "                , loss2: 0.00015146946534514428\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2310 epoch, average loss: -2055.59765625\n",
      "                , loss1: -7137.49765625\n",
      "                , loss2: 0.0013506636023521423\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2320 epoch, average loss: -2055.7609375\n",
      "                , loss1: -7138.0609375\n",
      "                , loss2: 0.0004129602108150721\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2330 epoch, average loss: -2055.7921875\n",
      "                , loss1: -7138.16875\n",
      "                , loss2: 0.00026555252261459825\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2340 epoch, average loss: -2055.847265625\n",
      "                , loss1: -7138.359375\n",
      "                , loss2: 0.00017412607558071614\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2350 epoch, average loss: -2055.8263671875\n",
      "                , loss1: -7138.2859375\n",
      "                , loss2: 0.0001890533836558461\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2360 epoch, average loss: -2055.89765625\n",
      "                , loss1: -7138.53359375\n",
      "                , loss2: 0.00010618395172059535\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2370 epoch, average loss: -2055.5681640625\n",
      "                , loss1: -7137.3921875\n",
      "                , loss2: 0.0006391691975295543\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2380 epoch, average loss: -2055.7142578125\n",
      "                , loss1: -7137.89921875\n",
      "                , loss2: 0.0003473591059446335\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2390 epoch, average loss: -2055.8166015625\n",
      "                , loss1: -7138.253125\n",
      "                , loss2: 0.0001841903431341052\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2400 epoch, average loss: -2055.7712890625\n",
      "                , loss1: -7138.09609375\n",
      "                , loss2: 0.00021131569519639015\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2410 epoch, average loss: -2055.8060546875\n",
      "                , loss1: -7138.2171875\n",
      "                , loss2: 0.0005148741416633129\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2420 epoch, average loss: -2055.8283203125\n",
      "                , loss1: -7138.29375\n",
      "                , loss2: 0.00022795195691287516\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2430 epoch, average loss: -2055.9015625\n",
      "                , loss1: -7138.54765625\n",
      "                , loss2: 0.0001402865396812558\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2440 epoch, average loss: -2055.739453125\n",
      "                , loss1: -7137.9859375\n",
      "                , loss2: 0.000252954731695354\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2450 epoch, average loss: -2055.737109375\n",
      "                , loss1: -7137.97890625\n",
      "                , loss2: 0.0005864221602678299\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2460 epoch, average loss: -2055.7318359375\n",
      "                , loss1: -7137.959375\n",
      "                , loss2: 0.000629044882953167\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2470 epoch, average loss: -2055.9240234375\n",
      "                , loss1: -7138.6265625\n",
      "                , loss2: 0.00010244623990729451\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n",
      "in 2480 epoch, average loss: -2055.791796875\n",
      "                , loss1: -7138.16640625\n",
      "                , loss2: 0.0002744174329563975\n",
      "                , loss2_weight: 0.2879999999999024\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      8\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 9\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     39\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer2\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.convlayers.parameters(), lr=lr, weight_decay=5e-8)\n",
    "optim2 = optim.Adam(hgnn_trainer.linearlayers.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer1 = optim1\n",
    "hgnn_trainer.optimizer2 = optim2\n",
    "for epoch in range(20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , loss2_weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([109., 109., 109.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
