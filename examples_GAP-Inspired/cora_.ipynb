{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycq/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import dhg\n",
    "from dhg import Hypergraph\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP\n",
    "from hgp.loss import loss_bs_matrix\n",
    "from hgp.utils import from_pickle_to_hypergraph\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 3\n",
    "\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 1330, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.4}\n",
    "h_hyper_prmts[\"convlayers3\"] = {\"in_channels\": 1024, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.3}\n",
    "h_hyper_prmts[\"convlayers4\"] = {\"in_channels\": 512, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.3}\n",
    "h_hyper_prmts[\"convlayers5\"] = {\"in_channels\": 512, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.3}\n",
    "\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":list(h_hyper_prmts.values())[-1][\"out_channels\"], \"out_channels\":128, \"use_bn\":True, \"drop_rate\":0.1}\n",
    "l_hyper_prmts[\"linerlayer2\"] = {\"in_channels\":128, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.1}\n",
    "l_hyper_prmts[\"linerlayer3\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":False, \"drop_rate\":0.1}\n",
    "l_hyper_prmts[\"linerlayer4\"] = {\"in_channels\":32, \"out_channels\":3, \"use_bn\":False, \"drop_rate\":0.1}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  \n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1413, 1330)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = from_pickle_to_hypergraph(\"../data/cora\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "X = torch.eye(n=G.num_v)\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "optim = optim.Adam(hgnn_trainer.parameters(), lr=4e-5, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.layers.0.theta.weight Parameter containing:\n",
      "tensor([[ 0.0104,  0.0207,  0.0186,  ..., -0.0215, -0.0219,  0.0268],\n",
      "        [ 0.0240, -0.0171,  0.0055,  ..., -0.0157, -0.0238, -0.0217],\n",
      "        [ 0.0026,  0.0239,  0.0012,  ..., -0.0055,  0.0034,  0.0106],\n",
      "        ...,\n",
      "        [-0.0011, -0.0259, -0.0078,  ..., -0.0077,  0.0194, -0.0233],\n",
      "        [ 0.0131, -0.0226, -0.0065,  ..., -0.0174, -0.0225, -0.0032],\n",
      "        [ 0.0023, -0.0008,  0.0026,  ..., -0.0176,  0.0216,  0.0036]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.0.theta.bias Parameter containing:\n",
      "tensor([-0.0206,  0.0176, -0.0196,  ...,  0.0268, -0.0214, -0.0069],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.1.theta.weight Parameter containing:\n",
      "tensor([[-0.0145,  0.0305, -0.0148,  ...,  0.0248,  0.0019, -0.0260],\n",
      "        [ 0.0257,  0.0139, -0.0047,  ..., -0.0202, -0.0243, -0.0012],\n",
      "        [-0.0019,  0.0008, -0.0276,  ..., -0.0158,  0.0153,  0.0309],\n",
      "        ...,\n",
      "        [ 0.0165,  0.0181,  0.0114,  ...,  0.0227,  0.0307,  0.0130],\n",
      "        [ 0.0235, -0.0109,  0.0094,  ..., -0.0039, -0.0203, -0.0177],\n",
      "        [ 0.0018,  0.0064,  0.0130,  ...,  0.0125,  0.0022,  0.0097]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.1.theta.bias Parameter containing:\n",
      "tensor([-3.0866e-02, -1.1652e-02, -2.9814e-02,  1.1367e-02,  2.9164e-02,\n",
      "        -2.8891e-02,  2.7828e-03,  2.9306e-02, -8.0155e-03, -1.7720e-02,\n",
      "         1.7510e-02, -2.2453e-02,  1.4811e-02, -2.9588e-03, -2.6733e-02,\n",
      "         1.2659e-02, -2.0021e-02, -1.1384e-02, -3.3809e-03, -3.0023e-02,\n",
      "         2.9897e-02, -1.0665e-02, -1.4927e-02,  1.6032e-02, -2.2383e-02,\n",
      "         1.1674e-03,  6.2807e-03, -2.8205e-02,  2.7619e-02, -2.8585e-02,\n",
      "         8.7394e-03,  2.0062e-02, -2.9745e-03, -4.7241e-03,  7.8912e-03,\n",
      "         1.8820e-02,  1.9044e-02,  2.9169e-05, -2.6214e-03,  4.8872e-04,\n",
      "         1.9519e-02, -1.1148e-02, -2.0273e-02,  2.0168e-03,  5.8893e-05,\n",
      "         3.4829e-03,  1.8565e-02, -8.9369e-03, -1.5380e-02, -1.0600e-03,\n",
      "         2.7748e-02,  1.7285e-02, -1.2952e-03,  3.8747e-03, -6.1780e-03,\n",
      "         2.8291e-02,  2.8977e-02,  2.1787e-02, -2.0110e-03,  1.6583e-02,\n",
      "        -3.0951e-02,  1.6420e-02,  2.6990e-03,  2.3881e-02,  3.0712e-02,\n",
      "        -5.3293e-03, -2.8383e-02, -2.9080e-02,  1.2166e-02,  2.0234e-02,\n",
      "        -1.3013e-02,  1.4529e-02, -2.9279e-02,  1.6917e-02,  3.4845e-03,\n",
      "         7.8022e-03,  2.5697e-03, -4.4672e-03,  2.8943e-02, -2.9040e-02,\n",
      "         2.1888e-02,  9.7888e-03,  1.9755e-03,  2.6521e-03,  9.0553e-03,\n",
      "         6.8836e-03,  3.8522e-03, -2.8785e-02, -1.1080e-02, -1.3922e-03,\n",
      "        -1.9620e-02,  2.7385e-02, -2.6407e-02,  1.5417e-02,  1.5024e-02,\n",
      "         1.5392e-02, -3.0886e-02, -8.4127e-03, -1.2604e-02, -8.8884e-03,\n",
      "         1.6701e-02, -7.6025e-03,  1.0871e-02,  4.3997e-03, -1.8451e-02,\n",
      "        -1.3408e-02,  1.9537e-02,  9.3602e-04, -1.2568e-02,  2.6403e-02,\n",
      "         2.8664e-02,  1.4648e-02,  2.2435e-02,  2.3235e-02, -2.0537e-02,\n",
      "        -1.4628e-02, -1.7243e-02,  2.5797e-03,  2.0459e-02,  5.9387e-03,\n",
      "         1.3529e-02,  2.4790e-02, -7.9453e-05, -9.3049e-03, -2.5170e-02,\n",
      "        -1.4220e-02,  2.7724e-02,  2.6003e-02,  5.9804e-03, -1.0115e-02,\n",
      "        -2.3867e-02,  1.6439e-02,  1.3729e-02, -2.7451e-02, -2.1787e-02,\n",
      "        -2.0340e-02, -2.3216e-02, -1.9351e-02, -3.0472e-02, -1.6982e-02,\n",
      "        -2.7205e-02,  1.5502e-02, -1.3346e-02, -1.3242e-02, -1.8862e-02,\n",
      "        -9.8617e-03, -6.4256e-03,  3.0460e-02, -2.2539e-02,  2.7563e-02,\n",
      "         4.2652e-03,  1.8397e-02, -1.3450e-02, -3.0471e-02, -2.7688e-02,\n",
      "         1.0671e-02,  7.6647e-03,  9.5756e-03, -1.6533e-02, -1.2589e-02,\n",
      "         2.9727e-02, -2.9675e-02, -2.0042e-02, -1.5131e-02,  5.2045e-03,\n",
      "        -2.0624e-02, -1.4178e-02,  3.5629e-03,  2.6356e-02, -2.0468e-02,\n",
      "         2.5244e-02,  1.6770e-02,  2.4559e-02, -7.4644e-03, -6.0589e-03,\n",
      "        -6.5729e-03, -2.4462e-02,  2.1041e-02, -1.3003e-02, -1.2471e-02,\n",
      "         2.0349e-03, -9.3617e-03,  1.4673e-03, -1.6648e-02, -1.6258e-02,\n",
      "         1.9573e-02,  1.1110e-02, -2.1565e-02,  4.2046e-03,  5.7643e-03,\n",
      "        -2.0613e-02, -1.6390e-02, -4.0367e-03,  1.7809e-02, -2.2662e-02,\n",
      "        -1.1936e-02, -1.5268e-02,  2.7887e-02,  2.1848e-02, -2.3084e-02,\n",
      "         3.0937e-02, -1.4317e-04,  1.1499e-02,  2.1871e-02,  8.7722e-03,\n",
      "        -3.1902e-03,  3.0170e-02, -4.4219e-05, -4.2939e-04,  2.4205e-02,\n",
      "        -2.3114e-03,  2.4972e-02, -1.3990e-02, -6.3492e-03, -2.4467e-02,\n",
      "        -1.6055e-02, -1.8180e-02, -1.9045e-02, -1.6475e-02, -2.5447e-02,\n",
      "        -2.2034e-02, -9.0363e-03,  2.0667e-02,  2.1527e-02, -5.5426e-03,\n",
      "        -1.4504e-02, -5.6474e-03,  3.9185e-03, -2.9824e-02,  1.6480e-02,\n",
      "         3.0800e-02,  1.3165e-02, -2.8777e-02,  1.0708e-02, -2.8937e-02,\n",
      "         2.8248e-02, -1.0954e-02,  1.9440e-02, -4.1559e-03,  7.5605e-03,\n",
      "        -2.2104e-02, -1.6160e-02,  2.9973e-02, -9.5821e-03, -7.3970e-03,\n",
      "        -9.2578e-04,  2.5319e-02,  9.2192e-03,  2.5555e-02, -2.8033e-02,\n",
      "         6.2154e-03, -1.9955e-02, -2.1747e-02, -1.6111e-02,  2.9517e-02,\n",
      "         2.2023e-02,  6.9687e-03,  1.4829e-03,  2.2684e-03,  3.0209e-02,\n",
      "        -1.6178e-02,  1.3691e-02,  2.5851e-02, -1.7338e-02, -1.5262e-02,\n",
      "        -2.9248e-02,  1.2175e-02, -7.2274e-03,  4.5098e-03, -1.1489e-02,\n",
      "         1.8354e-02,  8.6854e-03,  2.5248e-02, -6.9382e-03, -4.7194e-04,\n",
      "         2.2585e-02,  2.2208e-02, -5.5240e-03,  1.0085e-02,  8.5063e-03,\n",
      "         2.7635e-02,  2.1881e-02, -3.1083e-02,  4.5471e-03, -1.8344e-02,\n",
      "        -2.4231e-02, -1.6971e-02, -8.6596e-03, -2.1897e-02, -1.6813e-02,\n",
      "         1.9599e-02,  1.9975e-02,  2.4707e-03,  2.1730e-02, -1.7779e-02,\n",
      "         1.3665e-02, -1.7756e-02,  3.0414e-02, -2.7744e-02, -2.9812e-02,\n",
      "        -2.6286e-02,  8.6409e-03,  1.9992e-02, -7.9499e-03,  4.3405e-03,\n",
      "         1.6109e-03, -2.1218e-02, -2.6021e-02,  2.2388e-02,  7.8719e-03,\n",
      "         2.5262e-02, -7.6322e-03,  3.1178e-03, -1.1475e-02,  5.7962e-03,\n",
      "         2.8394e-02,  1.4207e-02, -1.9902e-03,  2.9412e-02, -7.5401e-03,\n",
      "         2.7894e-02,  8.5352e-03,  2.5893e-02,  3.0305e-02, -1.4595e-02,\n",
      "        -1.0688e-02, -6.7489e-03,  2.6110e-02, -2.1134e-02,  1.1987e-02,\n",
      "        -2.9248e-02,  5.7069e-03, -1.9204e-02,  2.3141e-04,  2.1959e-02,\n",
      "        -2.7158e-02, -2.3137e-02, -2.0444e-02, -2.2890e-02, -2.7073e-02,\n",
      "        -2.2217e-02, -1.5510e-02, -2.1941e-02, -2.1808e-03, -1.1831e-02,\n",
      "        -1.0328e-02,  8.5312e-03, -1.5585e-02,  5.7972e-03,  2.9986e-02,\n",
      "        -1.5077e-02,  1.6670e-02, -2.0356e-02,  2.3771e-02, -3.0466e-02,\n",
      "        -1.0882e-02,  2.3864e-02,  1.7206e-02,  2.3914e-02,  2.7473e-03,\n",
      "        -3.0614e-03,  1.4144e-02, -1.8112e-02, -2.4835e-02, -7.4980e-03,\n",
      "        -6.0679e-03, -1.7904e-02,  7.6434e-03,  3.0611e-02,  2.5020e-02,\n",
      "         1.7579e-02,  2.6641e-02, -1.5176e-02, -2.6978e-02, -1.8382e-02,\n",
      "        -1.2102e-03,  1.4393e-02,  1.8287e-02,  1.8701e-02,  9.9113e-03,\n",
      "         2.0620e-02, -3.4317e-03,  5.2962e-03,  1.2917e-02,  1.3414e-02,\n",
      "        -8.8054e-03,  1.3670e-02, -3.9973e-03,  2.4425e-02,  3.1187e-02,\n",
      "         2.8281e-02, -1.2991e-02,  1.6149e-02, -1.2532e-02,  2.8452e-02,\n",
      "        -7.5733e-03, -3.4792e-03,  2.8751e-02, -2.8144e-02,  2.8402e-02,\n",
      "        -9.1232e-03, -2.9494e-02,  4.2562e-03, -6.0195e-03, -6.1560e-05,\n",
      "         2.2807e-02, -1.9357e-02, -1.0043e-02, -6.8343e-03,  1.0581e-02,\n",
      "         3.0651e-02,  2.0643e-02, -1.9249e-02,  3.2793e-03, -1.0633e-02,\n",
      "        -1.5038e-02, -1.4177e-02, -2.3501e-02, -3.1140e-03,  1.2233e-02,\n",
      "        -2.5192e-02, -2.7991e-02, -2.4468e-02,  1.4968e-02,  6.7668e-03,\n",
      "        -1.8163e-02, -6.5539e-03, -7.4006e-03, -1.8470e-02,  2.0254e-02,\n",
      "        -2.0680e-02,  1.7801e-02,  8.0845e-03, -2.4906e-02, -1.4508e-02,\n",
      "         8.7725e-04, -2.3598e-02, -1.2146e-02, -4.4430e-03,  1.3557e-02,\n",
      "        -2.8624e-02,  1.3933e-02, -1.1931e-02, -1.7894e-02,  1.4691e-02,\n",
      "         1.3882e-02,  2.2856e-03,  3.6879e-03,  3.9686e-05,  3.5745e-03,\n",
      "         2.4531e-02,  2.7846e-02, -1.7643e-02,  1.7322e-02, -2.5428e-03,\n",
      "        -2.5154e-02, -6.5148e-03,  1.6873e-02,  5.0837e-03, -3.8156e-03,\n",
      "        -1.9074e-03,  1.7438e-02,  1.7471e-02, -1.6276e-02,  5.9197e-03,\n",
      "        -5.6507e-04,  2.2397e-03, -2.3931e-02,  2.3090e-02,  1.7984e-03,\n",
      "         2.7041e-02, -1.4454e-02,  2.9525e-02,  1.8979e-02, -1.8056e-02,\n",
      "         2.2813e-03, -1.4869e-02,  9.9765e-03, -2.7075e-02,  1.7459e-02,\n",
      "         2.9067e-02, -1.0277e-02, -2.0363e-02,  2.3475e-02, -2.2273e-02,\n",
      "         1.6542e-03, -1.0688e-02, -3.0325e-02, -8.6145e-03, -1.9451e-02,\n",
      "        -1.1520e-02, -1.9501e-03, -2.2322e-03,  1.0663e-03,  2.4295e-02,\n",
      "         6.3361e-03,  2.0088e-03,  5.8815e-03,  1.4312e-02,  3.4256e-03,\n",
      "        -1.2545e-02, -1.3163e-02, -2.9838e-02, -9.2595e-03, -3.0578e-02,\n",
      "         2.8291e-02, -2.7860e-02,  2.9893e-02, -1.9650e-02,  2.9220e-02,\n",
      "         1.4622e-02, -1.1720e-02], device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.2.theta.weight Parameter containing:\n",
      "tensor([[-0.0225,  0.0396,  0.0375,  ..., -0.0024, -0.0104, -0.0302],\n",
      "        [-0.0225, -0.0207,  0.0038,  ...,  0.0161, -0.0044, -0.0294],\n",
      "        [ 0.0270,  0.0144, -0.0160,  ..., -0.0418, -0.0397,  0.0204],\n",
      "        ...,\n",
      "        [-0.0133, -0.0043, -0.0246,  ..., -0.0372, -0.0237,  0.0403],\n",
      "        [ 0.0390,  0.0003,  0.0321,  ..., -0.0315, -0.0003,  0.0141],\n",
      "        [ 0.0372, -0.0077,  0.0397,  ...,  0.0064, -0.0139,  0.0014]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.2.theta.bias Parameter containing:\n",
      "tensor([ 4.1503e-02, -3.3636e-02,  2.3673e-02,  2.1384e-03, -1.3717e-02,\n",
      "        -3.0257e-02,  1.5347e-02,  8.3196e-03,  3.3251e-02, -3.5878e-02,\n",
      "        -2.9466e-02,  2.9686e-02,  4.0111e-02,  4.2496e-02, -4.7015e-03,\n",
      "         3.3520e-02,  1.6346e-02,  1.9487e-02,  8.8390e-03,  3.4183e-02,\n",
      "         1.3241e-02,  3.7304e-02, -1.1466e-02,  2.1361e-02, -4.0563e-02,\n",
      "         1.1725e-02,  1.3815e-02, -3.1963e-02,  6.5870e-04,  6.8983e-03,\n",
      "        -3.1833e-02,  4.1249e-02, -3.2795e-02,  3.9952e-02,  1.5526e-05,\n",
      "        -1.9722e-02,  3.3462e-03,  1.3718e-02, -4.0443e-02,  3.4161e-02,\n",
      "         3.6901e-02,  1.2701e-02,  2.9872e-02, -3.4839e-02,  3.7298e-02,\n",
      "        -3.4381e-02,  2.0487e-02, -2.0300e-02, -2.2928e-02,  3.7914e-02,\n",
      "        -3.1693e-02, -6.6753e-03,  1.2108e-02, -6.8201e-03, -2.2633e-02,\n",
      "         2.1233e-02, -1.1585e-02,  1.6189e-02,  3.6743e-02, -4.0376e-02,\n",
      "        -4.0189e-02,  1.1192e-02,  3.4119e-02,  3.8072e-02, -2.2204e-02,\n",
      "        -5.8058e-03,  8.7704e-03, -3.6716e-02,  1.1503e-03, -4.0519e-02,\n",
      "        -1.3755e-02, -2.2154e-02, -1.0198e-02,  1.0084e-02, -2.1068e-02,\n",
      "        -2.8702e-02,  7.2300e-03,  4.2102e-02,  3.3271e-02,  7.0203e-03,\n",
      "         3.3912e-02,  2.9601e-02, -2.0408e-03,  1.4574e-02, -4.1498e-02,\n",
      "        -2.8265e-02, -4.1814e-02, -2.8764e-02, -2.3886e-02,  4.0547e-02,\n",
      "        -4.2358e-03,  1.6080e-02, -3.4346e-02,  2.0901e-02, -4.5520e-03,\n",
      "        -3.8366e-02, -3.3264e-02,  3.2534e-02, -6.7218e-03, -6.4589e-03,\n",
      "        -1.9914e-02,  1.5820e-02,  2.6555e-02,  3.9930e-03, -2.5144e-02,\n",
      "         3.6588e-02,  3.0686e-02,  4.0290e-02, -2.5450e-02, -1.7264e-02,\n",
      "        -1.6532e-02, -2.4381e-02,  2.8142e-02, -2.5360e-02,  3.0052e-02,\n",
      "         2.4451e-02,  2.0556e-02, -3.0636e-02, -2.2844e-03,  3.9238e-03,\n",
      "        -1.5728e-02,  2.9447e-02,  1.7047e-02,  2.5676e-02,  1.3156e-02,\n",
      "        -2.5736e-02,  4.5575e-03,  1.3918e-02, -4.1791e-02, -1.7803e-02,\n",
      "         8.0435e-03,  4.3288e-02, -1.0499e-02,  1.7505e-02, -2.9563e-02,\n",
      "         1.1629e-02,  3.9312e-02, -3.3029e-02, -3.8336e-02, -6.9079e-03,\n",
      "         1.0571e-02, -6.6798e-03, -1.7241e-02,  1.7885e-02, -1.2071e-02,\n",
      "         6.6313e-04, -1.6596e-02,  3.8022e-02,  3.9194e-02, -4.2179e-03,\n",
      "         3.5390e-03,  4.2311e-02,  1.3057e-02, -3.8911e-02,  2.2035e-02,\n",
      "         8.7582e-03,  2.0288e-02, -1.6008e-02,  2.0057e-02, -2.8022e-02,\n",
      "         3.9821e-03, -2.7455e-02, -2.0391e-02,  3.8100e-02, -2.2628e-02,\n",
      "         2.3896e-02,  1.8707e-02, -3.9596e-02,  1.1889e-02,  2.1322e-02,\n",
      "        -3.3560e-02, -2.6611e-02, -4.1354e-02, -3.2058e-03, -1.0573e-02,\n",
      "        -7.0620e-03, -2.6208e-02,  2.7423e-02, -7.2435e-03,  3.5681e-02,\n",
      "         3.1153e-02,  3.9076e-02,  4.3467e-02,  2.9745e-02,  3.5736e-02,\n",
      "        -4.0981e-02,  3.0783e-02, -6.6397e-03, -3.9920e-02,  1.4541e-02,\n",
      "         3.5225e-02,  3.1122e-02, -8.0752e-03, -1.6101e-02, -4.2806e-02,\n",
      "        -9.4522e-04, -4.9527e-03,  4.0530e-02,  3.8455e-02,  2.9942e-03,\n",
      "         3.1050e-02,  1.8866e-03, -3.5701e-02,  3.0049e-02,  2.1462e-02,\n",
      "         4.2855e-02,  1.6126e-02, -2.9326e-02,  4.3256e-02,  8.2013e-03,\n",
      "         4.3232e-02, -1.3688e-02,  3.1184e-02, -4.1320e-02,  2.3261e-02,\n",
      "         2.5566e-02, -1.7031e-03, -2.9297e-02, -3.8882e-02, -2.6348e-02,\n",
      "        -2.4232e-03,  1.8313e-02,  2.2901e-02, -1.0270e-02,  4.2394e-03,\n",
      "         1.9391e-02,  2.7784e-02, -8.1413e-03,  4.1799e-02, -3.2612e-02,\n",
      "         8.2720e-03, -3.9244e-02,  3.3545e-02,  7.2581e-03,  1.6793e-02,\n",
      "         1.3597e-02, -3.2421e-04, -2.6537e-02,  1.5283e-02,  1.3786e-02,\n",
      "        -2.9629e-02,  7.4335e-03, -3.4557e-02, -3.6613e-04, -6.6435e-03,\n",
      "         2.4141e-02, -2.7923e-02,  2.2085e-02,  2.6222e-02,  3.4456e-02,\n",
      "        -1.9365e-02, -1.2798e-02,  4.2302e-02,  4.3968e-03,  3.5634e-02,\n",
      "         2.5947e-02, -7.5060e-03, -3.6474e-02,  2.9668e-02, -1.8682e-02,\n",
      "         7.0866e-03, -2.0566e-02, -3.8145e-02, -2.0647e-02, -1.9078e-02,\n",
      "        -4.1393e-03,  2.2259e-02,  2.7288e-03,  3.8779e-02,  4.0133e-02,\n",
      "        -3.3202e-02, -4.2729e-02,  2.0871e-03,  3.0914e-02, -6.1931e-03,\n",
      "        -2.1357e-02, -2.5317e-02,  6.2788e-03, -3.0508e-02, -2.4395e-02,\n",
      "        -1.3543e-02, -9.3985e-03, -1.9307e-02, -3.5379e-02,  1.2004e-02,\n",
      "         2.3364e-03,  1.7850e-02, -2.4509e-02, -2.2804e-02, -1.7067e-02,\n",
      "         1.5304e-02,  3.0853e-02, -3.3767e-02,  2.0367e-02, -1.5500e-02,\n",
      "        -4.1092e-02, -4.7022e-03,  1.0877e-02,  4.0863e-02,  3.2456e-02,\n",
      "        -5.6246e-03,  4.9966e-03, -4.3180e-02, -1.4880e-02, -3.0596e-03,\n",
      "         3.9856e-02,  2.1019e-02,  2.6730e-02,  3.5729e-02, -2.7879e-02,\n",
      "        -2.4889e-02, -1.1675e-02,  4.1977e-02, -1.8748e-02,  3.7388e-02,\n",
      "        -1.8699e-03,  4.8350e-03,  4.1686e-02, -5.7832e-03,  1.4741e-02,\n",
      "        -2.1132e-02,  1.9761e-02,  1.2615e-02, -2.9360e-02,  6.9647e-03,\n",
      "         9.9910e-03,  2.0750e-02,  1.6829e-02, -2.5957e-02,  3.8842e-02,\n",
      "         2.3535e-04, -7.4998e-03,  8.7039e-03,  7.2379e-03,  4.2958e-03,\n",
      "         1.2675e-02, -1.8771e-02, -3.7963e-02, -2.0031e-02, -3.9372e-02,\n",
      "         3.2964e-02,  4.0827e-02,  1.5038e-02, -4.2357e-02, -5.3418e-03,\n",
      "         3.3249e-02,  2.2228e-03, -3.2411e-03,  3.4041e-03,  2.4382e-02,\n",
      "        -9.5887e-03, -2.1690e-02,  2.0942e-05, -2.3970e-02, -4.1625e-03,\n",
      "         3.2864e-02,  5.8972e-03, -2.2996e-02,  3.7514e-02,  1.1338e-02,\n",
      "        -4.2394e-02,  2.8720e-02,  2.5620e-02,  1.7154e-02,  4.1296e-02,\n",
      "         4.3268e-02,  3.5227e-02,  3.6628e-02, -3.1016e-02,  1.7565e-02,\n",
      "        -5.3521e-03, -1.1117e-02,  9.1408e-03, -3.0926e-02,  1.4994e-02,\n",
      "         2.9946e-02, -1.5983e-02, -3.9912e-02,  4.9291e-03,  2.9030e-03,\n",
      "         2.4992e-02, -4.6059e-03,  5.4130e-03,  4.1376e-02, -2.9227e-02,\n",
      "        -3.7935e-02,  2.6525e-02, -1.7389e-03,  1.8222e-02,  1.6656e-02,\n",
      "         2.5591e-02,  2.9004e-02,  2.0554e-02, -1.8127e-02,  2.9251e-02,\n",
      "        -3.8696e-02,  3.4018e-02,  1.9401e-02,  1.0487e-02, -1.5289e-02,\n",
      "         2.5059e-02,  1.6726e-02,  4.1384e-02,  2.4136e-02, -9.1749e-03,\n",
      "        -3.5159e-02,  1.5613e-02,  4.2772e-02,  1.7479e-02, -1.3252e-02,\n",
      "         2.6797e-02, -4.0148e-02,  1.9551e-02, -1.4810e-02, -6.4682e-03,\n",
      "        -2.0570e-02, -4.9480e-03,  1.2537e-02,  1.8995e-02,  1.1826e-02,\n",
      "         2.9663e-02,  3.3391e-02, -3.4809e-02, -2.5442e-02,  1.7168e-02,\n",
      "         3.8112e-02, -7.8388e-03,  3.7861e-02,  9.6599e-03,  1.4356e-03,\n",
      "         1.6273e-02, -7.0343e-03, -4.0533e-02, -1.9244e-02,  3.2487e-02,\n",
      "        -1.9802e-02,  1.4952e-03, -1.5319e-02,  9.9929e-03, -1.1241e-03,\n",
      "        -2.3075e-02, -1.0658e-02, -7.5827e-03,  3.1108e-02, -6.2749e-03,\n",
      "         2.8037e-02, -1.1891e-03,  4.3481e-02,  1.8871e-02,  2.3902e-02,\n",
      "         4.1336e-02,  2.3948e-02, -4.3680e-02,  3.7002e-02, -1.3410e-02,\n",
      "         1.2605e-02,  1.3885e-02, -7.8057e-03,  1.5225e-02, -1.4704e-02,\n",
      "        -2.7014e-02,  2.1547e-02, -3.5032e-02, -1.2400e-02, -4.3954e-02,\n",
      "         1.7356e-03,  3.8964e-03, -2.9161e-02, -2.3180e-02,  3.8557e-02,\n",
      "        -2.7398e-02,  3.9298e-02, -2.8362e-02,  6.1290e-03,  3.5129e-02,\n",
      "        -2.9627e-02, -2.1854e-02,  2.3604e-02,  2.0889e-02, -2.0370e-02,\n",
      "         1.2364e-02,  2.0704e-02,  3.6764e-02, -2.5378e-02,  3.1404e-03,\n",
      "         1.7634e-02,  7.4906e-03, -2.5698e-02,  1.2805e-02, -2.9800e-02,\n",
      "        -2.0167e-02, -2.5435e-02,  4.1940e-02,  2.7513e-02, -3.7456e-02,\n",
      "         3.8826e-02,  3.8455e-02,  4.1106e-02,  2.5165e-02, -3.4466e-02,\n",
      "        -8.9121e-03, -3.6925e-02, -3.1806e-02, -3.9012e-02, -3.5410e-02,\n",
      "        -2.0820e-02, -3.0073e-02, -3.8394e-02, -3.0472e-02,  2.0464e-02,\n",
      "         1.6594e-02,  2.7692e-02], device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.3.theta.weight Parameter containing:\n",
      "tensor([[-0.0192, -0.0248, -0.0386,  ...,  0.0288, -0.0008,  0.0150],\n",
      "        [-0.0260, -0.0360,  0.0428,  ..., -0.0293, -0.0376, -0.0120],\n",
      "        [ 0.0059, -0.0109, -0.0301,  ...,  0.0397, -0.0185,  0.0083],\n",
      "        ...,\n",
      "        [ 0.0045,  0.0313,  0.0415,  ...,  0.0123, -0.0143,  0.0184],\n",
      "        [-0.0344,  0.0035, -0.0331,  ...,  0.0124, -0.0157,  0.0367],\n",
      "        [-0.0335, -0.0347, -0.0308,  ..., -0.0118, -0.0348, -0.0064]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.0.layers.3.theta.bias Parameter containing:\n",
      "tensor([ 4.1027e-02, -2.1761e-04, -1.0260e-02, -4.3487e-02, -2.3872e-02,\n",
      "        -2.0385e-02,  2.3865e-02,  4.5237e-03, -2.1787e-02, -1.0021e-02,\n",
      "         3.3603e-02, -7.6813e-03, -3.4364e-02,  2.5517e-03, -1.4934e-02,\n",
      "         1.3192e-02, -3.4527e-02,  7.5777e-03, -3.7334e-02,  4.2835e-03,\n",
      "         2.9923e-02, -2.4504e-02,  3.7208e-02, -3.7042e-02, -5.7452e-04,\n",
      "         3.0208e-02,  6.2138e-03,  3.3821e-02, -3.9476e-02, -1.8281e-02,\n",
      "        -1.0848e-02, -4.2393e-02,  2.8970e-02,  4.2591e-02, -3.2963e-02,\n",
      "         1.6556e-02,  3.3471e-02,  3.1123e-02, -3.9226e-02, -3.2658e-03,\n",
      "         1.5062e-02,  1.2487e-03,  2.7724e-02, -4.3800e-03,  3.5305e-02,\n",
      "        -2.0642e-02,  1.5110e-02,  3.5280e-03,  4.0521e-03,  3.9660e-02,\n",
      "         3.6268e-02,  1.4395e-02,  2.2883e-02,  2.7937e-02, -2.8737e-02,\n",
      "        -1.4097e-03,  1.8559e-02,  1.0065e-02, -3.5299e-02, -1.0029e-02,\n",
      "        -8.0079e-05, -8.7199e-04,  3.0429e-02,  3.7098e-02, -3.4746e-02,\n",
      "        -1.0621e-03,  1.8048e-02, -2.1259e-02, -2.0172e-02, -8.2683e-03,\n",
      "        -2.5884e-02,  3.0693e-02, -2.7752e-02, -1.0556e-02,  1.9848e-03,\n",
      "        -3.9116e-02,  2.4058e-02,  1.3046e-02,  2.3792e-02, -1.9651e-02,\n",
      "         2.0172e-02,  2.6285e-02,  3.5693e-03,  3.2378e-03, -3.3239e-02,\n",
      "        -3.4193e-02, -1.6455e-02,  2.8060e-02,  3.0082e-02, -4.0779e-02,\n",
      "        -3.2277e-02,  1.5219e-02,  4.3094e-02,  3.8739e-02,  4.2513e-02,\n",
      "         3.6625e-02,  2.2425e-02, -2.9893e-02, -4.3578e-02,  3.9804e-02,\n",
      "         1.7041e-02, -3.5131e-02, -2.0517e-03,  2.9452e-02, -8.3312e-03,\n",
      "         2.3383e-02, -3.7894e-02, -4.5920e-03, -2.3459e-02,  1.8469e-02,\n",
      "        -4.8873e-03,  1.5141e-02,  3.9069e-03,  1.2212e-02, -2.1875e-02,\n",
      "         3.1401e-02, -1.0050e-02, -2.2319e-02,  1.7703e-02, -2.9387e-02,\n",
      "        -3.7502e-02, -7.0520e-03, -3.5909e-03,  3.4670e-02, -1.2033e-03,\n",
      "         2.8532e-02,  7.6050e-03,  4.2697e-02, -2.9868e-02,  9.6291e-03,\n",
      "         2.8643e-02, -2.1402e-02,  2.7986e-02, -3.9821e-02, -3.8833e-02,\n",
      "         1.7563e-02,  3.3085e-02,  3.0512e-02, -4.1524e-02, -1.8877e-02,\n",
      "        -1.4564e-02,  4.7178e-04, -2.7234e-03, -3.3403e-02,  4.3541e-02,\n",
      "        -9.0419e-03, -2.0872e-02, -2.9488e-02, -2.9314e-02, -3.7475e-02,\n",
      "        -3.0041e-03, -8.6945e-03, -1.0861e-02,  3.0078e-02, -9.8712e-03,\n",
      "         1.0991e-02, -4.1531e-04, -4.3306e-02, -3.8675e-03,  2.7630e-02,\n",
      "        -4.3525e-02,  2.5445e-03, -1.0326e-02, -1.7912e-04, -1.4189e-02,\n",
      "        -6.0460e-03,  2.1874e-02,  2.5636e-02,  1.9217e-02,  2.2567e-03,\n",
      "         3.6191e-02, -3.5164e-02,  1.0329e-02,  3.3769e-02,  1.4661e-02,\n",
      "         2.4971e-02,  2.7032e-02, -1.9897e-02,  2.9087e-02,  2.9068e-02,\n",
      "         4.2148e-02,  2.0833e-02,  2.0202e-03,  8.6507e-03, -3.6682e-02,\n",
      "        -3.6164e-02,  2.0024e-02,  2.4021e-02,  4.0755e-02,  3.3313e-02,\n",
      "         2.9154e-02, -4.9917e-03,  3.0641e-02, -3.0929e-02, -2.4612e-02,\n",
      "         4.3379e-02, -1.0416e-03, -2.8874e-02, -3.9589e-02, -6.0176e-03,\n",
      "        -2.3122e-02, -1.2940e-02,  3.4873e-02,  1.6111e-02,  2.3060e-02,\n",
      "         1.5751e-02, -2.6424e-02,  1.9924e-02, -2.7042e-02, -1.8155e-02,\n",
      "         8.8702e-04,  3.0502e-02,  3.7572e-02,  4.0600e-02,  1.5537e-02,\n",
      "        -3.9275e-02,  4.0958e-02,  3.0698e-02,  1.8680e-02,  4.3603e-02,\n",
      "         1.8205e-02, -1.4308e-02,  1.7775e-02,  2.4687e-02, -7.5013e-03,\n",
      "         1.3215e-02, -1.1848e-02, -3.7877e-02,  3.6593e-02,  3.1994e-02,\n",
      "        -3.1432e-02, -5.9953e-03, -7.9809e-03, -1.7111e-03, -1.6033e-02,\n",
      "         6.7132e-03, -1.0825e-02, -3.8815e-02,  2.0334e-02, -2.1004e-02,\n",
      "         3.8541e-02,  1.1547e-02, -3.0053e-02,  2.0094e-02,  2.0630e-02,\n",
      "        -2.3774e-02,  3.0035e-02,  2.1649e-02, -3.8029e-02,  6.5994e-03,\n",
      "        -4.0697e-02, -4.1136e-02, -2.3911e-02, -1.7546e-02,  7.7354e-03,\n",
      "        -1.2529e-02], device='cuda:1', requires_grad=True)\n",
      "layers.1.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], device='cuda:1', requires_grad=True)\n",
      "layers.1.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.4.weight Parameter containing:\n",
      "tensor([[ 0.0141, -0.0612, -0.0127,  ...,  0.0169,  0.0015, -0.0405],\n",
      "        [-0.0611, -0.0308,  0.0571,  ...,  0.0249, -0.0542, -0.0270],\n",
      "        [-0.0185, -0.0246, -0.0158,  ..., -0.0256,  0.0250, -0.0312],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0224,  0.0069,  ..., -0.0342,  0.0268, -0.0420],\n",
      "        [-0.0589, -0.0130, -0.0527,  ..., -0.0172,  0.0177,  0.0196],\n",
      "        [ 0.0484,  0.0615, -0.0604,  ...,  0.0218,  0.0478,  0.0342]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.4.bias Parameter containing:\n",
      "tensor([ 0.0610, -0.0464,  0.0078,  0.0028,  0.0306,  0.0119,  0.0581,  0.0497,\n",
      "         0.0341,  0.0210,  0.0058,  0.0009,  0.0110, -0.0306,  0.0495, -0.0392,\n",
      "         0.0279, -0.0402,  0.0610,  0.0161, -0.0018,  0.0297, -0.0280,  0.0511,\n",
      "         0.0201,  0.0183, -0.0212, -0.0597, -0.0447, -0.0543, -0.0110,  0.0100,\n",
      "         0.0402,  0.0246,  0.0096, -0.0539,  0.0295,  0.0025,  0.0240, -0.0187,\n",
      "        -0.0607,  0.0513, -0.0498, -0.0283,  0.0251, -0.0406,  0.0314, -0.0557,\n",
      "         0.0586,  0.0128, -0.0468, -0.0183, -0.0544, -0.0348, -0.0425, -0.0143,\n",
      "         0.0436,  0.0275,  0.0367,  0.0434, -0.0239,  0.0186,  0.0512, -0.0097,\n",
      "        -0.0024,  0.0611,  0.0419, -0.0356,  0.0258,  0.0416,  0.0368, -0.0432,\n",
      "         0.0615,  0.0169, -0.0015,  0.0226,  0.0418, -0.0047,  0.0492,  0.0217,\n",
      "        -0.0262, -0.0445,  0.0580,  0.0328, -0.0080,  0.0422,  0.0446,  0.0585,\n",
      "        -0.0156,  0.0547, -0.0387, -0.0352,  0.0106, -0.0327, -0.0210, -0.0087,\n",
      "         0.0103, -0.0120, -0.0528, -0.0177,  0.0613,  0.0228, -0.0587, -0.0262,\n",
      "         0.0002,  0.0144, -0.0232, -0.0396, -0.0082, -0.0379, -0.0058,  0.0177,\n",
      "        -0.0468, -0.0580,  0.0480,  0.0510, -0.0620,  0.0117, -0.0161,  0.0079,\n",
      "        -0.0009, -0.0377,  0.0618, -0.0411, -0.0020, -0.0415, -0.0395,  0.0367],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.5.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:1', requires_grad=True)\n",
      "layers.5.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1', requires_grad=True)\n",
      "layers.8.weight Parameter containing:\n",
      "tensor([[ 0.0576, -0.0508,  0.0405,  ...,  0.0883,  0.0159, -0.0772],\n",
      "        [ 0.0438, -0.0032, -0.0877,  ...,  0.0263,  0.0700,  0.0276],\n",
      "        [-0.0245, -0.0688, -0.0698,  ..., -0.0339,  0.0738,  0.0557],\n",
      "        ...,\n",
      "        [ 0.0282, -0.0473,  0.0825,  ..., -0.0119,  0.0034,  0.0341],\n",
      "        [-0.0871,  0.0029,  0.0743,  ...,  0.0565,  0.0517,  0.0705],\n",
      "        [-0.0197, -0.0869,  0.0328,  ...,  0.0513, -0.0635, -0.0877]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.8.bias Parameter containing:\n",
      "tensor([ 0.0406, -0.0673, -0.0794, -0.0462, -0.0528,  0.0241,  0.0495,  0.0141,\n",
      "         0.0148, -0.0751,  0.0717, -0.0483,  0.0085, -0.0180, -0.0154,  0.0525,\n",
      "        -0.0801,  0.0784, -0.0637,  0.0251,  0.0822, -0.0411,  0.0233, -0.0442,\n",
      "        -0.0314, -0.0119,  0.0196, -0.0849,  0.0153, -0.0635, -0.0634, -0.0067,\n",
      "        -0.0066, -0.0555,  0.0675, -0.0024,  0.0132, -0.0472, -0.0232, -0.0444,\n",
      "        -0.0741,  0.0142, -0.0855,  0.0397,  0.0144,  0.0425,  0.0623,  0.0647,\n",
      "         0.0397, -0.0413,  0.0622, -0.0482, -0.0094,  0.0019, -0.0609,  0.0016,\n",
      "         0.0379, -0.0774,  0.0787,  0.0827, -0.0790,  0.0122, -0.0608,  0.0111],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.11.weight Parameter containing:\n",
      "tensor([[-0.0434,  0.1242, -0.1073,  ..., -0.0213, -0.0520, -0.0027],\n",
      "        [-0.0805, -0.0889, -0.0868,  ...,  0.0488,  0.1191, -0.0554],\n",
      "        [ 0.1245, -0.1052, -0.0716,  ...,  0.0981,  0.0616, -0.0802],\n",
      "        ...,\n",
      "        [ 0.0651,  0.0226, -0.0415,  ..., -0.0877,  0.1027, -0.0613],\n",
      "        [ 0.0777, -0.0088, -0.0808,  ..., -0.0027,  0.0561, -0.0012],\n",
      "        [-0.0080, -0.0390,  0.1155,  ...,  0.0069,  0.0100, -0.0381]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.11.bias Parameter containing:\n",
      "tensor([-0.0463, -0.0482,  0.0280, -0.0686, -0.0988, -0.0673, -0.0733, -0.1123,\n",
      "        -0.0716,  0.0571,  0.1165, -0.0762, -0.0144, -0.1066, -0.0080,  0.1027,\n",
      "        -0.0611,  0.0536,  0.1062,  0.0387, -0.0515, -0.0200, -0.0940,  0.0399,\n",
      "         0.0301, -0.0883,  0.1065,  0.0029, -0.1145,  0.0316, -0.0973,  0.0511],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.14.weight Parameter containing:\n",
      "tensor([[-0.0971,  0.0295, -0.0225,  0.0239, -0.1520,  0.1699,  0.0225, -0.1767,\n",
      "          0.0170,  0.1671, -0.0814,  0.0968,  0.1382,  0.0079,  0.0542,  0.1710,\n",
      "         -0.0563, -0.0667,  0.1051,  0.0428,  0.0532,  0.0223,  0.1251, -0.1670,\n",
      "         -0.0083, -0.0346,  0.0146,  0.0528,  0.1368,  0.0705, -0.0603,  0.0953],\n",
      "        [-0.1694, -0.0520,  0.0938, -0.1290,  0.1668,  0.1620, -0.0568,  0.0593,\n",
      "         -0.0088,  0.0803, -0.1614,  0.1681, -0.1018, -0.1176,  0.0847,  0.0355,\n",
      "          0.0374,  0.0165, -0.1625,  0.0556,  0.0378,  0.1437,  0.0892, -0.0136,\n",
      "         -0.0874,  0.1341,  0.0373,  0.0562,  0.0382,  0.1480,  0.0607, -0.1694],\n",
      "        [ 0.0902, -0.0152, -0.1387,  0.0800, -0.0626, -0.0819, -0.1462,  0.0383,\n",
      "          0.1084, -0.0776,  0.0205, -0.0499,  0.1565, -0.0380,  0.0080, -0.0395,\n",
      "         -0.0784,  0.0665,  0.1619, -0.1342,  0.1647, -0.1115,  0.0578,  0.1038,\n",
      "         -0.0358,  0.1442,  0.1339, -0.0072, -0.0602,  0.1479, -0.1150, -0.0521]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "layers.14.bias Parameter containing:\n",
      "tensor([-0.0501, -0.0712, -0.0604], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "hgnn_trainer.layers\n",
    "for n,p in hgnn_trainer.named_parameters():\n",
    "    print(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: 1092.68896484375\n",
      "                , loss1: 999.71162109375\n",
      "                , loss2: 92.97738647460938\n",
      "=================================\n",
      "in 10 epoch, average loss: 10704.05625\n",
      "                , loss1: 9999.51171875\n",
      "                , loss2: 704.5443359375\n",
      "=================================\n",
      "in 20 epoch, average loss: 10445.846875\n",
      "                , loss1: 10002.98125\n",
      "                , loss2: 442.866845703125\n",
      "=================================\n",
      "in 30 epoch, average loss: 10252.75546875\n",
      "                , loss1: 10005.871875\n",
      "                , loss2: 246.8821533203125\n",
      "=================================\n",
      "in 40 epoch, average loss: 10134.4359375\n",
      "                , loss1: 10007.559375\n",
      "                , loss2: 126.87652587890625\n",
      "=================================\n",
      "in 50 epoch, average loss: 10063.0703125\n",
      "                , loss1: 10008.603125\n",
      "                , loss2: 54.466497802734374\n",
      "=================================\n",
      "in 60 epoch, average loss: 10029.6125\n",
      "                , loss1: 10008.93515625\n",
      "                , loss2: 20.675538635253908\n",
      "=================================\n",
      "in 70 epoch, average loss: 10015.4078125\n",
      "                , loss1: 10009.3765625\n",
      "                , loss2: 6.031185913085937\n",
      "=================================\n",
      "in 80 epoch, average loss: 10010.0203125\n",
      "                , loss1: 10009.25546875\n",
      "                , loss2: 0.7649863243103028\n",
      "=================================\n",
      "in 90 epoch, average loss: 10009.94140625\n",
      "                , loss1: 10009.25390625\n",
      "                , loss2: 0.6869968891143798\n",
      "=================================\n",
      "in 100 epoch, average loss: 10009.696875\n",
      "                , loss1: 10009.3328125\n",
      "                , loss2: 0.3646153688430786\n",
      "=================================\n",
      "in 110 epoch, average loss: 10009.575\n",
      "                , loss1: 10009.36328125\n",
      "                , loss2: 0.21258292198181153\n",
      "=================================\n",
      "in 120 epoch, average loss: 10009.6234375\n",
      "                , loss1: 10009.2703125\n",
      "                , loss2: 0.3538097143173218\n",
      "=================================\n",
      "in 130 epoch, average loss: 10009.62265625\n",
      "                , loss1: 10009.30625\n",
      "                , loss2: 0.31538116931915283\n",
      "=================================\n",
      "in 140 epoch, average loss: 10009.58203125\n",
      "                , loss1: 10009.2203125\n",
      "                , loss2: 0.36097021102905275\n",
      "=================================\n",
      "in 150 epoch, average loss: 10009.55546875\n",
      "                , loss1: 10009.28671875\n",
      "                , loss2: 0.26951310634613035\n",
      "=================================\n",
      "in 160 epoch, average loss: 10009.4140625\n",
      "                , loss1: 10009.25078125\n",
      "                , loss2: 0.16349291801452637\n",
      "=================================\n",
      "in 170 epoch, average loss: 10009.64375\n",
      "                , loss1: 10009.28125\n",
      "                , loss2: 0.3635401725769043\n",
      "=================================\n",
      "in 180 epoch, average loss: 10009.56953125\n",
      "                , loss1: 10009.2\n",
      "                , loss2: 0.3703482151031494\n",
      "=================================\n",
      "in 190 epoch, average loss: 10009.66015625\n",
      "                , loss1: 10009.25625\n",
      "                , loss2: 0.4046112060546875\n",
      "=================================\n",
      "in 200 epoch, average loss: 10009.51171875\n",
      "                , loss1: 10009.19375\n",
      "                , loss2: 0.3176247596740723\n",
      "=================================\n",
      "in 210 epoch, average loss: 10009.40625\n",
      "                , loss1: 10009.16953125\n",
      "                , loss2: 0.23646013736724852\n",
      "=================================\n",
      "in 220 epoch, average loss: 10009.45703125\n",
      "                , loss1: 10009.171875\n",
      "                , loss2: 0.28528594970703125\n",
      "=================================\n",
      "in 230 epoch, average loss: 10009.659375\n",
      "                , loss1: 10009.20390625\n",
      "                , loss2: 0.4554089069366455\n",
      "=================================\n",
      "in 240 epoch, average loss: 10009.4984375\n",
      "                , loss1: 10009.13515625\n",
      "                , loss2: 0.3629593849182129\n",
      "=================================\n",
      "in 250 epoch, average loss: 10009.48671875\n",
      "                , loss1: 10009.11796875\n",
      "                , loss2: 0.36861655712127683\n",
      "=================================\n",
      "in 260 epoch, average loss: 10009.31796875\n",
      "                , loss1: 10009.171875\n",
      "                , loss2: 0.14536248445510863\n",
      "=================================\n",
      "in 270 epoch, average loss: 10009.4875\n",
      "                , loss1: 10009.13671875\n",
      "                , loss2: 0.3509302377700806\n",
      "=================================\n",
      "in 280 epoch, average loss: 10009.28125\n",
      "                , loss1: 10009.0328125\n",
      "                , loss2: 0.24820566177368164\n",
      "=================================\n",
      "in 290 epoch, average loss: 10009.20625\n",
      "                , loss1: 10008.94140625\n",
      "                , loss2: 0.26414918899536133\n",
      "=================================\n",
      "in 300 epoch, average loss: 10009.39296875\n",
      "                , loss1: 10009.1015625\n",
      "                , loss2: 0.2919086217880249\n",
      "=================================\n",
      "in 310 epoch, average loss: 10009.51953125\n",
      "                , loss1: 10009.0484375\n",
      "                , loss2: 0.47081823348999025\n",
      "=================================\n",
      "in 320 epoch, average loss: 10009.228125\n",
      "                , loss1: 10008.9078125\n",
      "                , loss2: 0.321474552154541\n",
      "=================================\n",
      "in 330 epoch, average loss: 10009.23125\n",
      "                , loss1: 10008.94765625\n",
      "                , loss2: 0.2833590507507324\n",
      "=================================\n",
      "in 340 epoch, average loss: 10009.1625\n",
      "                , loss1: 10008.8953125\n",
      "                , loss2: 0.2667792558670044\n",
      "=================================\n",
      "in 350 epoch, average loss: 10009.12578125\n",
      "                , loss1: 10008.84375\n",
      "                , loss2: 0.2828019857406616\n",
      "=================================\n",
      "in 360 epoch, average loss: 10009.26953125\n",
      "                , loss1: 10008.92578125\n",
      "                , loss2: 0.34331915378570554\n",
      "=================================\n",
      "in 370 epoch, average loss: 10009.20234375\n",
      "                , loss1: 10008.7734375\n",
      "                , loss2: 0.4279811859130859\n",
      "=================================\n",
      "in 380 epoch, average loss: 10009.41015625\n",
      "                , loss1: 10008.89375\n",
      "                , loss2: 0.516239070892334\n",
      "=================================\n",
      "in 390 epoch, average loss: 10009.15390625\n",
      "                , loss1: 10008.79609375\n",
      "                , loss2: 0.35843963623046876\n",
      "=================================\n",
      "in 400 epoch, average loss: 10008.9546875\n",
      "                , loss1: 10008.71328125\n",
      "                , loss2: 0.24137358665466307\n",
      "=================================\n",
      "in 410 epoch, average loss: 10009.09765625\n",
      "                , loss1: 10008.59609375\n",
      "                , loss2: 0.5008453845977783\n",
      "=================================\n",
      "in 420 epoch, average loss: 10009.11953125\n",
      "                , loss1: 10008.76484375\n",
      "                , loss2: 0.35454087257385253\n",
      "=================================\n",
      "in 430 epoch, average loss: 10008.9484375\n",
      "                , loss1: 10008.6328125\n",
      "                , loss2: 0.3142394542694092\n",
      "=================================\n",
      "in 440 epoch, average loss: 10008.78671875\n",
      "                , loss1: 10008.54296875\n",
      "                , loss2: 0.24456140995025635\n",
      "=================================\n",
      "in 450 epoch, average loss: 10008.81953125\n",
      "                , loss1: 10008.54375\n",
      "                , loss2: 0.2766376256942749\n",
      "=================================\n",
      "in 460 epoch, average loss: 10008.7640625\n",
      "                , loss1: 10008.4359375\n",
      "                , loss2: 0.3286996841430664\n",
      "=================================\n",
      "in 470 epoch, average loss: 10008.55234375\n",
      "                , loss1: 10008.37421875\n",
      "                , loss2: 0.17888816595077514\n",
      "=================================\n",
      "in 480 epoch, average loss: 10008.64296875\n",
      "                , loss1: 10008.39765625\n",
      "                , loss2: 0.24466338157653808\n",
      "=================================\n",
      "in 490 epoch, average loss: 10008.6734375\n",
      "                , loss1: 10008.340625\n",
      "                , loss2: 0.3323520660400391\n",
      "=================================\n",
      "in 500 epoch, average loss: 10008.428125\n",
      "                , loss1: 10008.21484375\n",
      "                , loss2: 0.21287219524383544\n",
      "=================================\n",
      "in 510 epoch, average loss: 10008.84296875\n",
      "                , loss1: 10008.3171875\n",
      "                , loss2: 0.5255755424499512\n",
      "=================================\n",
      "in 520 epoch, average loss: 10008.40625\n",
      "                , loss1: 10008.18125\n",
      "                , loss2: 0.22548575401306153\n",
      "=================================\n",
      "in 530 epoch, average loss: 10008.4625\n",
      "                , loss1: 10008.12890625\n",
      "                , loss2: 0.33325483798980715\n",
      "=================================\n",
      "in 540 epoch, average loss: 10008.49609375\n",
      "                , loss1: 10008.1015625\n",
      "                , loss2: 0.3945704460144043\n",
      "=================================\n",
      "in 550 epoch, average loss: 10008.54453125\n",
      "                , loss1: 10008.0890625\n",
      "                , loss2: 0.45557656288146975\n",
      "=================================\n",
      "in 560 epoch, average loss: 10008.14921875\n",
      "                , loss1: 10007.8921875\n",
      "                , loss2: 0.2569820165634155\n",
      "=================================\n",
      "in 570 epoch, average loss: 10008.096875\n",
      "                , loss1: 10007.77109375\n",
      "                , loss2: 0.3264949083328247\n",
      "=================================\n",
      "in 580 epoch, average loss: 10008.2609375\n",
      "                , loss1: 10007.7578125\n",
      "                , loss2: 0.5038678646087646\n",
      "=================================\n",
      "in 590 epoch, average loss: 10008.0\n",
      "                , loss1: 10007.65625\n",
      "                , loss2: 0.34330732822418214\n",
      "=================================\n",
      "in 600 epoch, average loss: 10007.5328125\n",
      "                , loss1: 10007.3625\n",
      "                , loss2: 0.16971771717071532\n",
      "=================================\n",
      "in 610 epoch, average loss: 10008.1734375\n",
      "                , loss1: 10007.3796875\n",
      "                , loss2: 0.7932600021362305\n",
      "=================================\n",
      "in 620 epoch, average loss: 10007.5625\n",
      "                , loss1: 10007.25625\n",
      "                , loss2: 0.30693042278289795\n",
      "=================================\n",
      "in 630 epoch, average loss: 10007.28828125\n",
      "                , loss1: 10006.98515625\n",
      "                , loss2: 0.3031515836715698\n",
      "=================================\n",
      "in 640 epoch, average loss: 10007.36796875\n",
      "                , loss1: 10006.86875\n",
      "                , loss2: 0.4996648788452148\n",
      "=================================\n",
      "in 650 epoch, average loss: 10006.8140625\n",
      "                , loss1: 10006.496875\n",
      "                , loss2: 0.3179983615875244\n",
      "=================================\n",
      "in 660 epoch, average loss: 10006.8140625\n",
      "                , loss1: 10006.5328125\n",
      "                , loss2: 0.28113200664520266\n",
      "=================================\n",
      "in 670 epoch, average loss: 10006.446875\n",
      "                , loss1: 10005.96484375\n",
      "                , loss2: 0.48182291984558107\n",
      "=================================\n",
      "in 680 epoch, average loss: 10006.3015625\n",
      "                , loss1: 10005.9234375\n",
      "                , loss2: 0.37791054248809813\n",
      "=================================\n",
      "in 690 epoch, average loss: 10005.80546875\n",
      "                , loss1: 10005.2734375\n",
      "                , loss2: 0.5323750495910644\n",
      "=================================\n",
      "in 700 epoch, average loss: 10005.771875\n",
      "                , loss1: 10005.3125\n",
      "                , loss2: 0.45919365882873536\n",
      "=================================\n",
      "in 710 epoch, average loss: 10005.07734375\n",
      "                , loss1: 10004.50625\n",
      "                , loss2: 0.5702591419219971\n",
      "=================================\n",
      "in 720 epoch, average loss: 10004.93984375\n",
      "                , loss1: 10004.475\n",
      "                , loss2: 0.463334846496582\n",
      "=================================\n",
      "in 730 epoch, average loss: 10004.253125\n",
      "                , loss1: 10003.92109375\n",
      "                , loss2: 0.33211379051208495\n",
      "=================================\n",
      "in 740 epoch, average loss: 10003.15703125\n",
      "                , loss1: 10002.8234375\n",
      "                , loss2: 0.3337759256362915\n",
      "=================================\n",
      "in 750 epoch, average loss: 10002.140625\n",
      "                , loss1: 10001.78046875\n",
      "                , loss2: 0.35928988456726074\n",
      "=================================\n",
      "in 760 epoch, average loss: 10001.3984375\n",
      "                , loss1: 10000.9578125\n",
      "                , loss2: 0.44021267890930177\n",
      "=================================\n",
      "in 770 epoch, average loss: 10000.19921875\n",
      "                , loss1: 9999.940625\n",
      "                , loss2: 0.25866677761077883\n",
      "=================================\n",
      "in 780 epoch, average loss: 9997.6421875\n",
      "                , loss1: 9997.3640625\n",
      "                , loss2: 0.27747042179107667\n",
      "=================================\n",
      "in 790 epoch, average loss: 9996.80625\n",
      "                , loss1: 9996.325\n",
      "                , loss2: 0.4810655117034912\n",
      "=================================\n",
      "in 800 epoch, average loss: 9992.19921875\n",
      "                , loss1: 9991.809375\n",
      "                , loss2: 0.3903312921524048\n",
      "=================================\n",
      "in 810 epoch, average loss: 9986.93125\n",
      "                , loss1: 9986.43984375\n",
      "                , loss2: 0.49067234992980957\n",
      "=================================\n",
      "in 820 epoch, average loss: 9974.35078125\n",
      "                , loss1: 9973.8453125\n",
      "                , loss2: 0.5051286220550537\n",
      "=================================\n",
      "in 830 epoch, average loss: 9949.003125\n",
      "                , loss1: 9948.2515625\n",
      "                , loss2: 0.7517617702484131\n",
      "=================================\n",
      "in 840 epoch, average loss: 9904.00234375\n",
      "                , loss1: 9902.040625\n",
      "                , loss2: 1.961330032348633\n",
      "=================================\n",
      "in 850 epoch, average loss: 9851.68125\n",
      "                , loss1: 9849.0828125\n",
      "                , loss2: 2.5978769302368163\n",
      "=================================\n",
      "in 860 epoch, average loss: 9781.703125\n",
      "                , loss1: 9777.96015625\n",
      "                , loss2: 3.743150329589844\n",
      "=================================\n",
      "in 870 epoch, average loss: 9683.92578125\n",
      "                , loss1: 9676.2203125\n",
      "                , loss2: 7.70548095703125\n",
      "=================================\n",
      "in 880 epoch, average loss: 9557.67890625\n",
      "                , loss1: 9544.22734375\n",
      "                , loss2: 13.451626586914063\n",
      "=================================\n",
      "in 890 epoch, average loss: 9419.440625\n",
      "                , loss1: 9406.0921875\n",
      "                , loss2: 13.348573303222656\n",
      "=================================\n",
      "in 900 epoch, average loss: 9264.9453125\n",
      "                , loss1: 9252.83984375\n",
      "                , loss2: 12.1037109375\n",
      "=================================\n",
      "in 910 epoch, average loss: 9068.8796875\n",
      "                , loss1: 9056.93359375\n",
      "                , loss2: 11.946177673339843\n",
      "=================================\n",
      "in 920 epoch, average loss: 8888.85234375\n",
      "                , loss1: 8881.225\n",
      "                , loss2: 7.625933074951172\n",
      "=================================\n",
      "in 930 epoch, average loss: 8677.10625\n",
      "                , loss1: 8660.4171875\n",
      "                , loss2: 16.68932342529297\n",
      "=================================\n",
      "in 940 epoch, average loss: 8419.6265625\n",
      "                , loss1: 8413.184375\n",
      "                , loss2: 6.443320465087891\n",
      "=================================\n",
      "in 950 epoch, average loss: 8154.52109375\n",
      "                , loss1: 8142.91796875\n",
      "                , loss2: 11.602047729492188\n",
      "=================================\n",
      "in 960 epoch, average loss: 7830.53203125\n",
      "                , loss1: 7816.8546875\n",
      "                , loss2: 13.677803039550781\n",
      "=================================\n",
      "in 970 epoch, average loss: 7504.94140625\n",
      "                , loss1: 7493.765625\n",
      "                , loss2: 11.175981140136718\n",
      "=================================\n",
      "in 980 epoch, average loss: 7091.03515625\n",
      "                , loss1: 7067.846875\n",
      "                , loss2: 23.187484741210938\n",
      "=================================\n",
      "in 990 epoch, average loss: 6733.77578125\n",
      "                , loss1: 6726.35859375\n",
      "                , loss2: 7.4178009033203125\n",
      "=================================\n",
      "in 1000 epoch, average loss: 6376.255078125\n",
      "                , loss1: 6363.702734375\n",
      "                , loss2: 12.552003479003906\n",
      "=================================\n",
      "in 1010 epoch, average loss: 6071.413671875\n",
      "                , loss1: 6060.923828125\n",
      "                , loss2: 10.490519714355468\n",
      "=================================\n",
      "in 1020 epoch, average loss: 5726.558984375\n",
      "                , loss1: 5717.519921875\n",
      "                , loss2: 9.039486694335938\n",
      "=================================\n",
      "in 1030 epoch, average loss: 5372.480078125\n",
      "                , loss1: 5368.32890625\n",
      "                , loss2: 4.15136833190918\n",
      "=================================\n",
      "in 1040 epoch, average loss: 5007.719921875\n",
      "                , loss1: 4998.65859375\n",
      "                , loss2: 9.061737823486329\n",
      "=================================\n",
      "in 1050 epoch, average loss: 4611.586328125\n",
      "                , loss1: 4605.36953125\n",
      "                , loss2: 6.217308425903321\n",
      "=================================\n",
      "in 1060 epoch, average loss: 4268.47890625\n",
      "                , loss1: 4261.369140625\n",
      "                , loss2: 7.110179138183594\n",
      "=================================\n",
      "in 1070 epoch, average loss: 3929.969140625\n",
      "                , loss1: 3918.520703125\n",
      "                , loss2: 11.448616027832031\n",
      "=================================\n",
      "in 1080 epoch, average loss: 3587.76171875\n",
      "                , loss1: 3571.605859375\n",
      "                , loss2: 16.15556945800781\n",
      "=================================\n",
      "in 1090 epoch, average loss: 3277.030859375\n",
      "                , loss1: 3267.2693359375\n",
      "                , loss2: 9.761868286132813\n",
      "=================================\n",
      "in 1100 epoch, average loss: 3005.5240234375\n",
      "                , loss1: 2995.7935546875\n",
      "                , loss2: 9.73050765991211\n",
      "=================================\n",
      "in 1110 epoch, average loss: 2782.614453125\n",
      "                , loss1: 2776.06328125\n",
      "                , loss2: 6.551239013671875\n",
      "=================================\n",
      "in 1120 epoch, average loss: 2584.5291015625\n",
      "                , loss1: 2580.4591796875\n",
      "                , loss2: 4.069887924194336\n",
      "=================================\n",
      "in 1130 epoch, average loss: 2415.190234375\n",
      "                , loss1: 2411.583203125\n",
      "                , loss2: 3.607047271728516\n",
      "=================================\n",
      "in 1140 epoch, average loss: 2297.3107421875\n",
      "                , loss1: 2291.2357421875\n",
      "                , loss2: 6.074846649169922\n",
      "=================================\n",
      "in 1150 epoch, average loss: 2157.059765625\n",
      "                , loss1: 2154.8921875\n",
      "                , loss2: 2.16720027923584\n",
      "=================================\n",
      "in 1160 epoch, average loss: 1998.5890625\n",
      "                , loss1: 1994.8060546875\n",
      "                , loss2: 3.783064270019531\n",
      "=================================\n",
      "in 1170 epoch, average loss: 1897.226171875\n",
      "                , loss1: 1893.606640625\n",
      "                , loss2: 3.6195709228515627\n",
      "=================================\n",
      "in 1180 epoch, average loss: 1805.091796875\n",
      "                , loss1: 1801.228515625\n",
      "                , loss2: 3.863195037841797\n",
      "=================================\n",
      "in 1190 epoch, average loss: 1718.6814453125\n",
      "                , loss1: 1712.5515625\n",
      "                , loss2: 6.129864501953125\n",
      "=================================\n",
      "in 1200 epoch, average loss: 1642.7640625\n",
      "                , loss1: 1638.833984375\n",
      "                , loss2: 3.930187225341797\n",
      "=================================\n",
      "in 1210 epoch, average loss: 1576.24189453125\n",
      "                , loss1: 1573.82158203125\n",
      "                , loss2: 2.420481491088867\n",
      "=================================\n",
      "in 1220 epoch, average loss: 1512.99912109375\n",
      "                , loss1: 1509.873828125\n",
      "                , loss2: 3.125253677368164\n",
      "=================================\n",
      "in 1230 epoch, average loss: 1450.1171875\n",
      "                , loss1: 1446.95654296875\n",
      "                , loss2: 3.1606130599975586\n",
      "=================================\n",
      "in 1240 epoch, average loss: 1409.49755859375\n",
      "                , loss1: 1406.26552734375\n",
      "                , loss2: 3.2320072174072267\n",
      "=================================\n",
      "in 1250 epoch, average loss: 1370.64267578125\n",
      "                , loss1: 1368.3048828125\n",
      "                , loss2: 2.3378421783447267\n",
      "=================================\n",
      "in 1260 epoch, average loss: 1331.98125\n",
      "                , loss1: 1330.09609375\n",
      "                , loss2: 1.8852338790893555\n",
      "=================================\n",
      "in 1270 epoch, average loss: 1290.79228515625\n",
      "                , loss1: 1288.81279296875\n",
      "                , loss2: 1.9797313690185547\n",
      "=================================\n",
      "in 1280 epoch, average loss: 1238.881640625\n",
      "                , loss1: 1236.63974609375\n",
      "                , loss2: 2.2419658660888673\n",
      "=================================\n",
      "in 1290 epoch, average loss: 1209.6087890625\n",
      "                , loss1: 1207.326171875\n",
      "                , loss2: 2.2825153350830076\n",
      "=================================\n",
      "in 1300 epoch, average loss: 1174.09384765625\n",
      "                , loss1: 1170.92333984375\n",
      "                , loss2: 3.1705144882202148\n",
      "=================================\n",
      "in 1310 epoch, average loss: 1155.50283203125\n",
      "                , loss1: 1153.3076171875\n",
      "                , loss2: 2.195179557800293\n",
      "=================================\n",
      "in 1320 epoch, average loss: 1132.9916015625\n",
      "                , loss1: 1130.7984375\n",
      "                , loss2: 2.1930604934692384\n",
      "=================================\n",
      "in 1330 epoch, average loss: 1118.591796875\n",
      "                , loss1: 1115.9376953125\n",
      "                , loss2: 2.6542684555053713\n",
      "=================================\n",
      "in 1340 epoch, average loss: 1100.64619140625\n",
      "                , loss1: 1098.7326171875\n",
      "                , loss2: 1.913620376586914\n",
      "=================================\n",
      "in 1350 epoch, average loss: 1090.47001953125\n",
      "                , loss1: 1087.5255859375\n",
      "                , loss2: 2.9444515228271486\n",
      "=================================\n",
      "in 1360 epoch, average loss: 1067.86123046875\n",
      "                , loss1: 1065.53955078125\n",
      "                , loss2: 2.3216005325317384\n",
      "=================================\n",
      "in 1370 epoch, average loss: 1054.5203125\n",
      "                , loss1: 1052.050390625\n",
      "                , loss2: 2.46991081237793\n",
      "=================================\n",
      "in 1380 epoch, average loss: 1043.2720703125\n",
      "                , loss1: 1040.319921875\n",
      "                , loss2: 2.952102279663086\n",
      "=================================\n",
      "in 1390 epoch, average loss: 1042.3931640625\n",
      "                , loss1: 1040.62119140625\n",
      "                , loss2: 1.7719566345214843\n",
      "=================================\n",
      "in 1400 epoch, average loss: 1027.82958984375\n",
      "                , loss1: 1025.610546875\n",
      "                , loss2: 2.219151496887207\n",
      "=================================\n",
      "in 1410 epoch, average loss: 1023.77529296875\n",
      "                , loss1: 1021.69345703125\n",
      "                , loss2: 2.081770896911621\n",
      "=================================\n",
      "in 1420 epoch, average loss: 1009.7064453125\n",
      "                , loss1: 1008.276953125\n",
      "                , loss2: 1.4295077323913574\n",
      "=================================\n",
      "in 1430 epoch, average loss: 1000.676953125\n",
      "                , loss1: 998.97294921875\n",
      "                , loss2: 1.704086685180664\n",
      "=================================\n",
      "in 1440 epoch, average loss: 992.1232421875\n",
      "                , loss1: 989.84697265625\n",
      "                , loss2: 2.276337242126465\n",
      "=================================\n",
      "in 1450 epoch, average loss: 988.27216796875\n",
      "                , loss1: 985.8037109375\n",
      "                , loss2: 2.468548393249512\n",
      "=================================\n",
      "in 1460 epoch, average loss: 977.815625\n",
      "                , loss1: 975.9966796875\n",
      "                , loss2: 1.8189773559570312\n",
      "=================================\n",
      "in 1470 epoch, average loss: 970.528515625\n",
      "                , loss1: 968.51015625\n",
      "                , loss2: 2.0183868408203125\n",
      "=================================\n",
      "in 1480 epoch, average loss: 975.765625\n",
      "                , loss1: 973.47265625\n",
      "                , loss2: 2.2930273056030273\n",
      "=================================\n",
      "in 1490 epoch, average loss: 958.1576171875\n",
      "                , loss1: 955.77822265625\n",
      "                , loss2: 2.379386329650879\n",
      "=================================\n",
      "in 1500 epoch, average loss: 951.9650390625\n",
      "                , loss1: 949.68369140625\n",
      "                , loss2: 2.281325912475586\n",
      "=================================\n",
      "in 1510 epoch, average loss: 953.31875\n",
      "                , loss1: 951.0953125\n",
      "                , loss2: 2.2234704971313475\n",
      "=================================\n",
      "in 1520 epoch, average loss: 946.08505859375\n",
      "                , loss1: 943.60966796875\n",
      "                , loss2: 2.475269317626953\n",
      "=================================\n",
      "in 1530 epoch, average loss: 946.83486328125\n",
      "                , loss1: 944.063671875\n",
      "                , loss2: 2.7712907791137695\n",
      "=================================\n",
      "in 1540 epoch, average loss: 936.84091796875\n",
      "                , loss1: 934.04443359375\n",
      "                , loss2: 2.796531105041504\n",
      "=================================\n",
      "in 1550 epoch, average loss: 933.7904296875\n",
      "                , loss1: 931.50615234375\n",
      "                , loss2: 2.2842479705810548\n",
      "=================================\n",
      "in 1560 epoch, average loss: 934.48662109375\n",
      "                , loss1: 931.6216796875\n",
      "                , loss2: 2.8649829864501952\n",
      "=================================\n",
      "in 1570 epoch, average loss: 935.04150390625\n",
      "                , loss1: 932.941015625\n",
      "                , loss2: 2.1004573822021486\n",
      "=================================\n",
      "in 1580 epoch, average loss: 928.10234375\n",
      "                , loss1: 926.27587890625\n",
      "                , loss2: 1.8263750076293945\n",
      "=================================\n",
      "in 1590 epoch, average loss: 923.3767578125\n",
      "                , loss1: 921.98896484375\n",
      "                , loss2: 1.3877829551696776\n",
      "=================================\n",
      "in 1600 epoch, average loss: 916.3416015625\n",
      "                , loss1: 915.0931640625\n",
      "                , loss2: 1.248389720916748\n",
      "=================================\n",
      "in 1610 epoch, average loss: 914.36923828125\n",
      "                , loss1: 912.7484375\n",
      "                , loss2: 1.6207304000854492\n",
      "=================================\n",
      "in 1620 epoch, average loss: 917.67353515625\n",
      "                , loss1: 916.209375\n",
      "                , loss2: 1.4641304016113281\n",
      "=================================\n",
      "in 1630 epoch, average loss: 910.64990234375\n",
      "                , loss1: 909.59267578125\n",
      "                , loss2: 1.0573307991027832\n",
      "=================================\n",
      "in 1640 epoch, average loss: 919.719140625\n",
      "                , loss1: 918.405078125\n",
      "                , loss2: 1.3139653205871582\n",
      "=================================\n",
      "in 1650 epoch, average loss: 904.84951171875\n",
      "                , loss1: 903.208203125\n",
      "                , loss2: 1.6414390563964845\n",
      "=================================\n",
      "in 1660 epoch, average loss: 904.20888671875\n",
      "                , loss1: 902.52109375\n",
      "                , loss2: 1.6878242492675781\n",
      "=================================\n",
      "in 1670 epoch, average loss: 899.52568359375\n",
      "                , loss1: 897.6634765625\n",
      "                , loss2: 1.862227439880371\n",
      "=================================\n",
      "in 1680 epoch, average loss: 900.03623046875\n",
      "                , loss1: 898.25224609375\n",
      "                , loss2: 1.7840085983276368\n",
      "=================================\n",
      "in 1690 epoch, average loss: 898.6955078125\n",
      "                , loss1: 896.94599609375\n",
      "                , loss2: 1.749415969848633\n",
      "=================================\n",
      "in 1700 epoch, average loss: 896.83232421875\n",
      "                , loss1: 895.157421875\n",
      "                , loss2: 1.6748828887939453\n",
      "=================================\n",
      "in 1710 epoch, average loss: 893.75068359375\n",
      "                , loss1: 892.035546875\n",
      "                , loss2: 1.7151357650756835\n",
      "=================================\n",
      "in 1720 epoch, average loss: 894.224609375\n",
      "                , loss1: 892.30634765625\n",
      "                , loss2: 1.9182113647460937\n",
      "=================================\n",
      "in 1730 epoch, average loss: 892.68291015625\n",
      "                , loss1: 890.96162109375\n",
      "                , loss2: 1.7212223052978515\n",
      "=================================\n",
      "in 1740 epoch, average loss: 888.63740234375\n",
      "                , loss1: 886.8771484375\n",
      "                , loss2: 1.7603261947631836\n",
      "=================================\n",
      "in 1750 epoch, average loss: 888.20634765625\n",
      "                , loss1: 886.41962890625\n",
      "                , loss2: 1.7867469787597656\n",
      "=================================\n",
      "in 1760 epoch, average loss: 883.256640625\n",
      "                , loss1: 881.19140625\n",
      "                , loss2: 2.0652772903442385\n",
      "=================================\n",
      "in 1770 epoch, average loss: 885.37509765625\n",
      "                , loss1: 883.4375\n",
      "                , loss2: 1.9375802993774414\n",
      "=================================\n",
      "in 1780 epoch, average loss: 882.1310546875\n",
      "                , loss1: 879.9576171875\n",
      "                , loss2: 2.173362922668457\n",
      "=================================\n",
      "in 1790 epoch, average loss: 882.49248046875\n",
      "                , loss1: 880.66865234375\n",
      "                , loss2: 1.8238372802734375\n",
      "=================================\n",
      "in 1800 epoch, average loss: 877.09521484375\n",
      "                , loss1: 874.337109375\n",
      "                , loss2: 2.757966232299805\n",
      "=================================\n",
      "in 1810 epoch, average loss: 880.44501953125\n",
      "                , loss1: 878.4185546875\n",
      "                , loss2: 2.0265213012695313\n",
      "=================================\n",
      "in 1820 epoch, average loss: 879.3833984375\n",
      "                , loss1: 877.27021484375\n",
      "                , loss2: 2.113251876831055\n",
      "=================================\n",
      "in 1830 epoch, average loss: 875.088671875\n",
      "                , loss1: 872.89111328125\n",
      "                , loss2: 2.197634696960449\n",
      "=================================\n",
      "in 1840 epoch, average loss: 874.62275390625\n",
      "                , loss1: 872.26513671875\n",
      "                , loss2: 2.3575830459594727\n",
      "=================================\n",
      "in 1850 epoch, average loss: 876.9044921875\n",
      "                , loss1: 874.31396484375\n",
      "                , loss2: 2.590565490722656\n",
      "=================================\n",
      "in 1860 epoch, average loss: 875.48203125\n",
      "                , loss1: 872.9240234375\n",
      "                , loss2: 2.5579986572265625\n",
      "=================================\n",
      "in 1870 epoch, average loss: 874.27451171875\n",
      "                , loss1: 872.33486328125\n",
      "                , loss2: 1.9396923065185547\n",
      "=================================\n",
      "in 1880 epoch, average loss: 870.222265625\n",
      "                , loss1: 867.756640625\n",
      "                , loss2: 2.4655508041381835\n",
      "=================================\n",
      "in 1890 epoch, average loss: 873.57587890625\n",
      "                , loss1: 871.24189453125\n",
      "                , loss2: 2.3341114044189455\n",
      "=================================\n",
      "in 1900 epoch, average loss: 867.8556640625\n",
      "                , loss1: 865.524609375\n",
      "                , loss2: 2.3311794281005858\n",
      "=================================\n",
      "in 1910 epoch, average loss: 870.646484375\n",
      "                , loss1: 868.04951171875\n",
      "                , loss2: 2.5969261169433593\n",
      "=================================\n",
      "in 1920 epoch, average loss: 867.326171875\n",
      "                , loss1: 864.71572265625\n",
      "                , loss2: 2.610468101501465\n",
      "=================================\n",
      "in 1930 epoch, average loss: 868.83076171875\n",
      "                , loss1: 866.01279296875\n",
      "                , loss2: 2.8179683685302734\n",
      "=================================\n",
      "in 1940 epoch, average loss: 866.906640625\n",
      "                , loss1: 864.5748046875\n",
      "                , loss2: 2.331808662414551\n",
      "=================================\n",
      "in 1950 epoch, average loss: 867.44033203125\n",
      "                , loss1: 864.6271484375\n",
      "                , loss2: 2.8131221771240233\n",
      "=================================\n",
      "in 1960 epoch, average loss: 867.70302734375\n",
      "                , loss1: 865.16689453125\n",
      "                , loss2: 2.5361305236816407\n",
      "=================================\n",
      "in 1970 epoch, average loss: 863.76142578125\n",
      "                , loss1: 861.24658203125\n",
      "                , loss2: 2.514727783203125\n",
      "=================================\n",
      "in 1980 epoch, average loss: 863.35830078125\n",
      "                , loss1: 861.00234375\n",
      "                , loss2: 2.355991554260254\n",
      "=================================\n",
      "in 1990 epoch, average loss: 864.22314453125\n",
      "                , loss1: 861.56015625\n",
      "                , loss2: 2.6629106521606447\n",
      "=================================\n",
      "in 2000 epoch, average loss: 863.831640625\n",
      "                , loss1: 860.8228515625\n",
      "                , loss2: 3.0088666915893554\n",
      "=================================\n",
      "in 2010 epoch, average loss: 864.00263671875\n",
      "                , loss1: 861.42861328125\n",
      "                , loss2: 2.574015235900879\n",
      "=================================\n",
      "in 2020 epoch, average loss: 861.29140625\n",
      "                , loss1: 858.7580078125\n",
      "                , loss2: 2.5333980560302733\n",
      "=================================\n",
      "in 2030 epoch, average loss: 863.50654296875\n",
      "                , loss1: 860.47509765625\n",
      "                , loss2: 3.031385803222656\n",
      "=================================\n",
      "in 2040 epoch, average loss: 858.87763671875\n",
      "                , loss1: 855.8169921875\n",
      "                , loss2: 3.0607776641845703\n",
      "=================================\n",
      "in 2050 epoch, average loss: 857.915625\n",
      "                , loss1: 855.123046875\n",
      "                , loss2: 2.7926362991333007\n",
      "=================================\n",
      "in 2060 epoch, average loss: 858.34658203125\n",
      "                , loss1: 855.2216796875\n",
      "                , loss2: 3.1250127792358398\n",
      "=================================\n",
      "in 2070 epoch, average loss: 859.32490234375\n",
      "                , loss1: 856.5857421875\n",
      "                , loss2: 2.7391075134277343\n",
      "=================================\n",
      "in 2080 epoch, average loss: 855.3375\n",
      "                , loss1: 852.2396484375\n",
      "                , loss2: 3.0978904724121095\n",
      "=================================\n",
      "in 2090 epoch, average loss: 855.4408203125\n",
      "                , loss1: 852.5162109375\n",
      "                , loss2: 2.924541473388672\n",
      "=================================\n",
      "in 2100 epoch, average loss: 860.7978515625\n",
      "                , loss1: 857.95732421875\n",
      "                , loss2: 2.840537261962891\n",
      "=================================\n",
      "in 2110 epoch, average loss: 856.80751953125\n",
      "                , loss1: 853.7578125\n",
      "                , loss2: 3.0496726989746095\n",
      "=================================\n",
      "in 2120 epoch, average loss: 856.16337890625\n",
      "                , loss1: 853.39208984375\n",
      "                , loss2: 2.771305465698242\n",
      "=================================\n",
      "in 2130 epoch, average loss: 855.405859375\n",
      "                , loss1: 852.22451171875\n",
      "                , loss2: 3.1812980651855467\n",
      "=================================\n",
      "in 2140 epoch, average loss: 852.9390625\n",
      "                , loss1: 849.6251953125\n",
      "                , loss2: 3.3138801574707033\n",
      "=================================\n",
      "in 2150 epoch, average loss: 856.58359375\n",
      "                , loss1: 853.443359375\n",
      "                , loss2: 3.140259552001953\n",
      "=================================\n",
      "in 2160 epoch, average loss: 853.38203125\n",
      "                , loss1: 850.374609375\n",
      "                , loss2: 3.007325553894043\n",
      "=================================\n",
      "in 2170 epoch, average loss: 852.74404296875\n",
      "                , loss1: 849.7857421875\n",
      "                , loss2: 2.9583532333374025\n",
      "=================================\n",
      "in 2180 epoch, average loss: 851.53759765625\n",
      "                , loss1: 848.27841796875\n",
      "                , loss2: 3.2591320037841798\n",
      "=================================\n",
      "in 2190 epoch, average loss: 851.615625\n",
      "                , loss1: 848.31181640625\n",
      "                , loss2: 3.303801345825195\n",
      "=================================\n",
      "in 2200 epoch, average loss: 852.09365234375\n",
      "                , loss1: 848.840625\n",
      "                , loss2: 3.2529666900634764\n",
      "=================================\n",
      "in 2210 epoch, average loss: 850.276171875\n",
      "                , loss1: 846.86259765625\n",
      "                , loss2: 3.4134674072265625\n",
      "=================================\n",
      "in 2220 epoch, average loss: 850.700390625\n",
      "                , loss1: 847.2908203125\n",
      "                , loss2: 3.409659576416016\n",
      "=================================\n",
      "in 2230 epoch, average loss: 849.9236328125\n",
      "                , loss1: 846.53017578125\n",
      "                , loss2: 3.3934700012207033\n",
      "=================================\n",
      "in 2240 epoch, average loss: 850.6025390625\n",
      "                , loss1: 847.35615234375\n",
      "                , loss2: 3.2463520050048826\n",
      "=================================\n",
      "in 2250 epoch, average loss: 849.64619140625\n",
      "                , loss1: 846.3275390625\n",
      "                , loss2: 3.3186824798583983\n",
      "=================================\n",
      "in 2260 epoch, average loss: 849.351953125\n",
      "                , loss1: 846.44921875\n",
      "                , loss2: 2.902577209472656\n",
      "=================================\n",
      "in 2270 epoch, average loss: 846.51337890625\n",
      "                , loss1: 843.05400390625\n",
      "                , loss2: 3.4593467712402344\n",
      "=================================\n",
      "in 2280 epoch, average loss: 848.3072265625\n",
      "                , loss1: 844.92255859375\n",
      "                , loss2: 3.3846588134765625\n",
      "=================================\n",
      "in 2290 epoch, average loss: 847.225\n",
      "                , loss1: 843.681640625\n",
      "                , loss2: 3.5434036254882812\n",
      "=================================\n",
      "in 2300 epoch, average loss: 847.594921875\n",
      "                , loss1: 844.0201171875\n",
      "                , loss2: 3.5748245239257814\n",
      "=================================\n",
      "in 2310 epoch, average loss: 848.20439453125\n",
      "                , loss1: 844.51943359375\n",
      "                , loss2: 3.684824752807617\n",
      "=================================\n",
      "in 2320 epoch, average loss: 847.55615234375\n",
      "                , loss1: 844.02294921875\n",
      "                , loss2: 3.5330997467041017\n",
      "=================================\n",
      "in 2330 epoch, average loss: 845.81611328125\n",
      "                , loss1: 841.89111328125\n",
      "                , loss2: 3.9248703002929686\n",
      "=================================\n",
      "in 2340 epoch, average loss: 846.5888671875\n",
      "                , loss1: 842.9802734375\n",
      "                , loss2: 3.6086170196533205\n",
      "=================================\n",
      "in 2350 epoch, average loss: 845.38623046875\n",
      "                , loss1: 841.6791015625\n",
      "                , loss2: 3.707202911376953\n",
      "=================================\n",
      "in 2360 epoch, average loss: 846.16318359375\n",
      "                , loss1: 842.32275390625\n",
      "                , loss2: 3.840412139892578\n",
      "=================================\n",
      "in 2370 epoch, average loss: 843.82978515625\n",
      "                , loss1: 840.08525390625\n",
      "                , loss2: 3.7444957733154296\n",
      "=================================\n",
      "in 2380 epoch, average loss: 845.93359375\n",
      "                , loss1: 842.0515625\n",
      "                , loss2: 3.8819248199462892\n",
      "=================================\n",
      "in 2390 epoch, average loss: 845.21875\n",
      "                , loss1: 841.78037109375\n",
      "                , loss2: 3.438343048095703\n",
      "=================================\n",
      "in 2400 epoch, average loss: 845.00576171875\n",
      "                , loss1: 841.5212890625\n",
      "                , loss2: 3.4843978881835938\n",
      "=================================\n",
      "in 2410 epoch, average loss: 844.2998046875\n",
      "                , loss1: 840.628515625\n",
      "                , loss2: 3.671295166015625\n",
      "=================================\n",
      "in 2420 epoch, average loss: 842.92080078125\n",
      "                , loss1: 838.97158203125\n",
      "                , loss2: 3.9492782592773437\n",
      "=================================\n",
      "in 2430 epoch, average loss: 843.4365234375\n",
      "                , loss1: 839.41240234375\n",
      "                , loss2: 4.024190521240234\n",
      "=================================\n",
      "in 2440 epoch, average loss: 842.8759765625\n",
      "                , loss1: 839.0779296875\n",
      "                , loss2: 3.7978843688964843\n",
      "=================================\n",
      "in 2450 epoch, average loss: 843.3375\n",
      "                , loss1: 839.6244140625\n",
      "                , loss2: 3.713042449951172\n",
      "=================================\n",
      "in 2460 epoch, average loss: 842.89111328125\n",
      "                , loss1: 838.89130859375\n",
      "                , loss2: 3.999776077270508\n",
      "=================================\n",
      "in 2470 epoch, average loss: 841.78330078125\n",
      "                , loss1: 838.0251953125\n",
      "                , loss2: 3.7580677032470704\n",
      "=================================\n",
      "in 2480 epoch, average loss: 842.3064453125\n",
      "                , loss1: 838.40322265625\n",
      "                , loss2: 3.9032272338867187\n",
      "=================================\n",
      "in 2490 epoch, average loss: 841.597265625\n",
      "                , loss1: 837.42265625\n",
      "                , loss2: 4.174659347534179\n",
      "=================================\n",
      "in 2500 epoch, average loss: 841.0830078125\n",
      "                , loss1: 837.3376953125\n",
      "                , loss2: 3.7452438354492186\n",
      "=================================\n",
      "in 2510 epoch, average loss: 840.955859375\n",
      "                , loss1: 836.99140625\n",
      "                , loss2: 3.9644546508789062\n",
      "=================================\n",
      "in 2520 epoch, average loss: 840.29111328125\n",
      "                , loss1: 836.33994140625\n",
      "                , loss2: 3.9510948181152346\n",
      "=================================\n",
      "in 2530 epoch, average loss: 841.1828125\n",
      "                , loss1: 837.1267578125\n",
      "                , loss2: 4.056039047241211\n",
      "=================================\n",
      "in 2540 epoch, average loss: 840.0017578125\n",
      "                , loss1: 836.199609375\n",
      "                , loss2: 3.802217483520508\n",
      "=================================\n",
      "in 2550 epoch, average loss: 840.341796875\n",
      "                , loss1: 837.183203125\n",
      "                , loss2: 3.158574676513672\n",
      "=================================\n",
      "in 2560 epoch, average loss: 838.30703125\n",
      "                , loss1: 835.534375\n",
      "                , loss2: 2.7726415634155273\n",
      "=================================\n",
      "in 2570 epoch, average loss: 838.89638671875\n",
      "                , loss1: 835.9552734375\n",
      "                , loss2: 2.9411510467529296\n",
      "=================================\n",
      "in 2580 epoch, average loss: 839.940234375\n",
      "                , loss1: 836.82314453125\n",
      "                , loss2: 3.1171010971069335\n",
      "=================================\n",
      "in 2590 epoch, average loss: 838.6998046875\n",
      "                , loss1: 835.2671875\n",
      "                , loss2: 3.4325992584228517\n",
      "=================================\n",
      "in 2600 epoch, average loss: 838.2697265625\n",
      "                , loss1: 835.2228515625\n",
      "                , loss2: 3.0468767166137694\n",
      "=================================\n",
      "in 2610 epoch, average loss: 837.2173828125\n",
      "                , loss1: 834.10439453125\n",
      "                , loss2: 3.113089752197266\n",
      "=================================\n",
      "in 2620 epoch, average loss: 836.741796875\n",
      "                , loss1: 833.4171875\n",
      "                , loss2: 3.3246318817138674\n",
      "=================================\n",
      "in 2630 epoch, average loss: 836.49111328125\n",
      "                , loss1: 833.2513671875\n",
      "                , loss2: 3.239771270751953\n",
      "=================================\n",
      "in 2640 epoch, average loss: 837.11953125\n",
      "                , loss1: 833.92138671875\n",
      "                , loss2: 3.1982389450073243\n",
      "=================================\n",
      "in 2650 epoch, average loss: 837.7150390625\n",
      "                , loss1: 834.4203125\n",
      "                , loss2: 3.2947307586669923\n",
      "=================================\n",
      "in 2660 epoch, average loss: 836.6390625\n",
      "                , loss1: 833.4474609375\n",
      "                , loss2: 3.1915760040283203\n",
      "=================================\n",
      "in 2670 epoch, average loss: 836.25986328125\n",
      "                , loss1: 832.98701171875\n",
      "                , loss2: 3.2728740692138674\n",
      "=================================\n",
      "in 2680 epoch, average loss: 836.687890625\n",
      "                , loss1: 833.5728515625\n",
      "                , loss2: 3.11514835357666\n",
      "=================================\n",
      "in 2690 epoch, average loss: 835.52275390625\n",
      "                , loss1: 832.28515625\n",
      "                , loss2: 3.237512969970703\n",
      "=================================\n",
      "in 2700 epoch, average loss: 836.7296875\n",
      "                , loss1: 833.46328125\n",
      "                , loss2: 3.2662845611572267\n",
      "=================================\n",
      "in 2710 epoch, average loss: 836.4806640625\n",
      "                , loss1: 833.1828125\n",
      "                , loss2: 3.297943878173828\n",
      "=================================\n",
      "in 2720 epoch, average loss: 835.9322265625\n",
      "                , loss1: 832.76748046875\n",
      "                , loss2: 3.1648765563964845\n",
      "=================================\n",
      "in 2730 epoch, average loss: 835.851953125\n",
      "                , loss1: 832.56328125\n",
      "                , loss2: 3.2886783599853517\n",
      "=================================\n",
      "in 2740 epoch, average loss: 834.66865234375\n",
      "                , loss1: 831.265234375\n",
      "                , loss2: 3.4032943725585936\n",
      "=================================\n",
      "in 2750 epoch, average loss: 835.6546875\n",
      "                , loss1: 832.355859375\n",
      "                , loss2: 3.2988548278808594\n",
      "=================================\n",
      "in 2760 epoch, average loss: 834.8462890625\n",
      "                , loss1: 831.46904296875\n",
      "                , loss2: 3.3773101806640624\n",
      "=================================\n",
      "in 2770 epoch, average loss: 834.45400390625\n",
      "                , loss1: 831.140625\n",
      "                , loss2: 3.313421630859375\n",
      "=================================\n",
      "in 2780 epoch, average loss: 834.248828125\n",
      "                , loss1: 830.95966796875\n",
      "                , loss2: 3.2890689849853514\n",
      "=================================\n",
      "in 2790 epoch, average loss: 835.8302734375\n",
      "                , loss1: 832.54833984375\n",
      "                , loss2: 3.2819698333740233\n",
      "=================================\n",
      "in 2800 epoch, average loss: 834.563671875\n",
      "                , loss1: 831.1828125\n",
      "                , loss2: 3.3807273864746095\n",
      "=================================\n",
      "in 2810 epoch, average loss: 835.148046875\n",
      "                , loss1: 831.83896484375\n",
      "                , loss2: 3.3090721130371095\n",
      "=================================\n",
      "in 2820 epoch, average loss: 833.8845703125\n",
      "                , loss1: 830.53583984375\n",
      "                , loss2: 3.3487354278564454\n",
      "=================================\n",
      "in 2830 epoch, average loss: 833.87294921875\n",
      "                , loss1: 830.5798828125\n",
      "                , loss2: 3.293064498901367\n",
      "=================================\n",
      "in 2840 epoch, average loss: 833.77587890625\n",
      "                , loss1: 830.3705078125\n",
      "                , loss2: 3.4053211212158203\n",
      "=================================\n",
      "in 2850 epoch, average loss: 834.1298828125\n",
      "                , loss1: 830.64541015625\n",
      "                , loss2: 3.4844844818115233\n",
      "=================================\n",
      "in 2860 epoch, average loss: 833.78271484375\n",
      "                , loss1: 830.40498046875\n",
      "                , loss2: 3.377598190307617\n",
      "=================================\n",
      "in 2870 epoch, average loss: 833.9673828125\n",
      "                , loss1: 830.5404296875\n",
      "                , loss2: 3.4269100189208985\n",
      "=================================\n",
      "in 2880 epoch, average loss: 833.53828125\n",
      "                , loss1: 830.1173828125\n",
      "                , loss2: 3.4209251403808594\n",
      "=================================\n",
      "in 2890 epoch, average loss: 833.94677734375\n",
      "                , loss1: 830.50205078125\n",
      "                , loss2: 3.444680404663086\n",
      "=================================\n",
      "in 2900 epoch, average loss: 833.2353515625\n",
      "                , loss1: 829.85849609375\n",
      "                , loss2: 3.3767776489257812\n",
      "=================================\n",
      "in 2910 epoch, average loss: 833.64375\n",
      "                , loss1: 830.1369140625\n",
      "                , loss2: 3.5068077087402343\n",
      "=================================\n",
      "in 2920 epoch, average loss: 832.3611328125\n",
      "                , loss1: 828.94404296875\n",
      "                , loss2: 3.417185592651367\n",
      "=================================\n",
      "in 2930 epoch, average loss: 832.5712890625\n",
      "                , loss1: 828.9826171875\n",
      "                , loss2: 3.5886299133300783\n",
      "=================================\n",
      "in 2940 epoch, average loss: 832.311328125\n",
      "                , loss1: 828.78017578125\n",
      "                , loss2: 3.531077575683594\n",
      "=================================\n",
      "in 2950 epoch, average loss: 832.60400390625\n",
      "                , loss1: 829.265625\n",
      "                , loss2: 3.3383880615234376\n",
      "=================================\n",
      "in 2960 epoch, average loss: 832.8556640625\n",
      "                , loss1: 829.2982421875\n",
      "                , loss2: 3.5574249267578124\n",
      "=================================\n",
      "in 2970 epoch, average loss: 831.7412109375\n",
      "                , loss1: 828.19013671875\n",
      "                , loss2: 3.5511112213134766\n",
      "=================================\n",
      "in 2980 epoch, average loss: 832.05478515625\n",
      "                , loss1: 828.64111328125\n",
      "                , loss2: 3.4136619567871094\n",
      "=================================\n",
      "in 2990 epoch, average loss: 833.75712890625\n",
      "                , loss1: 830.19130859375\n",
      "                , loss2: 3.5658233642578123\n",
      "=================================\n",
      "in 3000 epoch, average loss: 831.508203125\n",
      "                , loss1: 827.90751953125\n",
      "                , loss2: 3.6007568359375\n",
      "=================================\n",
      "in 3010 epoch, average loss: 831.37724609375\n",
      "                , loss1: 827.8328125\n",
      "                , loss2: 3.5443798065185548\n",
      "=================================\n",
      "in 3020 epoch, average loss: 832.2140625\n",
      "                , loss1: 828.7189453125\n",
      "                , loss2: 3.4951618194580076\n",
      "=================================\n",
      "in 3030 epoch, average loss: 832.11953125\n",
      "                , loss1: 828.556640625\n",
      "                , loss2: 3.562831497192383\n",
      "=================================\n",
      "in 3040 epoch, average loss: 831.35732421875\n",
      "                , loss1: 827.91103515625\n",
      "                , loss2: 3.446260452270508\n",
      "=================================\n",
      "in 3050 epoch, average loss: 831.787109375\n",
      "                , loss1: 828.2171875\n",
      "                , loss2: 3.570072555541992\n",
      "=================================\n",
      "in 3060 epoch, average loss: 831.504296875\n",
      "                , loss1: 827.88173828125\n",
      "                , loss2: 3.622578430175781\n",
      "=================================\n",
      "in 3070 epoch, average loss: 831.1751953125\n",
      "                , loss1: 827.4857421875\n",
      "                , loss2: 3.6895126342773437\n",
      "=================================\n",
      "in 3080 epoch, average loss: 831.27138671875\n",
      "                , loss1: 827.6431640625\n",
      "                , loss2: 3.6282413482666014\n",
      "=================================\n",
      "in 3090 epoch, average loss: 830.91142578125\n",
      "                , loss1: 827.22080078125\n",
      "                , loss2: 3.6905479431152344\n",
      "=================================\n",
      "in 3100 epoch, average loss: 830.368359375\n",
      "                , loss1: 826.790625\n",
      "                , loss2: 3.577694320678711\n",
      "=================================\n",
      "in 3110 epoch, average loss: 831.26162109375\n",
      "                , loss1: 827.5828125\n",
      "                , loss2: 3.678874969482422\n",
      "=================================\n",
      "in 3120 epoch, average loss: 830.94287109375\n",
      "                , loss1: 827.47587890625\n",
      "                , loss2: 3.4669876098632812\n",
      "=================================\n",
      "in 3130 epoch, average loss: 830.7005859375\n",
      "                , loss1: 827.121875\n",
      "                , loss2: 3.5786460876464843\n",
      "=================================\n",
      "in 3140 epoch, average loss: 830.72822265625\n",
      "                , loss1: 826.9681640625\n",
      "                , loss2: 3.76002197265625\n",
      "=================================\n",
      "in 3150 epoch, average loss: 830.30205078125\n",
      "                , loss1: 826.6552734375\n",
      "                , loss2: 3.6467922210693358\n",
      "=================================\n",
      "in 3160 epoch, average loss: 830.3921875\n",
      "                , loss1: 826.77138671875\n",
      "                , loss2: 3.6207901000976563\n",
      "=================================\n",
      "in 3170 epoch, average loss: 830.01953125\n",
      "                , loss1: 826.349609375\n",
      "                , loss2: 3.6699283599853514\n",
      "=================================\n",
      "in 3180 epoch, average loss: 830.202734375\n",
      "                , loss1: 826.741796875\n",
      "                , loss2: 3.460877227783203\n",
      "=================================\n",
      "in 3190 epoch, average loss: 830.330078125\n",
      "                , loss1: 826.569140625\n",
      "                , loss2: 3.7610027313232424\n",
      "=================================\n",
      "in 3200 epoch, average loss: 829.449609375\n",
      "                , loss1: 825.92880859375\n",
      "                , loss2: 3.5209121704101562\n",
      "=================================\n",
      "in 3210 epoch, average loss: 829.7634765625\n",
      "                , loss1: 826.069921875\n",
      "                , loss2: 3.693560791015625\n",
      "=================================\n",
      "in 3220 epoch, average loss: 829.3056640625\n",
      "                , loss1: 825.72763671875\n",
      "                , loss2: 3.577994155883789\n",
      "=================================\n",
      "in 3230 epoch, average loss: 829.20546875\n",
      "                , loss1: 825.58740234375\n",
      "                , loss2: 3.6179370880126953\n",
      "=================================\n",
      "in 3240 epoch, average loss: 829.40849609375\n",
      "                , loss1: 825.71494140625\n",
      "                , loss2: 3.6935211181640626\n",
      "=================================\n",
      "in 3250 epoch, average loss: 829.809765625\n",
      "                , loss1: 826.02958984375\n",
      "                , loss2: 3.7801868438720705\n",
      "=================================\n",
      "in 3260 epoch, average loss: 829.51669921875\n",
      "                , loss1: 825.8646484375\n",
      "                , loss2: 3.652085876464844\n",
      "=================================\n",
      "in 3270 epoch, average loss: 829.0939453125\n",
      "                , loss1: 825.3845703125\n",
      "                , loss2: 3.7093059539794924\n",
      "=================================\n",
      "in 3280 epoch, average loss: 829.13818359375\n",
      "                , loss1: 825.37060546875\n",
      "                , loss2: 3.767560577392578\n",
      "=================================\n",
      "in 3290 epoch, average loss: 829.890234375\n",
      "                , loss1: 826.14814453125\n",
      "                , loss2: 3.74206428527832\n",
      "=================================\n",
      "in 3300 epoch, average loss: 829.10419921875\n",
      "                , loss1: 825.270703125\n",
      "                , loss2: 3.8334144592285155\n",
      "=================================\n",
      "in 3310 epoch, average loss: 829.554296875\n",
      "                , loss1: 825.84072265625\n",
      "                , loss2: 3.7135387420654298\n",
      "=================================\n",
      "in 3320 epoch, average loss: 829.061328125\n",
      "                , loss1: 825.5416015625\n",
      "                , loss2: 3.519852066040039\n",
      "=================================\n",
      "in 3330 epoch, average loss: 829.23564453125\n",
      "                , loss1: 825.5509765625\n",
      "                , loss2: 3.6847064971923826\n",
      "=================================\n",
      "in 3340 epoch, average loss: 829.1423828125\n",
      "                , loss1: 825.35673828125\n",
      "                , loss2: 3.785719299316406\n",
      "=================================\n",
      "in 3350 epoch, average loss: 828.53408203125\n",
      "                , loss1: 824.77578125\n",
      "                , loss2: 3.7582931518554688\n",
      "=================================\n",
      "in 3360 epoch, average loss: 829.08466796875\n",
      "                , loss1: 825.32373046875\n",
      "                , loss2: 3.760928726196289\n",
      "=================================\n",
      "in 3370 epoch, average loss: 828.91669921875\n",
      "                , loss1: 825.29111328125\n",
      "                , loss2: 3.625559616088867\n",
      "=================================\n",
      "in 3380 epoch, average loss: 828.68486328125\n",
      "                , loss1: 824.9119140625\n",
      "                , loss2: 3.7730140686035156\n",
      "=================================\n",
      "in 3390 epoch, average loss: 830.00205078125\n",
      "                , loss1: 826.2884765625\n",
      "                , loss2: 3.7136199951171873\n",
      "=================================\n",
      "in 3400 epoch, average loss: 828.52890625\n",
      "                , loss1: 824.7625\n",
      "                , loss2: 3.7664569854736327\n",
      "=================================\n",
      "in 3410 epoch, average loss: 829.02197265625\n",
      "                , loss1: 824.93017578125\n",
      "                , loss2: 4.0917823791503904\n",
      "=================================\n",
      "in 3420 epoch, average loss: 828.5080078125\n",
      "                , loss1: 824.75029296875\n",
      "                , loss2: 3.7576526641845702\n",
      "=================================\n",
      "in 3430 epoch, average loss: 828.46279296875\n",
      "                , loss1: 824.70859375\n",
      "                , loss2: 3.7541229248046877\n",
      "=================================\n",
      "in 3440 epoch, average loss: 828.240625\n",
      "                , loss1: 824.40810546875\n",
      "                , loss2: 3.832579803466797\n",
      "=================================\n",
      "in 3450 epoch, average loss: 828.14609375\n",
      "                , loss1: 824.459375\n",
      "                , loss2: 3.6867408752441406\n",
      "=================================\n",
      "in 3460 epoch, average loss: 828.50185546875\n",
      "                , loss1: 824.740234375\n",
      "                , loss2: 3.7615550994873046\n",
      "=================================\n",
      "in 3470 epoch, average loss: 828.08125\n",
      "                , loss1: 824.2625\n",
      "                , loss2: 3.8186187744140625\n",
      "=================================\n",
      "in 3480 epoch, average loss: 828.20849609375\n",
      "                , loss1: 824.4650390625\n",
      "                , loss2: 3.743430328369141\n",
      "=================================\n",
      "in 3490 epoch, average loss: 827.7900390625\n",
      "                , loss1: 823.95537109375\n",
      "                , loss2: 3.834613037109375\n",
      "=================================\n",
      "in 3500 epoch, average loss: 827.24091796875\n",
      "                , loss1: 823.62578125\n",
      "                , loss2: 3.6151412963867187\n",
      "=================================\n",
      "in 3510 epoch, average loss: 827.5052734375\n",
      "                , loss1: 823.68291015625\n",
      "                , loss2: 3.8222660064697265\n",
      "=================================\n",
      "in 3520 epoch, average loss: 827.48017578125\n",
      "                , loss1: 823.6458984375\n",
      "                , loss2: 3.8342926025390627\n",
      "=================================\n",
      "in 3530 epoch, average loss: 827.52490234375\n",
      "                , loss1: 823.7568359375\n",
      "                , loss2: 3.767912673950195\n",
      "=================================\n",
      "in 3540 epoch, average loss: 828.4470703125\n",
      "                , loss1: 824.55966796875\n",
      "                , loss2: 3.8873340606689455\n",
      "=================================\n",
      "in 3550 epoch, average loss: 827.3556640625\n",
      "                , loss1: 823.6091796875\n",
      "                , loss2: 3.7465003967285155\n",
      "=================================\n",
      "in 3560 epoch, average loss: 828.06005859375\n",
      "                , loss1: 824.42197265625\n",
      "                , loss2: 3.638103485107422\n",
      "=================================\n",
      "in 3570 epoch, average loss: 827.44365234375\n",
      "                , loss1: 823.58291015625\n",
      "                , loss2: 3.860749435424805\n",
      "=================================\n",
      "in 3580 epoch, average loss: 827.5623046875\n",
      "                , loss1: 823.74404296875\n",
      "                , loss2: 3.818310546875\n",
      "=================================\n",
      "in 3590 epoch, average loss: 827.08408203125\n",
      "                , loss1: 823.22060546875\n",
      "                , loss2: 3.8633731842041015\n",
      "=================================\n",
      "in 3600 epoch, average loss: 827.9328125\n",
      "                , loss1: 824.084375\n",
      "                , loss2: 3.848448944091797\n",
      "=================================\n",
      "in 3610 epoch, average loss: 827.89150390625\n",
      "                , loss1: 824.0513671875\n",
      "                , loss2: 3.840096664428711\n",
      "=================================\n",
      "in 3620 epoch, average loss: 827.4755859375\n",
      "                , loss1: 823.7564453125\n",
      "                , loss2: 3.719157028198242\n",
      "=================================\n",
      "in 3630 epoch, average loss: 827.0828125\n",
      "                , loss1: 823.169921875\n",
      "                , loss2: 3.912823486328125\n",
      "=================================\n",
      "in 3640 epoch, average loss: 826.86416015625\n",
      "                , loss1: 822.95673828125\n",
      "                , loss2: 3.90736083984375\n",
      "=================================\n",
      "in 3650 epoch, average loss: 827.604296875\n",
      "                , loss1: 823.903515625\n",
      "                , loss2: 3.7007389068603516\n",
      "=================================\n",
      "in 3660 epoch, average loss: 827.164453125\n",
      "                , loss1: 823.2646484375\n",
      "                , loss2: 3.899724578857422\n",
      "=================================\n",
      "in 3670 epoch, average loss: 826.93828125\n",
      "                , loss1: 823.02841796875\n",
      "                , loss2: 3.9098735809326173\n",
      "=================================\n",
      "in 3680 epoch, average loss: 826.855078125\n",
      "                , loss1: 822.98251953125\n",
      "                , loss2: 3.872484588623047\n",
      "=================================\n",
      "in 3690 epoch, average loss: 826.6533203125\n",
      "                , loss1: 822.78447265625\n",
      "                , loss2: 3.868956756591797\n",
      "=================================\n",
      "in 3700 epoch, average loss: 827.2453125\n",
      "                , loss1: 823.3185546875\n",
      "                , loss2: 3.9267208099365236\n",
      "=================================\n",
      "in 3710 epoch, average loss: 827.1205078125\n",
      "                , loss1: 823.1697265625\n",
      "                , loss2: 3.9508846282958983\n",
      "=================================\n",
      "in 3720 epoch, average loss: 827.41865234375\n",
      "                , loss1: 823.553515625\n",
      "                , loss2: 3.8651702880859373\n",
      "=================================\n",
      "in 3730 epoch, average loss: 826.82861328125\n",
      "                , loss1: 822.87158203125\n",
      "                , loss2: 3.9570938110351563\n",
      "=================================\n",
      "in 3740 epoch, average loss: 826.58994140625\n",
      "                , loss1: 822.687109375\n",
      "                , loss2: 3.902914047241211\n",
      "=================================\n",
      "in 3750 epoch, average loss: 826.75400390625\n",
      "                , loss1: 822.87421875\n",
      "                , loss2: 3.879712677001953\n",
      "=================================\n",
      "in 3760 epoch, average loss: 826.6216796875\n",
      "                , loss1: 822.790625\n",
      "                , loss2: 3.8310611724853514\n",
      "=================================\n",
      "in 3770 epoch, average loss: 826.278125\n",
      "                , loss1: 822.35556640625\n",
      "                , loss2: 3.9224414825439453\n",
      "=================================\n",
      "in 3780 epoch, average loss: 826.5541015625\n",
      "                , loss1: 822.56318359375\n",
      "                , loss2: 3.990966033935547\n",
      "=================================\n",
      "in 3790 epoch, average loss: 826.49677734375\n",
      "                , loss1: 822.5857421875\n",
      "                , loss2: 3.9110748291015627\n",
      "=================================\n",
      "in 3800 epoch, average loss: 826.673828125\n",
      "                , loss1: 822.82861328125\n",
      "                , loss2: 3.845198059082031\n",
      "=================================\n",
      "in 3810 epoch, average loss: 827.1046875\n",
      "                , loss1: 823.22763671875\n",
      "                , loss2: 3.876985549926758\n",
      "=================================\n",
      "in 3820 epoch, average loss: 826.2705078125\n",
      "                , loss1: 822.3830078125\n",
      "                , loss2: 3.8875450134277343\n",
      "=================================\n",
      "in 3830 epoch, average loss: 826.783203125\n",
      "                , loss1: 822.8634765625\n",
      "                , loss2: 3.919708251953125\n",
      "=================================\n",
      "in 3840 epoch, average loss: 826.76923828125\n",
      "                , loss1: 822.88984375\n",
      "                , loss2: 3.879425811767578\n",
      "=================================\n",
      "in 3850 epoch, average loss: 826.2435546875\n",
      "                , loss1: 822.237890625\n",
      "                , loss2: 4.005479431152343\n",
      "=================================\n",
      "in 3860 epoch, average loss: 826.524609375\n",
      "                , loss1: 822.7390625\n",
      "                , loss2: 3.785593032836914\n",
      "=================================\n",
      "in 3870 epoch, average loss: 826.38984375\n",
      "                , loss1: 822.4767578125\n",
      "                , loss2: 3.913138580322266\n",
      "=================================\n",
      "in 3880 epoch, average loss: 826.93115234375\n",
      "                , loss1: 823.0193359375\n",
      "                , loss2: 3.911927032470703\n",
      "=================================\n",
      "in 3890 epoch, average loss: 826.39580078125\n",
      "                , loss1: 822.48583984375\n",
      "                , loss2: 3.9098770141601564\n",
      "=================================\n",
      "in 3900 epoch, average loss: 826.2341796875\n",
      "                , loss1: 822.28046875\n",
      "                , loss2: 3.9537673950195313\n",
      "=================================\n",
      "in 3910 epoch, average loss: 826.27392578125\n",
      "                , loss1: 822.30478515625\n",
      "                , loss2: 3.9690895080566406\n",
      "=================================\n",
      "in 3920 epoch, average loss: 826.03251953125\n",
      "                , loss1: 822.1060546875\n",
      "                , loss2: 3.926393508911133\n",
      "=================================\n",
      "in 3930 epoch, average loss: 826.4376953125\n",
      "                , loss1: 822.4974609375\n",
      "                , loss2: 3.940326690673828\n",
      "=================================\n",
      "in 3940 epoch, average loss: 826.07724609375\n",
      "                , loss1: 822.076953125\n",
      "                , loss2: 4.000297927856446\n",
      "=================================\n",
      "in 3950 epoch, average loss: 826.05673828125\n",
      "                , loss1: 822.09853515625\n",
      "                , loss2: 3.9582714080810546\n",
      "=================================\n",
      "in 3960 epoch, average loss: 826.0990234375\n",
      "                , loss1: 822.171875\n",
      "                , loss2: 3.9270938873291015\n",
      "=================================\n",
      "in 3970 epoch, average loss: 825.952734375\n",
      "                , loss1: 822.008203125\n",
      "                , loss2: 3.944532775878906\n",
      "=================================\n",
      "in 3980 epoch, average loss: 825.95732421875\n",
      "                , loss1: 822.00263671875\n",
      "                , loss2: 3.954758071899414\n",
      "=================================\n",
      "in 3990 epoch, average loss: 825.9359375\n",
      "                , loss1: 821.9787109375\n",
      "                , loss2: 3.957274627685547\n",
      "=================================\n",
      "in 4000 epoch, average loss: 826.164453125\n",
      "                , loss1: 822.08876953125\n",
      "                , loss2: 4.075621032714844\n",
      "=================================\n",
      "in 4010 epoch, average loss: 825.9328125\n",
      "                , loss1: 822.206640625\n",
      "                , loss2: 3.7261322021484373\n",
      "=================================\n",
      "in 4020 epoch, average loss: 825.651171875\n",
      "                , loss1: 821.704296875\n",
      "                , loss2: 3.946875\n",
      "=================================\n",
      "in 4030 epoch, average loss: 826.17353515625\n",
      "                , loss1: 822.17314453125\n",
      "                , loss2: 4.000476837158203\n",
      "=================================\n",
      "in 4040 epoch, average loss: 825.67431640625\n",
      "                , loss1: 821.6880859375\n",
      "                , loss2: 3.9863380432128905\n",
      "=================================\n",
      "in 4050 epoch, average loss: 825.61123046875\n",
      "                , loss1: 821.63427734375\n",
      "                , loss2: 3.976862335205078\n",
      "=================================\n",
      "in 4060 epoch, average loss: 825.7412109375\n",
      "                , loss1: 821.74794921875\n",
      "                , loss2: 3.9932987213134767\n",
      "=================================\n",
      "in 4070 epoch, average loss: 825.94345703125\n",
      "                , loss1: 822.00078125\n",
      "                , loss2: 3.9425228118896483\n",
      "=================================\n",
      "in 4080 epoch, average loss: 825.53349609375\n",
      "                , loss1: 821.52724609375\n",
      "                , loss2: 4.006223678588867\n",
      "=================================\n",
      "in 4090 epoch, average loss: 825.998828125\n",
      "                , loss1: 821.9591796875\n",
      "                , loss2: 4.0396728515625\n",
      "=================================\n",
      "in 4100 epoch, average loss: 825.71142578125\n",
      "                , loss1: 821.86494140625\n",
      "                , loss2: 3.846462631225586\n",
      "=================================\n",
      "in 4110 epoch, average loss: 825.354296875\n",
      "                , loss1: 821.3869140625\n",
      "                , loss2: 3.9675521850585938\n",
      "=================================\n",
      "in 4120 epoch, average loss: 825.83681640625\n",
      "                , loss1: 821.7630859375\n",
      "                , loss2: 4.0736640930175785\n",
      "=================================\n",
      "in 4130 epoch, average loss: 825.55537109375\n",
      "                , loss1: 821.54951171875\n",
      "                , loss2: 4.005944442749024\n",
      "=================================\n",
      "in 4140 epoch, average loss: 825.8923828125\n",
      "                , loss1: 821.97216796875\n",
      "                , loss2: 3.9202037811279298\n",
      "=================================\n",
      "in 4150 epoch, average loss: 825.60234375\n",
      "                , loss1: 821.5447265625\n",
      "                , loss2: 4.057609558105469\n",
      "=================================\n",
      "in 4160 epoch, average loss: 825.34287109375\n",
      "                , loss1: 821.35185546875\n",
      "                , loss2: 3.9910682678222655\n",
      "=================================\n",
      "in 4170 epoch, average loss: 825.25263671875\n",
      "                , loss1: 821.251953125\n",
      "                , loss2: 4.000770950317383\n",
      "=================================\n",
      "in 4180 epoch, average loss: 825.34208984375\n",
      "                , loss1: 821.3443359375\n",
      "                , loss2: 3.997727966308594\n",
      "=================================\n",
      "in 4190 epoch, average loss: 825.40234375\n",
      "                , loss1: 821.3443359375\n",
      "                , loss2: 4.0580181121826175\n",
      "=================================\n",
      "in 4200 epoch, average loss: 825.265625\n",
      "                , loss1: 821.284375\n",
      "                , loss2: 3.9811481475830077\n",
      "=================================\n",
      "in 4210 epoch, average loss: 825.6958984375\n",
      "                , loss1: 821.7193359375\n",
      "                , loss2: 3.976526641845703\n",
      "=================================\n",
      "in 4220 epoch, average loss: 825.4189453125\n",
      "                , loss1: 821.40126953125\n",
      "                , loss2: 4.017636489868164\n",
      "=================================\n",
      "in 4230 epoch, average loss: 825.7068359375\n",
      "                , loss1: 821.6484375\n",
      "                , loss2: 4.058300399780274\n",
      "=================================\n",
      "in 4240 epoch, average loss: 825.3810546875\n",
      "                , loss1: 821.35029296875\n",
      "                , loss2: 4.030622863769532\n",
      "=================================\n",
      "in 4250 epoch, average loss: 825.0365234375\n",
      "                , loss1: 820.99306640625\n",
      "                , loss2: 4.043511581420899\n",
      "=================================\n",
      "in 4260 epoch, average loss: 825.1009765625\n",
      "                , loss1: 821.0591796875\n",
      "                , loss2: 4.041731262207032\n",
      "=================================\n",
      "in 4270 epoch, average loss: 825.4916015625\n",
      "                , loss1: 821.38828125\n",
      "                , loss2: 4.103377151489258\n",
      "=================================\n",
      "in 4280 epoch, average loss: 825.12197265625\n",
      "                , loss1: 821.07236328125\n",
      "                , loss2: 4.049638748168945\n",
      "=================================\n",
      "in 4290 epoch, average loss: 825.19091796875\n",
      "                , loss1: 821.159375\n",
      "                , loss2: 4.031516647338867\n",
      "=================================\n",
      "in 4300 epoch, average loss: 825.3228515625\n",
      "                , loss1: 821.2859375\n",
      "                , loss2: 4.036917877197266\n",
      "=================================\n",
      "in 4310 epoch, average loss: 825.02783203125\n",
      "                , loss1: 820.992578125\n",
      "                , loss2: 4.035107421875\n",
      "=================================\n",
      "in 4320 epoch, average loss: 824.94052734375\n",
      "                , loss1: 820.87998046875\n",
      "                , loss2: 4.0606842041015625\n",
      "=================================\n",
      "in 4330 epoch, average loss: 824.9578125\n",
      "                , loss1: 820.90673828125\n",
      "                , loss2: 4.051120758056641\n",
      "=================================\n",
      "in 4340 epoch, average loss: 825.30400390625\n",
      "                , loss1: 821.37119140625\n",
      "                , loss2: 3.9328563690185545\n",
      "=================================\n",
      "in 4350 epoch, average loss: 825.31220703125\n",
      "                , loss1: 821.31171875\n",
      "                , loss2: 4.000479125976563\n",
      "=================================\n",
      "in 4360 epoch, average loss: 824.982421875\n",
      "                , loss1: 820.87939453125\n",
      "                , loss2: 4.103007507324219\n",
      "=================================\n",
      "in 4370 epoch, average loss: 824.86611328125\n",
      "                , loss1: 820.79150390625\n",
      "                , loss2: 4.074747467041016\n",
      "=================================\n",
      "in 4380 epoch, average loss: 825.10546875\n",
      "                , loss1: 821.2046875\n",
      "                , loss2: 3.9008052825927733\n",
      "=================================\n",
      "in 4390 epoch, average loss: 824.66201171875\n",
      "                , loss1: 820.5455078125\n",
      "                , loss2: 4.116557693481445\n",
      "=================================\n",
      "in 4400 epoch, average loss: 825.4544921875\n",
      "                , loss1: 821.403125\n",
      "                , loss2: 4.051301574707031\n",
      "=================================\n",
      "in 4410 epoch, average loss: 825.1373046875\n",
      "                , loss1: 821.0640625\n",
      "                , loss2: 4.073337554931641\n",
      "=================================\n",
      "in 4420 epoch, average loss: 824.7029296875\n",
      "                , loss1: 820.65078125\n",
      "                , loss2: 4.051957702636718\n",
      "=================================\n",
      "in 4430 epoch, average loss: 824.82353515625\n",
      "                , loss1: 820.73388671875\n",
      "                , loss2: 4.089701080322266\n",
      "=================================\n",
      "in 4440 epoch, average loss: 824.9330078125\n",
      "                , loss1: 820.85908203125\n",
      "                , loss2: 4.073904037475586\n",
      "=================================\n",
      "in 4450 epoch, average loss: 824.88203125\n",
      "                , loss1: 820.78173828125\n",
      "                , loss2: 4.100295639038086\n",
      "=================================\n",
      "in 4460 epoch, average loss: 824.807421875\n",
      "                , loss1: 820.78251953125\n",
      "                , loss2: 4.024990081787109\n",
      "=================================\n",
      "in 4470 epoch, average loss: 824.6361328125\n",
      "                , loss1: 820.5974609375\n",
      "                , loss2: 4.03857421875\n",
      "=================================\n",
      "in 4480 epoch, average loss: 824.56572265625\n",
      "                , loss1: 820.440625\n",
      "                , loss2: 4.125096130371094\n",
      "=================================\n",
      "in 4490 epoch, average loss: 824.58798828125\n",
      "                , loss1: 820.53759765625\n",
      "                , loss2: 4.0504600524902346\n",
      "=================================\n",
      "in 4500 epoch, average loss: 824.840625\n",
      "                , loss1: 820.73076171875\n",
      "                , loss2: 4.109852600097656\n",
      "=================================\n",
      "in 4510 epoch, average loss: 825.0267578125\n",
      "                , loss1: 820.9607421875\n",
      "                , loss2: 4.065959548950195\n",
      "=================================\n",
      "in 4520 epoch, average loss: 824.74931640625\n",
      "                , loss1: 820.56845703125\n",
      "                , loss2: 4.18098258972168\n",
      "=================================\n",
      "in 4530 epoch, average loss: 824.74736328125\n",
      "                , loss1: 820.80556640625\n",
      "                , loss2: 3.9417949676513673\n",
      "=================================\n",
      "in 4540 epoch, average loss: 824.75615234375\n",
      "                , loss1: 820.6498046875\n",
      "                , loss2: 4.106404495239258\n",
      "=================================\n",
      "in 4550 epoch, average loss: 824.476953125\n",
      "                , loss1: 820.42568359375\n",
      "                , loss2: 4.051352310180664\n",
      "=================================\n",
      "in 4560 epoch, average loss: 824.587890625\n",
      "                , loss1: 820.4763671875\n",
      "                , loss2: 4.111544418334961\n",
      "=================================\n",
      "in 4570 epoch, average loss: 824.50263671875\n",
      "                , loss1: 820.4185546875\n",
      "                , loss2: 4.084072875976562\n",
      "=================================\n",
      "in 4580 epoch, average loss: 824.61103515625\n",
      "                , loss1: 820.51435546875\n",
      "                , loss2: 4.096646499633789\n",
      "=================================\n",
      "in 4590 epoch, average loss: 824.58759765625\n",
      "                , loss1: 820.46826171875\n",
      "                , loss2: 4.11932601928711\n",
      "=================================\n",
      "in 4600 epoch, average loss: 824.63681640625\n",
      "                , loss1: 820.519921875\n",
      "                , loss2: 4.11683464050293\n",
      "=================================\n",
      "in 4610 epoch, average loss: 824.96171875\n",
      "                , loss1: 820.84072265625\n",
      "                , loss2: 4.1209667205810545\n",
      "=================================\n",
      "in 4620 epoch, average loss: 824.66552734375\n",
      "                , loss1: 820.50234375\n",
      "                , loss2: 4.16318359375\n",
      "=================================\n",
      "in 4630 epoch, average loss: 824.80546875\n",
      "                , loss1: 820.667578125\n",
      "                , loss2: 4.137896728515625\n",
      "=================================\n",
      "in 4640 epoch, average loss: 824.51611328125\n",
      "                , loss1: 820.43232421875\n",
      "                , loss2: 4.083840560913086\n",
      "=================================\n",
      "in 4650 epoch, average loss: 824.4845703125\n",
      "                , loss1: 820.39296875\n",
      "                , loss2: 4.0916088104248045\n",
      "=================================\n",
      "in 4660 epoch, average loss: 824.4685546875\n",
      "                , loss1: 820.46240234375\n",
      "                , loss2: 4.006087112426758\n",
      "=================================\n",
      "in 4670 epoch, average loss: 824.38095703125\n",
      "                , loss1: 820.2365234375\n",
      "                , loss2: 4.144451904296875\n",
      "=================================\n",
      "in 4680 epoch, average loss: 824.46220703125\n",
      "                , loss1: 820.3791015625\n",
      "                , loss2: 4.0830535888671875\n",
      "=================================\n",
      "in 4690 epoch, average loss: 824.274609375\n",
      "                , loss1: 820.1546875\n",
      "                , loss2: 4.1199695587158205\n",
      "=================================\n",
      "in 4700 epoch, average loss: 824.54326171875\n",
      "                , loss1: 820.451171875\n",
      "                , loss2: 4.092103958129883\n",
      "=================================\n",
      "in 4710 epoch, average loss: 824.70625\n",
      "                , loss1: 820.59111328125\n",
      "                , loss2: 4.11513671875\n",
      "=================================\n",
      "in 4720 epoch, average loss: 824.23828125\n",
      "                , loss1: 820.08740234375\n",
      "                , loss2: 4.150871276855469\n",
      "=================================\n",
      "in 4730 epoch, average loss: 824.37353515625\n",
      "                , loss1: 820.2416015625\n",
      "                , loss2: 4.131974792480468\n",
      "=================================\n",
      "in 4740 epoch, average loss: 824.24443359375\n",
      "                , loss1: 820.12373046875\n",
      "                , loss2: 4.12066421508789\n",
      "=================================\n",
      "in 4750 epoch, average loss: 824.2498046875\n",
      "                , loss1: 820.086328125\n",
      "                , loss2: 4.163352966308594\n",
      "=================================\n",
      "in 4760 epoch, average loss: 824.43310546875\n",
      "                , loss1: 820.32021484375\n",
      "                , loss2: 4.112803649902344\n",
      "=================================\n",
      "in 4770 epoch, average loss: 824.84599609375\n",
      "                , loss1: 820.747265625\n",
      "                , loss2: 4.098751831054687\n",
      "=================================\n",
      "in 4780 epoch, average loss: 824.1623046875\n",
      "                , loss1: 820.0154296875\n",
      "                , loss2: 4.146929931640625\n",
      "=================================\n",
      "in 4790 epoch, average loss: 824.3\n",
      "                , loss1: 820.1759765625\n",
      "                , loss2: 4.12390022277832\n",
      "=================================\n",
      "in 4800 epoch, average loss: 824.2791015625\n",
      "                , loss1: 820.1720703125\n",
      "                , loss2: 4.107001113891601\n",
      "=================================\n",
      "in 4810 epoch, average loss: 824.133984375\n",
      "                , loss1: 819.99716796875\n",
      "                , loss2: 4.136806869506836\n",
      "=================================\n",
      "in 4820 epoch, average loss: 824.1693359375\n",
      "                , loss1: 819.9962890625\n",
      "                , loss2: 4.173142623901367\n",
      "=================================\n",
      "in 4830 epoch, average loss: 824.14931640625\n",
      "                , loss1: 820.02265625\n",
      "                , loss2: 4.12674560546875\n",
      "=================================\n",
      "in 4840 epoch, average loss: 824.08291015625\n",
      "                , loss1: 819.9109375\n",
      "                , loss2: 4.172048950195313\n",
      "=================================\n",
      "in 4850 epoch, average loss: 824.0654296875\n",
      "                , loss1: 819.9517578125\n",
      "                , loss2: 4.113725662231445\n",
      "=================================\n",
      "in 4860 epoch, average loss: 824.2306640625\n",
      "                , loss1: 820.092578125\n",
      "                , loss2: 4.137913513183594\n",
      "=================================\n",
      "in 4870 epoch, average loss: 824.03291015625\n",
      "                , loss1: 819.8689453125\n",
      "                , loss2: 4.163985824584961\n",
      "=================================\n",
      "in 4880 epoch, average loss: 824.26923828125\n",
      "                , loss1: 820.10732421875\n",
      "                , loss2: 4.161993408203125\n",
      "=================================\n",
      "in 4890 epoch, average loss: 824.354296875\n",
      "                , loss1: 820.22890625\n",
      "                , loss2: 4.125362777709961\n",
      "=================================\n",
      "in 4900 epoch, average loss: 824.06923828125\n",
      "                , loss1: 819.93916015625\n",
      "                , loss2: 4.130037689208985\n",
      "=================================\n",
      "in 4910 epoch, average loss: 824.271875\n",
      "                , loss1: 820.1765625\n",
      "                , loss2: 4.095322036743164\n",
      "=================================\n",
      "in 4920 epoch, average loss: 824.07138671875\n",
      "                , loss1: 819.92705078125\n",
      "                , loss2: 4.144338226318359\n",
      "=================================\n",
      "in 4930 epoch, average loss: 824.123828125\n",
      "                , loss1: 819.991796875\n",
      "                , loss2: 4.132003402709961\n",
      "=================================\n",
      "in 4940 epoch, average loss: 824.10546875\n",
      "                , loss1: 819.94697265625\n",
      "                , loss2: 4.158538818359375\n",
      "=================================\n",
      "in 4950 epoch, average loss: 824.27841796875\n",
      "                , loss1: 820.12197265625\n",
      "                , loss2: 4.156503295898437\n",
      "=================================\n",
      "in 4960 epoch, average loss: 823.94853515625\n",
      "                , loss1: 819.80751953125\n",
      "                , loss2: 4.141033172607422\n",
      "=================================\n",
      "in 4970 epoch, average loss: 824.07236328125\n",
      "                , loss1: 819.97958984375\n",
      "                , loss2: 4.092764282226563\n",
      "=================================\n",
      "in 4980 epoch, average loss: 823.8908203125\n",
      "                , loss1: 819.76845703125\n",
      "                , loss2: 4.122265243530274\n",
      "=================================\n",
      "in 4990 epoch, average loss: 823.97236328125\n",
      "                , loss1: 819.8041015625\n",
      "                , loss2: 4.168255233764649\n",
      "=================================\n",
      "in 5000 epoch, average loss: 823.938671875\n",
      "                , loss1: 819.7837890625\n",
      "                , loss2: 4.1548820495605465\n",
      "=================================\n",
      "in 5010 epoch, average loss: 823.968359375\n",
      "                , loss1: 819.78583984375\n",
      "                , loss2: 4.182446670532227\n",
      "=================================\n",
      "in 5020 epoch, average loss: 824.29404296875\n",
      "                , loss1: 820.165625\n",
      "                , loss2: 4.128426361083984\n",
      "=================================\n",
      "in 5030 epoch, average loss: 823.99677734375\n",
      "                , loss1: 819.80634765625\n",
      "                , loss2: 4.190426635742187\n",
      "=================================\n",
      "in 5040 epoch, average loss: 823.9859375\n",
      "                , loss1: 819.80361328125\n",
      "                , loss2: 4.182321166992187\n",
      "=================================\n",
      "in 5050 epoch, average loss: 823.98564453125\n",
      "                , loss1: 819.77939453125\n",
      "                , loss2: 4.206161880493164\n",
      "=================================\n",
      "in 5060 epoch, average loss: 823.93330078125\n",
      "                , loss1: 819.7677734375\n",
      "                , loss2: 4.1655933380126955\n",
      "=================================\n",
      "in 5070 epoch, average loss: 823.93828125\n",
      "                , loss1: 819.77763671875\n",
      "                , loss2: 4.160678863525391\n",
      "=================================\n",
      "in 5080 epoch, average loss: 824.0033203125\n",
      "                , loss1: 819.84912109375\n",
      "                , loss2: 4.15422477722168\n",
      "=================================\n",
      "in 5090 epoch, average loss: 823.93203125\n",
      "                , loss1: 819.7484375\n",
      "                , loss2: 4.183526611328125\n",
      "=================================\n",
      "in 5100 epoch, average loss: 823.93056640625\n",
      "                , loss1: 819.75595703125\n",
      "                , loss2: 4.174640655517578\n",
      "=================================\n",
      "in 5110 epoch, average loss: 823.845703125\n",
      "                , loss1: 819.6548828125\n",
      "                , loss2: 4.190629577636718\n",
      "=================================\n",
      "in 5120 epoch, average loss: 824.198046875\n",
      "                , loss1: 820.08671875\n",
      "                , loss2: 4.111370086669922\n",
      "=================================\n",
      "in 5130 epoch, average loss: 823.85517578125\n",
      "                , loss1: 819.72529296875\n",
      "                , loss2: 4.129753112792969\n",
      "=================================\n",
      "in 5140 epoch, average loss: 823.9875\n",
      "                , loss1: 819.80185546875\n",
      "                , loss2: 4.185646820068359\n",
      "=================================\n",
      "in 5150 epoch, average loss: 823.68876953125\n",
      "                , loss1: 819.5111328125\n",
      "                , loss2: 4.177581024169922\n",
      "=================================\n",
      "in 5160 epoch, average loss: 823.65439453125\n",
      "                , loss1: 819.50302734375\n",
      "                , loss2: 4.151327514648438\n",
      "=================================\n",
      "in 5170 epoch, average loss: 823.7375\n",
      "                , loss1: 819.57001953125\n",
      "                , loss2: 4.167429351806641\n",
      "=================================\n",
      "in 5180 epoch, average loss: 823.86953125\n",
      "                , loss1: 819.72060546875\n",
      "                , loss2: 4.149068450927734\n",
      "=================================\n",
      "in 5190 epoch, average loss: 823.74150390625\n",
      "                , loss1: 819.5521484375\n",
      "                , loss2: 4.189507293701172\n",
      "=================================\n",
      "in 5200 epoch, average loss: 823.79033203125\n",
      "                , loss1: 819.6076171875\n",
      "                , loss2: 4.182811737060547\n",
      "=================================\n",
      "in 5210 epoch, average loss: 823.76826171875\n",
      "                , loss1: 819.59453125\n",
      "                , loss2: 4.173674392700195\n",
      "=================================\n",
      "in 5220 epoch, average loss: 823.80927734375\n",
      "                , loss1: 819.60009765625\n",
      "                , loss2: 4.2091819763183596\n",
      "=================================\n",
      "in 5230 epoch, average loss: 823.89033203125\n",
      "                , loss1: 819.7146484375\n",
      "                , loss2: 4.1757659912109375\n",
      "=================================\n",
      "in 5240 epoch, average loss: 823.729296875\n",
      "                , loss1: 819.5578125\n",
      "                , loss2: 4.171624374389649\n",
      "=================================\n",
      "in 5250 epoch, average loss: 823.785546875\n",
      "                , loss1: 819.5947265625\n",
      "                , loss2: 4.190873718261718\n",
      "=================================\n",
      "in 5260 epoch, average loss: 823.596484375\n",
      "                , loss1: 819.4517578125\n",
      "                , loss2: 4.14476318359375\n",
      "=================================\n",
      "in 5270 epoch, average loss: 823.7287109375\n",
      "                , loss1: 819.53388671875\n",
      "                , loss2: 4.194895172119141\n",
      "=================================\n",
      "in 5280 epoch, average loss: 823.953515625\n",
      "                , loss1: 819.76044921875\n",
      "                , loss2: 4.193009567260742\n",
      "=================================\n",
      "in 5290 epoch, average loss: 823.67373046875\n",
      "                , loss1: 819.53076171875\n",
      "                , loss2: 4.142898941040039\n",
      "=================================\n",
      "in 5300 epoch, average loss: 823.9431640625\n",
      "                , loss1: 819.78271484375\n",
      "                , loss2: 4.160404968261719\n",
      "=================================\n",
      "in 5310 epoch, average loss: 823.76611328125\n",
      "                , loss1: 819.60703125\n",
      "                , loss2: 4.159103775024414\n",
      "=================================\n",
      "in 5320 epoch, average loss: 823.76484375\n",
      "                , loss1: 819.6001953125\n",
      "                , loss2: 4.164683532714844\n",
      "=================================\n",
      "in 5330 epoch, average loss: 823.690234375\n",
      "                , loss1: 819.52880859375\n",
      "                , loss2: 4.161325454711914\n",
      "=================================\n",
      "in 5340 epoch, average loss: 823.54765625\n",
      "                , loss1: 819.34609375\n",
      "                , loss2: 4.201430130004883\n",
      "=================================\n",
      "in 5350 epoch, average loss: 823.75703125\n",
      "                , loss1: 819.59482421875\n",
      "                , loss2: 4.162258148193359\n",
      "=================================\n",
      "in 5360 epoch, average loss: 823.526953125\n",
      "                , loss1: 819.35009765625\n",
      "                , loss2: 4.176817321777344\n",
      "=================================\n",
      "in 5370 epoch, average loss: 823.6796875\n",
      "                , loss1: 819.465234375\n",
      "                , loss2: 4.2145263671875\n",
      "=================================\n",
      "in 5380 epoch, average loss: 823.66708984375\n",
      "                , loss1: 819.4712890625\n",
      "                , loss2: 4.195760345458984\n",
      "=================================\n",
      "in 5390 epoch, average loss: 823.8830078125\n",
      "                , loss1: 819.7486328125\n",
      "                , loss2: 4.1343944549560545\n",
      "=================================\n",
      "in 5400 epoch, average loss: 823.69609375\n",
      "                , loss1: 819.51259765625\n",
      "                , loss2: 4.183462905883789\n",
      "=================================\n",
      "in 5410 epoch, average loss: 823.769140625\n",
      "                , loss1: 819.56572265625\n",
      "                , loss2: 4.2034141540527346\n",
      "=================================\n",
      "in 5420 epoch, average loss: 823.77314453125\n",
      "                , loss1: 819.61416015625\n",
      "                , loss2: 4.158949279785157\n",
      "=================================\n",
      "in 5430 epoch, average loss: 823.52275390625\n",
      "                , loss1: 819.33193359375\n",
      "                , loss2: 4.1908618927001955\n",
      "=================================\n",
      "in 5440 epoch, average loss: 823.72705078125\n",
      "                , loss1: 819.52900390625\n",
      "                , loss2: 4.1980842590332035\n",
      "=================================\n",
      "in 5450 epoch, average loss: 823.4998046875\n",
      "                , loss1: 819.28984375\n",
      "                , loss2: 4.210005569458008\n",
      "=================================\n",
      "in 5460 epoch, average loss: 823.65771484375\n",
      "                , loss1: 819.44091796875\n",
      "                , loss2: 4.216674041748047\n",
      "=================================\n",
      "in 5470 epoch, average loss: 823.56279296875\n",
      "                , loss1: 819.37099609375\n",
      "                , loss2: 4.191706848144531\n",
      "=================================\n",
      "in 5480 epoch, average loss: 823.412890625\n",
      "                , loss1: 819.188671875\n",
      "                , loss2: 4.224253082275391\n",
      "=================================\n",
      "in 5490 epoch, average loss: 823.5037109375\n",
      "                , loss1: 819.27666015625\n",
      "                , loss2: 4.227091217041016\n",
      "=================================\n",
      "in 5500 epoch, average loss: 823.44404296875\n",
      "                , loss1: 819.23701171875\n",
      "                , loss2: 4.206974792480469\n",
      "=================================\n",
      "in 5510 epoch, average loss: 823.60859375\n",
      "                , loss1: 819.41943359375\n",
      "                , loss2: 4.189215087890625\n",
      "=================================\n",
      "in 5520 epoch, average loss: 823.6908203125\n",
      "                , loss1: 819.5126953125\n",
      "                , loss2: 4.17797622680664\n",
      "=================================\n",
      "in 5530 epoch, average loss: 823.51943359375\n",
      "                , loss1: 819.329296875\n",
      "                , loss2: 4.189990234375\n",
      "=================================\n",
      "in 5540 epoch, average loss: 823.48828125\n",
      "                , loss1: 819.27421875\n",
      "                , loss2: 4.214017868041992\n",
      "=================================\n",
      "in 5550 epoch, average loss: 823.5142578125\n",
      "                , loss1: 819.3208984375\n",
      "                , loss2: 4.193449401855469\n",
      "=================================\n",
      "in 5560 epoch, average loss: 823.43994140625\n",
      "                , loss1: 819.23583984375\n",
      "                , loss2: 4.204101181030273\n",
      "=================================\n",
      "in 5570 epoch, average loss: 823.497265625\n",
      "                , loss1: 819.27763671875\n",
      "                , loss2: 4.219603729248047\n",
      "=================================\n",
      "in 5580 epoch, average loss: 823.54716796875\n",
      "                , loss1: 819.3458984375\n",
      "                , loss2: 4.2013084411621096\n",
      "=================================\n",
      "in 5590 epoch, average loss: 823.5498046875\n",
      "                , loss1: 819.3427734375\n",
      "                , loss2: 4.206997299194336\n",
      "=================================\n",
      "in 5600 epoch, average loss: 823.410546875\n",
      "                , loss1: 819.190283203125\n",
      "                , loss2: 4.220272445678711\n",
      "=================================\n",
      "in 5610 epoch, average loss: 824.19443359375\n",
      "                , loss1: 820.0458984375\n",
      "                , loss2: 4.1486053466796875\n",
      "=================================\n",
      "in 5620 epoch, average loss: 823.46875\n",
      "                , loss1: 819.260546875\n",
      "                , loss2: 4.2081035614013675\n",
      "=================================\n",
      "in 5630 epoch, average loss: 823.3974609375\n",
      "                , loss1: 819.186572265625\n",
      "                , loss2: 4.210965728759765\n",
      "=================================\n",
      "in 5640 epoch, average loss: 823.31982421875\n",
      "                , loss1: 819.080859375\n",
      "                , loss2: 4.238993453979492\n",
      "=================================\n",
      "in 5650 epoch, average loss: 823.53232421875\n",
      "                , loss1: 819.3265625\n",
      "                , loss2: 4.205785751342773\n",
      "=================================\n",
      "in 5660 epoch, average loss: 823.35029296875\n",
      "                , loss1: 819.142578125\n",
      "                , loss2: 4.207778549194336\n",
      "=================================\n",
      "in 5670 epoch, average loss: 823.42001953125\n",
      "                , loss1: 819.19794921875\n",
      "                , loss2: 4.221974182128906\n",
      "=================================\n",
      "in 5680 epoch, average loss: 823.37001953125\n",
      "                , loss1: 819.163720703125\n",
      "                , loss2: 4.206369400024414\n",
      "=================================\n",
      "in 5690 epoch, average loss: 823.36171875\n",
      "                , loss1: 819.12490234375\n",
      "                , loss2: 4.2368419647216795\n",
      "=================================\n",
      "in 5700 epoch, average loss: 823.420703125\n",
      "                , loss1: 819.21357421875\n",
      "                , loss2: 4.207145690917969\n",
      "=================================\n",
      "in 5710 epoch, average loss: 823.37451171875\n",
      "                , loss1: 819.160888671875\n",
      "                , loss2: 4.213528442382812\n",
      "=================================\n",
      "in 5720 epoch, average loss: 823.34462890625\n",
      "                , loss1: 819.1048828125\n",
      "                , loss2: 4.239737701416016\n",
      "=================================\n",
      "in 5730 epoch, average loss: 823.34375\n",
      "                , loss1: 819.111962890625\n",
      "                , loss2: 4.231823348999024\n",
      "=================================\n",
      "in 5740 epoch, average loss: 823.2916015625\n",
      "                , loss1: 819.04912109375\n",
      "                , loss2: 4.242530441284179\n",
      "=================================\n",
      "in 5750 epoch, average loss: 823.35947265625\n",
      "                , loss1: 819.143505859375\n",
      "                , loss2: 4.215920257568359\n",
      "=================================\n",
      "in 5760 epoch, average loss: 823.32158203125\n",
      "                , loss1: 819.10537109375\n",
      "                , loss2: 4.216186141967773\n",
      "=================================\n",
      "in 5770 epoch, average loss: 823.36982421875\n",
      "                , loss1: 819.125048828125\n",
      "                , loss2: 4.2447254180908205\n",
      "=================================\n",
      "in 5780 epoch, average loss: 823.34560546875\n",
      "                , loss1: 819.148291015625\n",
      "                , loss2: 4.197331237792969\n",
      "=================================\n",
      "in 5790 epoch, average loss: 823.2052734375\n",
      "                , loss1: 818.962158203125\n",
      "                , loss2: 4.243057632446289\n",
      "=================================\n",
      "in 5800 epoch, average loss: 823.28544921875\n",
      "                , loss1: 819.041455078125\n",
      "                , loss2: 4.243965530395508\n",
      "=================================\n",
      "in 5810 epoch, average loss: 823.41181640625\n",
      "                , loss1: 819.19462890625\n",
      "                , loss2: 4.217258071899414\n",
      "=================================\n",
      "in 5820 epoch, average loss: 823.27001953125\n",
      "                , loss1: 819.06484375\n",
      "                , loss2: 4.205189514160156\n",
      "=================================\n",
      "in 5830 epoch, average loss: 823.24404296875\n",
      "                , loss1: 819.016748046875\n",
      "                , loss2: 4.2272602081298825\n",
      "=================================\n",
      "in 5840 epoch, average loss: 823.282421875\n",
      "                , loss1: 819.06005859375\n",
      "                , loss2: 4.2223258972167965\n",
      "=================================\n",
      "in 5850 epoch, average loss: 823.32353515625\n",
      "                , loss1: 819.10986328125\n",
      "                , loss2: 4.213653564453125\n",
      "=================================\n",
      "in 5860 epoch, average loss: 823.36181640625\n",
      "                , loss1: 819.218359375\n",
      "                , loss2: 4.14344367980957\n",
      "=================================\n",
      "in 5870 epoch, average loss: 823.30634765625\n",
      "                , loss1: 819.095703125\n",
      "                , loss2: 4.210634231567383\n",
      "=================================\n",
      "in 5880 epoch, average loss: 823.2771484375\n",
      "                , loss1: 819.067724609375\n",
      "                , loss2: 4.209413528442383\n",
      "=================================\n",
      "in 5890 epoch, average loss: 823.23837890625\n",
      "                , loss1: 818.99970703125\n",
      "                , loss2: 4.23868408203125\n",
      "=================================\n",
      "in 5900 epoch, average loss: 823.2005859375\n",
      "                , loss1: 818.94267578125\n",
      "                , loss2: 4.257794189453125\n",
      "=================================\n",
      "in 5910 epoch, average loss: 823.155078125\n",
      "                , loss1: 818.931591796875\n",
      "                , loss2: 4.223559188842773\n",
      "=================================\n",
      "in 5920 epoch, average loss: 823.25205078125\n",
      "                , loss1: 819.035400390625\n",
      "                , loss2: 4.216621398925781\n",
      "=================================\n",
      "in 5930 epoch, average loss: 823.1892578125\n",
      "                , loss1: 818.932958984375\n",
      "                , loss2: 4.2562507629394535\n",
      "=================================\n",
      "in 5940 epoch, average loss: 823.31962890625\n",
      "                , loss1: 819.12841796875\n",
      "                , loss2: 4.19122085571289\n",
      "=================================\n",
      "in 5950 epoch, average loss: 823.2650390625\n",
      "                , loss1: 819.03291015625\n",
      "                , loss2: 4.23210563659668\n",
      "=================================\n",
      "in 5960 epoch, average loss: 823.16953125\n",
      "                , loss1: 818.91259765625\n",
      "                , loss2: 4.257047653198242\n",
      "=================================\n",
      "in 5970 epoch, average loss: 823.16748046875\n",
      "                , loss1: 818.950244140625\n",
      "                , loss2: 4.217181015014648\n",
      "=================================\n",
      "in 5980 epoch, average loss: 823.21259765625\n",
      "                , loss1: 818.989208984375\n",
      "                , loss2: 4.223390579223633\n",
      "=================================\n",
      "in 5990 epoch, average loss: 823.10830078125\n",
      "                , loss1: 818.881884765625\n",
      "                , loss2: 4.22636604309082\n",
      "=================================\n",
      "in 6000 epoch, average loss: 823.2146484375\n",
      "                , loss1: 819.025146484375\n",
      "                , loss2: 4.18951187133789\n",
      "=================================\n",
      "in 6010 epoch, average loss: 823.398828125\n",
      "                , loss1: 819.1634765625\n",
      "                , loss2: 4.235329818725586\n",
      "=================================\n",
      "in 6020 epoch, average loss: 823.3798828125\n",
      "                , loss1: 819.16044921875\n",
      "                , loss2: 4.219420623779297\n",
      "=================================\n",
      "in 6030 epoch, average loss: 823.26865234375\n",
      "                , loss1: 819.030810546875\n",
      "                , loss2: 4.237883758544922\n",
      "=================================\n",
      "in 6040 epoch, average loss: 823.1490234375\n",
      "                , loss1: 818.9296875\n",
      "                , loss2: 4.219246673583984\n",
      "=================================\n",
      "in 6050 epoch, average loss: 823.1734375\n",
      "                , loss1: 818.949755859375\n",
      "                , loss2: 4.223659896850586\n",
      "=================================\n",
      "in 6060 epoch, average loss: 823.078125\n",
      "                , loss1: 819.07919921875\n",
      "                , loss2: 3.998889923095703\n",
      "=================================\n",
      "in 6070 epoch, average loss: 823.423046875\n",
      "                , loss1: 819.3041015625\n",
      "                , loss2: 4.118964767456054\n",
      "=================================\n",
      "in 6080 epoch, average loss: 823.2515625\n",
      "                , loss1: 819.00009765625\n",
      "                , loss2: 4.251492309570312\n",
      "=================================\n",
      "in 6090 epoch, average loss: 823.12578125\n",
      "                , loss1: 818.89287109375\n",
      "                , loss2: 4.232880401611328\n",
      "=================================\n",
      "in 6100 epoch, average loss: 823.16357421875\n",
      "                , loss1: 818.906494140625\n",
      "                , loss2: 4.257120895385742\n",
      "=================================\n",
      "in 6110 epoch, average loss: 823.1767578125\n",
      "                , loss1: 818.93798828125\n",
      "                , loss2: 4.238873672485352\n",
      "=================================\n",
      "in 6120 epoch, average loss: 823.2345703125\n",
      "                , loss1: 818.995361328125\n",
      "                , loss2: 4.239162445068359\n",
      "=================================\n",
      "in 6130 epoch, average loss: 823.39462890625\n",
      "                , loss1: 819.18388671875\n",
      "                , loss2: 4.210679626464843\n",
      "=================================\n",
      "in 6140 epoch, average loss: 823.07802734375\n",
      "                , loss1: 818.874658203125\n",
      "                , loss2: 4.203362274169922\n",
      "=================================\n",
      "in 6150 epoch, average loss: 823.1412109375\n",
      "                , loss1: 818.89521484375\n",
      "                , loss2: 4.245877838134765\n",
      "=================================\n",
      "in 6160 epoch, average loss: 823.13154296875\n",
      "                , loss1: 818.882763671875\n",
      "                , loss2: 4.2487537384033205\n",
      "=================================\n",
      "in 6170 epoch, average loss: 823.37412109375\n",
      "                , loss1: 819.2619140625\n",
      "                , loss2: 4.112205123901367\n",
      "=================================\n",
      "in 6180 epoch, average loss: 823.17119140625\n",
      "                , loss1: 818.9544921875\n",
      "                , loss2: 4.2167011260986325\n",
      "=================================\n",
      "in 6190 epoch, average loss: 823.1421875\n",
      "                , loss1: 818.948583984375\n",
      "                , loss2: 4.19366226196289\n",
      "=================================\n",
      "in 6200 epoch, average loss: 823.28046875\n",
      "                , loss1: 819.078076171875\n",
      "                , loss2: 4.202349472045898\n",
      "=================================\n",
      "in 6210 epoch, average loss: 823.009375\n",
      "                , loss1: 818.742236328125\n",
      "                , loss2: 4.267190170288086\n",
      "=================================\n",
      "in 6220 epoch, average loss: 823.05859375\n",
      "                , loss1: 818.813525390625\n",
      "                , loss2: 4.24505386352539\n",
      "=================================\n",
      "in 6230 epoch, average loss: 823.00322265625\n",
      "                , loss1: 818.770068359375\n",
      "                , loss2: 4.233157730102539\n",
      "=================================\n",
      "in 6240 epoch, average loss: 823.07158203125\n",
      "                , loss1: 818.831787109375\n",
      "                , loss2: 4.239707183837891\n",
      "=================================\n",
      "in 6250 epoch, average loss: 823.068359375\n",
      "                , loss1: 818.85\n",
      "                , loss2: 4.218295669555664\n",
      "=================================\n",
      "in 6260 epoch, average loss: 823.01611328125\n",
      "                , loss1: 818.766796875\n",
      "                , loss2: 4.249334716796875\n",
      "=================================\n",
      "in 6270 epoch, average loss: 823.01279296875\n",
      "                , loss1: 818.756689453125\n",
      "                , loss2: 4.25616455078125\n",
      "=================================\n",
      "in 6280 epoch, average loss: 823.07119140625\n",
      "                , loss1: 818.836962890625\n",
      "                , loss2: 4.234317016601563\n",
      "=================================\n",
      "in 6290 epoch, average loss: 823.08271484375\n",
      "                , loss1: 818.8384765625\n",
      "                , loss2: 4.244228363037109\n",
      "=================================\n",
      "in 6300 epoch, average loss: 823.06376953125\n",
      "                , loss1: 818.7861328125\n",
      "                , loss2: 4.277606964111328\n",
      "=================================\n",
      "in 6310 epoch, average loss: 822.9416015625\n",
      "                , loss1: 818.67607421875\n",
      "                , loss2: 4.265387725830078\n",
      "=================================\n",
      "in 6320 epoch, average loss: 823.02177734375\n",
      "                , loss1: 818.75546875\n",
      "                , loss2: 4.266162872314453\n",
      "=================================\n",
      "in 6330 epoch, average loss: 823.07138671875\n",
      "                , loss1: 818.845849609375\n",
      "                , loss2: 4.225583267211914\n",
      "=================================\n",
      "in 6340 epoch, average loss: 823.12392578125\n",
      "                , loss1: 818.8638671875\n",
      "                , loss2: 4.2600963592529295\n",
      "=================================\n",
      "in 6350 epoch, average loss: 823.13037109375\n",
      "                , loss1: 818.892724609375\n",
      "                , loss2: 4.23773307800293\n",
      "=================================\n",
      "in 6360 epoch, average loss: 823.00263671875\n",
      "                , loss1: 818.73896484375\n",
      "                , loss2: 4.2636566162109375\n",
      "=================================\n",
      "in 6370 epoch, average loss: 823.16513671875\n",
      "                , loss1: 818.925927734375\n",
      "                , loss2: 4.239170074462891\n",
      "=================================\n",
      "in 6380 epoch, average loss: 822.948828125\n",
      "                , loss1: 818.696923828125\n",
      "                , loss2: 4.2519889831542965\n",
      "=================================\n",
      "in 6390 epoch, average loss: 823.0669921875\n",
      "                , loss1: 818.816552734375\n",
      "                , loss2: 4.250408935546875\n",
      "=================================\n",
      "in 6400 epoch, average loss: 823.12861328125\n",
      "                , loss1: 818.920166015625\n",
      "                , loss2: 4.2084697723388675\n",
      "=================================\n",
      "in 6410 epoch, average loss: 822.97021484375\n",
      "                , loss1: 818.720556640625\n",
      "                , loss2: 4.249612045288086\n",
      "=================================\n",
      "in 6420 epoch, average loss: 822.9876953125\n",
      "                , loss1: 818.73603515625\n",
      "                , loss2: 4.251702499389649\n",
      "=================================\n",
      "in 6430 epoch, average loss: 822.98720703125\n",
      "                , loss1: 818.711279296875\n",
      "                , loss2: 4.275948715209961\n",
      "=================================\n",
      "in 6440 epoch, average loss: 822.955859375\n",
      "                , loss1: 818.684375\n",
      "                , loss2: 4.27142105102539\n",
      "=================================\n",
      "in 6450 epoch, average loss: 822.9609375\n",
      "                , loss1: 818.762744140625\n",
      "                , loss2: 4.198200988769531\n",
      "=================================\n",
      "in 6460 epoch, average loss: 823.09365234375\n",
      "                , loss1: 818.83486328125\n",
      "                , loss2: 4.258829116821289\n",
      "=================================\n",
      "in 6470 epoch, average loss: 823.15185546875\n",
      "                , loss1: 818.88271484375\n",
      "                , loss2: 4.2691192626953125\n",
      "=================================\n",
      "in 6480 epoch, average loss: 823.08720703125\n",
      "                , loss1: 818.855078125\n",
      "                , loss2: 4.232180786132813\n",
      "=================================\n",
      "in 6490 epoch, average loss: 822.98466796875\n",
      "                , loss1: 818.73427734375\n",
      "                , loss2: 4.250339508056641\n",
      "=================================\n",
      "in 6500 epoch, average loss: 822.9158203125\n",
      "                , loss1: 818.653564453125\n",
      "                , loss2: 4.262115097045898\n",
      "=================================\n",
      "in 6510 epoch, average loss: 822.953125\n",
      "                , loss1: 818.69853515625\n",
      "                , loss2: 4.254618453979492\n",
      "=================================\n",
      "in 6520 epoch, average loss: 823.0578125\n",
      "                , loss1: 818.784521484375\n",
      "                , loss2: 4.273295593261719\n",
      "=================================\n",
      "in 6530 epoch, average loss: 822.9916015625\n",
      "                , loss1: 818.707568359375\n",
      "                , loss2: 4.284024810791015\n",
      "=================================\n",
      "in 6540 epoch, average loss: 822.92119140625\n",
      "                , loss1: 818.662109375\n",
      "                , loss2: 4.258994293212891\n",
      "=================================\n",
      "in 6550 epoch, average loss: 822.94140625\n",
      "                , loss1: 818.6857421875\n",
      "                , loss2: 4.255679702758789\n",
      "=================================\n",
      "in 6560 epoch, average loss: 822.97294921875\n",
      "                , loss1: 818.717138671875\n",
      "                , loss2: 4.255856704711914\n",
      "=================================\n",
      "in 6570 epoch, average loss: 822.96640625\n",
      "                , loss1: 818.717578125\n",
      "                , loss2: 4.248821258544922\n",
      "=================================\n",
      "in 6580 epoch, average loss: 822.90869140625\n",
      "                , loss1: 818.643603515625\n",
      "                , loss2: 4.265142822265625\n",
      "=================================\n",
      "in 6590 epoch, average loss: 822.95625\n",
      "                , loss1: 818.69013671875\n",
      "                , loss2: 4.266102600097656\n",
      "=================================\n",
      "in 6600 epoch, average loss: 822.92236328125\n",
      "                , loss1: 818.662353515625\n",
      "                , loss2: 4.259910964965821\n",
      "=================================\n",
      "in 6610 epoch, average loss: 822.94599609375\n",
      "                , loss1: 818.700146484375\n",
      "                , loss2: 4.24597282409668\n",
      "=================================\n",
      "in 6620 epoch, average loss: 823.0025390625\n",
      "                , loss1: 818.732177734375\n",
      "                , loss2: 4.270352935791015\n",
      "=================================\n",
      "in 6630 epoch, average loss: 822.90859375\n",
      "                , loss1: 818.61494140625\n",
      "                , loss2: 4.293633651733399\n",
      "=================================\n",
      "in 6640 epoch, average loss: 822.9923828125\n",
      "                , loss1: 818.68271484375\n",
      "                , loss2: 4.309707260131836\n",
      "=================================\n",
      "in 6650 epoch, average loss: 823.03095703125\n",
      "                , loss1: 820.17978515625\n",
      "                , loss2: 2.851181221008301\n",
      "=================================\n",
      "in 6660 epoch, average loss: 822.60205078125\n",
      "                , loss1: 821.28662109375\n",
      "                , loss2: 1.3154054641723634\n",
      "=================================\n",
      "in 6670 epoch, average loss: 821.95283203125\n",
      "                , loss1: 820.63330078125\n",
      "                , loss2: 1.319490337371826\n",
      "=================================\n",
      "in 6680 epoch, average loss: 821.9765625\n",
      "                , loss1: 820.67548828125\n",
      "                , loss2: 1.301180362701416\n",
      "=================================\n",
      "in 6690 epoch, average loss: 821.99658203125\n",
      "                , loss1: 820.70068359375\n",
      "                , loss2: 1.2960012435913086\n",
      "=================================\n",
      "in 6700 epoch, average loss: 821.89775390625\n",
      "                , loss1: 820.59228515625\n",
      "                , loss2: 1.3054723739624023\n",
      "=================================\n",
      "in 6710 epoch, average loss: 822.05966796875\n",
      "                , loss1: 820.75634765625\n",
      "                , loss2: 1.3033392906188965\n",
      "=================================\n",
      "in 6720 epoch, average loss: 822.0203125\n",
      "                , loss1: 820.70927734375\n",
      "                , loss2: 1.31111421585083\n",
      "=================================\n",
      "in 6730 epoch, average loss: 821.96962890625\n",
      "                , loss1: 820.66064453125\n",
      "                , loss2: 1.308995819091797\n",
      "=================================\n",
      "in 6740 epoch, average loss: 822.1240234375\n",
      "                , loss1: 820.82236328125\n",
      "                , loss2: 1.3016729354858398\n",
      "=================================\n",
      "in 6750 epoch, average loss: 821.89599609375\n",
      "                , loss1: 820.5845703125\n",
      "                , loss2: 1.3113727569580078\n",
      "=================================\n",
      "in 6760 epoch, average loss: 822.0810546875\n",
      "                , loss1: 820.773046875\n",
      "                , loss2: 1.308028507232666\n",
      "=================================\n",
      "in 6770 epoch, average loss: 821.96279296875\n",
      "                , loss1: 820.68525390625\n",
      "                , loss2: 1.2775464057922363\n",
      "=================================\n",
      "in 6780 epoch, average loss: 821.9984375\n",
      "                , loss1: 820.71767578125\n",
      "                , loss2: 1.2807626724243164\n",
      "=================================\n",
      "in 6790 epoch, average loss: 822.10517578125\n",
      "                , loss1: 820.801953125\n",
      "                , loss2: 1.3031749725341797\n",
      "=================================\n",
      "in 6800 epoch, average loss: 821.99501953125\n",
      "                , loss1: 820.6845703125\n",
      "                , loss2: 1.3104074478149415\n",
      "=================================\n",
      "in 6810 epoch, average loss: 821.9205078125\n",
      "                , loss1: 820.61220703125\n",
      "                , loss2: 1.3083727836608887\n",
      "=================================\n",
      "in 6820 epoch, average loss: 821.88046875\n",
      "                , loss1: 820.57646484375\n",
      "                , loss2: 1.3040237426757812\n",
      "=================================\n",
      "in 6830 epoch, average loss: 821.88876953125\n",
      "                , loss1: 820.58779296875\n",
      "                , loss2: 1.3009923934936523\n",
      "=================================\n",
      "in 6840 epoch, average loss: 821.87412109375\n",
      "                , loss1: 820.56953125\n",
      "                , loss2: 1.3045767784118651\n",
      "=================================\n",
      "in 6850 epoch, average loss: 821.791015625\n",
      "                , loss1: 820.4806640625\n",
      "                , loss2: 1.3102883338928222\n",
      "=================================\n",
      "in 6860 epoch, average loss: 821.95048828125\n",
      "                , loss1: 820.6384765625\n",
      "                , loss2: 1.3120445251464843\n",
      "=================================\n",
      "in 6870 epoch, average loss: 821.84375\n",
      "                , loss1: 820.5341796875\n",
      "                , loss2: 1.3094919204711915\n",
      "=================================\n",
      "in 6880 epoch, average loss: 821.84052734375\n",
      "                , loss1: 820.53466796875\n",
      "                , loss2: 1.3059250831604003\n",
      "=================================\n",
      "in 6890 epoch, average loss: 822.0353515625\n",
      "                , loss1: 820.72578125\n",
      "                , loss2: 1.3096054077148438\n",
      "=================================\n",
      "in 6900 epoch, average loss: 821.87373046875\n",
      "                , loss1: 820.5626953125\n",
      "                , loss2: 1.3110069274902343\n",
      "=================================\n",
      "in 6910 epoch, average loss: 821.93720703125\n",
      "                , loss1: 820.62802734375\n",
      "                , loss2: 1.3091301918029785\n",
      "=================================\n",
      "in 6920 epoch, average loss: 821.803515625\n",
      "                , loss1: 820.4908203125\n",
      "                , loss2: 1.3126985549926757\n",
      "=================================\n",
      "in 6930 epoch, average loss: 821.79716796875\n",
      "                , loss1: 820.4841796875\n",
      "                , loss2: 1.3129913330078125\n",
      "=================================\n",
      "in 6940 epoch, average loss: 821.83076171875\n",
      "                , loss1: 820.5169921875\n",
      "                , loss2: 1.3135976791381836\n",
      "=================================\n",
      "in 6950 epoch, average loss: 821.86455078125\n",
      "                , loss1: 820.5447265625\n",
      "                , loss2: 1.3197940826416015\n",
      "=================================\n",
      "in 6960 epoch, average loss: 821.821484375\n",
      "                , loss1: 820.509375\n",
      "                , loss2: 1.312113094329834\n",
      "=================================\n",
      "in 6970 epoch, average loss: 821.83828125\n",
      "                , loss1: 820.51865234375\n",
      "                , loss2: 1.3195807456970214\n",
      "=================================\n",
      "in 6980 epoch, average loss: 821.8103515625\n",
      "                , loss1: 820.49794921875\n",
      "                , loss2: 1.3123846054077148\n",
      "=================================\n",
      "in 6990 epoch, average loss: 821.99990234375\n",
      "                , loss1: 820.69912109375\n",
      "                , loss2: 1.3007702827453613\n",
      "=================================\n",
      "in 7000 epoch, average loss: 821.865625\n",
      "                , loss1: 820.55166015625\n",
      "                , loss2: 1.3139584541320801\n",
      "=================================\n",
      "in 7010 epoch, average loss: 821.83994140625\n",
      "                , loss1: 820.5314453125\n",
      "                , loss2: 1.3084531784057618\n",
      "=================================\n",
      "in 7020 epoch, average loss: 821.91669921875\n",
      "                , loss1: 820.60966796875\n",
      "                , loss2: 1.3071197509765624\n",
      "=================================\n",
      "in 7030 epoch, average loss: 821.791015625\n",
      "                , loss1: 820.4728515625\n",
      "                , loss2: 1.318169116973877\n",
      "=================================\n",
      "in 7040 epoch, average loss: 821.8818359375\n",
      "                , loss1: 820.57021484375\n",
      "                , loss2: 1.3115714073181153\n",
      "=================================\n",
      "in 7050 epoch, average loss: 821.9919921875\n",
      "                , loss1: 820.684765625\n",
      "                , loss2: 1.307140064239502\n",
      "=================================\n",
      "in 7060 epoch, average loss: 821.801953125\n",
      "                , loss1: 820.49052734375\n",
      "                , loss2: 1.3114311218261718\n",
      "=================================\n",
      "in 7070 epoch, average loss: 821.76962890625\n",
      "                , loss1: 820.45849609375\n",
      "                , loss2: 1.3111420631408692\n",
      "=================================\n",
      "in 7080 epoch, average loss: 821.7892578125\n",
      "                , loss1: 820.47529296875\n",
      "                , loss2: 1.313974952697754\n",
      "=================================\n",
      "in 7090 epoch, average loss: 821.88515625\n",
      "                , loss1: 820.56171875\n",
      "                , loss2: 1.3234453201293945\n",
      "=================================\n",
      "in 7100 epoch, average loss: 821.76552734375\n",
      "                , loss1: 820.44970703125\n",
      "                , loss2: 1.3158719062805175\n",
      "=================================\n",
      "in 7110 epoch, average loss: 821.88193359375\n",
      "                , loss1: 820.5693359375\n",
      "                , loss2: 1.312553596496582\n",
      "=================================\n",
      "in 7120 epoch, average loss: 821.7806640625\n",
      "                , loss1: 820.45771484375\n",
      "                , loss2: 1.322848415374756\n",
      "=================================\n",
      "in 7130 epoch, average loss: 821.77392578125\n",
      "                , loss1: 820.45869140625\n",
      "                , loss2: 1.315223503112793\n",
      "=================================\n",
      "in 7140 epoch, average loss: 821.8158203125\n",
      "                , loss1: 820.49931640625\n",
      "                , loss2: 1.3165644645690917\n",
      "=================================\n",
      "in 7150 epoch, average loss: 821.76240234375\n",
      "                , loss1: 820.4453125\n",
      "                , loss2: 1.317183494567871\n",
      "=================================\n",
      "in 7160 epoch, average loss: 821.8486328125\n",
      "                , loss1: 820.53779296875\n",
      "                , loss2: 1.3109862327575683\n",
      "=================================\n",
      "in 7170 epoch, average loss: 821.7625\n",
      "                , loss1: 820.45390625\n",
      "                , loss2: 1.3086673736572265\n",
      "=================================\n",
      "in 7180 epoch, average loss: 821.819140625\n",
      "                , loss1: 820.4935546875\n",
      "                , loss2: 1.3255271911621094\n",
      "=================================\n",
      "in 7190 epoch, average loss: 821.7408203125\n",
      "                , loss1: 820.42626953125\n",
      "                , loss2: 1.3144396781921386\n",
      "=================================\n",
      "in 7200 epoch, average loss: 821.7693359375\n",
      "                , loss1: 820.45966796875\n",
      "                , loss2: 1.3096108436584473\n",
      "=================================\n",
      "in 7210 epoch, average loss: 821.884375\n",
      "                , loss1: 820.57353515625\n",
      "                , loss2: 1.3107950210571289\n",
      "=================================\n",
      "in 7220 epoch, average loss: 821.757421875\n",
      "                , loss1: 820.437890625\n",
      "                , loss2: 1.3196385383605957\n",
      "=================================\n",
      "in 7230 epoch, average loss: 821.771875\n",
      "                , loss1: 820.45029296875\n",
      "                , loss2: 1.3216095924377442\n",
      "=================================\n",
      "in 7240 epoch, average loss: 821.69873046875\n",
      "                , loss1: 820.38408203125\n",
      "                , loss2: 1.3147488594055177\n",
      "=================================\n",
      "in 7250 epoch, average loss: 821.818359375\n",
      "                , loss1: 820.49306640625\n",
      "                , loss2: 1.325136089324951\n",
      "=================================\n",
      "in 7260 epoch, average loss: 821.7607421875\n",
      "                , loss1: 820.4595703125\n",
      "                , loss2: 1.3011987686157227\n",
      "=================================\n",
      "in 7270 epoch, average loss: 821.85615234375\n",
      "                , loss1: 820.5421875\n",
      "                , loss2: 1.313863468170166\n",
      "=================================\n",
      "in 7280 epoch, average loss: 821.74970703125\n",
      "                , loss1: 820.42978515625\n",
      "                , loss2: 1.3200443267822266\n",
      "=================================\n",
      "in 7290 epoch, average loss: 821.761328125\n",
      "                , loss1: 820.4458984375\n",
      "                , loss2: 1.3154310226440429\n",
      "=================================\n",
      "in 7300 epoch, average loss: 821.791796875\n",
      "                , loss1: 820.47470703125\n",
      "                , loss2: 1.3170766830444336\n",
      "=================================\n",
      "in 7310 epoch, average loss: 821.700390625\n",
      "                , loss1: 820.38017578125\n",
      "                , loss2: 1.3201890945434571\n",
      "=================================\n",
      "in 7320 epoch, average loss: 821.75849609375\n",
      "                , loss1: 820.4390625\n",
      "                , loss2: 1.3195094108581542\n",
      "=================================\n",
      "in 7330 epoch, average loss: 821.685546875\n",
      "                , loss1: 820.36953125\n",
      "                , loss2: 1.3160202026367187\n",
      "=================================\n",
      "in 7340 epoch, average loss: 821.76015625\n",
      "                , loss1: 820.44990234375\n",
      "                , loss2: 1.3102945327758788\n",
      "=================================\n",
      "in 7350 epoch, average loss: 821.7005859375\n",
      "                , loss1: 820.38212890625\n",
      "                , loss2: 1.318463134765625\n",
      "=================================\n",
      "in 7360 epoch, average loss: 821.75615234375\n",
      "                , loss1: 820.43232421875\n",
      "                , loss2: 1.3238059997558593\n",
      "=================================\n",
      "in 7370 epoch, average loss: 821.7513671875\n",
      "                , loss1: 820.43564453125\n",
      "                , loss2: 1.3156536102294922\n",
      "=================================\n",
      "in 7380 epoch, average loss: 821.6740234375\n",
      "                , loss1: 820.35537109375\n",
      "                , loss2: 1.3186485290527343\n",
      "=================================\n",
      "in 7390 epoch, average loss: 821.7240234375\n",
      "                , loss1: 820.40400390625\n",
      "                , loss2: 1.3199641227722168\n",
      "=================================\n",
      "in 7400 epoch, average loss: 821.86787109375\n",
      "                , loss1: 820.55234375\n",
      "                , loss2: 1.3156070709228516\n",
      "=================================\n",
      "in 7410 epoch, average loss: 821.7380859375\n",
      "                , loss1: 820.41591796875\n",
      "                , loss2: 1.322218132019043\n",
      "=================================\n",
      "in 7420 epoch, average loss: 821.683984375\n",
      "                , loss1: 820.3669921875\n",
      "                , loss2: 1.3170625686645507\n",
      "=================================\n",
      "in 7430 epoch, average loss: 821.70712890625\n",
      "                , loss1: 820.38896484375\n",
      "                , loss2: 1.3182117462158203\n",
      "=================================\n",
      "in 7440 epoch, average loss: 821.6876953125\n",
      "                , loss1: 820.37666015625\n",
      "                , loss2: 1.3110371589660645\n",
      "=================================\n",
      "in 7450 epoch, average loss: 821.7140625\n",
      "                , loss1: 820.39736328125\n",
      "                , loss2: 1.3168085098266602\n",
      "=================================\n",
      "in 7460 epoch, average loss: 821.65068359375\n",
      "                , loss1: 820.32744140625\n",
      "                , loss2: 1.3231033325195312\n",
      "=================================\n",
      "in 7470 epoch, average loss: 821.73251953125\n",
      "                , loss1: 820.41279296875\n",
      "                , loss2: 1.3197307586669922\n",
      "=================================\n",
      "in 7480 epoch, average loss: 821.680078125\n",
      "                , loss1: 820.35654296875\n",
      "                , loss2: 1.3235456466674804\n",
      "=================================\n",
      "in 7490 epoch, average loss: 821.63359375\n",
      "                , loss1: 820.31376953125\n",
      "                , loss2: 1.3199090957641602\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "for epoch in range(7500):\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    # train\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    # validation\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
