{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exs/.conda/envs/partition/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) \n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed) \n",
    "random.seed(seed) \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 2\n",
    "\n",
    "# 1253 target\n",
    "weight = 50\n",
    "limit = 0.1\n",
    "sub = 0.022\n",
    "\n",
    "lr = 3e-3\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 3824, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.9}\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 2048, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0}\n",
    "h_hyper_prmts[\"convlayers12\"] = {\"in_channels\": 1024, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 512, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0}\n",
    "h_hyper_prmts[\"convlayers13\"] = {\"in_channels\": 256, \"out_channels\": 128, \"use_bn\": False, \"drop_rate\": 0}\n",
    "h_hyper_prmts[\"convlayers131\"] = {\"in_channels\": 128, \"out_channels\": 64, \"use_bn\": False, \"drop_rate\": 0}\n",
    "\n",
    "\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":list(h_hyper_prmts.values())[-1][\"out_channels\"], \"out_channels\":32, \"use_bn\":False, \"drop_rate\":0}\n",
    "# l_hyper_prmts[\"linerlayer42\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":False, \"drop_rate\":0}\n",
    "l_hyper_prmts[\"linerlayer423\"] = {\"in_channels\":32, \"out_channels\":6, \"use_bn\":True, \"drop_rate\":0}\n",
    "\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device, weight):\n",
    "\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "\n",
    "    X_ = outs.t().unsqueeze(-1)\n",
    "    H_ = H.unsqueeze(0)\n",
    "    xweight = H.sum(dim=0)\n",
    "    mid = X_.mul(H_)\n",
    "    sum = (mid * (1 / xweight)).sum()\n",
    "    sub = (mid + (1 - H)).prod(dim=1).sum()\n",
    "    loss_1 = sum - sub\n",
    "\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  \n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7523, 3824)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/pubmed\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (4): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  (6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: 20.499978637695314\n",
      "                , loss1: 204.99384765625\n",
      "                , loss2: 0.0005931682419031859\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 10 epoch, average loss: 6637.33125\n",
      "                , loss1: 2297.69765625\n",
      "                , loss2: 6407.5609375\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 20 epoch, average loss: 983.2755859375\n",
      "                , loss1: 2509.217578125\n",
      "                , loss2: 732.35380859375\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 30 epoch, average loss: 387.8644775390625\n",
      "                , loss1: 2481.701953125\n",
      "                , loss2: 139.6942626953125\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 40 epoch, average loss: 288.9712646484375\n",
      "                , loss1: 2448.86015625\n",
      "                , loss2: 44.08523864746094\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 50 epoch, average loss: 256.250244140625\n",
      "                , loss1: 2436.1294921875\n",
      "                , loss2: 12.637281036376953\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 60 epoch, average loss: 246.46787109375\n",
      "                , loss1: 2427.251953125\n",
      "                , loss2: 3.742667007446289\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 70 epoch, average loss: 243.001220703125\n",
      "                , loss1: 2418.4859375\n",
      "                , loss2: 1.1525989532470704\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 80 epoch, average loss: 241.7490966796875\n",
      "                , loss1: 2413.7486328125\n",
      "                , loss2: 0.3742168664932251\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 90 epoch, average loss: 240.8458251953125\n",
      "                , loss1: 2407.36015625\n",
      "                , loss2: 0.10980452299118042\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 100 epoch, average loss: 239.737060546875\n",
      "                , loss1: 2396.528125\n",
      "                , loss2: 0.08421592712402344\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 110 epoch, average loss: 236.8378173828125\n",
      "                , loss1: 2367.32734375\n",
      "                , loss2: 0.1050870418548584\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 120 epoch, average loss: 231.85048828125\n",
      "                , loss1: 2316.487890625\n",
      "                , loss2: 0.20171873569488524\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 130 epoch, average loss: 223.77197265625\n",
      "                , loss1: 2236.9619140625\n",
      "                , loss2: 0.07577816843986511\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 140 epoch, average loss: 216.6910888671875\n",
      "                , loss1: 2166.3638671875\n",
      "                , loss2: 0.05467472672462463\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 150 epoch, average loss: 212.310546875\n",
      "                , loss1: 2122.854296875\n",
      "                , loss2: 0.025116366147994996\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 160 epoch, average loss: 209.7191650390625\n",
      "                , loss1: 2096.649609375\n",
      "                , loss2: 0.05418531894683838\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 170 epoch, average loss: 209.01376953125\n",
      "                , loss1: 2089.77890625\n",
      "                , loss2: 0.035878044366836545\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 180 epoch, average loss: 208.628173828125\n",
      "                , loss1: 2086.0765625\n",
      "                , loss2: 0.020540760457515718\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 190 epoch, average loss: 208.3365234375\n",
      "                , loss1: 2083.2033203125\n",
      "                , loss2: 0.016191065311431885\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 200 epoch, average loss: 208.1108154296875\n",
      "                , loss1: 2080.9521484375\n",
      "                , loss2: 0.01556890606880188\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 210 epoch, average loss: 207.9228759765625\n",
      "                , loss1: 2079.085546875\n",
      "                , loss2: 0.014289379119873047\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 220 epoch, average loss: 207.7540283203125\n",
      "                , loss1: 2077.371875\n",
      "                , loss2: 0.016844943165779114\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 230 epoch, average loss: 207.5942626953125\n",
      "                , loss1: 2075.724609375\n",
      "                , loss2: 0.021805010735988617\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 240 epoch, average loss: 207.4487548828125\n",
      "                , loss1: 2074.2427734375\n",
      "                , loss2: 0.024444153904914855\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 250 epoch, average loss: 207.313232421875\n",
      "                , loss1: 2072.9138671875\n",
      "                , loss2: 0.02183688133955002\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 260 epoch, average loss: 207.160888671875\n",
      "                , loss1: 2071.451171875\n",
      "                , loss2: 0.015759685635566713\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 270 epoch, average loss: 207.018896484375\n",
      "                , loss1: 2069.925390625\n",
      "                , loss2: 0.02638491988182068\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 280 epoch, average loss: 206.9113037109375\n",
      "                , loss1: 2068.893359375\n",
      "                , loss2: 0.021946658194065095\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 290 epoch, average loss: 206.81611328125\n",
      "                , loss1: 2067.958203125\n",
      "                , loss2: 0.020297500491142272\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 300 epoch, average loss: 206.7502197265625\n",
      "                , loss1: 2067.171875\n",
      "                , loss2: 0.033013054728508\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 310 epoch, average loss: 206.6716064453125\n",
      "                , loss1: 2066.54765625\n",
      "                , loss2: 0.016841596364974974\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 320 epoch, average loss: 206.6121826171875\n",
      "                , loss1: 2065.9640625\n",
      "                , loss2: 0.015787723660469054\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 330 epoch, average loss: 206.56923828125\n",
      "                , loss1: 2065.4138671875\n",
      "                , loss2: 0.02784433662891388\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 340 epoch, average loss: 206.51337890625\n",
      "                , loss1: 2064.9375\n",
      "                , loss2: 0.019617900252342224\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 350 epoch, average loss: 206.515966796875\n",
      "                , loss1: 2064.5615234375\n",
      "                , loss2: 0.05983128547668457\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 360 epoch, average loss: 206.4458984375\n",
      "                , loss1: 2064.1974609375\n",
      "                , loss2: 0.02616259753704071\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 370 epoch, average loss: 206.4026123046875\n",
      "                , loss1: 2063.855859375\n",
      "                , loss2: 0.017025685310363768\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 380 epoch, average loss: 206.3635009765625\n",
      "                , loss1: 2063.4875\n",
      "                , loss2: 0.014788100123405456\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 390 epoch, average loss: 206.3261962890625\n",
      "                , loss1: 2063.14453125\n",
      "                , loss2: 0.011754925549030303\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 400 epoch, average loss: 206.3022216796875\n",
      "                , loss1: 2062.8298828125\n",
      "                , loss2: 0.019249413907527924\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 410 epoch, average loss: 206.2942138671875\n",
      "                , loss1: 2062.533984375\n",
      "                , loss2: 0.0407599687576294\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 420 epoch, average loss: 206.25107421875\n",
      "                , loss1: 2062.309765625\n",
      "                , loss2: 0.020066681504249572\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 430 epoch, average loss: 206.222314453125\n",
      "                , loss1: 2062.06015625\n",
      "                , loss2: 0.01629359573125839\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 440 epoch, average loss: 206.1976806640625\n",
      "                , loss1: 2061.858984375\n",
      "                , loss2: 0.011791395395994187\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 450 epoch, average loss: 206.192626953125\n",
      "                , loss1: 2061.66171875\n",
      "                , loss2: 0.026437214016914366\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 460 epoch, average loss: 206.21376953125\n",
      "                , loss1: 2061.4490234375\n",
      "                , loss2: 0.06885975003242492\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 470 epoch, average loss: 206.152685546875\n",
      "                , loss1: 2061.2974609375\n",
      "                , loss2: 0.02291083037853241\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 480 epoch, average loss: 206.127490234375\n",
      "                , loss1: 2061.13046875\n",
      "                , loss2: 0.014454282820224762\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 490 epoch, average loss: 206.1086669921875\n",
      "                , loss1: 2060.9693359375\n",
      "                , loss2: 0.011712004989385605\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 500 epoch, average loss: 206.090966796875\n",
      "                , loss1: 2060.801953125\n",
      "                , loss2: 0.01075584813952446\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 510 epoch, average loss: 206.07353515625\n",
      "                , loss1: 2060.643359375\n",
      "                , loss2: 0.009182560443878173\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 520 epoch, average loss: 206.1474365234375\n",
      "                , loss1: 2060.498046875\n",
      "                , loss2: 0.09765695929527282\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 530 epoch, average loss: 206.1052001953125\n",
      "                , loss1: 2060.3369140625\n",
      "                , loss2: 0.07151367664337158\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 540 epoch, average loss: 206.04658203125\n",
      "                , loss1: 2060.1921875\n",
      "                , loss2: 0.027349761128425597\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 550 epoch, average loss: 206.0226806640625\n",
      "                , loss1: 2060.05859375\n",
      "                , loss2: 0.016808496415615083\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 560 epoch, average loss: 206.0018310546875\n",
      "                , loss1: 2059.91640625\n",
      "                , loss2: 0.01017499566078186\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 570 epoch, average loss: 205.9858642578125\n",
      "                , loss1: 2059.76796875\n",
      "                , loss2: 0.009055416285991668\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 580 epoch, average loss: 205.9700927734375\n",
      "                , loss1: 2059.61640625\n",
      "                , loss2: 0.008421571552753448\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 590 epoch, average loss: 205.9540771484375\n",
      "                , loss1: 2059.459375\n",
      "                , loss2: 0.008164623379707336\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 600 epoch, average loss: 205.9372802734375\n",
      "                , loss1: 2059.2921875\n",
      "                , loss2: 0.008090168982744218\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 610 epoch, average loss: 205.9194091796875\n",
      "                , loss1: 2059.11640625\n",
      "                , loss2: 0.007755281776189804\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 620 epoch, average loss: 205.9010498046875\n",
      "                , loss1: 2058.930078125\n",
      "                , loss2: 0.00803910493850708\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 630 epoch, average loss: 205.890869140625\n",
      "                , loss1: 2058.7265625\n",
      "                , loss2: 0.018236276507377625\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 640 epoch, average loss: 205.9216552734375\n",
      "                , loss1: 2058.5484375\n",
      "                , loss2: 0.06679587960243225\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 650 epoch, average loss: 205.857470703125\n",
      "                , loss1: 2058.318359375\n",
      "                , loss2: 0.025624707341194153\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 660 epoch, average loss: 205.8212158203125\n",
      "                , loss1: 2058.1009765625\n",
      "                , loss2: 0.011128118634223938\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 670 epoch, average loss: 205.792041015625\n",
      "                , loss1: 2057.839453125\n",
      "                , loss2: 0.008096754550933838\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 680 epoch, average loss: 205.755517578125\n",
      "                , loss1: 2057.49296875\n",
      "                , loss2: 0.00621132031083107\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 690 epoch, average loss: 205.7068359375\n",
      "                , loss1: 2057.0076171875\n",
      "                , loss2: 0.006101993843913078\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 700 epoch, average loss: 205.662158203125\n",
      "                , loss1: 2056.571484375\n",
      "                , loss2: 0.005014684796333313\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 710 epoch, average loss: 205.631640625\n",
      "                , loss1: 2056.260546875\n",
      "                , loss2: 0.005582873895764351\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 720 epoch, average loss: 205.6075439453125\n",
      "                , loss1: 2056.030078125\n",
      "                , loss2: 0.004546048492193222\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 730 epoch, average loss: 205.5896240234375\n",
      "                , loss1: 2055.853515625\n",
      "                , loss2: 0.004302427172660828\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 740 epoch, average loss: 205.5743408203125\n",
      "                , loss1: 2055.70078125\n",
      "                , loss2: 0.004256630316376686\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 750 epoch, average loss: 205.5611083984375\n",
      "                , loss1: 2055.57109375\n",
      "                , loss2: 0.004004140570759773\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 760 epoch, average loss: 205.5494873046875\n",
      "                , loss1: 2055.456640625\n",
      "                , loss2: 0.0038375087082386018\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 770 epoch, average loss: 205.5390625\n",
      "                , loss1: 2055.3484375\n",
      "                , loss2: 0.004188757389783859\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 780 epoch, average loss: 205.5291015625\n",
      "                , loss1: 2055.2533203125\n",
      "                , loss2: 0.0037568725645542147\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 790 epoch, average loss: 205.519970703125\n",
      "                , loss1: 2055.1611328125\n",
      "                , loss2: 0.003860127553343773\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 800 epoch, average loss: 205.511083984375\n",
      "                , loss1: 2055.07421875\n",
      "                , loss2: 0.0036984976381063462\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 810 epoch, average loss: 205.502734375\n",
      "                , loss1: 2054.99140625\n",
      "                , loss2: 0.003620553016662598\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 820 epoch, average loss: 205.49482421875\n",
      "                , loss1: 2054.91328125\n",
      "                , loss2: 0.003498583659529686\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 830 epoch, average loss: 205.4871826171875\n",
      "                , loss1: 2054.837109375\n",
      "                , loss2: 0.0034649379551410673\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 840 epoch, average loss: 205.4802490234375\n",
      "                , loss1: 2054.7673828125\n",
      "                , loss2: 0.0035041425377130508\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 850 epoch, average loss: 205.4734375\n",
      "                , loss1: 2054.70078125\n",
      "                , loss2: 0.003379223495721817\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 860 epoch, average loss: 205.4673095703125\n",
      "                , loss1: 2054.637890625\n",
      "                , loss2: 0.003517327830195427\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 870 epoch, average loss: 205.4613037109375\n",
      "                , loss1: 2054.576953125\n",
      "                , loss2: 0.0035981856286525725\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 880 epoch, average loss: 205.45546875\n",
      "                , loss1: 2054.51953125\n",
      "                , loss2: 0.003508796915411949\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 890 epoch, average loss: 205.449609375\n",
      "                , loss1: 2054.4640625\n",
      "                , loss2: 0.0032096274197101595\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 900 epoch, average loss: 205.4443603515625\n",
      "                , loss1: 2054.4103515625\n",
      "                , loss2: 0.0033195063471794127\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 910 epoch, average loss: 205.43916015625\n",
      "                , loss1: 2054.36015625\n",
      "                , loss2: 0.0031593933701515196\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 920 epoch, average loss: 205.4341552734375\n",
      "                , loss1: 2054.308984375\n",
      "                , loss2: 0.003257772698998451\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 930 epoch, average loss: 205.429345703125\n",
      "                , loss1: 2054.2623046875\n",
      "                , loss2: 0.0031115207821130753\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 940 epoch, average loss: 205.4247314453125\n",
      "                , loss1: 2054.2154296875\n",
      "                , loss2: 0.003177417442202568\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 950 epoch, average loss: 205.420068359375\n",
      "                , loss1: 2054.1681640625\n",
      "                , loss2: 0.003273559734225273\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 960 epoch, average loss: 205.415966796875\n",
      "                , loss1: 2054.1224609375\n",
      "                , loss2: 0.003688068687915802\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 970 epoch, average loss: 205.41171875\n",
      "                , loss1: 2054.076953125\n",
      "                , loss2: 0.004015756770968437\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 980 epoch, average loss: 205.407861328125\n",
      "                , loss1: 2054.0337890625\n",
      "                , loss2: 0.004472880065441132\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 990 epoch, average loss: 205.403759765625\n",
      "                , loss1: 2053.990234375\n",
      "                , loss2: 0.0047019034624099735\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1000 epoch, average loss: 205.3982421875\n",
      "                , loss1: 2053.9474609375\n",
      "                , loss2: 0.003509463369846344\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1010 epoch, average loss: 205.3994384765625\n",
      "                , loss1: 2053.905859375\n",
      "                , loss2: 0.008856132626533508\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1020 epoch, average loss: 205.391845703125\n",
      "                , loss1: 2053.864453125\n",
      "                , loss2: 0.00538734495639801\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1030 epoch, average loss: 205.3869873046875\n",
      "                , loss1: 2053.823828125\n",
      "                , loss2: 0.004613394290208817\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1040 epoch, average loss: 205.3822021484375\n",
      "                , loss1: 2053.7833984375\n",
      "                , loss2: 0.0038630694150924684\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1050 epoch, average loss: 205.38740234375\n",
      "                , loss1: 2053.74765625\n",
      "                , loss2: 0.012657465040683746\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1060 epoch, average loss: 205.378955078125\n",
      "                , loss1: 2053.711328125\n",
      "                , loss2: 0.007827813923358917\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1070 epoch, average loss: 205.37197265625\n",
      "                , loss1: 2053.673828125\n",
      "                , loss2: 0.004573536291718483\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1080 epoch, average loss: 205.3672607421875\n",
      "                , loss1: 2053.63671875\n",
      "                , loss2: 0.0036035683006048203\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1090 epoch, average loss: 205.3630615234375\n",
      "                , loss1: 2053.60234375\n",
      "                , loss2: 0.002830350399017334\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1100 epoch, average loss: 205.3828857421875\n",
      "                , loss1: 2053.5734375\n",
      "                , loss2: 0.025533503293991087\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1110 epoch, average loss: 205.364892578125\n",
      "                , loss1: 2053.5453125\n",
      "                , loss2: 0.010360752791166305\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1120 epoch, average loss: 205.3567138671875\n",
      "                , loss1: 2053.51171875\n",
      "                , loss2: 0.005532120913267135\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1130 epoch, average loss: 205.3516357421875\n",
      "                , loss1: 2053.4796875\n",
      "                , loss2: 0.0036585457623004914\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1140 epoch, average loss: 205.3477294921875\n",
      "                , loss1: 2053.44609375\n",
      "                , loss2: 0.0030995339155197145\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1150 epoch, average loss: 205.34443359375\n",
      "                , loss1: 2053.4150390625\n",
      "                , loss2: 0.0029142254963517187\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1160 epoch, average loss: 205.3457763671875\n",
      "                , loss1: 2053.387890625\n",
      "                , loss2: 0.006990960240364075\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1170 epoch, average loss: 205.35078125\n",
      "                , loss1: 2053.358984375\n",
      "                , loss2: 0.014854784309864043\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1180 epoch, average loss: 205.3383544921875\n",
      "                , loss1: 2053.331640625\n",
      "                , loss2: 0.005197633057832718\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1190 epoch, average loss: 205.3339599609375\n",
      "                , loss1: 2053.3037109375\n",
      "                , loss2: 0.0035628676414489746\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1200 epoch, average loss: 205.33056640625\n",
      "                , loss1: 2053.273828125\n",
      "                , loss2: 0.0032104719430208206\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1210 epoch, average loss: 205.3282958984375\n",
      "                , loss1: 2053.2474609375\n",
      "                , loss2: 0.003552352637052536\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1220 epoch, average loss: 205.348193359375\n",
      "                , loss1: 2053.228515625\n",
      "                , loss2: 0.025323721766471862\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1230 epoch, average loss: 205.329931640625\n",
      "                , loss1: 2053.2037109375\n",
      "                , loss2: 0.009582293033599854\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1240 epoch, average loss: 205.3228515625\n",
      "                , loss1: 2053.17578125\n",
      "                , loss2: 0.0052910100668668745\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1250 epoch, average loss: 205.3186767578125\n",
      "                , loss1: 2053.148046875\n",
      "                , loss2: 0.00386943481862545\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1260 epoch, average loss: 205.3152587890625\n",
      "                , loss1: 2053.123046875\n",
      "                , loss2: 0.0029599152505397795\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1270 epoch, average loss: 205.312451171875\n",
      "                , loss1: 2053.09609375\n",
      "                , loss2: 0.0028414398431777952\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1280 epoch, average loss: 205.3111328125\n",
      "                , loss1: 2053.073046875\n",
      "                , loss2: 0.0038441892713308333\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1290 epoch, average loss: 205.32890625\n",
      "                , loss1: 2053.052734375\n",
      "                , loss2: 0.023617315292358398\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1300 epoch, average loss: 205.3109375\n",
      "                , loss1: 2053.029296875\n",
      "                , loss2: 0.007974144071340561\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1310 epoch, average loss: 205.3049072265625\n",
      "                , loss1: 2053.0041015625\n",
      "                , loss2: 0.004511032998561859\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1320 epoch, average loss: 205.301806640625\n",
      "                , loss1: 2052.980859375\n",
      "                , loss2: 0.0037420995533466337\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1330 epoch, average loss: 205.29873046875\n",
      "                , loss1: 2052.9564453125\n",
      "                , loss2: 0.0030895832926034926\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1340 epoch, average loss: 205.296142578125\n",
      "                , loss1: 2052.932421875\n",
      "                , loss2: 0.0028899241238832473\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1350 epoch, average loss: 205.3154052734375\n",
      "                , loss1: 2052.9142578125\n",
      "                , loss2: 0.023961201310157776\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1360 epoch, average loss: 205.3146484375\n",
      "                , loss1: 2052.9021484375\n",
      "                , loss2: 0.024441374838352202\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1370 epoch, average loss: 205.2963623046875\n",
      "                , loss1: 2052.8740234375\n",
      "                , loss2: 0.008961637318134309\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1380 epoch, average loss: 205.2890625\n",
      "                , loss1: 2052.846484375\n",
      "                , loss2: 0.004421716928482056\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1390 epoch, average loss: 205.2857421875\n",
      "                , loss1: 2052.8208984375\n",
      "                , loss2: 0.0036573462188243867\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1400 epoch, average loss: 205.2828857421875\n",
      "                , loss1: 2052.798046875\n",
      "                , loss2: 0.0030729226768016816\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1410 epoch, average loss: 205.2804443359375\n",
      "                , loss1: 2052.7755859375\n",
      "                , loss2: 0.0028402265161275864\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1420 epoch, average loss: 205.27802734375\n",
      "                , loss1: 2052.751171875\n",
      "                , loss2: 0.0029190991073846815\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1430 epoch, average loss: 205.275732421875\n",
      "                , loss1: 2052.7296875\n",
      "                , loss2: 0.0027759561315178873\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1440 epoch, average loss: 205.2736083984375\n",
      "                , loss1: 2052.70859375\n",
      "                , loss2: 0.002770002372562885\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1450 epoch, average loss: 205.271875\n",
      "                , loss1: 2052.685546875\n",
      "                , loss2: 0.0032764047384262083\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1460 epoch, average loss: 205.2973388671875\n",
      "                , loss1: 2052.6662109375\n",
      "                , loss2: 0.030729848146438598\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1470 epoch, average loss: 205.292724609375\n",
      "                , loss1: 2052.6611328125\n",
      "                , loss2: 0.026613956689834593\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1480 epoch, average loss: 205.272412109375\n",
      "                , loss1: 2052.63828125\n",
      "                , loss2: 0.008593110740184784\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1490 epoch, average loss: 205.2662109375\n",
      "                , loss1: 2052.61640625\n",
      "                , loss2: 0.004572140797972679\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1500 epoch, average loss: 205.2626220703125\n",
      "                , loss1: 2052.589453125\n",
      "                , loss2: 0.0036695674061775208\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1510 epoch, average loss: 205.2598388671875\n",
      "                , loss1: 2052.56640625\n",
      "                , loss2: 0.003197929635643959\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1520 epoch, average loss: 205.257568359375\n",
      "                , loss1: 2052.5431640625\n",
      "                , loss2: 0.0032359622418880463\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1530 epoch, average loss: 205.2553466796875\n",
      "                , loss1: 2052.52109375\n",
      "                , loss2: 0.003237481042742729\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1540 epoch, average loss: 205.2548828125\n",
      "                , loss1: 2052.500390625\n",
      "                , loss2: 0.004843439906835556\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1550 epoch, average loss: 205.343505859375\n",
      "                , loss1: 2052.503125\n",
      "                , loss2: 0.0932058870792389\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1560 epoch, average loss: 205.299658203125\n",
      "                , loss1: 2052.52265625\n",
      "                , loss2: 0.04738619029521942\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1570 epoch, average loss: 205.262744140625\n",
      "                , loss1: 2052.4880859375\n",
      "                , loss2: 0.013931746780872344\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1580 epoch, average loss: 205.251318359375\n",
      "                , loss1: 2052.448828125\n",
      "                , loss2: 0.006402336061000824\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1590 epoch, average loss: 205.2466552734375\n",
      "                , loss1: 2052.4216796875\n",
      "                , loss2: 0.004476311430335045\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1600 epoch, average loss: 205.2433349609375\n",
      "                , loss1: 2052.397265625\n",
      "                , loss2: 0.0036057222634553908\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1610 epoch, average loss: 205.240869140625\n",
      "                , loss1: 2052.3732421875\n",
      "                , loss2: 0.003551144152879715\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1620 epoch, average loss: 205.2385986328125\n",
      "                , loss1: 2052.35078125\n",
      "                , loss2: 0.0035020463168621064\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1630 epoch, average loss: 205.236572265625\n",
      "                , loss1: 2052.3306640625\n",
      "                , loss2: 0.0035120055079460146\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1640 epoch, average loss: 205.2345703125\n",
      "                , loss1: 2052.3107421875\n",
      "                , loss2: 0.0034826360642910004\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1650 epoch, average loss: 205.2327392578125\n",
      "                , loss1: 2052.2919921875\n",
      "                , loss2: 0.003578423336148262\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1660 epoch, average loss: 205.2374755859375\n",
      "                , loss1: 2052.273828125\n",
      "                , loss2: 0.010092943906784058\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1670 epoch, average loss: 205.2566650390625\n",
      "                , loss1: 2052.263671875\n",
      "                , loss2: 0.03028002381324768\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1680 epoch, average loss: 205.233447265625\n",
      "                , loss1: 2052.246875\n",
      "                , loss2: 0.00875970870256424\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1690 epoch, average loss: 205.228515625\n",
      "                , loss1: 2052.2267578125\n",
      "                , loss2: 0.005833394825458527\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1700 epoch, average loss: 205.225439453125\n",
      "                , loss1: 2052.206640625\n",
      "                , loss2: 0.004788269847631454\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1710 epoch, average loss: 205.22294921875\n",
      "                , loss1: 2052.18515625\n",
      "                , loss2: 0.004425660148262978\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1720 epoch, average loss: 205.2217041015625\n",
      "                , loss1: 2052.1669921875\n",
      "                , loss2: 0.005012877285480499\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1730 epoch, average loss: 205.335791015625\n",
      "                , loss1: 2052.1767578125\n",
      "                , loss2: 0.118117356300354\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1740 epoch, average loss: 205.25908203125\n",
      "                , loss1: 2052.2376953125\n",
      "                , loss2: 0.03532145321369171\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1750 epoch, average loss: 205.2338623046875\n",
      "                , loss1: 2052.194921875\n",
      "                , loss2: 0.014369332790374756\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1760 epoch, average loss: 205.2227783203125\n",
      "                , loss1: 2052.15\n",
      "                , loss2: 0.007805740833282471\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1770 epoch, average loss: 205.217822265625\n",
      "                , loss1: 2052.1185546875\n",
      "                , loss2: 0.005948610603809357\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1780 epoch, average loss: 205.214013671875\n",
      "                , loss1: 2052.09296875\n",
      "                , loss2: 0.004712284356355667\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1790 epoch, average loss: 205.211328125\n",
      "                , loss1: 2052.06875\n",
      "                , loss2: 0.0044229235500097275\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1800 epoch, average loss: 205.2091796875\n",
      "                , loss1: 2052.04921875\n",
      "                , loss2: 0.004246788844466209\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1810 epoch, average loss: 205.207080078125\n",
      "                , loss1: 2052.0294921875\n",
      "                , loss2: 0.0041443448513746265\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1820 epoch, average loss: 205.205419921875\n",
      "                , loss1: 2052.00625\n",
      "                , loss2: 0.004752987250685692\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1830 epoch, average loss: 205.2056640625\n",
      "                , loss1: 2051.9892578125\n",
      "                , loss2: 0.006724376231431961\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1840 epoch, average loss: 205.23388671875\n",
      "                , loss1: 2051.98046875\n",
      "                , loss2: 0.03579976260662079\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1850 epoch, average loss: 205.2091064453125\n",
      "                , loss1: 2051.9705078125\n",
      "                , loss2: 0.012055487930774688\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1860 epoch, average loss: 205.2028076171875\n",
      "                , loss1: 2051.9484375\n",
      "                , loss2: 0.007985033839941025\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1870 epoch, average loss: 205.1990234375\n",
      "                , loss1: 2051.9259765625\n",
      "                , loss2: 0.006423575431108474\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1880 epoch, average loss: 205.197412109375\n",
      "                , loss1: 2051.9064453125\n",
      "                , loss2: 0.006769106537103653\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1890 epoch, average loss: 205.27197265625\n",
      "                , loss1: 2051.9068359375\n",
      "                , loss2: 0.08129695653915406\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1900 epoch, average loss: 205.225732421875\n",
      "                , loss1: 2051.9359375\n",
      "                , loss2: 0.03213753700256348\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1910 epoch, average loss: 205.208203125\n",
      "                , loss1: 2051.909375\n",
      "                , loss2: 0.017246904969215392\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1920 epoch, average loss: 205.1977294921875\n",
      "                , loss1: 2051.8787109375\n",
      "                , loss2: 0.009866035729646682\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1930 epoch, average loss: 205.1916015625\n",
      "                , loss1: 2051.8509765625\n",
      "                , loss2: 0.006494708359241486\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1940 epoch, average loss: 205.188427734375\n",
      "                , loss1: 2051.8296875\n",
      "                , loss2: 0.005437202751636505\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1950 epoch, average loss: 205.1859619140625\n",
      "                , loss1: 2051.805078125\n",
      "                , loss2: 0.005422302708029747\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1960 epoch, average loss: 205.18349609375\n",
      "                , loss1: 2051.787109375\n",
      "                , loss2: 0.0047885715961456295\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1970 epoch, average loss: 205.183056640625\n",
      "                , loss1: 2051.763671875\n",
      "                , loss2: 0.006681135296821595\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1980 epoch, average loss: 205.4957763671875\n",
      "                , loss1: 2051.8708984375\n",
      "                , loss2: 0.30868732929229736\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 1990 epoch, average loss: 205.3818359375\n",
      "                , loss1: 2052.160546875\n",
      "                , loss2: 0.16580063104629517\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2000 epoch, average loss: 205.2721435546875\n",
      "                , loss1: 2052.0544921875\n",
      "                , loss2: 0.06669065356254578\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2010 epoch, average loss: 205.22158203125\n",
      "                , loss1: 2051.9828125\n",
      "                , loss2: 0.023286965489387513\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2020 epoch, average loss: 205.20595703125\n",
      "                , loss1: 2051.9337890625\n",
      "                , loss2: 0.012578532099723816\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2030 epoch, average loss: 205.1952880859375\n",
      "                , loss1: 2051.883203125\n",
      "                , loss2: 0.006982604414224625\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2040 epoch, average loss: 205.18916015625\n",
      "                , loss1: 2051.834375\n",
      "                , loss2: 0.005718301609158516\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2050 epoch, average loss: 205.1843017578125\n",
      "                , loss1: 2051.7890625\n",
      "                , loss2: 0.005413629487156868\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2060 epoch, average loss: 205.1804443359375\n",
      "                , loss1: 2051.753125\n",
      "                , loss2: 0.005101828277111054\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2070 epoch, average loss: 205.1771728515625\n",
      "                , loss1: 2051.7203125\n",
      "                , loss2: 0.005130970478057861\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2080 epoch, average loss: 205.17421875\n",
      "                , loss1: 2051.691015625\n",
      "                , loss2: 0.005109208822250366\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2090 epoch, average loss: 205.171484375\n",
      "                , loss1: 2051.6640625\n",
      "                , loss2: 0.005082223191857338\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2100 epoch, average loss: 205.1689453125\n",
      "                , loss1: 2051.6384765625\n",
      "                , loss2: 0.0050914004445075985\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2110 epoch, average loss: 205.176904296875\n",
      "                , loss1: 2051.60859375\n",
      "                , loss2: 0.016005243360996246\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2120 epoch, average loss: 205.1695556640625\n",
      "                , loss1: 2051.582421875\n",
      "                , loss2: 0.011334136873483659\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2130 epoch, average loss: 205.1617919921875\n",
      "                , loss1: 2051.5330078125\n",
      "                , loss2: 0.008503609895706176\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2140 epoch, average loss: 205.154638671875\n",
      "                , loss1: 2051.468359375\n",
      "                , loss2: 0.0077785603702068325\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2150 epoch, average loss: 205.1499267578125\n",
      "                , loss1: 2051.3884765625\n",
      "                , loss2: 0.011087720096111298\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2160 epoch, average loss: 205.158349609375\n",
      "                , loss1: 2051.281640625\n",
      "                , loss2: 0.03016124963760376\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2170 epoch, average loss: 205.1312744140625\n",
      "                , loss1: 2051.170703125\n",
      "                , loss2: 0.014229688048362731\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2180 epoch, average loss: 205.117578125\n",
      "                , loss1: 2051.048828125\n",
      "                , loss2: 0.01270148903131485\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2190 epoch, average loss: 205.2253662109375\n",
      "                , loss1: 2050.9939453125\n",
      "                , loss2: 0.12598652839660646\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2200 epoch, average loss: 205.2016845703125\n",
      "                , loss1: 2051.0171875\n",
      "                , loss2: 0.09994205236434936\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2210 epoch, average loss: 205.1338134765625\n",
      "                , loss1: 2050.89140625\n",
      "                , loss2: 0.044650453329086306\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2220 epoch, average loss: 205.090771484375\n",
      "                , loss1: 2050.710546875\n",
      "                , loss2: 0.01970270574092865\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2230 epoch, average loss: 205.06826171875\n",
      "                , loss1: 2050.574609375\n",
      "                , loss2: 0.010815609991550446\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2240 epoch, average loss: 205.0573486328125\n",
      "                , loss1: 2050.495703125\n",
      "                , loss2: 0.007776767015457153\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2250 epoch, average loss: 205.049755859375\n",
      "                , loss1: 2050.433203125\n",
      "                , loss2: 0.0064310722053051\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2260 epoch, average loss: 205.04443359375\n",
      "                , loss1: 2050.384765625\n",
      "                , loss2: 0.005945340916514397\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2270 epoch, average loss: 205.0401611328125\n",
      "                , loss1: 2050.342578125\n",
      "                , loss2: 0.0058836046606302265\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2280 epoch, average loss: 205.036474609375\n",
      "                , loss1: 2050.304296875\n",
      "                , loss2: 0.006023186072707176\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2290 epoch, average loss: 205.0332275390625\n",
      "                , loss1: 2050.2703125\n",
      "                , loss2: 0.006186392158269882\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2300 epoch, average loss: 205.0302001953125\n",
      "                , loss1: 2050.240234375\n",
      "                , loss2: 0.006143468245863914\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2310 epoch, average loss: 205.02734375\n",
      "                , loss1: 2050.209765625\n",
      "                , loss2: 0.006326017528772354\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2320 epoch, average loss: 205.02451171875\n",
      "                , loss1: 2050.1818359375\n",
      "                , loss2: 0.006345953792333603\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2330 epoch, average loss: 205.0224853515625\n",
      "                , loss1: 2050.1529296875\n",
      "                , loss2: 0.007191015034914016\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2340 epoch, average loss: 205.0314697265625\n",
      "                , loss1: 2050.126953125\n",
      "                , loss2: 0.018764327466487884\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2350 epoch, average loss: 205.0198486328125\n",
      "                , loss1: 2050.099609375\n",
      "                , loss2: 0.009874632954597473\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2360 epoch, average loss: 205.0155517578125\n",
      "                , loss1: 2050.070703125\n",
      "                , loss2: 0.008470679074525833\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2370 epoch, average loss: 205.0111572265625\n",
      "                , loss1: 2050.0337890625\n",
      "                , loss2: 0.007774384319782257\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2380 epoch, average loss: 205.008251953125\n",
      "                , loss1: 2049.993359375\n",
      "                , loss2: 0.008911444246768952\n",
      "                , weight: 0.1\n",
      "=================================\n",
      "in 2390 epoch, average loss: 205.006982421875\n",
      "                , loss1: 2049.9353515625\n",
      "                , loss2: 0.013401466608047485\n",
      "                , weight: 0.1\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(40000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    elif hgnn_trainer.weight < limit:\n",
    "        hgnn_trainer.weight = limit\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    if loss_1 < 2050 and loss_2 < 0.003:\n",
    "        break\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([637., 637., 637., 638., 637., 638.], device='cuda:1',\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
