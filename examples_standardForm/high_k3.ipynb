{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exs/.conda/envs/partition/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 3\n",
    "\n",
    "weight = 1.03\n",
    "lr = 2.3e-4\n",
    "sub = 0.0005\n",
    "limit = 0.02\n",
    "\n",
    "# h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 300, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "# h_hyper_prmts[\"convlayers14\"] = {\"in_channels\":512, \"out_channels\": 256, \"use_bn\":  False, \"drop_rate\": 0}\n",
    "# h_hyper_prmts[\"convlayers143\"] = {\"in_channels\": 256, \"out_channels\": 3, \"use_bn\": True, \"drop_rate\": 0}\n",
    "\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 300, \"out_channels\": 550, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\":550, \"out_channels\": 256, \"use_bn\":  False, \"drop_rate\": 0}\n",
    "h_hyper_prmts[\"convlayers143\"] = {\"in_channels\": 256, \"out_channels\": 3, \"use_bn\": True, \"drop_rate\": 0}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device, weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的标准.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "\n",
    "    X_ = outs.t().unsqueeze(-1)\n",
    "    H_ = H.unsqueeze(0)\n",
    "    xweight = H.sum(dim=0)\n",
    "    mid = X_.mul(H_)\n",
    "    sum = (mid * (1 / xweight)).sum()\n",
    "    sub = (mid + (1 - H)).prod(dim=1).sum()\n",
    "    loss_1 = sum - sub\n",
    "\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "\n",
    "    return loss, loss_1, loss_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7818, 327)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/high\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=300, out_features=550, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=550, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=3, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU6().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut():\n",
    "    hgnn_trainer.eval()\n",
    "    outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "    outs_straight = StraightThroughEstimator.apply(outs)\n",
    "    G_clone = G.clone()\n",
    "    edges, _  = G_clone.e\n",
    "    cut = 0\n",
    "    for vertices in edges:\n",
    "        if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "            cut += 1\n",
    "        else:\n",
    "            G_clone.remove_hyperedges(vertices)\n",
    "    assert cut == G_clone.num_e\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 20 epoch, average loss: 5889.146484375\n",
      "                , loss1: 5743.960546875\n",
      "                , loss2: 3.023299217224121\n",
      "                , weight: 1.0200000000000011\n",
      "=================================\n",
      "in 40 epoch, average loss: 5824.959375\n",
      "                , loss1: 5739.976953125\n",
      "                , loss2: 0.3067940711975098\n",
      "                , weight: 1.0100000000000022\n",
      "=================================\n",
      "in 60 epoch, average loss: 5540.280859375\n",
      "                , loss1: 5511.74609375\n",
      "                , loss2: 1.7600980758666993\n",
      "                , weight: 1.0000000000000033\n",
      "=================================\n",
      "in 80 epoch, average loss: 4062.7765625\n",
      "                , loss1: 4077.43515625\n",
      "                , loss2: 5.615902328491211\n",
      "                , weight: 0.9900000000000044\n",
      "=================================\n",
      "in 100 epoch, average loss: 2597.257421875\n",
      "                , loss1: 2612.5580078125\n",
      "                , loss2: 22.5818603515625\n",
      "                , weight: 0.9800000000000055\n",
      "=================================\n",
      "in 120 epoch, average loss: 928.525390625\n",
      "                , loss1: 893.1119140625\n",
      "                , loss2: 57.64454956054688\n",
      "                , weight: 0.9700000000000066\n",
      "=================================\n",
      "in 140 epoch, average loss: 805.76669921875\n",
      "                , loss1: 776.4841796875\n",
      "                , loss2: 56.642523193359374\n",
      "                , weight: 0.9600000000000077\n",
      "=================================\n",
      "in 160 epoch, average loss: 791.65791015625\n",
      "                , loss1: 769.994775390625\n",
      "                , loss2: 56.50315551757812\n",
      "                , weight: 0.9500000000000088\n",
      "=================================\n",
      "in 180 epoch, average loss: 782.197021484375\n",
      "                , loss1: 768.01171875\n",
      "                , loss2: 56.61676025390625\n",
      "                , weight: 0.9400000000000099\n",
      "=================================\n",
      "in 200 epoch, average loss: 773.558642578125\n",
      "                , loss1: 766.99306640625\n",
      "                , loss2: 56.61106567382812\n",
      "                , weight: 0.930000000000011\n",
      "=================================\n",
      "in 220 epoch, average loss: 765.25986328125\n",
      "                , loss1: 766.232666015625\n",
      "                , loss2: 56.68555908203125\n",
      "                , weight: 0.9200000000000121\n",
      "=================================\n",
      "in 240 epoch, average loss: 757.12646484375\n",
      "                , loss1: 765.68359375\n",
      "                , loss2: 56.717108154296874\n",
      "                , weight: 0.9100000000000132\n",
      "=================================\n",
      "in 260 epoch, average loss: 749.1341796875\n",
      "                , loss1: 765.280419921875\n",
      "                , loss2: 56.746527099609374\n",
      "                , weight: 0.9000000000000143\n",
      "=================================\n",
      "in 280 epoch, average loss: 741.232666015625\n",
      "                , loss1: 765.00478515625\n",
      "                , loss2: 56.74442138671875\n",
      "                , weight: 0.8900000000000154\n",
      "=================================\n",
      "in 300 epoch, average loss: 733.386181640625\n",
      "                , loss1: 764.755419921875\n",
      "                , loss2: 56.76861572265625\n",
      "                , weight: 0.8800000000000165\n",
      "=================================\n",
      "in 320 epoch, average loss: 725.575390625\n",
      "                , loss1: 764.55517578125\n",
      "                , loss2: 56.78062133789062\n",
      "                , weight: 0.8700000000000176\n",
      "=================================\n",
      "in 340 epoch, average loss: 717.7990234375\n",
      "                , loss1: 764.4076171875\n",
      "                , loss2: 56.77742919921875\n",
      "                , weight: 0.8600000000000187\n",
      "=================================\n",
      "in 360 epoch, average loss: 710.037255859375\n",
      "                , loss1: 764.2517578125\n",
      "                , loss2: 56.79302978515625\n",
      "                , weight: 0.8500000000000199\n",
      "=================================\n",
      "in 380 epoch, average loss: 702.31650390625\n",
      "                , loss1: 764.14794921875\n",
      "                , loss2: 56.80232543945313\n",
      "                , weight: 0.840000000000021\n",
      "=================================\n",
      "in 400 epoch, average loss: 694.602197265625\n",
      "                , loss1: 764.0431640625\n",
      "                , loss2: 56.81715087890625\n",
      "                , weight: 0.830000000000022\n",
      "=================================\n",
      "in 420 epoch, average loss: 686.8974609375\n",
      "                , loss1: 763.95810546875\n",
      "                , loss2: 56.823065185546874\n",
      "                , weight: 0.8200000000000232\n",
      "=================================\n",
      "in 440 epoch, average loss: 679.206103515625\n",
      "                , loss1: 763.897998046875\n",
      "                , loss2: 56.82020263671875\n",
      "                , weight: 0.8100000000000243\n",
      "=================================\n",
      "in 460 epoch, average loss: 671.52373046875\n",
      "                , loss1: 763.844677734375\n",
      "                , loss2: 56.819635009765626\n",
      "                , weight: 0.8000000000000254\n",
      "=================================\n",
      "in 480 epoch, average loss: 663.8451171875\n",
      "                , loss1: 763.78955078125\n",
      "                , loss2: 56.823291015625\n",
      "                , weight: 0.7900000000000265\n",
      "=================================\n",
      "in 500 epoch, average loss: 656.177392578125\n",
      "                , loss1: 763.74130859375\n",
      "                , loss2: 56.83121948242187\n",
      "                , weight: 0.7800000000000276\n",
      "=================================\n",
      "in 520 epoch, average loss: 648.514599609375\n",
      "                , loss1: 763.70927734375\n",
      "                , loss2: 56.83088989257813\n",
      "                , weight: 0.7700000000000287\n",
      "=================================\n",
      "in 540 epoch, average loss: 640.851953125\n",
      "                , loss1: 763.668359375\n",
      "                , loss2: 56.83660888671875\n",
      "                , weight: 0.7600000000000298\n",
      "=================================\n",
      "in 560 epoch, average loss: 633.1953125\n",
      "                , loss1: 763.65068359375\n",
      "                , loss2: 56.829901123046874\n",
      "                , weight: 0.7500000000000309\n",
      "=================================\n",
      "in 580 epoch, average loss: 625.53583984375\n",
      "                , loss1: 763.624267578125\n",
      "                , loss2: 56.82661743164063\n",
      "                , weight: 0.740000000000032\n",
      "=================================\n",
      "in 600 epoch, average loss: 617.879833984375\n",
      "                , loss1: 763.587158203125\n",
      "                , loss2: 56.83418579101563\n",
      "                , weight: 0.7300000000000331\n",
      "=================================\n",
      "in 620 epoch, average loss: 610.2306640625\n",
      "                , loss1: 763.56953125\n",
      "                , loss2: 56.83359985351562\n",
      "                , weight: 0.7200000000000342\n",
      "=================================\n",
      "in 640 epoch, average loss: 602.5857421875\n",
      "                , loss1: 763.563427734375\n",
      "                , loss2: 56.82874755859375\n",
      "                , weight: 0.7100000000000353\n",
      "=================================\n",
      "in 660 epoch, average loss: 594.937109375\n",
      "                , loss1: 763.5333984375\n",
      "                , loss2: 56.83692626953125\n",
      "                , weight: 0.7000000000000364\n",
      "=================================\n",
      "in 680 epoch, average loss: 587.285986328125\n",
      "                , loss1: 763.535302734375\n",
      "                , loss2: 56.8198486328125\n",
      "                , weight: 0.6900000000000375\n",
      "=================================\n",
      "in 700 epoch, average loss: 579.642724609375\n",
      "                , loss1: 763.520751953125\n",
      "                , loss2: 56.8219970703125\n",
      "                , weight: 0.6800000000000386\n",
      "=================================\n",
      "in 720 epoch, average loss: 572.0005859375\n",
      "                , loss1: 763.5166015625\n",
      "                , loss2: 56.81773071289062\n",
      "                , weight: 0.6700000000000397\n",
      "=================================\n",
      "in 740 epoch, average loss: 564.3583984375\n",
      "                , loss1: 763.51376953125\n",
      "                , loss2: 56.81251831054688\n",
      "                , weight: 0.6600000000000408\n",
      "=================================\n",
      "in 760 epoch, average loss: 556.716943359375\n",
      "                , loss1: 763.51806640625\n",
      "                , loss2: 56.803521728515626\n",
      "                , weight: 0.6500000000000419\n",
      "=================================\n",
      "in 780 epoch, average loss: 549.073828125\n",
      "                , loss1: 763.50693359375\n",
      "                , loss2: 56.802703857421875\n",
      "                , weight: 0.640000000000043\n",
      "=================================\n",
      "in 800 epoch, average loss: 541.430859375\n",
      "                , loss1: 763.52333984375\n",
      "                , loss2: 56.78446655273437\n",
      "                , weight: 0.6300000000000441\n",
      "=================================\n",
      "in 820 epoch, average loss: 533.7908203125\n",
      "                , loss1: 763.52841796875\n",
      "                , loss2: 56.7765380859375\n",
      "                , weight: 0.6200000000000452\n",
      "=================================\n",
      "in 840 epoch, average loss: 526.1521484375\n",
      "                , loss1: 763.5294921875\n",
      "                , loss2: 56.772430419921875\n",
      "                , weight: 0.6100000000000463\n",
      "=================================\n",
      "in 860 epoch, average loss: 518.509619140625\n",
      "                , loss1: 763.56376953125\n",
      "                , loss2: 56.74444580078125\n",
      "                , weight: 0.6000000000000474\n",
      "=================================\n",
      "in 880 epoch, average loss: 510.868798828125\n",
      "                , loss1: 763.581982421875\n",
      "                , loss2: 56.72840576171875\n",
      "                , weight: 0.5900000000000485\n",
      "=================================\n",
      "in 900 epoch, average loss: 503.225341796875\n",
      "                , loss1: 763.63505859375\n",
      "                , loss2: 56.68977661132813\n",
      "                , weight: 0.5800000000000496\n",
      "=================================\n",
      "in 920 epoch, average loss: 495.5826171875\n",
      "                , loss1: 763.709130859375\n",
      "                , loss2: 56.640838623046875\n",
      "                , weight: 0.5700000000000507\n",
      "=================================\n",
      "in 940 epoch, average loss: 487.937158203125\n",
      "                , loss1: 763.79521484375\n",
      "                , loss2: 56.583935546875\n",
      "                , weight: 0.5600000000000518\n",
      "=================================\n",
      "in 960 epoch, average loss: 480.2853515625\n",
      "                , loss1: 763.96513671875\n",
      "                , loss2: 56.47596435546875\n",
      "                , weight: 0.5500000000000529\n",
      "=================================\n",
      "in 980 epoch, average loss: 472.620751953125\n",
      "                , loss1: 764.22216796875\n",
      "                , loss2: 56.3110595703125\n",
      "                , weight: 0.540000000000054\n",
      "=================================\n",
      "in 1000 epoch, average loss: 464.907373046875\n",
      "                , loss1: 764.981884765625\n",
      "                , loss2: 55.83421020507812\n",
      "                , weight: 0.5300000000000551\n",
      "=================================\n",
      "in 1020 epoch, average loss: 456.8751953125\n",
      "                , loss1: 768.8833984375\n",
      "                , loss2: 53.410430908203125\n",
      "                , weight: 0.5200000000000562\n",
      "=================================\n",
      "in 1040 epoch, average loss: 446.39072265625\n",
      "                , loss1: 809.368212890625\n",
      "                , loss2: 29.828689575195312\n",
      "                , weight: 0.5100000000000573\n",
      "=================================\n",
      "in 1060 epoch, average loss: 435.3912109375\n",
      "                , loss1: 827.28388671875\n",
      "                , loss2: 17.83391418457031\n",
      "                , weight: 0.5000000000000584\n",
      "=================================\n",
      "in 1080 epoch, average loss: 421.879296875\n",
      "                , loss1: 830.7533203125\n",
      "                , loss2: 10.86104736328125\n",
      "                , weight: 0.4900000000000584\n",
      "=================================\n",
      "in 1100 epoch, average loss: 410.02724609375\n",
      "                , loss1: 822.4763671875\n",
      "                , loss2: 11.334239196777343\n",
      "                , weight: 0.4800000000000584\n",
      "=================================\n",
      "in 1120 epoch, average loss: 401.0616943359375\n",
      "                , loss1: 822.16416015625\n",
      "                , loss2: 10.737067413330077\n",
      "                , weight: 0.47000000000005837\n",
      "=================================\n",
      "in 1140 epoch, average loss: 392.3282958984375\n",
      "                , loss1: 822.53046875\n",
      "                , loss2: 10.055391693115235\n",
      "                , weight: 0.46000000000005836\n",
      "=================================\n",
      "in 1160 epoch, average loss: 383.720849609375\n",
      "                , loss1: 821.87216796875\n",
      "                , loss2: 9.974928283691407\n",
      "                , weight: 0.45000000000005835\n",
      "=================================\n",
      "in 1180 epoch, average loss: 375.091162109375\n",
      "                , loss1: 822.13359375\n",
      "                , loss2: 9.447000122070312\n",
      "                , weight: 0.44000000000005834\n",
      "=================================\n",
      "in 1200 epoch, average loss: 366.4426513671875\n",
      "                , loss1: 821.9806640625\n",
      "                , loss2: 9.084524536132813\n",
      "                , weight: 0.43000000000005834\n",
      "=================================\n",
      "in 1220 epoch, average loss: 357.9093505859375\n",
      "                , loss1: 821.03193359375\n",
      "                , loss2: 9.17517547607422\n",
      "                , weight: 0.4200000000000583\n",
      "=================================\n",
      "in 1240 epoch, average loss: 349.4681396484375\n",
      "                , loss1: 820.0095703125\n",
      "                , loss2: 9.368114471435547\n",
      "                , weight: 0.4100000000000583\n",
      "=================================\n",
      "in 1260 epoch, average loss: 341.1335205078125\n",
      "                , loss1: 819.61865234375\n",
      "                , loss2: 9.391706085205078\n",
      "                , weight: 0.4000000000000583\n",
      "=================================\n",
      "in 1280 epoch, average loss: 332.8781005859375\n",
      "                , loss1: 820.072265625\n",
      "                , loss2: 9.155870056152343\n",
      "                , weight: 0.3900000000000583\n",
      "=================================\n",
      "in 1300 epoch, average loss: 324.6060791015625\n",
      "                , loss1: 820.2185546875\n",
      "                , loss2: 9.026070404052735\n",
      "                , weight: 0.3800000000000583\n",
      "=================================\n",
      "in 1320 epoch, average loss: 316.3598388671875\n",
      "                , loss1: 820.9998046875\n",
      "                , loss2: 8.691108703613281\n",
      "                , weight: 0.3700000000000583\n",
      "=================================\n",
      "in 1340 epoch, average loss: 308.1156005859375\n",
      "                , loss1: 822.28251953125\n",
      "                , loss2: 8.189185333251952\n",
      "                , weight: 0.3600000000000583\n",
      "=================================\n",
      "in 1360 epoch, average loss: 299.8630859375\n",
      "                , loss1: 822.83330078125\n",
      "                , loss2: 7.964077758789062\n",
      "                , weight: 0.35000000000005826\n",
      "=================================\n",
      "in 1380 epoch, average loss: 291.609814453125\n",
      "                , loss1: 823.88466796875\n",
      "                , loss2: 7.575914001464843\n",
      "                , weight: 0.34000000000005826\n",
      "=================================\n",
      "in 1400 epoch, average loss: 283.3388427734375\n",
      "                , loss1: 825.05546875\n",
      "                , loss2: 7.152095794677734\n",
      "                , weight: 0.33000000000005825\n",
      "=================================\n",
      "in 1420 epoch, average loss: 275.0639892578125\n",
      "                , loss1: 825.8783203125\n",
      "                , loss2: 6.860233306884766\n",
      "                , weight: 0.32000000000005824\n",
      "=================================\n",
      "in 1440 epoch, average loss: 266.7706298828125\n",
      "                , loss1: 827.13232421875\n",
      "                , loss2: 6.431997680664063\n",
      "                , weight: 0.31000000000005823\n",
      "=================================\n",
      "in 1460 epoch, average loss: 258.48232421875\n",
      "                , loss1: 828.0275390625\n",
      "                , loss2: 6.1418201446533205\n",
      "                , weight: 0.3000000000000582\n",
      "=================================\n",
      "in 1480 epoch, average loss: 250.168212890625\n",
      "                , loss1: 829.3291015625\n",
      "                , loss2: 5.723745346069336\n",
      "                , weight: 0.2900000000000582\n",
      "=================================\n",
      "in 1500 epoch, average loss: 241.8403564453125\n",
      "                , loss1: 830.7392578125\n",
      "                , loss2: 5.2878868103027346\n",
      "                , weight: 0.2800000000000582\n",
      "=================================\n",
      "in 1520 epoch, average loss: 233.5005859375\n",
      "                , loss1: 831.8669921875\n",
      "                , loss2: 4.946707153320313\n",
      "                , weight: 0.2700000000000582\n",
      "=================================\n",
      "in 1540 epoch, average loss: 225.1561767578125\n",
      "                , loss1: 833.04345703125\n",
      "                , loss2: 4.608998107910156\n",
      "                , weight: 0.2600000000000582\n",
      "=================================\n",
      "in 1560 epoch, average loss: 216.7990966796875\n",
      "                , loss1: 834.1248046875\n",
      "                , loss2: 4.306191253662109\n",
      "                , weight: 0.2500000000000582\n",
      "=================================\n",
      "in 1580 epoch, average loss: 208.4281494140625\n",
      "                , loss1: 835.34462890625\n",
      "                , loss2: 3.9786697387695313\n",
      "                , weight: 0.24000000000005817\n",
      "=================================\n",
      "in 1600 epoch, average loss: 200.0564697265625\n",
      "                , loss1: 835.93486328125\n",
      "                , loss2: 3.82208366394043\n",
      "                , weight: 0.23000000000005816\n",
      "=================================\n",
      "in 1620 epoch, average loss: 191.67340087890625\n",
      "                , loss1: 837.1564453125\n",
      "                , loss2: 3.522892379760742\n",
      "                , weight: 0.22000000000005815\n",
      "=================================\n",
      "in 1640 epoch, average loss: 183.28309326171876\n",
      "                , loss1: 837.95009765625\n",
      "                , loss2: 3.334712600708008\n",
      "                , weight: 0.21000000000005814\n",
      "=================================\n",
      "in 1660 epoch, average loss: 174.8845458984375\n",
      "                , loss1: 838.7927734375\n",
      "                , loss2: 3.1427894592285157\n",
      "                , weight: 0.20000000000005813\n",
      "=================================\n",
      "in 1680 epoch, average loss: 166.4778564453125\n",
      "                , loss1: 839.6884765625\n",
      "                , loss2: 2.949179267883301\n",
      "                , weight: 0.19000000000005812\n",
      "=================================\n",
      "in 1700 epoch, average loss: 158.06414794921875\n",
      "                , loss1: 840.5376953125\n",
      "                , loss2: 2.7754444122314452\n",
      "                , weight: 0.1800000000000581\n",
      "=================================\n",
      "in 1720 epoch, average loss: 149.63717041015624\n",
      "                , loss1: 841.5171875\n",
      "                , loss2: 2.583258056640625\n",
      "                , weight: 0.1700000000000581\n",
      "=================================\n",
      "in 1740 epoch, average loss: 141.1911865234375\n",
      "                , loss1: 842.940234375\n",
      "                , loss2: 2.3180845260620115\n",
      "                , weight: 0.1600000000000581\n",
      "=================================\n",
      "in 1760 epoch, average loss: 132.7177490234375\n",
      "                , loss1: 844.42109375\n",
      "                , loss2: 2.045833396911621\n",
      "                , weight: 0.1500000000000581\n",
      "=================================\n",
      "in 1780 epoch, average loss: 124.18701171875\n",
      "                , loss1: 845.80322265625\n",
      "                , loss2: 1.7579559326171874\n",
      "                , weight: 0.14000000000005808\n",
      "=================================\n",
      "in 1800 epoch, average loss: 115.6197998046875\n",
      "                , loss1: 847.10712890625\n",
      "                , loss2: 1.4720736503601075\n",
      "                , weight: 0.13000000000005807\n",
      "=================================\n",
      "in 1820 epoch, average loss: 107.03265380859375\n",
      "                , loss1: 847.2923828125\n",
      "                , loss2: 1.333827590942383\n",
      "                , weight: 0.12000000000005806\n",
      "=================================\n",
      "in 1840 epoch, average loss: 98.48301391601562\n",
      "                , loss1: 847.5375\n",
      "                , loss2: 1.2285672187805177\n",
      "                , weight: 0.11000000000005805\n",
      "=================================\n",
      "in 1860 epoch, average loss: 89.9591552734375\n",
      "                , loss1: 847.9197265625\n",
      "                , loss2: 1.1392709732055664\n",
      "                , weight: 0.10000000000005804\n",
      "=================================\n",
      "in 1880 epoch, average loss: 81.44414672851562\n",
      "                , loss1: 848.209375\n",
      "                , loss2: 1.0766707420349122\n",
      "                , weight: 0.09000000000005803\n",
      "=================================\n",
      "in 1900 epoch, average loss: 72.94168701171876\n",
      "                , loss1: 848.65400390625\n",
      "                , loss2: 1.0177217483520509\n",
      "                , weight: 0.08000000000005802\n",
      "=================================\n",
      "in 1920 epoch, average loss: 64.43841552734375\n",
      "                , loss1: 848.90341796875\n",
      "                , loss2: 0.983400535583496\n",
      "                , weight: 0.07000000000005802\n",
      "=================================\n",
      "in 1940 epoch, average loss: 55.93562622070313\n",
      "                , loss1: 849.59697265625\n",
      "                , loss2: 0.9244644165039062\n",
      "                , weight: 0.06000000000005801\n",
      "=================================\n",
      "in 1960 epoch, average loss: 47.419375610351565\n",
      "                , loss1: 850.3755859375\n",
      "                , loss2: 0.8623543739318847\n",
      "                , weight: 0.050000000000058\n",
      "=================================\n",
      "in 1980 epoch, average loss: 38.87277526855469\n",
      "                , loss1: 851.5107421875\n",
      "                , loss2: 0.7691216945648194\n",
      "                , weight: 0.04000000000005799\n",
      "=================================\n",
      "in 2000 epoch, average loss: 30.201449584960937\n",
      "                , loss1: 854.644921875\n",
      "                , loss2: 0.5063021659851075\n",
      "                , weight: 0.03000000000005798\n",
      "=================================\n",
      "in 2020 epoch, average loss: 21.38953094482422\n",
      "                , loss1: 861.0951171875\n",
      "                , loss2: 0.08002583384513855\n",
      "                , weight: 0.02000000000005797\n",
      "=================================\n",
      "in 2040 epoch, average loss: 16.831024169921875\n",
      "                , loss1: 860.83828125\n",
      "                , loss2: 0.04467731416225433\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2060 epoch, average loss: 16.82556610107422\n",
      "                , loss1: 860.6767578125\n",
      "                , loss2: 0.042368119955062865\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2080 epoch, average loss: 16.817567443847658\n",
      "                , loss1: 860.98310546875\n",
      "                , loss2: 0.028395706415176393\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2100 epoch, average loss: 16.811190795898437\n",
      "                , loss1: 860.495703125\n",
      "                , loss2: 0.03152649700641632\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2120 epoch, average loss: 16.80803985595703\n",
      "                , loss1: 860.14736328125\n",
      "                , loss2: 0.03516528010368347\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2140 epoch, average loss: 16.804905700683594\n",
      "                , loss1: 860.2748046875\n",
      "                , loss2: 0.02954428195953369\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2160 epoch, average loss: 16.803524780273438\n",
      "                , loss1: 860.05986328125\n",
      "                , loss2: 0.032358106970787046\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2180 epoch, average loss: 16.800839233398438\n",
      "                , loss1: 860.008984375\n",
      "                , loss2: 0.03066391348838806\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2200 epoch, average loss: 16.797401428222656\n",
      "                , loss1: 859.9263671875\n",
      "                , loss2: 0.028836551308631896\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2220 epoch, average loss: 16.796295166015625\n",
      "                , loss1: 860.01611328125\n",
      "                , loss2: 0.025980129837989807\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2240 epoch, average loss: 16.794764709472656\n",
      "                , loss1: 859.789453125\n",
      "                , loss2: 0.028868323564529418\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2260 epoch, average loss: 16.791836547851563\n",
      "                , loss1: 859.9126953125\n",
      "                , loss2: 0.02353910207748413\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2280 epoch, average loss: 16.79113006591797\n",
      "                , loss1: 859.66123046875\n",
      "                , loss2: 0.02773425281047821\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2300 epoch, average loss: 16.79004669189453\n",
      "                , loss1: 859.659765625\n",
      "                , loss2: 0.02668006718158722\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2320 epoch, average loss: 16.78887939453125\n",
      "                , loss1: 859.8474609375\n",
      "                , loss2: 0.02185613811016083\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2340 epoch, average loss: 16.788836669921874\n",
      "                , loss1: 859.45400390625\n",
      "                , loss2: 0.029483938217163087\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2360 epoch, average loss: 16.78515625\n",
      "                , loss1: 859.792578125\n",
      "                , loss2: 0.01919909715652466\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2380 epoch, average loss: 16.784829711914064\n",
      "                , loss1: 859.44765625\n",
      "                , loss2: 0.025602039694786072\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2400 epoch, average loss: 16.78540802001953\n",
      "                , loss1: 859.57158203125\n",
      "                , loss2: 0.023760025203227998\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2420 epoch, average loss: 16.782711791992188\n",
      "                , loss1: 859.496875\n",
      "                , loss2: 0.0225215807557106\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2440 epoch, average loss: 16.781781005859376\n",
      "                , loss1: 859.521875\n",
      "                , loss2: 0.021102021634578704\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2460 epoch, average loss: 16.781941223144532\n",
      "                , loss1: 859.56533203125\n",
      "                , loss2: 0.020416492223739625\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2480 epoch, average loss: 16.77913818359375\n",
      "                , loss1: 859.2140625\n",
      "                , loss2: 0.024466009438037874\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2500 epoch, average loss: 16.779325866699217\n",
      "                , loss1: 859.422265625\n",
      "                , loss2: 0.020594000816345215\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2520 epoch, average loss: 16.77771911621094\n",
      "                , loss1: 859.31826171875\n",
      "                , loss2: 0.021012821793556215\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2540 epoch, average loss: 16.777919006347656\n",
      "                , loss1: 859.3703125\n",
      "                , loss2: 0.020198000967502593\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2560 epoch, average loss: 16.776220703125\n",
      "                , loss1: 859.4083984375\n",
      "                , loss2: 0.01775800287723541\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2580 epoch, average loss: 16.772837829589843\n",
      "                , loss1: 859.14072265625\n",
      "                , loss2: 0.01959211826324463\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2600 epoch, average loss: 16.770835876464844\n",
      "                , loss1: 859.05537109375\n",
      "                , loss2: 0.01925380975008011\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2620 epoch, average loss: 16.768959045410156\n",
      "                , loss1: 859.08759765625\n",
      "                , loss2: 0.01675085872411728\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2640 epoch, average loss: 16.765667724609376\n",
      "                , loss1: 858.8791015625\n",
      "                , loss2: 0.017524434626102446\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2660 epoch, average loss: 16.760565185546874\n",
      "                , loss1: 858.654296875\n",
      "                , loss2: 0.016805896162986757\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2680 epoch, average loss: 16.75581512451172\n",
      "                , loss1: 858.3818359375\n",
      "                , loss2: 0.01736912876367569\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2700 epoch, average loss: 16.753494262695312\n",
      "                , loss1: 858.020703125\n",
      "                , loss2: 0.022089412808418273\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2720 epoch, average loss: 16.74681396484375\n",
      "                , loss1: 857.766015625\n",
      "                , loss2: 0.020375306904315948\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2740 epoch, average loss: 16.733921813964844\n",
      "                , loss1: 857.3685546875\n",
      "                , loss2: 0.015234616398811341\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2760 epoch, average loss: 16.72270050048828\n",
      "                , loss1: 856.4765625\n",
      "                , loss2: 0.02140931934118271\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2780 epoch, average loss: 16.70653839111328\n",
      "                , loss1: 855.7451171875\n",
      "                , loss2: 0.019508525729179382\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2800 epoch, average loss: 16.69432373046875\n",
      "                , loss1: 855.04541015625\n",
      "                , loss2: 0.02093701660633087\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2820 epoch, average loss: 16.6770751953125\n",
      "                , loss1: 854.0173828125\n",
      "                , loss2: 0.02373703718185425\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2840 epoch, average loss: 16.664273071289063\n",
      "                , loss1: 853.64267578125\n",
      "                , loss2: 0.01824123114347458\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2860 epoch, average loss: 16.654119873046874\n",
      "                , loss1: 853.1572265625\n",
      "                , loss2: 0.017553350329399107\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2880 epoch, average loss: 16.643492126464842\n",
      "                , loss1: 852.65419921875\n",
      "                , loss2: 0.016734860837459564\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2900 epoch, average loss: 16.638050842285157\n",
      "                , loss1: 852.30546875\n",
      "                , loss2: 0.01809324324131012\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2920 epoch, average loss: 16.63270263671875\n",
      "                , loss1: 852.1041015625\n",
      "                , loss2: 0.01667173355817795\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2940 epoch, average loss: 16.628318786621094\n",
      "                , loss1: 851.99345703125\n",
      "                , loss2: 0.014444735646247864\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2960 epoch, average loss: 16.62528839111328\n",
      "                , loss1: 851.7388671875\n",
      "                , loss2: 0.016380664706230164\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 2980 epoch, average loss: 16.623167419433592\n",
      "                , loss1: 851.816015625\n",
      "                , loss2: 0.01275297999382019\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3000 epoch, average loss: 16.620362854003908\n",
      "                , loss1: 851.59375\n",
      "                , loss2: 0.014284723997116089\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3020 epoch, average loss: 16.621176147460936\n",
      "                , loss1: 851.37216796875\n",
      "                , loss2: 0.01941726952791214\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3040 epoch, average loss: 16.618548583984374\n",
      "                , loss1: 851.7400390625\n",
      "                , loss2: 0.009618575870990752\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3060 epoch, average loss: 16.618072509765625\n",
      "                , loss1: 851.31005859375\n",
      "                , loss2: 0.01752782166004181\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3080 epoch, average loss: 16.61666259765625\n",
      "                , loss1: 851.48330078125\n",
      "                , loss2: 0.012738628685474396\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3100 epoch, average loss: 16.616627502441407\n",
      "                , loss1: 851.412109375\n",
      "                , loss2: 0.014093008637428284\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3120 epoch, average loss: 16.61523895263672\n",
      "                , loss1: 851.42333984375\n",
      "                , loss2: 0.012483954429626465\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3140 epoch, average loss: 16.61402587890625\n",
      "                , loss1: 851.1443359375\n",
      "                , loss2: 0.016708829998970033\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3160 epoch, average loss: 16.613911437988282\n",
      "                , loss1: 851.26787109375\n",
      "                , loss2: 0.0141888827085495\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3180 epoch, average loss: 16.61381378173828\n",
      "                , loss1: 851.246484375\n",
      "                , loss2: 0.014505289494991302\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3200 epoch, average loss: 16.613113403320312\n",
      "                , loss1: 851.33134765625\n",
      "                , loss2: 0.012150125205516815\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3220 epoch, average loss: 16.61280517578125\n",
      "                , loss1: 851.06396484375\n",
      "                , loss2: 0.017058072984218596\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3240 epoch, average loss: 16.61212921142578\n",
      "                , loss1: 851.2900390625\n",
      "                , loss2: 0.011971542984247208\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3260 epoch, average loss: 16.611248779296876\n",
      "                , loss1: 851.12763671875\n",
      "                , loss2: 0.014259530603885651\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3280 epoch, average loss: 16.611407470703124\n",
      "                , loss1: 851.20859375\n",
      "                , loss2: 0.012838084995746613\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3300 epoch, average loss: 16.611054992675783\n",
      "                , loss1: 851.09921875\n",
      "                , loss2: 0.014621582627296448\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3320 epoch, average loss: 16.61060791015625\n",
      "                , loss1: 851.077734375\n",
      "                , loss2: 0.01459105610847473\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3340 epoch, average loss: 16.610987854003906\n",
      "                , loss1: 851.0626953125\n",
      "                , loss2: 0.01526423841714859\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3360 epoch, average loss: 16.610328674316406\n",
      "                , loss1: 851.2015625\n",
      "                , loss2: 0.01189606711268425\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3380 epoch, average loss: 16.60986328125\n",
      "                , loss1: 851.16533203125\n",
      "                , loss2: 0.012138652801513671\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3400 epoch, average loss: 16.61034240722656\n",
      "                , loss1: 850.94892578125\n",
      "                , loss2: 0.016838088631629944\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3420 epoch, average loss: 16.609356689453126\n",
      "                , loss1: 851.10654296875\n",
      "                , loss2: 0.012780962884426117\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3440 epoch, average loss: 16.609495544433592\n",
      "                , loss1: 851.0423828125\n",
      "                , loss2: 0.014168480038642883\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3460 epoch, average loss: 16.609478759765626\n",
      "                , loss1: 851.0619140625\n",
      "                , loss2: 0.013770569860935212\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3480 epoch, average loss: 16.60909423828125\n",
      "                , loss1: 851.0765625\n",
      "                , loss2: 0.013104434311389922\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3500 epoch, average loss: 16.60889129638672\n",
      "                , loss1: 850.978125\n",
      "                , loss2: 0.014817768335342407\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3520 epoch, average loss: 16.608854675292967\n",
      "                , loss1: 851.04560546875\n",
      "                , loss2: 0.013465647399425507\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3540 epoch, average loss: 16.60851593017578\n",
      "                , loss1: 851.08046875\n",
      "                , loss2: 0.012445534765720367\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3560 epoch, average loss: 16.60865173339844\n",
      "                , loss1: 850.86865234375\n",
      "                , loss2: 0.016712909936904906\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3580 epoch, average loss: 16.608822631835938\n",
      "                , loss1: 851.11611328125\n",
      "                , loss2: 0.012059155106544494\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3600 epoch, average loss: 16.608296203613282\n",
      "                , loss1: 851.00478515625\n",
      "                , loss2: 0.01370311975479126\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3620 epoch, average loss: 16.60828399658203\n",
      "                , loss1: 851.0314453125\n",
      "                , loss2: 0.013172192871570588\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3640 epoch, average loss: 16.607598876953126\n",
      "                , loss1: 851.05029296875\n",
      "                , loss2: 0.012119514495134353\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3660 epoch, average loss: 16.607577514648437\n",
      "                , loss1: 850.91953125\n",
      "                , loss2: 0.014644607901573181\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3680 epoch, average loss: 16.607501220703124\n",
      "                , loss1: 850.96767578125\n",
      "                , loss2: 0.013632915914058685\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3700 epoch, average loss: 16.607130432128905\n",
      "                , loss1: 850.9572265625\n",
      "                , loss2: 0.013463647663593292\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3720 epoch, average loss: 16.607279968261718\n",
      "                , loss1: 850.9294921875\n",
      "                , loss2: 0.014155678451061249\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3740 epoch, average loss: 16.606993103027342\n",
      "                , loss1: 851.04931640625\n",
      "                , loss2: 0.011532856523990631\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3760 epoch, average loss: 16.606866455078126\n",
      "                , loss1: 850.86982421875\n",
      "                , loss2: 0.014902007579803467\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3780 epoch, average loss: 16.607101440429688\n",
      "                , loss1: 850.9228515625\n",
      "                , loss2: 0.014105549454689026\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3800 epoch, average loss: 16.60657958984375\n",
      "                , loss1: 850.961328125\n",
      "                , loss2: 0.01283404380083084\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3820 epoch, average loss: 16.606451416015624\n",
      "                , loss1: 850.9681640625\n",
      "                , loss2: 0.012574215233325959\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3840 epoch, average loss: 16.60663299560547\n",
      "                , loss1: 850.8609375\n",
      "                , loss2: 0.014842687547206879\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3860 epoch, average loss: 16.60635986328125\n",
      "                , loss1: 850.95859375\n",
      "                , loss2: 0.012667833268642426\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3880 epoch, average loss: 16.606248474121095\n",
      "                , loss1: 850.927734375\n",
      "                , loss2: 0.01315477341413498\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3900 epoch, average loss: 16.606275939941405\n",
      "                , loss1: 850.921875\n",
      "                , loss2: 0.01329585462808609\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3920 epoch, average loss: 16.605868530273437\n",
      "                , loss1: 850.87646484375\n",
      "                , loss2: 0.013775700330734253\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3940 epoch, average loss: 16.606350708007813\n",
      "                , loss1: 850.9373046875\n",
      "                , loss2: 0.013072222471237183\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3960 epoch, average loss: 16.60594787597656\n",
      "                , loss1: 850.902734375\n",
      "                , loss2: 0.013347657024860382\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 3980 epoch, average loss: 16.60584716796875\n",
      "                , loss1: 850.8564453125\n",
      "                , loss2: 0.014144736528396606\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4000 epoch, average loss: 16.605812072753906\n",
      "                , loss1: 850.861328125\n",
      "                , loss2: 0.014016380906105042\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4020 epoch, average loss: 16.605624389648437\n",
      "                , loss1: 850.9576171875\n",
      "                , loss2: 0.011949989199638366\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4040 epoch, average loss: 16.605744934082033\n",
      "                , loss1: 850.88193359375\n",
      "                , loss2: 0.01354687362909317\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4060 epoch, average loss: 16.605433654785156\n",
      "                , loss1: 850.8330078125\n",
      "                , loss2: 0.014190943539142608\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4080 epoch, average loss: 16.605345153808592\n",
      "                , loss1: 850.894921875\n",
      "                , loss2: 0.012893399596214295\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4100 epoch, average loss: 16.605184936523436\n",
      "                , loss1: 850.9232421875\n",
      "                , loss2: 0.01218273788690567\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4120 epoch, average loss: 16.60517578125\n",
      "                , loss1: 850.7037109375\n",
      "                , loss2: 0.016456562280654907\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4140 epoch, average loss: 16.605122375488282\n",
      "                , loss1: 850.99228515625\n",
      "                , loss2: 0.010772756487131118\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4160 epoch, average loss: 16.605311584472656\n",
      "                , loss1: 850.888671875\n",
      "                , loss2: 0.01298055499792099\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4180 epoch, average loss: 16.605465698242188\n",
      "                , loss1: 850.867578125\n",
      "                , loss2: 0.013548585772514343\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4200 epoch, average loss: 16.605105590820312\n",
      "                , loss1: 850.79990234375\n",
      "                , loss2: 0.014506298303604125\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4220 epoch, average loss: 16.604595947265626\n",
      "                , loss1: 850.83935546875\n",
      "                , loss2: 0.013230647146701812\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4240 epoch, average loss: 16.60472717285156\n",
      "                , loss1: 850.80615234375\n",
      "                , loss2: 0.014006191492080688\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4260 epoch, average loss: 16.604707336425783\n",
      "                , loss1: 850.85390625\n",
      "                , loss2: 0.013056543469429017\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4280 epoch, average loss: 16.604736328125\n",
      "                , loss1: 850.8767578125\n",
      "                , loss2: 0.012636983394622802\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4300 epoch, average loss: 16.604507446289062\n",
      "                , loss1: 850.7810546875\n",
      "                , loss2: 0.014277444779872894\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4320 epoch, average loss: 16.604815673828124\n",
      "                , loss1: 850.9306640625\n",
      "                , loss2: 0.011666356027126313\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4340 epoch, average loss: 16.604554748535158\n",
      "                , loss1: 850.80947265625\n",
      "                , loss2: 0.013770751655101776\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4360 epoch, average loss: 16.604399108886717\n",
      "                , loss1: 850.802734375\n",
      "                , loss2: 0.013746985793113708\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4380 epoch, average loss: 16.60469970703125\n",
      "                , loss1: 850.80595703125\n",
      "                , loss2: 0.013984963297843933\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4400 epoch, average loss: 16.604280090332033\n",
      "                , loss1: 850.8509765625\n",
      "                , loss2: 0.01268497109413147\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4420 epoch, average loss: 16.604267883300782\n",
      "                , loss1: 850.82626953125\n",
      "                , loss2: 0.013155214488506317\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4440 epoch, average loss: 16.604364013671876\n",
      "                , loss1: 850.9064453125\n",
      "                , loss2: 0.011684729903936385\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4460 epoch, average loss: 16.604376220703124\n",
      "                , loss1: 850.71962890625\n",
      "                , loss2: 0.015344163775444031\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4480 epoch, average loss: 16.6041748046875\n",
      "                , loss1: 850.79453125\n",
      "                , loss2: 0.013678330183029174\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4500 epoch, average loss: 16.605271911621095\n",
      "                , loss1: 850.70078125\n",
      "                , loss2: 0.016608305275440216\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4520 epoch, average loss: 16.604713439941406\n",
      "                , loss1: 851.067578125\n",
      "                , loss2: 0.008893649280071258\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4540 epoch, average loss: 16.604856872558592\n",
      "                , loss1: 850.912890625\n",
      "                , loss2: 0.012053963541984559\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4560 epoch, average loss: 16.604052734375\n",
      "                , loss1: 850.68603515625\n",
      "                , loss2: 0.015675732493400575\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4580 epoch, average loss: 16.604124450683592\n",
      "                , loss1: 850.90322265625\n",
      "                , loss2: 0.011511334776878357\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4600 epoch, average loss: 16.603799438476564\n",
      "                , loss1: 850.783984375\n",
      "                , loss2: 0.013511201739311219\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4620 epoch, average loss: 16.603993225097657\n",
      "                , loss1: 850.73740234375\n",
      "                , loss2: 0.014615042507648468\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4640 epoch, average loss: 16.603794860839844\n",
      "                , loss1: 850.85185546875\n",
      "                , loss2: 0.012180852144956589\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4660 epoch, average loss: 16.603651428222655\n",
      "                , loss1: 850.7412109375\n",
      "                , loss2: 0.014200103282928467\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4680 epoch, average loss: 16.604054260253907\n",
      "                , loss1: 850.86806640625\n",
      "                , loss2: 0.012127723544836044\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4700 epoch, average loss: 16.603961181640624\n",
      "                , loss1: 850.7384765625\n",
      "                , loss2: 0.014561447501182555\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4720 epoch, average loss: 16.60382537841797\n",
      "                , loss1: 850.86943359375\n",
      "                , loss2: 0.011872468143701553\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4740 epoch, average loss: 16.603701782226562\n",
      "                , loss1: 850.783203125\n",
      "                , loss2: 0.013427142798900605\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4760 epoch, average loss: 16.603468322753905\n",
      "                , loss1: 850.73984375\n",
      "                , loss2: 0.014039787650108337\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4780 epoch, average loss: 16.603553771972656\n",
      "                , loss1: 850.7970703125\n",
      "                , loss2: 0.013013426959514619\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4800 epoch, average loss: 16.603608703613283\n",
      "                , loss1: 850.765234375\n",
      "                , loss2: 0.013685941696166992\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4820 epoch, average loss: 16.60359344482422\n",
      "                , loss1: 850.8025390625\n",
      "                , loss2: 0.012942351400852203\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4840 epoch, average loss: 16.603945922851562\n",
      "                , loss1: 850.72314453125\n",
      "                , loss2: 0.014845547080039979\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4860 epoch, average loss: 16.603800964355468\n",
      "                , loss1: 850.887109375\n",
      "                , loss2: 0.011502614617347718\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4880 epoch, average loss: 16.603521728515624\n",
      "                , loss1: 850.7748046875\n",
      "                , loss2: 0.013409806787967682\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4900 epoch, average loss: 16.603622436523438\n",
      "                , loss1: 850.75966796875\n",
      "                , loss2: 0.013811035454273224\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4920 epoch, average loss: 16.603300476074217\n",
      "                , loss1: 850.7720703125\n",
      "                , loss2: 0.013241341710090638\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4940 epoch, average loss: 16.603901672363282\n",
      "                , loss1: 850.84140625\n",
      "                , loss2: 0.012493538856506347\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4960 epoch, average loss: 16.603916931152344\n",
      "                , loss1: 850.7279296875\n",
      "                , loss2: 0.014722883701324463\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 4980 epoch, average loss: 16.60364532470703\n",
      "                , loss1: 850.902734375\n",
      "                , loss2: 0.011039934307336807\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5000 epoch, average loss: 16.60340270996094\n",
      "                , loss1: 850.59873046875\n",
      "                , loss2: 0.016727374494075777\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5020 epoch, average loss: 16.603330993652342\n",
      "                , loss1: 850.923046875\n",
      "                , loss2: 0.010329440981149674\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5040 epoch, average loss: 16.603428649902344\n",
      "                , loss1: 850.7484375\n",
      "                , loss2: 0.01383485496044159\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5060 epoch, average loss: 16.602938842773437\n",
      "                , loss1: 850.8294921875\n",
      "                , loss2: 0.01176338866353035\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5080 epoch, average loss: 16.603416442871094\n",
      "                , loss1: 850.689453125\n",
      "                , loss2: 0.014970992505550385\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5100 epoch, average loss: 16.603526306152343\n",
      "                , loss1: 850.78203125\n",
      "                , loss2: 0.01327771097421646\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5120 epoch, average loss: 16.602886962890626\n",
      "                , loss1: 850.802734375\n",
      "                , loss2: 0.012230000644922256\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5140 epoch, average loss: 16.602963256835938\n",
      "                , loss1: 850.712109375\n",
      "                , loss2: 0.01407616287469864\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5160 epoch, average loss: 16.60327606201172\n",
      "                , loss1: 850.7671875\n",
      "                , loss2: 0.01331486701965332\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5180 epoch, average loss: 16.603408813476562\n",
      "                , loss1: 850.768359375\n",
      "                , loss2: 0.013424338400363922\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5200 epoch, average loss: 16.603164672851562\n",
      "                , loss1: 850.73994140625\n",
      "                , loss2: 0.013737235963344575\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5220 epoch, average loss: 16.603048706054686\n",
      "                , loss1: 850.883203125\n",
      "                , loss2: 0.010825462639331818\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5240 epoch, average loss: 16.603160095214843\n",
      "                , loss1: 850.66005859375\n",
      "                , loss2: 0.015289133787155152\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5260 epoch, average loss: 16.603103637695312\n",
      "                , loss1: 850.79365234375\n",
      "                , loss2: 0.012626279890537263\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5280 epoch, average loss: 16.602885437011718\n",
      "                , loss1: 850.7423828125\n",
      "                , loss2: 0.013409671187400819\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5300 epoch, average loss: 16.60286102294922\n",
      "                , loss1: 850.86875\n",
      "                , loss2: 0.010921885073184968\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5320 epoch, average loss: 16.603173828125\n",
      "                , loss1: 850.57529296875\n",
      "                , loss2: 0.01695565730333328\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5340 epoch, average loss: 16.603294372558594\n",
      "                , loss1: 850.85029296875\n",
      "                , loss2: 0.011714761704206466\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5360 epoch, average loss: 16.602813720703125\n",
      "                , loss1: 850.7119140625\n",
      "                , loss2: 0.013929413259029388\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5380 epoch, average loss: 16.602716064453126\n",
      "                , loss1: 850.800390625\n",
      "                , loss2: 0.012107938528060913\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5400 epoch, average loss: 16.603007507324218\n",
      "                , loss1: 850.694140625\n",
      "                , loss2: 0.014474047720432282\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5420 epoch, average loss: 16.60286102294922\n",
      "                , loss1: 850.83857421875\n",
      "                , loss2: 0.011507496982812882\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5440 epoch, average loss: 16.602694702148437\n",
      "                , loss1: 850.6771484375\n",
      "                , loss2: 0.014491786062717438\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5460 epoch, average loss: 16.60277557373047\n",
      "                , loss1: 850.805078125\n",
      "                , loss2: 0.01207655593752861\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5480 epoch, average loss: 16.60277099609375\n",
      "                , loss1: 850.687890625\n",
      "                , loss2: 0.01435369998216629\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5500 epoch, average loss: 16.602497863769532\n",
      "                , loss1: 850.7185546875\n",
      "                , loss2: 0.013490729033946991\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5520 epoch, average loss: 16.60277404785156\n",
      "                , loss1: 850.80283203125\n",
      "                , loss2: 0.012114819884300233\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5540 epoch, average loss: 16.602613830566405\n",
      "                , loss1: 850.628125\n",
      "                , loss2: 0.015366277098655701\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5560 epoch, average loss: 16.602960205078126\n",
      "                , loss1: 850.76220703125\n",
      "                , loss2: 0.013098056614398956\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5580 epoch, average loss: 16.603207397460938\n",
      "                , loss1: 850.8376953125\n",
      "                , loss2: 0.011871137470006943\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5600 epoch, average loss: 16.603265380859376\n",
      "                , loss1: 850.74140625\n",
      "                , loss2: 0.013809075951576233\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5620 epoch, average loss: 16.602777099609376\n",
      "                , loss1: 850.7478515625\n",
      "                , loss2: 0.01319609433412552\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5640 epoch, average loss: 16.60284881591797\n",
      "                , loss1: 850.80146484375\n",
      "                , loss2: 0.012220282107591629\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5660 epoch, average loss: 16.60283508300781\n",
      "                , loss1: 850.6677734375\n",
      "                , loss2: 0.014811386168003083\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5680 epoch, average loss: 16.602481079101562\n",
      "                , loss1: 850.803125\n",
      "                , loss2: 0.011820624023675919\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5700 epoch, average loss: 16.60253448486328\n",
      "                , loss1: 850.63681640625\n",
      "                , loss2: 0.01511543095111847\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5720 epoch, average loss: 16.602638244628906\n",
      "                , loss1: 850.8513671875\n",
      "                , loss2: 0.011033251136541366\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5740 epoch, average loss: 16.602438354492186\n",
      "                , loss1: 850.6734375\n",
      "                , loss2: 0.01430761069059372\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5760 epoch, average loss: 16.602587890625\n",
      "                , loss1: 850.76298828125\n",
      "                , loss2: 0.012707126140594483\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5780 epoch, average loss: 16.602244567871093\n",
      "                , loss1: 850.72177734375\n",
      "                , loss2: 0.013168609142303467\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5800 epoch, average loss: 16.602317810058594\n",
      "                , loss1: 850.7298828125\n",
      "                , loss2: 0.013085733354091644\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5820 epoch, average loss: 16.60260009765625\n",
      "                , loss1: 850.67939453125\n",
      "                , loss2: 0.014348119497299194\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5840 epoch, average loss: 16.602944946289064\n",
      "                , loss1: 850.7287109375\n",
      "                , loss2: 0.013733024895191192\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5860 epoch, average loss: 16.6025146484375\n",
      "                , loss1: 850.78125\n",
      "                , loss2: 0.012278196215629578\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5880 epoch, average loss: 16.60230407714844\n",
      "                , loss1: 850.7056640625\n",
      "                , loss2: 0.013545723259449005\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5900 epoch, average loss: 16.602310180664062\n",
      "                , loss1: 850.70390625\n",
      "                , loss2: 0.013580995798110961\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5920 epoch, average loss: 16.60265350341797\n",
      "                , loss1: 850.79013671875\n",
      "                , loss2: 0.012247518450021744\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5940 epoch, average loss: 16.602296447753908\n",
      "                , loss1: 850.6740234375\n",
      "                , loss2: 0.014153179526329041\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5960 epoch, average loss: 16.602301025390624\n",
      "                , loss1: 850.76201171875\n",
      "                , loss2: 0.01244022771716118\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 5980 epoch, average loss: 16.602496337890624\n",
      "                , loss1: 850.6837890625\n",
      "                , loss2: 0.014164315164089203\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6000 epoch, average loss: 16.603211975097658\n",
      "                , loss1: 850.7736328125\n",
      "                , loss2: 0.013125386834144593\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6020 epoch, average loss: 16.602239990234374\n",
      "                , loss1: 850.7390625\n",
      "                , loss2: 0.012826652824878692\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6040 epoch, average loss: 16.602449035644533\n",
      "                , loss1: 850.6953125\n",
      "                , loss2: 0.013887797296047211\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6060 epoch, average loss: 16.602439880371094\n",
      "                , loss1: 850.78642578125\n",
      "                , loss2: 0.01210465058684349\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6080 epoch, average loss: 16.60223846435547\n",
      "                , loss1: 850.721484375\n",
      "                , loss2: 0.013170567154884339\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6100 epoch, average loss: 16.602574157714844\n",
      "                , loss1: 850.6203125\n",
      "                , loss2: 0.015479275584220886\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6120 epoch, average loss: 16.602114868164062\n",
      "                , loss1: 850.8396484375\n",
      "                , loss2: 0.010741949081420898\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6140 epoch, average loss: 16.602088928222656\n",
      "                , loss1: 850.663671875\n",
      "                , loss2: 0.014147503674030304\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6160 epoch, average loss: 16.602200317382813\n",
      "                , loss1: 850.6564453125\n",
      "                , loss2: 0.014399157464504242\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6180 epoch, average loss: 16.602230834960938\n",
      "                , loss1: 850.821875\n",
      "                , loss2: 0.011206135898828507\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6200 epoch, average loss: 16.602114868164062\n",
      "                , loss1: 850.61357421875\n",
      "                , loss2: 0.015150479972362518\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6220 epoch, average loss: 16.60229949951172\n",
      "                , loss1: 850.7330078125\n",
      "                , loss2: 0.013007698953151703\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6240 epoch, average loss: 16.602388000488283\n",
      "                , loss1: 850.73984375\n",
      "                , loss2: 0.012960200011730195\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6260 epoch, average loss: 16.602418518066408\n",
      "                , loss1: 850.72646484375\n",
      "                , loss2: 0.013253031671047211\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6280 epoch, average loss: 16.60212097167969\n",
      "                , loss1: 850.70830078125\n",
      "                , loss2: 0.01331014484167099\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6300 epoch, average loss: 16.601992797851562\n",
      "                , loss1: 850.736328125\n",
      "                , loss2: 0.012635990977287292\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6320 epoch, average loss: 16.602389526367187\n",
      "                , loss1: 850.76806640625\n",
      "                , loss2: 0.012412852048873902\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6340 epoch, average loss: 16.602297973632812\n",
      "                , loss1: 850.6634765625\n",
      "                , loss2: 0.014360907673835754\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6360 epoch, average loss: 16.602239990234374\n",
      "                , loss1: 850.7310546875\n",
      "                , loss2: 0.012985625863075256\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6380 epoch, average loss: 16.602377319335936\n",
      "                , loss1: 850.68359375\n",
      "                , loss2: 0.014046058058738708\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6400 epoch, average loss: 16.602072143554686\n",
      "                , loss1: 850.75791015625\n",
      "                , loss2: 0.012291720509529114\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6420 epoch, average loss: 16.60274658203125\n",
      "                , loss1: 850.76357421875\n",
      "                , loss2: 0.012856215238571167\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6440 epoch, average loss: 16.60218505859375\n",
      "                , loss1: 850.6470703125\n",
      "                , loss2: 0.014566373825073243\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6460 epoch, average loss: 16.60198059082031\n",
      "                , loss1: 850.76796875\n",
      "                , loss2: 0.01200551986694336\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6480 epoch, average loss: 16.602166748046876\n",
      "                , loss1: 850.7150390625\n",
      "                , loss2: 0.013225223124027252\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6500 epoch, average loss: 16.601988220214842\n",
      "                , loss1: 850.71240234375\n",
      "                , loss2: 0.013095510005950928\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6520 epoch, average loss: 16.602005004882812\n",
      "                , loss1: 850.6740234375\n",
      "                , loss2: 0.013862651586532593\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6540 epoch, average loss: 16.60191650390625\n",
      "                , loss1: 850.7025390625\n",
      "                , loss2: 0.01321822851896286\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6560 epoch, average loss: 16.601976013183595\n",
      "                , loss1: 850.7205078125\n",
      "                , loss2: 0.012925581634044647\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6580 epoch, average loss: 16.601966857910156\n",
      "                , loss1: 850.7060546875\n",
      "                , loss2: 0.013201838731765747\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6600 epoch, average loss: 16.602178955078124\n",
      "                , loss1: 850.69404296875\n",
      "                , loss2: 0.01364341825246811\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6620 epoch, average loss: 16.60210418701172\n",
      "                , loss1: 850.69853515625\n",
      "                , loss2: 0.013480031490325927\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6640 epoch, average loss: 16.601887512207032\n",
      "                , loss1: 850.69990234375\n",
      "                , loss2: 0.013239702582359314\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6660 epoch, average loss: 16.60161895751953\n",
      "                , loss1: 850.66328125\n",
      "                , loss2: 0.013681453466415406\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6680 epoch, average loss: 16.601983642578126\n",
      "                , loss1: 850.662109375\n",
      "                , loss2: 0.01407100111246109\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6700 epoch, average loss: 16.602389526367187\n",
      "                , loss1: 850.80244140625\n",
      "                , loss2: 0.011740878969430924\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6720 epoch, average loss: 16.601910400390626\n",
      "                , loss1: 850.6470703125\n",
      "                , loss2: 0.014293812215328217\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6740 epoch, average loss: 16.60169677734375\n",
      "                , loss1: 850.76494140625\n",
      "                , loss2: 0.011782092601060867\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6760 epoch, average loss: 16.60227813720703\n",
      "                , loss1: 850.64169921875\n",
      "                , loss2: 0.014766031503677368\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6780 epoch, average loss: 16.602354431152342\n",
      "                , loss1: 850.687890625\n",
      "                , loss2: 0.013939188420772552\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6800 epoch, average loss: 16.602369689941405\n",
      "                , loss1: 850.7642578125\n",
      "                , loss2: 0.012463534623384476\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6820 epoch, average loss: 16.602018737792967\n",
      "                , loss1: 850.7375\n",
      "                , loss2: 0.012637735903263092\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6840 epoch, average loss: 16.602012634277344\n",
      "                , loss1: 850.713671875\n",
      "                , loss2: 0.013096557557582855\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6860 epoch, average loss: 16.60199737548828\n",
      "                , loss1: 850.678515625\n",
      "                , loss2: 0.013765402138233185\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6880 epoch, average loss: 16.60260467529297\n",
      "                , loss1: 850.85849609375\n",
      "                , loss2: 0.010863655805587768\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6900 epoch, average loss: 16.602145385742187\n",
      "                , loss1: 850.66181640625\n",
      "                , loss2: 0.014238078892230988\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6920 epoch, average loss: 16.60191955566406\n",
      "                , loss1: 850.6939453125\n",
      "                , loss2: 0.013386480510234833\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6940 epoch, average loss: 16.601803588867188\n",
      "                , loss1: 850.6810546875\n",
      "                , loss2: 0.013521705567836762\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6960 epoch, average loss: 16.601765441894532\n",
      "                , loss1: 850.6923828125\n",
      "                , loss2: 0.013263581693172455\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 6980 epoch, average loss: 16.60203399658203\n",
      "                , loss1: 850.70556640625\n",
      "                , loss2: 0.013277772068977355\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7000 epoch, average loss: 16.601683044433592\n",
      "                , loss1: 850.66728515625\n",
      "                , loss2: 0.013673326373100281\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7020 epoch, average loss: 16.601663208007814\n",
      "                , loss1: 850.714453125\n",
      "                , loss2: 0.012728303670883179\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7040 epoch, average loss: 16.602761840820314\n",
      "                , loss1: 850.7609375\n",
      "                , loss2: 0.012923337519168854\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7060 epoch, average loss: 16.601792907714845\n",
      "                , loss1: 850.62353515625\n",
      "                , loss2: 0.01463082730770111\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7080 epoch, average loss: 16.601986694335938\n",
      "                , loss1: 850.78408203125\n",
      "                , loss2: 0.011695636808872223\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7100 epoch, average loss: 16.602516174316406\n",
      "                , loss1: 850.76181640625\n",
      "                , loss2: 0.012657226622104644\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7120 epoch, average loss: 16.601591491699217\n",
      "                , loss1: 850.6091796875\n",
      "                , loss2: 0.014710889756679535\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7140 epoch, average loss: 16.601551818847657\n",
      "                , loss1: 850.7302734375\n",
      "                , loss2: 0.012311434745788575\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7160 epoch, average loss: 16.601710510253906\n",
      "                , loss1: 850.655078125\n",
      "                , loss2: 0.013935887813568115\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7180 epoch, average loss: 16.601612854003907\n",
      "                , loss1: 850.7009765625\n",
      "                , loss2: 0.012939722836017608\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7200 epoch, average loss: 16.60206298828125\n",
      "                , loss1: 850.72490234375\n",
      "                , loss2: 0.012926150858402253\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7220 epoch, average loss: 16.602244567871093\n",
      "                , loss1: 850.7025390625\n",
      "                , loss2: 0.013547590374946595\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7240 epoch, average loss: 16.6014404296875\n",
      "                , loss1: 850.64951171875\n",
      "                , loss2: 0.013775286078453065\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7260 epoch, average loss: 16.601478576660156\n",
      "                , loss1: 850.7146484375\n",
      "                , loss2: 0.012543193995952606\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7280 epoch, average loss: 16.601634216308593\n",
      "                , loss1: 850.64892578125\n",
      "                , loss2: 0.013980655372142792\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7300 epoch, average loss: 16.601603698730468\n",
      "                , loss1: 850.7181640625\n",
      "                , loss2: 0.012595857679843902\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7320 epoch, average loss: 16.60154571533203\n",
      "                , loss1: 850.6126953125\n",
      "                , loss2: 0.014598281681537628\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7340 epoch, average loss: 16.601719665527344\n",
      "                , loss1: 850.73359375\n",
      "                , loss2: 0.012418217211961746\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7360 epoch, average loss: 16.602040100097657\n",
      "                , loss1: 850.70986328125\n",
      "                , loss2: 0.01319655030965805\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7380 epoch, average loss: 16.601591491699217\n",
      "                , loss1: 850.66171875\n",
      "                , loss2: 0.01368730068206787\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7400 epoch, average loss: 16.601731872558595\n",
      "                , loss1: 850.67626953125\n",
      "                , loss2: 0.013544109463691712\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7420 epoch, average loss: 16.60186767578125\n",
      "                , loss1: 850.7240234375\n",
      "                , loss2: 0.012748096883296967\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7440 epoch, average loss: 16.601681518554688\n",
      "                , loss1: 850.6849609375\n",
      "                , loss2: 0.013328227400779723\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7460 epoch, average loss: 16.601507568359374\n",
      "                , loss1: 850.68330078125\n",
      "                , loss2: 0.013182024657726287\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7480 epoch, average loss: 16.601608276367188\n",
      "                , loss1: 850.66796875\n",
      "                , loss2: 0.013582152128219605\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7500 epoch, average loss: 16.601519775390624\n",
      "                , loss1: 850.6765625\n",
      "                , loss2: 0.01332966834306717\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7520 epoch, average loss: 16.601960754394533\n",
      "                , loss1: 850.7236328125\n",
      "                , loss2: 0.012850375473499298\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7540 epoch, average loss: 16.601634216308593\n",
      "                , loss1: 850.712109375\n",
      "                , loss2: 0.012746934592723847\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7560 epoch, average loss: 16.601603698730468\n",
      "                , loss1: 850.63662109375\n",
      "                , loss2: 0.0141897052526474\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7580 epoch, average loss: 16.601603698730468\n",
      "                , loss1: 850.6259765625\n",
      "                , loss2: 0.014396998286247253\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7600 epoch, average loss: 16.601609802246095\n",
      "                , loss1: 850.7552734375\n",
      "                , loss2: 0.011885210126638412\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7620 epoch, average loss: 16.601495361328126\n",
      "                , loss1: 850.695703125\n",
      "                , loss2: 0.012932366132736206\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7640 epoch, average loss: 16.602392578125\n",
      "                , loss1: 850.775390625\n",
      "                , loss2: 0.01226968839764595\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7660 epoch, average loss: 16.601593017578125\n",
      "                , loss1: 850.5798828125\n",
      "                , loss2: 0.01528940349817276\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7680 epoch, average loss: 16.601519775390624\n",
      "                , loss1: 850.7119140625\n",
      "                , loss2: 0.012638486921787262\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7700 epoch, average loss: 16.601542663574218\n",
      "                , loss1: 850.714453125\n",
      "                , loss2: 0.012607210874557495\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7720 epoch, average loss: 16.601664733886718\n",
      "                , loss1: 850.7029296875\n",
      "                , loss2: 0.012958407402038574\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7740 epoch, average loss: 16.601765441894532\n",
      "                , loss1: 850.6041015625\n",
      "                , loss2: 0.014984892308712005\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7760 epoch, average loss: 16.601710510253906\n",
      "                , loss1: 850.74140625\n",
      "                , loss2: 0.012251653522253037\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7780 epoch, average loss: 16.601725769042968\n",
      "                , loss1: 850.6869140625\n",
      "                , loss2: 0.013330805301666259\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7800 epoch, average loss: 16.601948547363282\n",
      "                , loss1: 850.644140625\n",
      "                , loss2: 0.014385838806629182\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7820 epoch, average loss: 16.601846313476564\n",
      "                , loss1: 850.8033203125\n",
      "                , loss2: 0.011181551218032836\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7840 epoch, average loss: 16.60185089111328\n",
      "                , loss1: 850.6908203125\n",
      "                , loss2: 0.013376253843307494\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7860 epoch, average loss: 16.601654052734375\n",
      "                , loss1: 850.63203125\n",
      "                , loss2: 0.014329002797603607\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7880 epoch, average loss: 16.601777648925783\n",
      "                , loss1: 850.73642578125\n",
      "                , loss2: 0.01241810992360115\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7900 epoch, average loss: 16.601487731933595\n",
      "                , loss1: 850.6935546875\n",
      "                , loss2: 0.012962573766708374\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7920 epoch, average loss: 16.601687622070312\n",
      "                , loss1: 850.67734375\n",
      "                , loss2: 0.0134796142578125\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7940 epoch, average loss: 16.601499938964842\n",
      "                , loss1: 850.6544921875\n",
      "                , loss2: 0.013737821578979492\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7960 epoch, average loss: 16.601467895507813\n",
      "                , loss1: 850.685546875\n",
      "                , loss2: 0.013098880648612976\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 7980 epoch, average loss: 16.60138854980469\n",
      "                , loss1: 850.678125\n",
      "                , loss2: 0.013164515793323516\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8000 epoch, average loss: 16.601840209960937\n",
      "                , loss1: 850.7677734375\n",
      "                , loss2: 0.011869913339614869\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8020 epoch, average loss: 16.60187530517578\n",
      "                , loss1: 850.71162109375\n",
      "                , loss2: 0.012996315956115723\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8040 epoch, average loss: 16.602386474609375\n",
      "                , loss1: 850.71044921875\n",
      "                , loss2: 0.013532789051532745\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8060 epoch, average loss: 16.601564025878908\n",
      "                , loss1: 850.63515625\n",
      "                , loss2: 0.014178770780563354\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8080 epoch, average loss: 16.601643371582032\n",
      "                , loss1: 850.65576171875\n",
      "                , loss2: 0.01385336071252823\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8100 epoch, average loss: 16.60196533203125\n",
      "                , loss1: 850.77138671875\n",
      "                , loss2: 0.011923785507678985\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8120 epoch, average loss: 16.6016357421875\n",
      "                , loss1: 850.748828125\n",
      "                , loss2: 0.012031739950180054\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8140 epoch, average loss: 16.601565551757812\n",
      "                , loss1: 850.67353515625\n",
      "                , loss2: 0.013429048657417297\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8160 epoch, average loss: 16.601646423339844\n",
      "                , loss1: 850.634375\n",
      "                , loss2: 0.014274673163890838\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8180 epoch, average loss: 16.601589965820313\n",
      "                , loss1: 850.73388671875\n",
      "                , loss2: 0.01227906420826912\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8200 epoch, average loss: 16.601695251464843\n",
      "                , loss1: 850.6689453125\n",
      "                , loss2: 0.013647446036338806\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8220 epoch, average loss: 16.60138854980469\n",
      "                , loss1: 850.661328125\n",
      "                , loss2: 0.013491809368133545\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8240 epoch, average loss: 16.60131072998047\n",
      "                , loss1: 850.6365234375\n",
      "                , loss2: 0.013897983729839325\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8260 epoch, average loss: 16.60111083984375\n",
      "                , loss1: 850.69033203125\n",
      "                , loss2: 0.012652069330215454\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8280 epoch, average loss: 16.60193786621094\n",
      "                , loss1: 850.70791015625\n",
      "                , loss2: 0.013131418824195861\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8300 epoch, average loss: 16.601617431640626\n",
      "                , loss1: 850.652734375\n",
      "                , loss2: 0.013885791599750518\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8320 epoch, average loss: 16.601641845703124\n",
      "                , loss1: 850.76298828125\n",
      "                , loss2: 0.011763061583042144\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8340 epoch, average loss: 16.601893615722656\n",
      "                , loss1: 850.70859375\n",
      "                , loss2: 0.01307450383901596\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8360 epoch, average loss: 16.601469421386717\n",
      "                , loss1: 850.6171875\n",
      "                , loss2: 0.014435875415802001\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8380 epoch, average loss: 16.601731872558595\n",
      "                , loss1: 850.7138671875\n",
      "                , loss2: 0.01281195729970932\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8400 epoch, average loss: 16.60125274658203\n",
      "                , loss1: 850.66923828125\n",
      "                , loss2: 0.013203239440917969\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8420 epoch, average loss: 16.601402282714844\n",
      "                , loss1: 850.680859375\n",
      "                , loss2: 0.013122755289077758\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8440 epoch, average loss: 16.601734924316407\n",
      "                , loss1: 850.7111328125\n",
      "                , loss2: 0.012870472669601441\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8460 epoch, average loss: 16.601405334472656\n",
      "                , loss1: 850.62900390625\n",
      "                , loss2: 0.014141128957271576\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8480 epoch, average loss: 16.601637268066405\n",
      "                , loss1: 850.66640625\n",
      "                , loss2: 0.013643711805343628\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8500 epoch, average loss: 16.601402282714844\n",
      "                , loss1: 850.6818359375\n",
      "                , loss2: 0.013105267286300659\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8520 epoch, average loss: 16.601473999023437\n",
      "                , loss1: 850.744921875\n",
      "                , loss2: 0.011950115859508514\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8540 epoch, average loss: 16.60182342529297\n",
      "                , loss1: 850.68955078125\n",
      "                , loss2: 0.013377243280410766\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8560 epoch, average loss: 16.601312255859376\n",
      "                , loss1: 850.6763671875\n",
      "                , loss2: 0.013123518228530884\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8580 epoch, average loss: 16.601460266113282\n",
      "                , loss1: 850.64951171875\n",
      "                , loss2: 0.013796132802963258\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8600 epoch, average loss: 16.60117950439453\n",
      "                , loss1: 850.7048828125\n",
      "                , loss2: 0.012433618307113647\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8620 epoch, average loss: 16.601278686523436\n",
      "                , loss1: 850.65693359375\n",
      "                , loss2: 0.013464343547821046\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8640 epoch, average loss: 16.601211547851562\n",
      "                , loss1: 850.6140625\n",
      "                , loss2: 0.014235603809356689\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8660 epoch, average loss: 16.60138854980469\n",
      "                , loss1: 850.65654296875\n",
      "                , loss2: 0.013585892319679261\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8680 epoch, average loss: 16.601734924316407\n",
      "                , loss1: 850.619921875\n",
      "                , loss2: 0.014644497632980346\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8700 epoch, average loss: 16.602085876464844\n",
      "                , loss1: 850.74599609375\n",
      "                , loss2: 0.012541314959526062\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8720 epoch, average loss: 16.601670837402345\n",
      "                , loss1: 850.773046875\n",
      "                , loss2: 0.011595104634761811\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8740 epoch, average loss: 16.601840209960937\n",
      "                , loss1: 850.6826171875\n",
      "                , loss2: 0.013529692590236665\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8760 epoch, average loss: 16.601103210449217\n",
      "                , loss1: 850.71162109375\n",
      "                , loss2: 0.012225858867168427\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8780 epoch, average loss: 16.602021789550783\n",
      "                , loss1: 850.7501953125\n",
      "                , loss2: 0.01239389106631279\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8800 epoch, average loss: 16.602244567871093\n",
      "                , loss1: 850.721875\n",
      "                , loss2: 0.01316908746957779\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8820 epoch, average loss: 16.601400756835936\n",
      "                , loss1: 850.6416015625\n",
      "                , loss2: 0.013887903094291687\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8840 epoch, average loss: 16.6016357421875\n",
      "                , loss1: 850.7177734375\n",
      "                , loss2: 0.012636737525463104\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8860 epoch, average loss: 16.601226806640625\n",
      "                , loss1: 850.57294921875\n",
      "                , loss2: 0.01505538672208786\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8880 epoch, average loss: 16.60150604248047\n",
      "                , loss1: 850.7642578125\n",
      "                , loss2: 0.011604273319244384\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8900 epoch, average loss: 16.60131378173828\n",
      "                , loss1: 850.66416015625\n",
      "                , loss2: 0.013359661400318145\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8920 epoch, average loss: 16.601014709472658\n",
      "                , loss1: 850.59716796875\n",
      "                , loss2: 0.014371217787265777\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8940 epoch, average loss: 16.601300048828126\n",
      "                , loss1: 850.7068359375\n",
      "                , loss2: 0.012515334784984589\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8960 epoch, average loss: 16.601300048828126\n",
      "                , loss1: 850.69501953125\n",
      "                , loss2: 0.012748201191425324\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 8980 epoch, average loss: 16.601803588867188\n",
      "                , loss1: 850.6767578125\n",
      "                , loss2: 0.013609942793846131\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9000 epoch, average loss: 16.601730346679688\n",
      "                , loss1: 850.6880859375\n",
      "                , loss2: 0.01331174373626709\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9020 epoch, average loss: 16.601516723632812\n",
      "                , loss1: 850.68046875\n",
      "                , loss2: 0.013247713446617126\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9040 epoch, average loss: 16.601251220703126\n",
      "                , loss1: 850.65556640625\n",
      "                , loss2: 0.0134649395942688\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9060 epoch, average loss: 16.6012451171875\n",
      "                , loss1: 850.7048828125\n",
      "                , loss2: 0.012497662007808686\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9080 epoch, average loss: 16.601469421386717\n",
      "                , loss1: 850.589453125\n",
      "                , loss2: 0.01497543454170227\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9100 epoch, average loss: 16.601605224609376\n",
      "                , loss1: 850.74072265625\n",
      "                , loss2: 0.012161241471767425\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9120 epoch, average loss: 16.602035522460938\n",
      "                , loss1: 850.803125\n",
      "                , loss2: 0.011372648924589158\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9140 epoch, average loss: 16.601551818847657\n",
      "                , loss1: 850.66083984375\n",
      "                , loss2: 0.013666145503520966\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9160 epoch, average loss: 16.601231384277344\n",
      "                , loss1: 850.6353515625\n",
      "                , loss2: 0.013844132423400879\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9180 epoch, average loss: 16.601280212402344\n",
      "                , loss1: 850.62890625\n",
      "                , loss2: 0.01401367038488388\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9200 epoch, average loss: 16.60136260986328\n",
      "                , loss1: 850.7025390625\n",
      "                , loss2: 0.012660199403762817\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9220 epoch, average loss: 16.60124816894531\n",
      "                , loss1: 850.7037109375\n",
      "                , loss2: 0.012524779140949249\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9240 epoch, average loss: 16.60111846923828\n",
      "                , loss1: 850.6099609375\n",
      "                , loss2: 0.014226096868515014\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9260 epoch, average loss: 16.601068115234376\n",
      "                , loss1: 850.6421875\n",
      "                , loss2: 0.01354748010635376\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9280 epoch, average loss: 16.6010498046875\n",
      "                , loss1: 850.6865234375\n",
      "                , loss2: 0.012660905718803406\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9300 epoch, average loss: 16.601686096191408\n",
      "                , loss1: 850.67646484375\n",
      "                , loss2: 0.013495801389217377\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9320 epoch, average loss: 16.601359558105468\n",
      "                , loss1: 850.6978515625\n",
      "                , loss2: 0.012749890983104705\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9340 epoch, average loss: 16.601289367675783\n",
      "                , loss1: 850.6671875\n",
      "                , loss2: 0.013279205560684204\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9360 epoch, average loss: 16.601329040527343\n",
      "                , loss1: 850.6552734375\n",
      "                , loss2: 0.013549591600894927\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9380 epoch, average loss: 16.601014709472658\n",
      "                , loss1: 850.6521484375\n",
      "                , loss2: 0.01330053061246872\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9400 epoch, average loss: 16.601420593261718\n",
      "                , loss1: 850.68134765625\n",
      "                , loss2: 0.0131360724568367\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9420 epoch, average loss: 16.601373291015626\n",
      "                , loss1: 850.68193359375\n",
      "                , loss2: 0.013075439631938935\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9440 epoch, average loss: 16.60113983154297\n",
      "                , loss1: 850.63134765625\n",
      "                , loss2: 0.013824960589408875\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9460 epoch, average loss: 16.60133514404297\n",
      "                , loss1: 850.64306640625\n",
      "                , loss2: 0.013798414170742035\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9480 epoch, average loss: 16.601454162597655\n",
      "                , loss1: 850.693359375\n",
      "                , loss2: 0.012935656309127807\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9500 epoch, average loss: 16.60137481689453\n",
      "                , loss1: 850.7072265625\n",
      "                , loss2: 0.012583909928798676\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9520 epoch, average loss: 16.601211547851562\n",
      "                , loss1: 850.67177734375\n",
      "                , loss2: 0.013112521171569825\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9540 epoch, average loss: 16.600953674316408\n",
      "                , loss1: 850.64853515625\n",
      "                , loss2: 0.013306477665901184\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9560 epoch, average loss: 16.601234436035156\n",
      "                , loss1: 850.66240234375\n",
      "                , loss2: 0.013317689299583435\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9580 epoch, average loss: 16.60143280029297\n",
      "                , loss1: 850.66103515625\n",
      "                , loss2: 0.013541561365127564\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9600 epoch, average loss: 16.601901245117187\n",
      "                , loss1: 850.77578125\n",
      "                , loss2: 0.011773192882537841\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9620 epoch, average loss: 16.601707458496094\n",
      "                , loss1: 850.6919921875\n",
      "                , loss2: 0.013214656710624694\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n",
      "in 9640 epoch, average loss: 16.601255798339842\n",
      "                , loss1: 850.62861328125\n",
      "                , loss2: 0.013997416198253631\n",
      "                , weight: 0.01950000000005797\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m limit:\n\u001b[1;32m      6\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m sub\n\u001b[0;32m----> 7\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     31\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), loss_1\u001b[38;5;241m.\u001b[39mitem(), loss_2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/partition/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/partition/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=lr, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(1,20000):\n",
    "    if hgnn_trainer.weight > limit:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - sub\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 20}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 20}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 20}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "    hgnn_trainer.train()\n",
    "    # if loss_1 < -8500 and loss_2 < 2 and cut() < 5072:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([109., 109., 109.], device='cuda:1', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
